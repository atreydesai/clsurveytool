{"id": "1eea6165-8eec-442c-9982-3c1b45f0fb6c", "title": "The Origin of Speech", "authors": ["Hockett,  Charles F."], "year": "1960", "journal": "Scientific American", "abstract": "", "doi": "10.1038/scientificamerican0960-88", "analysis_notes": "The Origin of Speech\nAuthor(s): Charles F. Hockett and Charles D. Hockett\nSource:\nScientific American , Vol. 203, No. 3 (September 1960), pp. 88-97\nPublished by: Scientific American, a division of Nature America, Inc.\nStable URL: https://www.jstor.org/stable/10.2307/24940617\nJSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide\nrange of content in a trusted digital archive. We use information technology and tools to increase productivity and\nfacilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.\nYour use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at\nhttps://about.jstor.org/terms\nScientific American, a division of Nature America, Inc. is collaborating with JSTOR to digitize,\npreserve and extend access to\nScientific American\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsTHREAT POSTURE of male stickleback is example of nonvocal\ncommunication in lower animals. In this picture, made by N. Tin·\nbergen of the University of Oxford, the fish is responding to it\"\nmirror image by indicating readiness to figllt \"intruding\" male,© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsThe Origin of Speech\nMan lS the only animal that can communicate by nleans of abstract\nsYlnbols. Yet this ability shares lnany features with conlmunication\nIn other animals, and has arisen fr01n these lnore prilniti(Je syste71IS\nXout 50 years ago the Linguistic\nSociety of Paris established a\nstanding rule barring from its\nsessions papers on the origin of language.\nThis action was a symptom of the times.\nSpeculation about the origin of language\nhad been common throughout the 19th\ncentury, but had reached no conclusive\nresults. The whole enterprise in conse\nquence had come to be frowned upon\nas futile or crackpot-in respectable\nlinguistic and philological circles. Yet\namidst the speculations there were two\nwell-reasoned empirical plans that de\nserve mention even though their results\nwere negative.\nA century ago there were still many\ncorners of the world that had not been\nvisited by European travelers. It was\nreasonable for the European scholar to\nsuspect that beyond the farthest fron\ntiers there might lurk half-men or man\napes who would be \"living fossils\"\nattesting to earlier stages of human\nevolution. The speech (or quasi-speech)\nof these men (or quasi-men) might\nthen similarly attest to earlier stages in\nthe evolution of language. The search\nwas vain. Nowhere in the world has\nthere been discovered a language that\ncan validly and meaningfully be called\n\"primitive.\" Edward Sapir wrote in\n1921: \"There is no more striking gen\neral fact about language than its uni\nversality. One may argue as to whether\na particular tribe engages in activities\nthat are worthy of the name of religion\nor of art, but we know of no people that\nis not possessed of a fully developed\nlanguage. The lowliest South African\nBushman speaks in the forms of a rich\nsymbolic system that is in essence per\nfectly comparable to the speech of the\ncultivated Frenchman.\"\nThe other empirical hope in the 19th\ncentury rested on the comparative meth-\nby Charlcs F. Hockett\nod of historical linguistics, the discovery\nof which was one of the triumphs of the\nperiod. Between two languages the re\nsemblances are sometimes so extensive\nand orderly that they cannot be attrib\nuted to chance or to parallel develop\nment. The alternative explanation is that\nthe two are divergent descendants of a\nsingle earlier language. English, Dutch,\nGerman and the Scandinavian languages\nare related in just this way. The com\nparative method makes it possible to ex\namine such a group of related languages\nand to construct, often in surprising de\ntail, a portrayal of the common ancestor,\nin this case the proto-Germanic lan\nguage. Direct documentary evidence of\nproto-Germanic does not exist, yet un\nderstanding of its workings exceeds that\nof many languages spoken today. .\nThere was at first some hope that the\ncomparative method might help deter\nmine the origin of language. This hope\nwas rational in a day when it was\nthought that language might be only a\nfew thousands or tens of thousands of\nyears old, and when it was repeatedly\nbeing demonstrated that languages that\nhad been thought to be unrelated were\nin fact related. By applying the com\nparative method to all the languages of\nthe world, some earliest reconstructable\nhorizon would be reached. This might\nnot date back so early as the origin of\nlanguage, but it might bear certain ear\nmarks of primitiveness, and thus it would\nenable investigators to extrapolate to\nward the origin. This hope also proved\nvain. The earliest reconstructable stage\nfor any language family shows all the\ncomplexities and ftexibilities of the lan\nguages of today.\nT hese points had become clear a half\ncentury ago, by the time of the Paris\nruling. Scholars cannot really approve of\nsuch a prohibition. But in this instance\nit had the useful result of channeling the\nenergies of investigators toward the\ngathering of more and better information\nabout languages as they are today. The\nsubsequent progress in understanding\nthe workings of language has been truly\nremarkable. Various related fields have\nalso made vast strides in the last half\ncentury: zoologists know more about the\nevolutionary process, anthropologists\nknow more about the nature of culture,\nand so on. In the light of these develop\nments there need be no apology for re\nopening the issue of the origins of hu\nman speech.\nAlthough the comparative method of\nlinguistics, as has been shown, throws no\nlight on the origin of language, the in\nvestigation may be furthered by a com\npat'ative method modeled on that of the\nzoologist. The frame of reference must\nbe such that all languages look alike\nwhen viewed through it, but such that\nwithin it human language as a whole can\nbe compared with the communicative\nsystems of other animals, especially the\nother hominoids, man's closest living\nrelatives, the gibbons and great apes.\nThe useful items for this sort of com\nparison cannot be things such as the\nword for \"sky\"; languages have such\nwords, but gibbon calls do not involve\nwords at all. Nor can they be even the\nsignal for \"danger,\" which gibbons do\nhave. Rather, they must be the basic\nfeatures of design that can be present\nor absent in any communicative system,\nwhether it be a communicative system\nof humans, of animals or of machines.\nWith this sort of comparative method\nit may be possible to reconstruct the\ncommunicative habits of the remote an\ncestors of the hominoid line, which may\nbe called the protohominoids. The task,\nthen, is to work out the sequence by\n89© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsA set of 13 design-features is presented in the illustration on the op\nposite page. There is solid empirical jus\ntification for the belief that all the lan\nguages of the world share every one of\nthem. At first sight some appear so trivial\nthat no one looking just at language\nwould bother to note them. They become\nworthy of mention only when it is real\nized that certain animal systems-and\ncertain human systems other than lan\nguage-lack them.\nThe first design-feature-the \"vocal\nauditory channel\"-is perhaps the most\nobvious. There are systems of communi\ncation that use other channels; for exam\nple, gesture, the dancing of bees or the\ncourtship ritual of the stickleback. The\nvocal-auditory channel has the advan\ntage-at least for primates;-that it leaves\nmuch of the body free for other activities\nthat can be carried on at the same time.\nThe next two design-features-\"rapid\nfading\" and \"broadcast transmission and\ndirectional reception,\" stemming from\nthe physics of sound-are almost un\navoidable consequences of the first. A\nlinguistic signal can be heard by any\nauditory system within earshot, and the\nsource can normally be localized by bin\naural direction-finding. The rapid fad\ning of such a signal means that it does\nnot linger for reception at the hearer's\nconvenience. Animal tracks and spoors,\non the other hand, persist for a while; so\nof course do written records, a product\nof man's extremely recent cultural ev\nlution.\nThe significance of \"interchangeabil\nity\" and \"total feedback\" for language\nbecomes clear upon comparison with\nother systems. In general a speaker of a\nlanguage can reproduce any linguistic\nmessag� he can understand, whereas the\ncharacteristic courtship motipns of the\nmale and female stickleback are differ\nent, and neither can act out those ap\npropriate to the other. For that matter\nin the communication of a human moth\ner and infant neither is apt to transmit\nthe characteristic signals or to manifest\nthe typical responses of the other. Again,\nthe speaker of a language hears, by total\nfeedback, everything of linguistic rele\nvance in what he himself says. In con\ntrast, the male stickleback does not see\nthe colors of his own eye and belly that\nare crucial in stimulating the fe\nmale. Feedback is important, since it\nmakes possible the so-called internali\nzation of Communicative behavior that\n90\ntion,\" refers to the fact that the bodily\neffort and spreading sound waves of\nspeech serve no function except as sig\nnals. A dog, panting with his tongue\nhanging out, is performing a biologically\nessential activity, since this is how dogs\ncool themselves off and maintain the\nproper body temperature. The panting\ndog incidentally produces sound, and\nthereby may inform other dogs (or Im\nmans) as to where he is and how he\nfeels. But this transmission of informa\ntion is strictly a side effect. Nor does the\ndog's panting exhibit the design-feature\nof \"semanticity.\" It is not a signal mean\ning that the dog is hot; it is part of being\nhot. In language, however, a message\ntriggers the particular result it does be\ncause there are relatively fixed associa\ntions between elements in messages\n(e.g., words) and recurrent features or\nsituations of the world around us. For\nexample, the English word \"salt\" means\nsalt, not sugar or pepper. The calls of\ngibbons also possess semanticity. The\ngibbon has a danger call, for example,\nand it does not in principle matter that\nthe meaning of the call is a great deal\nbroader and more vague than, say, the\ncry of \"Fire!\"\nIn a semantic communicative system\nthe ties between meaningful message\nelements and their meanings can be ar\nbitrary or nonarbitrary. In language the\nties are arbitrary. The word \"salt\" is not\nsalty nor granular; \"dog\" is not \"canine\";\n\"whale\" is a small word for a large ob\nject; \"microorganism\" is the reverse. A\npicture, on the other hand, looks like\nwhat it is a picture of. A bee dances\nfaster if the source of nectar she is re\nporting is closer, and slower if it is far\nther away. The design-feature of \"arbi\ntrariness\" has the disadvantage of being\narbitrary, but the great advantage that\nthere is no limit to what can be com\nmunicated about.\nHuman vocal organs can produce a\nhuge variety of sound. But in any one\nlanguage only a relatively small set of\nranges of sound is used, and the differ\nences between these ranges are function\nally absolute. The English words \"pin\"\nand \"bin\" are different to the ear only at\none point. If a speaker produces a syl\nlable that deviates from the normal pro\nnunciation of \"pin\" in the direction of\nthat of \"bin,\" he is not producing still a\nthird word, but just saying \"pin\" (@r\nperhaps \"bin\") in a noisy way. The\nhearer compensates if he can, on the\nbasis of context, or else fails to under-\neffects by way of vocal gesture. There is\nan effectively continuous scale of de\ngrees to which one may raise his voice\nas in anger, or lower it to signal confi\ndentiality. Bee-dancing also is continu\nous rather than discrete. ,\nMan is apparently almost unique in\nbeing able to talk about things that are\nremote in space or time (or both) from\nwhere the talking goes on. This feature\n\"displacement\" -seems to be definitely\nlacking in the vocal signaling of man's\nclosest relatives, though it does occur in\nbee-dancing.\nOne of the most important design\nfeatures of language is \"productivity\";\nthat is, the capacity to say things that\nhave never been said or heard before\nand yet to be understood by other speak\ners of the language. If a gibbon makes\nany vocal sound at all, it is one or an\nother of a small finite repertory of fa\nmiliar calls. The gibbon call system can\nbe characterized as closed. Language is\nopen, or \"productive,\" in the sense that\none can coin new utterances by putting\ntogether pieces familiar from old utter\nances, assembling them by patterns of\narrangement also familiar in old utter\nances.\nHuman genes carry the capacity to\nacquire a language, and probably also\na strong drive toward such acquisition,\nbut the detailed conventions of any one\nlanguage are transmitted extragenetical\nly by learning and teaching. To what\nextent such \"traditional transmission\"\nplays a part in gibbon calls or for other\nmammalian systems of vocal Signals is\nnot known, though in some instances the\nuniformity of the sounds made by a spe\ncies, wherever the species is found over\nthe world, is so great that genetics must\nbe responsible.\nThe meaningful elements in any lan\nguage-\"words\" in everyday parlance,\n\"morphemes\" to the linguist-constitute\nan enormous stock. Yet they are repre\nsented by small arrangements of a rela\ntively very small stock of distinguishable\nsounds which are in themselves wholly\nmeaningless. This \"duality of pattern\ning\" is illustrated by the English words\nTHIRTEEN DESIGN·FEATURES of ani.\nmal communication, discussed in detail in\nthe text of this article, are symbolized on\nopposite page. The patterns of the words\n\"pin,\" \"bin,\" \"teanl\" and \"nleal\" were\nrecorded at Bell Telephone Laboratories.© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/terms4 INTE RCHANGE A BILI TY\n7 SEMANTICITY\n'')///./�\n, J\nl\n/\"\n\",\n5\n\"1\n� PASS THE SAL T\n'-\n10 DISPLACEMENT\nI �1\nu.j\\!iI,J ..,\n,\"\nSHADES OF JULIUS CAESAR\nk)', TO TAL FEEDBACK\n8 A RBI TRA RINESS\nWHALE\nMICROORGANISMS\nSHE HAS GREEN HAIR\n6 SPECIALIZATION\n9\nD\nISCRE TEN�SS\n-- �1'\\\\ �MWN�I,¥/lAAhMlM WII�\nPIN\n12 TRADITIONAL TRANSMISSION\n13 DUAUT. OF � �\n�\n.\nT . . . . ,., ............ E A. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . , ..........................M\n9 1© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsNORWEGIAN\nSWEDISH\nNORTH\nGERMAN\nDIALECTS\nPROTO-GERMANIC\nPROTO- INDO-EUROPEAN\nDIALECTS\nORIGIN OF MODERN GERMANIC LANGUAGES, as indicated by this \"family tree,\"\nwas proto-Germanic, spoken some 2,700 years ago. Comparison of present·day languages\nhas provided detailed knowledge of proto·Germanic, although no direct documentary evi·\ndence for the language exists. It grew, in turn, from the proto·lndo-European of 5000 B.C.\nHistorical studies cannot, however, trace origins of language hack much further in time.\n92\nsounds in different permutations. Few\nanimal communicative systems share this\ndesign-feature of language-none among\nthe other hominoids, and perhaps none\nat all.\nI t should be noted that some of these\n13 design-features are not independ\nent. In particular, a system cannot be\neither arbitrary or nonarbitrary unless it\nis semantic, and it cannot have duality\nof patterning unless it is semantic. It\nshould also be noted that the listing does\nnot attempt to include all the features\nthat might be discovered in the commu\nnicative behavior of this or that species,\nbut only those that are clearly important\nfor language.\nIt is probably safe to assume that nine\nof the 13 features were already present\nin the vocal-auditory communication of\nthe protohominoids-just the nine that\nare securely attested for the gibbons and\nhumans of today. That is, there were a\ndozen or so distinct calls, each the ap\npropriate vocal response (or vocal part\nof the whole response) to a recurrent\nand biologically important type of situ\nation: the discovery of food, the detec\ntion of a predator, sexual interest, need\nfor maternal care, and so on. The prob\nlem of the origin of human speech, then,\nis that of trying to determine how such a\nsystem could have developed the four\nadditional properties of displacement,\nproductivity and full-blown traditional\ntransmission. Of course the full story in\nvolves a great deal more than communi\ncative behavior alone. The development\nmust be visualized as occurring in the\ncontext of the evolution of the primate\nhorde into the primitive society of food\ngatherers and huntel s, an integral part,\nbut a part, of the total evolution of be\nhavior.\nIt is possible to imagine a closed sys\ntem developing some degree of produc\ntivity, even in the absence of the other\nthree features. Human speech exhibits a\nphenomenon that could have this effect,\nthe phenomenon of \"blending.\" Some\ntimes a speaker will hesitate between\ntwo words or phrases, both reasonably\nappropriate for the situation in which he\nis speaking, and actually say something\nthat is neither wholly one nor wholly the\nother, but a combination of parts of\neach. Hesitating between \"Don't shout\nso loud\" and \"Don't yell so loud,\" he\nmight come out with \"Don't shell so\nloud.\" Blending is almost always in\nvolved in slips of the tongue, but it may© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/terms-------_ .._.. __.\nREPTILES\n� � r�\nVERTEBRATES\nCHORDATES\nr\nP R ODUCTI VITY\nDUALITY OF PATT ERNING\nDISCR E TE NESS\nTRADITI ONAL TRANSMI SSION\nSPEC I ALIZATION\nSEMANTICITY\nA R B I T R ARINESS\nBROAD C AST T R ANSMISSI ON\nAND DIRECTI ONAL RE C EPTI ON\nINTE RCHA NGEABILI T Y\nRAPI D F A DING TOTAL FEEDBACK\nVOCAL - AUD I TO R Y CHANNel\nTOOL-MAKING AND CARRYING\nLARYNX AND SOFT PALATE SEPARATED\nHUMOR VOWEL COLOR MUSIC\nBIPEDAL LOCOMOTION, NOT UPRIGHT\nOCCASIONAl.TOOL USING\nHANDS HAND-EYE COORDINATION\nBINOCULAR VISION\nMOBILE FACIAL MUSCLES\nOMNIVOROUS?\nSOCIAL BEHAVIOR \"PLAY\"\"\nWARM BLOODEDNESS\nLAND EGG\nBREATHING WITH THORACIC MUSCLES\nLEGS\nSLEEPING VERSUS WAKING\nEXTERNAL EAR\nVISION\nHEARING (INTERNAL EAR)\nMOTILITY BILATERAL SYMMETRY\nFRONT AND REAR ENDS\nEVOLUTION OF LANGUAGE and some related characteristics\nare suggested by this classification of chordates. The lowest form\nof animal in each classification exhibits the features listed at the\nright of the class. Brackets indicate that each group possesses or has\nevolved beyond the characteristics exhibited by all the groups\nbelow. The 13 design-features of language appear in the colored\nrectangle. Some but by no means all of the characteristics asso\nciated with communication are presented in the column at right_\n93© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsthat he has not said before. Anything a\nspeaker says must be either an exact\nrepetition of an utterance he has heard\nbefore, or else some blended product of\ntwo or more such familiar utterances.\nThus even such a smooth and normal\nsentence as \"I tried to get there, but the\ncar broke down\" might be produced as\na blend, say, of \"I tried to get there but\ncouldn't\" and \"While 1 was driving down\nMain Street the car broke down.\"\nChildren acquiring the language of\ntheir community pass through a stage\nthat is closed in just the way gibbon calls\n1 THE VOCAL·AUDITORY CHANNEl\n2 BROADCAST TRANSMISSION\nAND DIRECTIONAL RECEPTION\n3 RAPID FADING (TRANSITORINESS)\n4 INTERCHANGEABILITY\n0 TOTAL FEEDBACK\n6 SPECIALIZATION\n7 SEMANTICITY\n8 ARBITRARINESS\n9 DISCRETENESS\n10 DISPLACEMENT\n11 PRODUCTIVITY\n12 TRADITIONAL TRANSMISSION\n13 DUALITY OF PATTERNING\nin adult terms, has an internal structure,\nand yet for the child each may be an\nindivisible whole. He may also learn\nnew whole utterances from surrounding\nadults. The child takes the crucial step,\nhowever, when he first' says something\nthat he has not learned from others. The\nonly way in which the child can possibly\ndo this is by blending two of the whole\nutterances that he already knows.\nI n the case of the closed call-system\nof the gibbons or the protohominoids,\nthere is no source for the addition of new\nA\nSOME GRYLLIDAE\nAND TETTIGONIIDAE\nAUDITORY,\nNOT VOCAL\nYES\nYES, REPEATED\nLIMITED\nYES\nYES ?\n?\nYES?\n? ( T RIVIAL)\nB\nBEE DANCING\nYES, ALWAYS\nYES\nPROBABLY NOT\nand cries of other species. Even this\nwould not render the system productive,\nbut would merely enlarge it. But blend\ning might occur. Let AB represent the\nfood call and CD the danger call, each\na fairly complex phonetic pattern. Sup\npose a protohominoid encountered food\nand caught sight of a predator at the\nsame time. If the two stimuli were bal\nanced just right, he might emit the calls\nABCD or CDAB in quick sequence, or\nmight even produce AD or CB. Any of\nthese would be a blend. AD, for example,\nwould mean \"both food and danger.\" By\nc\nSTICKLEBACK\nCOURTSHIP\nD\nWESTERN\nMEADOWLARK\nSONG\nYES\nYES\nYES\n?\nYES\nYES?\nIN PART?\nIF SEMANTIC, YES\n?\n?\n?\n?\n?\nEIGHT SYSTEMS OF COMMUNICATION possess in varying de·\ngrees the 13 design.features of language. Column A refers to\nmembers of the cricket family. Column H concerns only Western\nmusic since the time of Bach. A question mark means that it is\n94© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsout danger\" and \"danger without food.\"\nAnd all three of these calls-AB, CD and\nAD-would now be composite rather\nthan unitary, built out of smaller ele\nments with their own individual mean\ning�,\n: A ,;:ould m��n \"food\" ;,\nB, \"no �an\nger ; C, no food ; and D, danger.\nBut this is only part of the story. The\ngeneration of a blend can have no effect\nunless it is understood. Human beings\nare so good at understanding blends that\nit is hard to tell a blend from a rote repe\ntition, except in the case of slips of the\ntongue and some of the earliest and most\nE\nGIBBON CALLS\nF\nPARALINGUISTIC\nPHENOMENA\nYES\nYES\nYES\nLARGElY YES\nYES\nYES?\nYES?\nIN PART\nLARGElY NO\nIN PART\nascribed to man's prehuman ancestors. It\nmust be supposed, therefore, that occa\nsional blends occurred over many tens\nof thousands of years (perhaps, indeed,\nthey still may occur from time to time\namong gibbons or the great apes) , with\nrarely any appropriate communicative\nimpact on hearers, before the under\nstanding of blends became speedy\nenough to reinforce their production.\nHowever, once that did happen, the\nearlier closed system had become open\nand productive.\nIt is also possible to see how faint\nG\nLANGUAGE\nYES\nYES\nYES\nYES\nYES\nYES\nYES\nYES\nYES\nYES, OFTEN\nYES\nYES\nYES\nH\nINSTRUMENTAL\nMUSIC\nAUD I TORY,\nNOT VOCAL\nYES\nYES\n?\nYES\nYES\nNO ( IN GENERAL)\nIN PART\nYES\nYES\ndoubtful or not known if the system has the particular feature. A blank space indicates\nthat feature cannot be determined because another feature is lacking or is indefinite.\nductivity, duality and thoroughgoing\ntraditional transmission. Suppose an\nearly hominid, a man-ape say, caught\nsight of a predator without himself be\ning seen. Suppose that for whatever rea\nson-perhaps through fear-he sneaked\nsilently back toward others of his band\nand only a bit later gave forth the dan\nger call. This might give the whole band\na better chance to escape the predator,\nthus bestowing at least slight survival\nvalue on whatever factor was responsi\nble for the delay.\nSomething akin to communicative dis\nplacement is involved in lugging a stick\nor a stone around-it is like talking today\nabout what one should do tomorrow. Of\ncourse it is not to be supposed that the\nfirst tool-carrying was purposeful, any\nmore than that the Rrst displaced com\nmunication was a discussion of plans.\nCaught in a cul-de-sac by a predator,\nhowever, the early hominid might strike\nout in terror with his stick or stone and\nby chance disable or drive off his enemy.\nIn other words, the Rrst tool-carrying\nhad a consequence but not a purpose.\nBecause the outcome was fortunate, it\ntended to reinforce whatever factor,\ngenetic or traditional, prompted the be\nhavior and made the outcome possible.\nIn the end such events do lead to pur\nposive behavior.\nAlthough elements of displacement\nmight arise in this fashion, on the whole\nit seems likely that some degree of pro\nductivity preceded any great prolifera\ntion of communicative displacement as\nwell as any signiRcant capacity for tra\nditional transmission. A productive sys\ntem requires the young to catch on to\nthe ways in which whole signals are\nbuilt out of smaller meaningful elements,\nsome of which may never occur as whole\nsignals in isolation. The young can do\nthis only in the way that human children\nlearn their language: by learning some\nutterances as whole units, in due time\ntesting various blends based on that\nrepertory, and Rnally adjusting their pat\nterns of blending until the bulk of what\nthey say matches what adults would say\nand is therefore understood. Part of this\n!,earning process is bound to take place\naway from the precise situations for\nwhich the responses are baSically appro\npriate, and this means the promotion of\ndisplacement. Learning and teaching,\nmoreover, call on any capacity for tradi\ntional transmission that the band may\nhave. Insofar as the communicative sys\ntem itself has survival value, all this be\nstows survival value also on the capacity\n95© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termstem. A child can be taught how to avoid\ncertain dangers before he actually en\ncounters them.\nl' hese developments are also necessarily related to the appearance of\nlarge and convoluted brains, which are\nbetter storage units for the conventions\nof a complex communicative system and\nfor other traditionally transmitted skills\nand practices. Hence the adaptative\nvalue of the behavior serves to select\ngenetically for the change in structure.\nA lengthened period of childhood help\nlessness is also a longer period of plastic\nity for learning. There is therefore selec\ntion for prolonged childhood and, with\nit, later maturity and longer life. With\nmore for the young to learn, and with\nmale as well as female tasks to be taught,\nfathers become more domesticated. The\nincrease of displacement promotes reat the moment hunger for her.\nThere is excellent reason to believe\nthat duality of patterning was the last\nproperty to be developed, because one\ncan find little if any reason why a com\nmunicative system should have this\nproperty unless it is highly complicated.\nIf a vocal-auditory system comes to have\na larger and larger number of distinct\nmeaningful elements, those elements in\nevitably come to be more and more sim\nilar to one another in sound. There is a\npractical limit, for any species or any\nmachine, to the number of distinct stim\nuli that can be discriminated, especially\nwhen the discriminations typically have\nto be made in noisy conditions. Suppose\nthat Samuel F. B. Morse, in devising his\ntelegraph code, had proposed a signal\n.1 second long for \"A,\" .2 second long\nfor \"B,\" and so on up to 2.6 seconds for\n\"Z.\" Operators would have enormous\nSUBHUMAN PRIMATE CALLS are represented here hy sound spectrograms of the roar\n(top) and bark (bottom) of the howler monkey. Frequencies are shown vertically; time,\nhorizontally. Roaring, the most prominent howler vocalization, regnlates interactions and\nmovements of gronps of monkeys, and has both defensive and offensive fnnctions. Barking\nhas similar meanings hnt occnrs when the monkeys are not quite so excited. Spectrograms\nwere produced at Bell Telephone Laboratories from recordings made by Charles Southwick\nof the University of Southern Ohio during an expedition to Barro Colorado Island in the\nCanal Zone. The expedition was directed by C. R. Carpenter of Pennsylvania State University.\n96\npatterning. The telegraph operator has\nto learn to discriminate, in the first in\nstance, only two lengths of pulse and\nabout three lengths of pause. Each letter\nis' coded into a different arrangement of\nthese elementary meaningless units. Th�\narrangements are easily kept apart be\ncause the few meaningless units are\nplainly distinguishable.\nThe analogy explains why it was ad\nvantageous for the forerunner of lan\nguage, as it was becoming increasingly\ncomplex, to acquire duality of pattern\ning. However it occurred, this was a\nmajor breakthrough; without it language\ncould not possibly have achieved the\nefficiency and flexibility it has.\nOne of the basic principles of evolu\ntionary theory holds that the initial sur\nvival value of any innovation is con\nservative in that it makes possible the\nmaintenance of a largely traditional way\nof life in the face of changed circum\nstances. There was nothing in the make\nup of the protohominoids that destined\ntheir descendants to become human.\nSome of them, indeed, did not. They\nmade their way to ecological niches\nwhere food was plentiful and predators\nsufficiently avoidable, and where the de\nvelopment of primitive varieties of lan\nguage and culture would have bestowed\nno advantage. They survive still, with\nvarious sorts of specialization, as the\ngibbons and the great apes.\nMan's own remote ancestors, then,\nmust have come to live in circum\nstances where a slightly more flexible\nsystem of communication, the incipient\ncarrying and shaping of tools, and a\nslight increase in the capacity for tradi\ntional transmission made jqst the differ\nence between surviving-largely, be it\nnoted, by the good old protohominoid\nway of life-and dying out. There are\nvarious possibilities. If predators become\nmore numerous and dangerous, any\nnonce use of a tool as a weapon, any\nco-operative mode of escape or attack\nmight restore the balance. If food be\ncame scarcer, any technique for crack\ning harder nuts, for foraging over a\nwider territory, for sharing food so gath\nered or storing it when it was plentiful\nmight promote survival of the band.\nOnly after a very long period of such\nsmall adjustments to tiny changes of liv\ning conditions could the factors involved\n-incipient language, incipient tool-car\nrying and toolmaking, incipient culture\nhave started leading the way to a new\npattern of life, of the kind called human.© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/termsA human talent\nThe June issue of this magazine contained an article full of learned speculation\non the neurological mechanism by which lines, straight and curved, are perceived.\nWhatever the mechanism, the nervous system is very good at seeing a line from\nexceedingly faint physical stimuli. We had been thinking about ways this talent\ncould help solve the nasty signal-to-noise problem that keeps cropping up on such\noccasions as when defense from submarine attack is considered. Today's almost\ninstantly available photography makes a fine bridge from an electronic system to a\nhuman nervous system. For example:\n1. Instead of an ordinary A-scope trace like � let's modulate intensity and sweep over mavthis... ing film with much overlap...\n2. so that even when the significant pulse � photographic summing-up finds it rather easily;\nstands out from the noise no more than this...\n3. and even when the A-scope shows only � the weak but non-random blip holds position\nthis... and builds up from all the sweeps to where\nthe marvelous combination of photography\nand the human perceptive mechanism says,\n\"There!\"\nOrganizations active in military developmenls who wish to know more about this work\nshould communicate with Eastman Kodak Company, Apparatus and Optical Division,\nRochester 4, N. Y.\nCreamed butyrate\nIn this nation of do-it-yourselfers and\nof housewives capable of taking the\nbit in their own teeth when occasion\ndemands, do you think there would be\na market for a cream that can be spread\nover bare wood with cheesecloth to\ndeposit in seconds a surface chemically\nand physically identical to a coat of\nhighest quality lacquer?\nWe have made such a cream-a\nstable, freeze-and-thaw-resistant water\nemulsion of the same kind of cellulose\nacetate butyrate on which the best\ngrades of conventional lacquers are\nbased.\nThe cream eliminates separate fill\ners, sealers and wash coats, long dry\ning periods, excessive sanding opera\ntions, and spraying equipment. With\none, two, or three coats a range of\neffects can be produced from a flat\n\"natural\" surface to a rich, semi\nglossy, \"rubbed\" surface. The fast\nfilm formation permits application of\nsuccessive coats within minutes and\neliminates the problem of surface im\nperfections from dust in the air. Gentle\nrubbing as the film forms fills the ir\nregularities in the wood and smooths\nout the top of the lacquer. Though\nwater-based, the cream does not raise\ngrain. After drying, the film has good\nresistance to water. It adheres well to\nthe wood, seals it well, prevents pene\ntration of subsequently applied con\nventional finishes (if they are desired)\nbut holds them tenaciously.\nThe product itself is almost water\nwhite, with the color stability to sun-\n• light for which all cellulose acetate\nbutyrate coatings have been esteemed.\nIt neither darkens wood nor is itself\ndarkened with the passage of time.\nAll these interesting properties we have\ndemonstrated to our own satisfaction. The\nilltricacies of marketing stich a produci\nthrough paint stores, stlpermarkels, five\nalld-dimes, or similarly formidable retail\nchannels fill us with dismay. Therefore we\nthought we would here ask around what\ncompanies are interested in trying to make\nhay wilh this lovely development. if indeed\nIhere are any such companies, Eastman\nChemical Producls inc., Kingsport, Tenll.\n(Subsidiary of Eastman Kodak Company)\nwill tell them all about emulsified butyrate.\nAmylose and culture\nSpaghetti and macaroni are basic.\nThe idea of making wheat flour up\ninto a paste and drying it for future\nuse must have come very early. Enter\nesthetics. The human spirit must be\nnourished along with the human body.\nFor reasons apparently unrelated to\nbiological metabolism, the paste must\nbe dried in certain shapes, and the in\ntegrity of these shapes must be preserved\nright to the pearly portal of the alimen\ntary tract. This principle is ancient: the\nancient Romans ate spaghetti with\ncheese; the ancient Japanese ate maca\nroni pressed from a paste of cooked\nrice.\nWhen spaghetti or macaroni is\ncooked for too long or allowed to\nstand cooked, the human spirit is\noffended. The morsels of pasta revert\nto a sticky paste, millenia of cultural\nadvance undone because amylose has\ngone into solution and then has loosely\nhydrogen-bonded itself into a net of\nslime. But for this unfortunate tend\nency, the world's food supply would be\nless dependent on specialized durum\nwheats. Without them, the spaghetti\nand macaroni would get even stickier.\nThe problem now appears to be as\nsoluble as the amylose itself.\nFirst fruits of the victory can already\nbe tasted. Try any of the up-to-date\ndehydrated potato-flake brands. Com\npare with home-whipped potato.\nWhatever the future holds for spaghetti\nand macaroni, the reason the instant-potato\nthing works out so well is that the processors\nadd a very small percentage of pure mono\nglyceride. it complexes the dissolved\namylose so securely that even the familiar\niodine-blue test can scarcely find it.\nThese Myverol Distilled Monoglycer\nides we prepare by glycerolysis of familial'\nvegetable and animal food fats. They are\nofficially recognized as safe. investigators\nwho would like samples of them with which\nto try remedying stickiness ill\nany starchy foods are invited\nto write Distillation Producls\nIndustries, Rochester 3,\nN. Y.(Division ofEast\nman Kodak CompaIlY).\nThis is another advertisement where Eastman Kodak Company probes at random for mutual interests\nand occasionally a IiHle revenue from those whose work has something to do with science© 1960 SCIENTIFIC AMERICAN, INC\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n74.111.45.22 on Sun, 28 Oct 2018 19:32:23 UTC��������������\nAll use subject to https://about.jstor.org/terms", "affiliations": [{"country": "United States", "discipline": "Linguistics", "university": "Cornell University"}], "species_categories": ["Fish", "Primate", "Other", "Bird"], "specialized_species": ["stickleback", "gibbon", "howler monkey", "Western Meadowlark"], "computational_stages": [], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Broadcast and Direct Reception", "Semanticity", "Arbitrariness and Duality of Patterns", "Discreteness and Syntax", "Displacement", "Productivity", "Traditional Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882639", "updated_at": "2026-01-13T16:06:44.167318", "committed_at": "2026-01-13T13:07:29.650118"}
{"id": "6161760c-d002-497b-9782-7f1da871009a", "title": "A Critical Companion to Zoosemiotics", "authors": ["Martinelli,  Dario"], "year": "2010", "journal": "Biosemiotics", "abstract": "", "doi": "10.1007/978-90-481-9249-6", "analysis_notes": "A critical companion of zoosemiotics is the first attempt to systematise the study of animal communication and signification through its most important and/or problematic terms and concepts, and its most representative scholars. It is a companion, in that it attempts to cover the entire range of key terms in the field, and it's critical, in that it aims not only to describe, but also to discuss, problematise and, in some cases, resolve, these terms.\n", "affiliations": [{"university": "University of Helsinki", "country": "Finland", "discipline": "Other"}], "species_categories": ["Primate", "Insect", "Marine Mammal", "Bird"], "specialized_species": ["vervet monkey", "greater spot-nosed monkey", "honeybee", "bottlenose dolphin", "humpback whale", "chimpanzee", "gorilla", "bonobo", "african grey parrot", "satin bowerbird"], "computational_stages": ["Data Collection", "Sequence Representation", "Meaning Identification"], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Broadcast and Direct Reception", "Reference and Displacement", "Arbitrariness and Duality of Patterns", "Discreteness and Syntax", "Semanticity", "Prevarication", "Openness", "Tradition and Cultural Transmission", "Learnability"], "status": "saved", "created_at": "2026-01-13T12:49:59.882657", "updated_at": "2026-01-13T16:08:01.085195", "committed_at": "2026-01-13T13:18:17.657152"}
{"id": "2955d7b2-5dc8-4e76-8426-e9f10c023de5", "title": "Derived vocalizations of geladas (Theropithecus gelada) and the evolution of vocal complexity in primates", "authors": ["Gustison,  Morgan L.", "le Roux,  Aliza", "Bergman,  Thore J."], "year": "2012", "journal": "Philosophical Transactions of the Royal Society B: Biological Sciences", "abstract": "", "doi": "10.1098/rstb.2011.0218", "analysis_notes": "Research\nDerived vocalizations of geladas\n(Theropithecus gelada) and the evolution of\nvocal complexity in primates\nMorgan L. Gustison1,*, Aliza le Roux1,3 and Thore J. Bergman1,2\n1Department of Psychology, and 2Department of Ecology and Evolutionary Biology, University of\nMichigan, Ann Arbor, MI 48109, USA\n3Department of Zoology and Entomology, University of the Free State, Qwaqwa 9866, South Africa\nPrimates are intensely social and exhibit extreme variation in social structure, making them particularly well suited for uncovering evolutionary connections between sociality and vocal complexity.\nAlthough comparative studies find a correlation between social and vocal complexity, the function\nof large vocal repertoires in more complex societies remains unclear. We compared the vocal complexity found in primates to both mammals in general and human language in particular and found\nthat non-human primates are not unusual in the complexity of their vocal repertoires. To better\nunderstand the function of vocal complexity within primates, we compared two closely related primates (chacma baboons and geladas) that differ in their ecology and social structures. A key\ndifference is that gelada males form long-term bonds with the 2– 12 females in their harem-like\nreproductive unit, while chacma males primarily form temporary consortships with females.\nWe identified homologous and non-homologous calls and related the use of the derived nonhomologous calls to specific social situations. We found that the socially complex (but ecologically\nsimple) geladas have larger vocal repertoires. Derived vocalizations of geladas were primarily used\nby leader males in affiliative interactions with ‘their’ females. The derived calls were frequently\nused following fights within the unit suggesting that maintaining cross-sex bonds within a reproductive unit contributed to this instance of evolved vocal complexity. Thus, our comparison highlights\nthe utility of using closely related species to better understand the function of vocal complexity.\nKeywords: derived vocalizations; group size; homologous vocalizations; social complexity;\nvocal complexity; vocal repertoire\n1. INTRODUCTION\nThe complexity of vocal communication varies enormously across species, from humans with an endless\nrepertoire of sound combinations, to species of mongoose\nthat produce only three different sounds [1]. As we continue to document the diversity that exists in nature, we\nare increasingly able to use comparative studies to identify\nthe selective pressures responsible for increasing vocal\ncomplexity. One of the most salient findings that has\nemerged is that high levels of sociality are found in combination with a high degree of vocal complexity [2–5].\nFor example, ground-dwelling sciurid species with\nsocially complex groups (i.e. many age/sex classes) produce more acoustically distinct alarm calls than species\nwith fewer age/sex classes [2]. Although non-primate\ntaxa can be excellent study subjects for investigating the\nevolution of vocal complexity in general (e.g. rodents:\n[6]; bats [5]) primates, as our closest relatives, can provide insight into the evolution of the most complex\nvocal system—our own [7,8]. Moreover, primates exhibit\nextreme variation in social structure, making them\nparticularly well suited for uncovering evolutionary\nconnections between sociality and vocal complexity.\nFacets of primates’ sociality distinguish them from\nmost other mammals. First, primates exhibit an unusual\ndegree of sociality that some have proposed has resulted\nin a kind of ‘Machiavellian intelligence’ [9,10] in that\nindividuals are capable of forming coalitions [11],\ndeceiving others [12] and maintaining strong, longterm social bonds with both kin and non-kin [13–15].\nSecond, primates are unusual among mammals in that\nthe size of their groups is positively associated with\nsome aspects of brain size [10,13]. One intriguing explanation for this relationship is that primates require\nsophisticated cognitive abilities for keeping track of and\nmaintaining complex networks of social relationships\n[9,16,17]—particularly considering recent findings\nthat social networks actually enhance individuals’ fitness\n[18,19]. Offering further support, the strong positive\nrelationship between group size, time spent grooming\nand diversity of vocal repertoire in primates [20] suggest\nthat more vocalizations may indeed be necessary for\nnavigating the complex network of social relationships\nin primate societies.\n* Author for correspondence (gustison@umich.edu).\nOne contribution of 13 to a Theme Issue ‘The social network and\ncommunicative complexity in animals’.\nPhil. Trans. R. Soc. B (2012) 367, 1847–1859\ndoi:10.1098/rstb.2011.0218\n1847 This journal is q 2012 The Royal SocietyIn this review, we first focus on the evolution of\nvocal complexity in primates, and then propose a\nnovel approach for studying the function of vocal complexity. Although a species’ repertoire size provides\none useful comparative metric, it is a composite\nmeasure with no information about the function of\nthe individual calls that comprise it. Here, we propose\nthat the function of vocal complexity can be understood by comparing vocalizations among closely\nrelated species with differing repertoire sizes to identify\nspecies-specific derived calls. In such cases, the function of greater vocal complexity matches the function\nof the derived calls. As an example of how this\napproach can provide insights about the evolution of\ncomplexity, we compare the vocalizations of geladas\n(Theropithecus gelada) and chacma baboons (Papio\nursinus)—two closely related Old World monkeys\nwith overlapping vocal repertoires but very different\necological and social structures.\n2. VOCAL REPERTOIRES OF PRIMATES\nAND OTHER MAMMALS\n(a) Repertoire size as a measure of complexity\nMammalian vocal communication is typically\ndescribed as being made up of discrete, functional\nunits, or ‘calls’ [21 – 23]. Based on these functional\nunits, vocal complexity is quantified in terms of (i)\nnumber of discrete vocalizations in the repertoire\n(repertoire size) [2,20,24,25], or less commonly, (ii)\ndegree of individuality within discrete calls [5,6,26].\nOther ways of assessing vocal complexity include quantifying syllable complexity, amount of information\ncontained within a call [5], or the number of calls\nwithin a specific category of vocalizations (e.g. alarm\ncalls [2]).\nSeveral mammalian species produce call variants, or\ngraded calls, which vary slightly in acoustic properties\n[27– 31], such as fundamental frequency [28], ‘pitch’\n[29] or duration [24] and, as a result, have different\nmeanings to receivers [29,32– 34]. For species with\nsmall, fixed vocal repertoires, these subtle alterations\nmay help to extend the flexibility of an otherwise limited repertoire [7]. However, identifying graded calls\nrequires detailed acoustic and behavioural analyses\nand data of comparable detail are rarely available for\nmultiple species. Therefore, as has become the convention in vocal studies [2,20,24,25], we refer to\nrepertoire size as the number of discrete calls that\nanimals in a population or species produce.\n(b) Vocalization types\nVocalizations are produced in many different contexts.\nSome are produced in response to external stimuli such\nas predators and food. We call these ‘allospecific’ vocalizations (table 1) and include alarm calls and food calls.\nAlarm calls can communicate the degree of risk\ninvolved [2,24], indicate predator type (i.e. aerial or\nterrestrial) [53,54], or combine information on risk\nand predator type [51]. Primates, in particular, are\nknown to produce alarm vocalizations specific to predator type, eliciting appropriate responses in receivers\n[55– 57]. Notably, the complexity of primate alarm\ncalls is generally attributed to a complex physical\n(rather than social) environment [58]. If different predators have different modes of hunting, primate prey\nshould have evolved different predator responses to\neach. By contrast, the complexity of alarm calls in a\nsmall social carnivore, the meerkat (Suricata suricatta),\nhas been attributed to the need for social coordination\n[4]. Relative to a sympatric-living herbivore species like\nCape ground squirrels (Xerus inauris), meerkats travel\nfarther from underground shelters in their open habitat\nto find living prey, and they depend on ‘sentinels’ to\nemit referential alarm calls that vary acoustically\nbased on predator type [4]. This strategy allows individual meerkats to decrease time spent being vigilant\nand increase foraging efficiency.\nThe other allospecific vocalizations, food calls, are\nless variable than alarm calls. Only a handful of studies\nhave demonstrated that variation in calls is related to\nthe quantity or quality of the food source [59]; but\nmost studies report a lack of variation [60]. Although\nalarm and food calls differ substantially in degree of\ncomplexity, they share two features: (i) they are elicited\nby non-conspecifics, and (ii) they are the only two contexts where proto-syntax (i.e. the combination of call\nelements to form new meanings) has been reported,\nspecifically in primates (food calls [61]; alarm calls [62]).\nThe vast majority of mammalian vocalizations are\nemitted during social interactions with conspecifics,\nunder conditions of varying motivational states (e.g.\nmating, aggression, fear). We call these ‘social’ vocalizations and divide them into two main classes—calls\nthat function over a long distance (‘loud calls’) and\ncalls produced in close-range social interactions\n(‘close-range calls’, table 1). Loud calls may function\nto attract or defend mating partners [63], defend a\nterritory or food source through maintenance of intergroup spacing [42,64], or re-establish contact with\ngroup members that are out of sight (‘separation\ncalls’) [38].\nClose-range calls are produced in agonistic, neutral\nor affiliative contexts. Calls produced in agonistic\ncontexts may function to assess or warn rivals, such as\ncontest calls that advertise fitness [42] or threat calls\nthat maintain a dominance hierarchy [46,65]. Harassed\nindividuals, on the other hand, may produce distress\ncalls, which probably function to appease the aggressor\nand attract coalition partners [50]. The specific function of some close-range calls made in strictly neutral\nor affiliative social situations has been more difficult\nto ascertain and little is known about them besides\nthe contexts in which they are produced [7]. Copulation calls, for example, do not appear to have the\nsame function across different species and may even\nserve no function in some instances [66,67]. Other\nclose-range calls are ascribed to an affiliative function,\noften described as ‘contact calls’ (e.g. in raccoons (Procyon lotor) [65]; capuchins (Cebus capucinus) [68]).\nContact calls can be produced in various ‘friendly’ contexts, such as during post-conflict reconciliation\ninteractions [69] and prior to friendly behaviours like\nallogrooming [50,70,71]. These close-range contact\ncalls are also produced in more ‘neutral’ behavioural\nstates like foraging and resting, and therefore could be\ninvolved in the maintenance of group cohesion and\ninter-individual spacing [72].\n1848 M. L. Gustison et al. Primate vocal complexity\nPhil. Trans. R. Soc. B (2012)Primate vocal repertoires are similar to those of\nother terrestrial mammals (table 1). Although primate\nrepertoires may be slightly larger (on average), there is\nconsiderable overlap between primates and other taxa,\nboth in total repertoire size and within each category of\ncalls. Species with large repertoires relative to other\nspecies in their order generally produce a large proportion of calls in just one or two categories of calls\n(e.g. long distance and competitive calls—Callicebus\nmoloch [38]; distress and contact calls—Pan troglodytes\n[46]; allospecific and contact calls—Suricata suricatta\n[51,52]). This suggests that specific needs related to\none domain (e.g. competition or affiliation) might\ndrive the development of large repertoires, rather\nthan an overall increase in repertoire across all categories. Within primates, no clear taxonomic pattern\nhas emerged with respect to repertoire size. Each\nfamily of primates (including great apes) contains\nspecies with large and small repertoires. Surprisingly,\ndespite the social complexity of primates, there is no\nconsistent trend for primates to have more social calls\nthan other mammals, which suggests that simple comparisons of numbers of calls are of limited utility.\n(c) Function of larger repertoires\nOne of the primary hypotheses put forward to explain\nlarge, complex vocal repertoires is that social complexity creates the need for more vocalizations [21,73– 76].\nComparative studies have found a positive relationship between social complexity and communicative\ncomplexity, providing support for this hypothesis\n[2,3,5,20]. In sciurids, the alarm call repertoire size\nincreases with the number of demographic ‘roles’\n[2]. Additionally, in primates, an increase in total\nvocal repertoire size was associated with both larger\ngroups and increases in time spent grooming—a\nmeasure of social cohesion [20]. These studies have\nbeen important for pinpointing aspects of sociality\nTable 1. Vocal repertoire size for exemplar species from Primata, Rodentia, and Carnivora broken down into six categories:\nAllospecific (alarm calls and food calls), long distance (separation calls, intergroup spacing calls), contact (short-range soft\ncalls), competitive (threat and display calls), distress calls (fear calls during agonism) and other (contexts unknown or made\nin several different contexts). Sources from Primata are drawn from the repertoire analysis made by McComb & Semple\n[20], excluding captive studies. Total repertoire sizes in this paper are slightly different because we did not count sequences\nof discrete call units as separate calls if the units were produced singly. Sounds that are not strictly ‘vocalizations’, such as\nsneezes, coughs and teeth chattering, are excluded from the table. For comparison, we focus on exemplar species from\nRodentia and Carnivora because of similarities in social and vocal behaviour.\nspecies name allospecific long distance contact competitive distress other total size citations\nOrder Primata\nAlouatta palliata — 1 — 8 2 1 12 [35]\nArctocebus calabarensis — 1 — 1 1 — 3 [36]\nCallicebus moloch 1 3 1 1 3 1 10 [37]\nCallimico goeldii 4 7 3 6 4 1 25 [38]\nCebus olivaceus — — 4 4 2 1 11 [39]\nCercocebus torquatus 4 1 3 5 1 — 14 [40]\nCercopithecus aethiops 5 — 3 5 3 3 19 [41]\nEuoticus elegantulus 2 1 2 — 1 — 6 [36]\nGalago alleni 1 — 2 1 1 — 5 [36]\nG. demidovii 1 1 3 1 1 1 8 [36]\nMacaca fascicularis 2 2 1 1 4 5 15 [42]\nM. radiata 1 1 3 7 4 3 19 [43]\nM. silenus 1 2 3 5 2 1 14 [43]\nMandrillus sphinx 1 3 1 — 4 — 9 [44]\nPan paniscus — — 4 — 1 4 9 [45]\nP. troglodytes 3 1 8 4 8 3 27 [46]\nPerodicticus potto — 1 2 1 1 5 [36]\nPongo pygmaeus 1 1 1 2 2 1 8 [47]\nPresbytis entellus 3 1 2 3 3 2 14 [43]\nP. johnii 2 1 3 4 3 1 14 [43]\nProcolobus badius 2 — — 5 2 2 11 [48]\nOrder Rodentia\nNotomys alexis — — 1 1 1 2 5 [23]\nN. cervinus — — — 1 1 2 4 [23]\nN. mitchellii — — 1 1 1 2 5 [23]\nN. fuscus — — 1 1 1 2 5 [23]\nOctodon degus 2 — 4 5 2 — 13 [49]\nOrder Carnivora\nLycaon pictus 3 2 7 5 2 6 25 [50]\nSuricata suricatta 11 — 7 2 2 3 25 [51,52]\nCynictis penicillata 3 — 2 2 — 1 8 [24]\nSpeothos venaticus — 1 3 2 1 — 7 [27]\nCerdocyon thous 2 1 2 1 — — 6 [27]\nChrysocyon brachyurus 1 2 2 2 1 — 8 [27]\nPrimate vocal complexity M. L. Gustison et al. 1849\nPhil. Trans. R. Soc. B (2012)(i.e. large sociable groups, various demographic roles)\nthat may drive the evolution of large repertoires. However, vocal repertoires of different species may be\n‘large’ for different reasons (table 1), and more work\nis clearly needed to understand the selective pressures\nunderlying expansions in repertoires.\n3. VOCAL COMPLEXITY OF HUMANS AND\nOTHER PRIMATES\nRelative to humans, non-human primates (henceforth\nreferred to as ‘primates’) exhibit surprisingly simplistic\nvocal production [77,78]. (Note that a focus on vocal\nproduction ignores the more sophisticated language-like\nabilities that primates exhibit in terms of vocal perception [79]). According to the ‘source-filter-theory’ first\ndeveloped to describe human speech [80,81], vocal\nproduction entails two components: the ‘source’ of a\nvocalization (i.e. lungs and the vocal folds) and the\nmeans by which a vocalization is shaped, or ‘filtered’,\nin the vocal cavities (i.e. vocal tract). Speech relies\nheavily on the control of ‘formants’ or vocal resonances (a product of vocal tract morphology) to\nproduce distinct syllables and hence encode information [81]. Primates also produce formants but the\nformant structure (i.e. distance between sound frequency ‘peaks and valleys’ [81]) mainly encodes\nlimited information such as individual identity\n[82,83] and body size [84 – 86]. Even more elaborate\nare humans’ filtering tools, the descended larynx and\ntongue [81]. In most primates and other mammals,\nthe tongue remains flat inside the mouth. By\ncontrast, humans have remarkable control over the\nlocation and shape of the tongue [81,87], giving\nhumans unmatched plasticity in sound invention\n[88]. This unique vocal plasticity allows us to imitate\ncomplex sounds and invent novel sounds, a feat\nshared with some birds and cetaceans [89,90] but\nnot with other primates [77,78].\nDespite having a limited ability to imitate and create\nnew sounds, there are some features of primate vocal\nproduction that show similarities to human language.\nFor instance, some primates exhibit vocal dialects—\ngeographical variation in the acoustic structure of\ncertain vocalizations [91– 93]. Calls are recognizably\nhomologous between different populations of the\nsame species, but show acoustic distinctions related to\nvariation in habitat and the duration of isolation, similar\nto patterns in human linguistic diversity (e.g. [94]).\nAdditionally, primates such as chimpanzees (Pan\ntroglodytes) [95,96], blue monkeys (Cercopithecus mitis)\n[97] and capuchins (Cebus apella) [98,99] produce or\nsuppress vocalizations depending on the composition\nof the conspecific audience.\nPrimate communication also resembles the semantic\ncontent of human language. Several primates exhibit\npotentially ‘referential’ allospecific calls that are elicited\nby external stimuli (table 1). In some cases, the referential nature of these calls has been supported with\nplayback experiments. For example, each vervet\nmonkey (Chlorocebus pygerythrus) alarm call ‘refers’ to\na different type of predator (leopards, eagles and\nsnakes). Experimental playbacks in the wild indicate\nthat these different alarm calls produce different\npredator-appropriate responses in the absence of a\npredator [56]. In further support of the functionally\nreferential nature of primate vocalizations, habituation – dishabituation experiments on Diana monkeys\n(Cercopithecus aethiops) demonstrated that playbacks of\nleopard alarm calls or leopard growls resulted in predator-appropriate responses. These results suggest that\nDiana monkey responses are based on the underlying\nreferent (the predator) rather than any differences in\nthe calls’ acoustic properties [100].\nDespite some language-like properties of primate\ncommunication, humans exhibit unrivaled flexibility\nin mixing and matching different sounds to create\nnew meanings through syntax [77,78,101]. Very few\nmammalian species use combinations of calls, and\neven those that do are unlikely to use these combinations to generate new meanings. There are only a\nfew known cases where primates combine calls in\nways that change the meaning of the call elements\n(red-capped mangabeys (Cercocebus torquatus) [102];\nCampbell’s monkeys (Cercopithecus campbelli) [61];\nDiana monkeys (Cercopithecus diana) [57]). Importantly, these semantic combinations of sounds only\ncomprise a few specific elements and are highly constrained [102,103]. Non-human primate vocal\n‘productivity’ [104] is therefore far simpler than\nhuman communication and may, at best, be labelled\nas ‘proto-syntax’—a term that refers to rule-governed,\nrather than random, combinations of discrete sounds\nthat lack the sophistication of human grammar [61].\n4. FUNCTION OF DERIVED VOCALIZATIONS\nAlthough previous studies have been pivotal for identifying aspects of sociality that drive vocal complexity,\nwe still know relatively little about how large vocal\nrepertoires function in complex societies. One reason\nfor this is that comparisons of repertoire size alone\nfail to identify the specific calls that may have evolved\nin association with social complexity. With no knowledge about which calls are derived, we can say\nnothing about how those calls function. Another\nreason is that comparisons of group size alone fail to\nidentify the specific features about group life that\nrequire an increase in vocal complexity. Thus, several\nquestions remain unanswered: first, what specific\naspects of sociality create a need for vocal complexity?\nIs it the number of relationships, the nature of relationships or something else? Second, can we identify the\nderived components of the vocal repertoire that\nrelate to the demands of increased sociality? That is,\nif more social species have more calls, how are they\nusing these ‘extra’ calls?\nTo help answer these questions, we propose a systematic investigation of closely related species that\nmake detailed comparisons of the functions of ‘homologous’ (shared between species) and ‘derived’\n(unique to a species) vocalizations. Note that, although\na vocalization may be unique to a species because it was\npresent in the common ancestor and lost in the other\nspecies, we call them derived calls for simplicity,\nalthough the direction of the change (gain or loss)\nremains a hypothesis that can be examined by comparison to an outgroup. Previous studies have used\n1850 M. L. Gustison et al. Primate vocal complexity\nPhil. Trans. R. Soc. B (2012)comparisons among closely related species to understand vocal evolution [71] although not with the goal\nof understanding vocal complexity per se. In the\nprimate literature, several researchers have made comparisons of vocal behaviour between related species\n[36,43,105,106]. These studies often include general\nsimilarities and differences of call categories [36],\nacoustic structure [105] and/or contextual use [43]. In\none case [43], there was a clear attempt to identify\nhomologous and unique calls in two species of macaque\n(bonnet macaque (Macaca radiata) and lion-tailed\nmacaque (M. silenus)) and two species of langurs (Nilgiri\nlangur, Presbytis johnii ) and common langur (P. entellus));\nhowever, much of the ensuing analyses focused on the\ndifferential use of the homologous calls rather than\nexplaining the function of unique calls. The only study\nto date to focus on unique calls [44] compared the\nvocal behaviour of the forest-dwelling mandrill (Mandrillus sphinx) to published accounts of savannah-living\nbaboons (Papio spp.) and geladas (Theropithecus\ngelada). Kudo reported that mandrills produced two\nunique long-distance contact calls instead of the various\nshort-range calls made by baboons and geladas. Kudo\nproposed that this difference was likely due to ecological\npressures, as low-amplitude vocalizations do not travel\nwell in a forested environment where visual contact is\nalso limited [44].\nIdentifying homologous and derived vocalizations is\ncritical for identifying the specific social or ecological\nfactors that may account for complex vocal repertoires.\nHere, we use a comparison of the vocal complexity in\ngeladas with that in chacma baboons to demonstrate\nhow this homologous-derived vocalization strategy\nmay be implemented. By analysing calls from both\nspecies (all obtained from wild populations under\nnatural conditions), we control for variability in how\ncalls are classified which may drive some of the variation in overall repertoire size found in meta-analyses.\n5. GELADAS AND BABOONS—A CASE STUDY\nEarly researchers were struck by the intricate vocal behaviour of geladas as well as their unusually complex\nsocial groups [107 – 109]. Although some have proposed a causal connection between these factors\n[107], little progress has been made towards understanding why geladas, the only extant Theropithecus\nspecies, have elaborate vocal communication compared\nwith other primates. Thus, a comparison between the\nvocal behaviour of geladas and Papio baboons serves\ntwo purposes. First, these two taxa split relatively\nrecently (about 4 Myr ago), and Theropithecus and\nPapio are probably sister genera [110]. To human observers, they appear to produce similar calls in similar\ncontexts (e.g. affiliative grunts, threat grunts and\nalarm calls). It is therefore relatively straightforward\nto identify homologous calls, and simultaneously, to\npinpoint the unique call types that result in differences\nin vocal repertoire size. We can then assess how these\nunique calls are used to highlight the selective pressures\nthat may have favoured greater vocal complexity.\nSecond, the differences in the social system and\necology of geladas and baboons make the comparison\nparticularly useful for testing contrasting predictions\nabout the evolution of behavioural differences [111].\nBoth species live in matrilineal groups in which males\ndisperse [108,112,113]. Geladas aggregate into a\nmulti-level, fission – fusion society (forming groups as\nlarge as 1100 individuals) [114,115] and within this\ngroup they only recognize and primarily interact with\na small subset of the individuals within ‘harem-like’\nreproductive units of 2– 15 individuals [108,114 –\n117]. In these reproductive units, ‘leader’ males must\nmaintain social relationships with several females, and\nit is thought that maintaining close social bonds with\nhis unit females may serve to decrease the likelihood\nthat he will be out-competed by a non-unit, ‘bachelor’\nmale [118,119]. In contrast to their complex social\nsystem, gelada diets are simple and specialized, with\ngrass as the primary food item [120 –122].\nUnlike geladas, many baboons (e.g. chacma baboons\n(Papio ursinus)) have a single-level, multimale –\nmultifemale society with no discrete reproductive\nunits (20– 120 animals, [123 – 125]). Baboons maintain\ndifferentiated relationships based on kinship and dominance with all members of their group, but cross-sex\nrelationships consist mainly of temporary consortships\n[123 – 126]. In terms of ecology, baboons are extremely\ncomplex; they live in a range of habitat types and consume anything from fruits and seeds to insects and\nvertebrates [127 – 130].\nGiven that geladas and baboons differ in their sociality and ecology, we predict corresponding differences\nin the call types comprising their vocal repertoires. For\ninstance, geladas—specifically males—may produce\nmore types of calls that are used in affiliative situations.\nOn the other hand, baboons may use proportionally\nmore allospecific calls to communicate about general\nfeatures of the environment such as food items. To\ntest our predictions, we compared the vocal behaviour\nof geladas with one representative of the Papio genus—\nthe chacma baboon [44]—to identify derived call\ntypes. While we recognize that vocalizations from a\nsingle population may obscure variation within the\ngenus, both the literature and our experience with\nmultiple types of Papio baboons suggests that repertoire variation within Papio is minimal [44] and that\nthe types of vocalizations used by chacma baboons\nare very similar to even the socially-divergent Papio\nspecies, P. hamadryas [44,131]. Furthermore, our\ndescriptions of gelada vocalizations closely match\nthose from captive geladas [132] suggesting that such\nvocalizations are not unique to one population. For\nany derived vocalizations, we then conducted intraspecific analyses to determine their possible functions.\n(a) Study subjects\nData for this study come from 14 units within three\ndifferent bands in one community of wild geladas\n(about 1200 individuals) living in the Sankaber area\nof the Simien Mountains National Park, Ethiopia\n(2008 –2010) [113,114] and a single group of\nchacma baboons (group C) living in the Moremi\nGame Reserve in the Okavango Delta of Botswana\n(2001 –2002). The gelada units comprised one\nleader male, 0– 3 follower males, and 1– 11 females\nand their immature offspring. The gelada habitat\nPrimate vocal complexity M. L. Gustison et al. 1851\nPhil. Trans. R. Soc. B (2012)consisted of high-elevation open grassland and adjacent escarpments (sleeping sites). The chacma\nbaboon group ranged from 82 to 91 individuals,\nincluding 9 – 11 adult males, 29 – 31 adult females,\nand their immature offspring. The baboon habitat\nwas patchy scrub forest interspersed with seasonally\nflooded grasslands.\n(b) Comparison of gelada and chacma\nvocal repertoires\n(i) Data analysis\nWe opportunistically recorded vocalizations from 81\nadult geladas (males ¼ 36; Feb 2008–Apr 2010) and\n32 adult chacma baboons (males ¼ 11; Apr 2001–\nMay 2002) with a Sennheiser ME66 directional microphone connected to a digital stereo recorder (Marantz\nPMD 660 Digital Recorder for geladas; Sony VW-D6\nProfessional Walkman for chacma baboons). The call\ntypes and contexts of all vocalizations were described\nat the time of recording. Our analyses focus on\ncommon calls that occurred repeatedly during focal\nsampling and we do not attempt to describe all vocalizations produced in each species. The inter-observer\nreliability (between assignments made in the field and\nassignments that were blind to previous designations\nand based on isolated calls in the absence of contextual\ninformation) of a subset of these calls (five exemplars/\ncall type/species/sex class) was 96 per cent. We used\nAVISOFT (v. 5.1.12, R. Specht, Berlin) to generate\nspectrograms with a fast Fourier transformation size\nof 1024 points. Focusing on spectrograms with high\nsignal-to-noise ratio, we categorized call types by ear,\nvisual inspection of the spectrograms and the contexts\nin which they occurred (chacma females ¼ 50 calls;\nchacma males ¼ 32 calls; gelada females ¼ 72 calls;\ngelada males ¼ 92 calls). There were an equal\nnumber of calls per individual (within species/sex\nclass) for each call type (n ¼ 1 –3 call replicates per\nindividual, 6 –12 total calls per call type). We optimized\nthe frequency range of different call types (11 or\n22 kHz) where appropriate (time resolution of\n2.667–2.903 ms and a 100% frame).\nWe used Avisoft to quantify eight temporal and spectrum-based acoustic parameters in the spectrograms:\nduration, mean bandwidth, frequency under which\n25 per cent of the call’s energy lies (start, maximum\nand mean), number of harmonic peaks under 20 dB\n(maximum and mean), maximum peak frequency.\nThen, to determine the probability of correctly assigning each vocalization to a pre-categorized call type, we\nperformed stepwise discriminant function analyses\n(DFAs) with a subsequent leave-on-out cross-validation procedure for each of the four species/sex\nclasses separately [133]. We used multivariate analyses\nof variance (MANOVAs) to verify the significance of\nthe final DFA parameters. Finally, we identified homologous calls between species based on both acoustic\nand contextual similarity.\n(ii) Results\nMale and female geladas and chacma baboons produced a range of allospecific and social calls used in\nboth affiliative contexts (e.g. grooming and\ncopulation) and non-affiliative contexts (e.g. challenge\ndisplays and dominance interactions), with geladas\nproducing a greater number of call types (table 2).\nOf the 14 call types we identified, eight were found\nin both geladas and chacmas and six were unique to\ngeladas. The derived gelada calls occurred primarily\nin short-range affiliative contexts (table 2). Extant literature and our own observations indicated that most\nof the homologous call types are produced in a similar\nmorphological way—a vocalized exhale—while geladas\nproduce both inhaled and exhaled versions of calls that\nare acoustically distinct (we only separate inhaled and\nexhaled grunts here because they are the most\ncommon, but they also produce inhaled ‘moans’ and\n‘wobbles’, table 2).\nWe performed further analyses on 12 vocalization\ntypes, of which only seven were found in chacmas\n(figures 1 and 2). Other call types were excluded from\nfurther DFA analyses because they were rarely produced without overlapping vocalizations, and hence,\nthere were too few high-quality recordings to analyse\n(gelada female: display calls, moans, inhaled grunts,\nwobbles and yawns; gelada male: how barks, nasal\ninhaled grunts and alarm calls; chacma female: alarm\ncalls; chacma male: fear grunt, alarm calls and copulation calls). We were able to discriminate between\nall call types for each age-sex class, using DFAs;\nbased on eight acoustic parameters, we classified call\ntypes at a higher rate (range: 67.4 –93.8%; leave-oneout classification range: 50 –90.6%) than expected\nby random classification (range: 10 –33.3%). A\nMANOVA test carried out for each of the four\nspecies/sex classes showed that pre-categorized call\ntypes were significantly different from each other\nbased on variation in at least four of the chosen acoustic\nparameters (p , 0.003).\nIn sum, acoustic analysis shows that geladas share\na number of vocalization types with chacma baboons.\nWhile chacma baboons did not appear to have any\nunique calls, the analysis allowed identification of at\nleast five derived vocalization types in geladas:\ninhaled grunts, moans, pre-copulation calls, wobble\ncalls and yawns. We then carried out intraspecific\nanalysis to determine how these calls function in\ngelada society.\n(c) Intraspecific analysis of derived gelada\nvocalizations\n(i) Comparison of derived call use in gelada\nmales and females\nTo determine the function of the derived gelada vocalizations identified above, we first examined potential\nsex differences in the use of these calls. By definition,\npre-copulation calls were produced only by females\nin very straightforward contexts (i.e. produced prior\nto copulation). Thus, we focused here on the use of\ninhaled grunts, moans, wobbles and yawns. Behavioural data on adult male and female geladas were\nobtained between January 2009 and December 2010\nduring repeated 15-min focal follows of 53 females\n(mean + s.d.: 6.55 + 2.59 h per female; 348.50 h in\ntotal) and 13 leader males (6.60 + 1.86 h per male,\n85.75 h in total). During these focal follows we\n1852 M. L. Gustison et al. Primate vocal complexity\nPhil. Trans. R. Soc. B (2012)noted all vocalizations uttered by the focal animal, as\nwell as all social behaviour (e.g. approaches and\ngrooming interactions) involving the focal individual.\nNext, we determined sex differences in the use of\nderived vocalizations by carrying out a general linear\nmodel (GLM) with sex and average reproductive\nunit size (over the entire study period) as fixed factors.\nWe found that gelada males produced four of the\nderived calls (i.e. inhaled grunts, moans, wobbles\nand yawns) at a higher mean rate (14.13 calls per h)\nthan did gelada females (0.39 calls per h) (F1,63 ¼\n708.144, p , 0.001), and reproductive unit size did\nnot come out as a significant covariate (F1,63 ¼\n0.942, p ¼ 0.336). Thus, males appeared to be the\nsex using derived vocalizations. We next explored\nwhether these unique calls were used in contexts that\nare unique to males in gelada society.\n(ii) Functionality of derived gelada male calls\nFirst, we tested the hypothesis that derived social calls\nare used by males to maintain social relationships\nwith the unit females by examining vocal behaviour\nin the context of conflict resolution. Using all adult\nfemale focal data, we identified every fight (both as\nactor and receiver) in which the focal female was\ninvolved. These fights (n ¼ 107 events) were characterized by loud screams from the focal female (n ¼\n48 events), or direct, physical attacks from the focal\nfemale that included biting and slapping (n ¼ 59\nevents). We deliberately excluded any inconspicuous\nagonistic interactions (such as soft threat calls or\nvisual threats) that may have gone unnoticed by\nother group members. For each fight event we counted\nall derived vocalizations directed at the focal animal by\nmales in the 2 min preceding the event and the 2 min\nfollowing the event and compared these values with\nbinomial tests of proportions.\nSecond, we tested the hypothesis that derived social\ncalls were used by males in association with the presence\nof non-unit, ‘bachelor’ males that pose a threat to the\nleader males (all leader males are eventually ousted by\nbachelor males). We used all adult leader male focal\nTable 2. Descriptions of call types used by geladas and chacma baboons in short-range and in long-distance situations,\nincluding the way in which they are physically produced and the contexts in which they occur. CF, chacma female; CM,\nchacma male; GF, gelada female; GM, gelada male. Asterisks denote vocalizations that were not used in discriminant\nfunction analyses due to low sample size.\ncall type mode of production context\nI. Shared vocalizations in chacma baboons and geladas\naffiliative grunt (CF, CM,\nGF, GM)\nexhale a soft tonal contact call used during approaching, grooming,\nand infant-handling, as well as while moving and foraging\n[30,109,132,134,135]\ncopulation call (CF, CM*,\nGF, GM)\nexhale loud grunts given before and during mating [132]\nfear bark (CF, CM*, GF) exhale with retracted lips a ‘cough-like’ vocalization [136] given by subordinate\nindividuals to high-ranking animals [132]\nthreat grunt (CF, CM, GF,\nGM)\nexhale a staccato-like vocalization uttered by the dominant individual\nin an aggressive encounter [132,137,138]\nalarm call (CF*, CM*, GF) exhale noisy, harsh calls used in response to predators and other\nenvironmental threats [109,123]\ndisplay call or ‘wahoo’\n(CM, GF*, GM)\ninhale and exhale loud calls typically uttered during competitive displays\n[132,136]; chacma and gelada males, in particular, make a\n‘roar’ that often comes before these wahoo calls\nlost call\n(CM*,CF*,GF*,GM*)\nlong exhale a noisy vocalization that rises in pitch towards the end of the\ncall and associated with separation from the group or\nparticular individuals\nscream (CF, GF, GM) long exhale with\nretracted lips\na noisy drawn-out defensive call, usually given by subordinates\nwhen attacked by a higher-ranking individual [109,132,134]\nII. Derived gelada vocalizations\ninhaled grunt (GF*, GM) vocal inhale vocalized inhales often part of an affiliative grunt calling bout\n[135]; sometimes, inhaled grunts can have an audibly ‘nasal’\nsound, produced by the withdrawn lip obscuring nasal\npassages [135]\nmoan (GF*, GM) long exhale (sometimes\ninhaled)\nlong drawn-out affiliative grunt, often given by leader males\nto their unit’s females ([109,132,139]; this study)\nwobble (GF*, GM) vocal inhale or exhale with\nlip or tongue-flicking\nsoft, undulating calls usually given by males to their unit\nfemales, often following ‘anxiety-producing’ situations (this\nstudy)\nyawn (GF*, GM) inhale a vocalized yawn given in social contexts, often involving\ngrooming sessions and also after mating or in competitive\nsituations ([140]; this study)\npre-copulation call (GF) short exhale calls given by oestrous females while presenting their\ngenitals to males\nhow barks (GM*) exhale high-pitched barks/whinnies given by non-leader males\ngiving chase to other males in competitive displays\nPrimate vocal complexity M. L. Gustison et al. 1853\nPhil. Trans. R. Soc. B (2012)data for which the location of bachelors was stable\nthroughout the entire 15-min focal sample. In other\nwords, bachelor groups were either close to the focal\nmale (within 20 m: n ¼ 16 focals), far (more than 20 m;\nn ¼ 24 focals), or out of sight (n ¼ 26 focals). We carried\nout two GLMs with male identity as a random factor,\nbachelor distance as a fixed factor, and the rate of derived\ncalls as the dependent variable (first model: close versus\nfar; second model: close versus out of sight).\nWe found evidence that males used non-homologous\nderived calls to maintain cross-sex social relationships\nwith females in his units. Specifically, we found that\nmales directed derived non-homologous calls at\nfemales after fights happened (14 occurrences), and\nthey never used them before a fight (binomial test of\nproportions:\nx2\n1 ¼ 12:916, p , 0.001). On the other\nhand, we did not find any evidence that males used\nthe derived calls in response to the presence of bachelors. Leader males did not produce derived calls at a\nhigh rate when bachelor groups were close (3.23 calls\nper h) compared with when they were far away\n(2.04 calls per h) (F1,8 ¼ 0.394, p ¼ 0.548). Similarly,\nleader males did not produce derived calls at a higher\nrate when bachelor groups were close compared to\nwhen they were out of sight (2.51 calls per h) (F1,11 ¼\n0.078, p ¼ 0.785).\n(d) General discussion\nGeladas have an elaborate, almost ‘choral’ vocal repertoire [109] and live in a complex society with social\ngroups of varying sizes, making geladas an important\nmodel system for addressing hypotheses about\nvocal evolution. Identifying homologous vocalizations\nshared with Papio baboons allowed us to study the function of derived gelada vocalizations. It did not appear\nthat interacting with many individuals [20,141] was\nnecessarily an important factor in the use of derived\ncalls, as their production was not correlated with the\nsize of the reproductive unit. Rather, the need to maintain long-term bonds within the unit seemed most\nimportant; leader males used these derived vocalizations after fights broke out within their units. Thus,\nthe gelada-specific vocalizations may have evolved as\nan adaptation to simultaneously maintaining relationships both with and among multiple females—leader\nmales that are better able to ‘keep the peace’ of\ntheir reproductive units may, in turn, have higher\naffiliative\ngrunt\n100\n1 1 1 1 1 1 1\n1111\n11\n1 1 1 1\n1 111\n11\n100 100 100 100 100 100\n100\n100 100 100 100\n100 100100100100100\n100 100 100 100 100 100\ngelada\nmale\ngelada\nfemale\nchacma\nmale\nchacma\nfemale\nfrequency\n(kHz)\ntime (ms)\ncopulation\ncall\nthreat\ngrunt\nfear\ngrunt\nalarm\ncall scream\ndisplay\ncall\nFigure 1. Spectrograms of homologous calls shared by geladas and chacma baboons. Dashes represent calls that were not\nproduced or produced at a very low rate.\n1854 M. L. Gustison et al. Primate vocal complexity\nPhil. Trans. R. Soc. B (2012)reproductive success [118]. It remains to be determined why the cross-sex bonds seen in geladas seem\nmore tightly linked to vocal complexity than the\nwithin-sex bonds found in both species.\nOur results suggest that future studies should examine whether hamadryas baboons (Papio anubis), a Papio\nspecies that also has a ‘harem-like’ structure [142],\nhave any evidence of greater elaboration of affiliative\ncall use by males. This comparison is particularly\nimportant for uncovering how vocalizations relate to\nspecific aspects of long-term bonds because hamadryas\nmales form long-term bonds with females but the\nrelationship is more coercive than in geladas and\nthere does not appear to be a need to ‘keep the\npeace’. In geladas, investigations of how females\nrespond to derived vocalizations and the subsequent\nbenefits to leader male fitness is an exciting direction\nfor future research. It may be the case, for instance,\nthat these derived vocalizations reduce female anxiety,\nsimilarly to the proposed anxiolytic effects of grooming\n[143 – 145].\nOne puzzling aspect of our findings is that the\nderived calls used by males are all used in similar contexts. Further work is needed to tease apart any\npotential differences between the derived gelada\ncalls but this redundancy suggests an additional\nhypothesis. Perhaps the extremely large groups of\ngeladas (herds can number up to 1000) and high\nrates of vocalizations (mean + s.d.: chacmas: 8.84 +\n4.49 calls per h, geladas: 16.95 + 8.51 calls per h)\ncreate ‘vocal clutter’ that the geladas have overcome\nby diversifying their most common call types—affiliative vocalizations. Thus the need to maintain bonds\nwithin a noisy backdrop of conspecific vocalizations\nmay favour greater vocal complexity, possibly explaining some of the group size effects seen in other\nstudies [20].\n6. CONCLUSIONS\nComparisons of repertoire size and components\nsuggest that primates are broadly similar to other\nmammals, despite primates having greater social complexity. However, our comparison of baboons and\ngeladas highlights the utility of making detailed comparisons among closely related species to understand\nvocal evolution. We were able to examine the function\nof recently evolved calls in detail and examine the\nspecific social implications of increased repertoires\nby focusing on specific call types, addressing sexual\ndifferences, and using behavioural measures to\ndescribe social complexity. We found that the larger\nvocal repertoire of geladas is linked to the maintenance of cross-sex bonds within the reproductive unit.\nBroadly focused theoretical and comparative analyses\n[2,3,5,20] are vital to drive the investigation of\ncommunicative complexity. We argue that there is\nalso a need for more focused analyses among carefully\nchosen taxa using directly comparable measures in the\nstudy of vocal complexity.\nWe are grateful to the Ethiopian Wildlife Conservation\nDepartment, the Amhara National Regional State Parks\nDevelopment and Protection Authority, and the wardens\nand staff of the Simien Mountains National Park for\ngranting us the permission to conduct this research in\nEthiopia. We thank the Office of the President and the\nDepartment of Wildlife and National Parks of the Republic\nof Botswana for permission to conduct research in the\nMoremi Reserve. We would like to thank Esheti Jejaw,\nDavid Pappano, Eila Roberts, Noah Snyder-Mackler and\nVanessa Wilson for their assistance with collecting\nbehavioural data in the field. Tiffany Fritzler and Chelsea\nMiller helped us with the acoustic analysis and Ken Guire\nprovided expert statistical advice. Research in Botswana\nwas supported by NIH grant MH62249, an NRSA\nfellowship, the Leakey Foundation and the University of\nPennsylvania. Research in Ethiopia was supported by the\nWildlife Conservation Society (SSF grant no. 67250, the\nwobble yawn\ninhaled\ngrunt moan\npre-copulation\ncall\ngelada\nmale\ngelada\nfemale\n1\n100\n1 1 1\n1s 100 1s\n1\n100 100\ntime (ms)\nfrequency (kHz)\nFigure 2. Spectrograms of derived call types produced only by geladas. Dashes represent calls that were not produced or\nproduced at a very low rate.\nPrimate vocal complexity M. L. Gustison et al. 1855\nPhil. Trans. R. Soc. B (2012)National Geographic Society (grant no. 8100–06), the\nLeakey Foundation, the National Science Foundation\n(grant no. BCS-0715179), and the University of Michigan.\nWe thank Dr Robin Dunbar, Dr Jacinta Beehner and two\nanonymous reviewers for helpful comments on a previous\nversion of this manuscript.\nREFERENCES\n1 Baker, C. 1988 Vocalization of captive water mongooses, Atilax paludinosus. Z. Saugetierkd 53, 83–91.\n2 Blumstein, D. T. & Armitage, K. B. 1997 Does sociality\ndrive the evolution of communicative complexity?\nA comparative test with ground-dwelling sciurid alarm\ncalls. Am. Nat. 150, 179 –200. (doi:10.1086/286062)\n3 Freeberg, T. M. 2006 Social complexity can drive vocal\ncomplexity: group size influences vocal information\nin Carolina chickadees. Psychol. Sci. 17, 557 –561.\n(doi:10.1111/j.1467-9280.2006.01743.x)\n4 Furrer, R. D. & Manser, M. B. 2009 The evolution of\nurgency-based and functionally referential alarm calls\nin ground-dwelling species. Am. Nat. 173, 400 –410.\n(doi:10.1086/596541)\n5 Wilkinson, G. S. 2003 Social and vocal complexity in\nbats. In Animal social complexity: intelligence, culture,\nand individualized societies (eds F. B. M. de Waal &\nP. L. Tyack), pp. 322– 341. Cambridge, MA: Harvard\nUniversity Press.\n6 Pollard, K. A. & Blumstein, D. T. 2012 Evolving communicative complexity: insights from rodents and\nbeyond. Phil. Trans. R. Soc. B 367, 1869–1878.\n(doi:10.1098/rstb.2011.0221)\n7 Fedurek, P. & Slocombe, K. E. 2011 Primate vocal\ncommunication: a useful tool for understanding\nhuman speech and language evolution? Hum. Biol. 83,\n153– 173. (doi:10.3378/027.083.0202)\n8 Pinker, S. & Bloom, P. 1990 Natural-language and\nnatural selection. Behav. Brain Sci. 13, 707 –726.\n(doi:10.1017/S0140525X00081061)\n9 Byrne, R. W. & Whiten, A. 1988 Machiavellian intelligence. Oxford, UK: Oxford University Press.\n10 Dunbar, R. I. M. 1998 The social brain hypothesis.\nEvol. Anthropol. 6, 178–190. (doi:10.1002/(SICI)15206505(1998)6:5&lt;178::AID-EVAN5.3.0.CO;2-8)\n11 Whiten, A. & Byrne, R. W. 1988 Tactical deception in\nprimates. Behav. Brain Sci. 11, 233–273. (doi:10.\n1017/S0140525X00049682)\n12 Harcourt, A. & Stewart, K. J. 1989 Functions of alliances in contests within wild gorilla groups. Behaviour\n109, 176 –190. (doi:10.1163/156853989X00213)\n13 Dunbar, R. I. M. & Shultz, S. 2010 Bondedness and\nsociality. Behaviour 147, 775 –803. (doi:10.1163/\n000579510X501151)\n14 Silk, J. B. 2002 Using the ‘F’-word in primatology. Behaviour 139, 421–446. (doi:10.1163/156853902760102735)\n15 Smuts, B. B. 1985 Sex and friendship in baboons.\nNew York, NY: Aldine Publishing.\n16 Cheney, D. L. & Seyfarth, R. M. 2007 Baboon metaphysics: the evolution of a social mind. Chicago, IL: University\nof Chicago Press.\n17 Dunbar, R. I. M. 2009 The social brain hypothesis and\nits implications for social evolution. Ann. Hum. Biol. 36,\n562 –572. (doi:10.1080/03014460902960289)\n18 Silk, J. B., Alberts, S. C. & Altmann, J. 2003 Social bonds\nof female baboons enhance infant survival. Science 302,\n1231–1234. (doi:10.1126/science.1088580)\n19 Silk, J. B., Beehner, J. C., Bergman, T. J., Crockford, C.,\nEngh, A. L., Moscovice, L. R., Wittig, R. M., Seyfarth,\nR. M. & Cheney, D. L. 2010 Strong and consistent\nsocial bonds enhance the longevity of female baboons.\nCurr. Biol. 20, 1359–1361. (doi:10.1016/j.cub.2010.\n05.067)\n20 McComb, K. & Semple, S. 2005 Coevolution of vocal\ncommunication and sociality in primates. Biol. Lett. 1,\n381 –385. (doi:10.1098/rsbl.2005.0366)\n21 Hauser, M. D. 1996 The evolution of communication.\nCambridge, MA: MIT Press.\n22 Mulligan, B. E. & Nellis, D. W. 1975 Vocal repertoire of\nthe mongoose Herpestes auropunctatus. Behaviour 55,\n237 –257. (doi:10.1163/156853975X00489)\n23 Watts, C. H. S. 1975 Vocalizations of Australian hopping mice (Rodentia: Nutumys). J. Zool. Lond. 177,\n247 –263. (doi:10.1111/j.1469-7998.1975.tb05982.x)\n24 le Roux, A., Cherry, M. I. & Manser, M. B. 2009 The\nvocal repertoire in a solitary foraging carnivore, Cynictis\npenicillata, may reflect facultative sociality. Naturwissenschaften 96, 575– 584. (doi:10.1007/s00114-0080506-5)\n25 Wong, J., Stewart, P. & Macdonald, D. 1999 Vocal\nrepertoire in the European badger (Meles meles): structure, context, and function. J. Mammal. 80, 570 –588.\n(doi:10.2307/1383302)\n26 Pollard, K. A. & Blumstein, D. T. 2011 Social group\nsize predicts the evolution of individuality. Curr. Biol.\n21, 413–417. (doi:10.1016/j.cub.2011.01.051)\n27 Brady, C. A. 1981 The vocal repertoires of the bush dog\n(Speothos venaticus), crab-eating fox (Cerdocyon thous),\nand maned wolf (Chrysocyon brachyurus). Anim. Behav.\n29, 649 –669. (doi:10.1016/S0003-3472(81)80001-2)\n28 Green, S. 1975 Communication by a graded vocal\nsystem in Japanese monkeys. In Primate behavior, pp.\n1 –102. New York, NY: Academic Press.\n29 Leger, D. W., Owings, D. H. & Gelfand, D. L. 1980\nSingle-note vocalizations of California ground squirrels:\ngraded signals and situation-specificity of predator and\nsocially evoked calls. Z. Tierpsychol. 52, 227 –246.\n(doi:10.1111/j.1439-0310.1980.tb00714.x)\n30 Meise, K., Keller, C., Cowlishaw, G. & Fischer, J. 2011\nSources of acoustic variation: implications for production specificity and call categorization in chacma\nbaboon (Papio ursinus) grunts. J. Acoust. Soc. Am. 129,\n1631– 1641. (doi:10.1121/1.3531944)\n31 Peters, G. & Sliwa, A. 1997 Acoustic communication in\nthe aardwolf, Proteles cristatus (Carnivora: Hyaenidae).\nZ. Sa ̈ugetierkd 62, 219–238.\n32 Fischer, J., Metz, M., Seyfarth, R. M. & Cheney, D. L.\n2001 Baboon responses to graded bark variants. Anim.\nBehav. 61, 925 –931. (doi:10.1006/anbe.2000.1687)\n33 Harris, M. A., Murie, J. O. & Duncan, J. A. 1983\nResponses of Columbian ground squirrels to playback\nof recorded calls. Z. Tierpsychol. 63, 318–330. (doi:10.\n1111/j.1439-0310.1983.tb00747.x)\n34 le Roux, A., Jackson, T. P. & Cherry, M. I. 2001 Does\nBrants’ whistling rat (Parotomys brantsii ) use an\nurgency-based alarm system in reaction to aerial and\nterrestrial predators? Behaviour 138, 757–773. (doi:10.\n1163/156853901752233398)\n35 Baldwin, J. D. & Baldwin, J. I. 1976 Vocalizations of howler\nmonkeys (Alouatta palliata) in southwestern Panama. Folia\nPrimatol. 26, 81–108. (doi:10.1159/000155733)\n36 Charles-Dominique, P. 1977 Ecology and behaviour of\nnocturnal primates: prosimians of equatorial West Africa.\nNew York, NY: Columbia University Press.\n37 Robinson, J. G. 1979 An analysis of the organization of\nvocal communication in the titi monkey Callicebus\nmoloch. Z. Tierpsychol. 49, 381 –405. (doi:10.1111/j.\n1439-0310.1979.tb00300.x)\n38 Masataka, N. 1982 A field study on the vocalizations\nof Goeldi’s monkeys (Callimico goeldii). Primates 23,\n206 –219. (doi:10.1007/BF02381161)\n1856 M. L. Gustison et al. Primate vocal complexity\nPhil. Trans. R. Soc. B (2012)39 Robinson, J. G. 1984 Syntactic structures in the vocalizations of wedge-capped capuchin monkeys, Cebus\nolivaceus. Behaviour 90, 46– 79. (doi:10.1163/\n156853984X00551)\n40 Range, F. & Fischer, J. 2004 Vocal repertoire of sooty\nmangabeys (Cercocebus torquatus atys) in the Taı ̈\nNational Park. Ethology 110, 301 –321. (doi:10.1111/j.\n1439-0310.2004.00973.x)\n41 Strushaker, T. T. 1967 Auditory communication among\nvervet monkeys (Cercopithecus aethiops). In Social communication among primates (ed. S. A. Altmann)\nChicago, IL: University of Chicago Press.\n42 Palombit, R. A. 1992 A preliminary study of vocal communication in wild long-tailed macaques (Macaca\nfascicularis). I. Vocal repertoire and call emission. Int. J.\nPrimatol. 13, 143 –182. (doi:10.1007/BF02547839)\n43 Hohmann, G. 1991 Comparative analyses of agespecific and sex-specific patterns of vocal behavior in\n4 species of Old-World monkeys. Folia Primatol. 56,\n133 –156. (doi:10.1159/000156538)\n44 Kudo, H. 1987 The study of vocal communication of\nwild mandrills in Cameroon in relation to their social\nstructure. Primates 28, 289 –308. (doi:10.1007/\nBF02381013)\n45 Bermejo, M. & Omedes, A. 1999 Preliminary vocal\nrepertoire and vocal communication of wild bonobos\n(Pan paniscus) at Lilungu (Democratic Republic of\nCongo). Folia Primatol. 70, 328–357. (doi:10.1159/\n000021717)\n46 Goodall, J. 1986 The chimpanzees of Gombe. Cambridge,\nMA: Belknapp.\n47 MacKinnon, J. 1974 The behaviour and ecology of wild\norangutans (Pongo pygmaeus). Anim. Behav. 22, 3 –74.\n(doi:10.1016/S0003-3472(74)80054-0)\n48 Strushaker, T. T. 1975 The red colobus monkey. Chicago,\nIL: University of Chicago Press.\n49 Long, C. V. 2007 Vocalisations of the degu Octodon\ndegus, a social caviomorph rodent. Bioacoustics 16,\n223 –244.\n50 Robbins, R. L. 2000 Vocal communication in freeranging African wild dogs (Lycaon pictus). Behaviour\n137, 1271 –1298. (doi:10.1163/156853900501926)\n51 Manser, M. B. 2001 The acoustic structure of suricates’\nalarm calls varies with predator type and the level of\nresponse urgency. Proc. R. Soc. Lond. B 268, 2315–\n2324. (doi:10.1098/rspb.2001.1773)\n52 Manser, M. B. 1998 The evolution of auditory communication in suricates, Suricata suricatta. PhD thesis,\nUniversity of Cambridge, UK.\n53 Ackers, S. H. & Slobodchikoff, C. N. 1999 Communication of stimulus size and shape in alarm calls of\nGunnison’s prairie dogs, Cynomys gunnisoni. Ethology\n105, 149–162. (doi:10.1046/j.1439-0310.1999.00381.x)\n54 Greene, G. & Meagher, T. 1998 Red squirrels, Tamiasciurus hudsonicus, produce predator-class specific alarm\ncalls. Anim. Behav. 55, 511 –518. (doi:10.1006/anbe.\n1997.0620)\n55 Crockford, C. & Boesch, C. 2003 Context-specific calls\nin wild chimpanzees, Pan troglodytes verus: analysis of\nbarks. Anim. Behav. 66, 115 –125. (doi:10.1006/anbe.\n2003.2166)\n56 Seyfarth, R. M., Cheney, D. L. & Marler, P. 1980 Vervet\nmonkey alarm calls: semantic communication in a freeranging primate. Anim. Behav. 28, 1070–1094. (doi:10.\n1016/S0003-3472(80)80097-2)\n57 Stephan, C. & Zuberbu ̈ hler, K. 2008 Predation\nincreases acoustic complexity in primate alarm calls.\nBiol. Lett. 4, 641 –644. (doi:10.1098/rsbl.2008.0488)\n58 Macedonia, J. M. & Evans, C. S. 1993 Variation among\nmammalian alarm call systems and the problem of\nmeaning in animal signals. Ethology 93, 177 –197.\n(doi:10.1111/j.1439-0310.1993.tb00988.x)\n59 Hauser, M. D., Teixidor, P., Field, L. & Flaherty, R. 1993\nFood-elicited calls in chimpanzees –effects of food quantity and divisability. Anim. Behav. 45, 817 –819. (doi:10.\n1006/anbe.1993.1096)\n60 Roush, R. S. & Snowdon, C. T. 2000 Quality, quantity,\ndistribution and audience effects on food calling in\ncotton-top tamarins. Ethology 106, 673 –690. (doi:10.\n1046/j.1439-0310.2000.00581.x)\n61 Ouattara, K., Lemasson, A. & Zuberbu ̈ hler, K. 2009\nCampbell’s monkeys concatenate vocalizations into context-specific call sequences. Proc. Natl Acad. Sci. USA\n106, 22 026 –22 031. (doi:10.1073/pnas.0908118106)\n62 Arnold, K. & Zuberbu ̈ hler, K. 2006 The alarm-calling\nsystem of adult male putty-nosed monkeys, Cercopithecus nictitans martini. Anim. Behav. 72, 643 –653.\n(doi:10.1016/j.anbehav.2005.11.017)\n63 Cap, H., Deleporte, P., Joachim, J. & Reby, D. 2008\nMale vocal behavior and phylogeny in deer. Cladistics\n24, 917 –931. (doi:10.1111/j.1096-0031.2008.00223.x)\n64 Knornschild, M., Glockner, V. & von Helversen, O.\n2010 The vocal repertoire of two sympatric species of\nnectar-feeding bats (Glossophaga soricina and G. commissarisi). Acta Chiropterol. 12, 205 –215. (doi:10.3161/\n150811010X504707)\n65 Sieber, O. J. 1984 Vocal communication in raccoons\n(Procyon lotor). Behaviour 90, 80– 113. (doi:10.1163/\n156853984X00560)\n66 Hamilton III, W. J. & Arrowood, P. C. 1978 Copulatory\nvocalizations of chacma baboons (Papio ursinus), gibbons (Hylobates hoolock), and humans. Science 200,\n1405–1409. (doi:10.1126/science.663622)\n67 Henzi, P. S. 1996 Copulation calls and paternity in\nchacma baboons. Anim. Behav. 51, 233 –234. (doi:10.\n1006/anbe.1996.0021)\n68 Gros-Louis, J. 2002 Contexts and behavioral correlates\nof trill vocalizations in wild white-faced capuchin monkeys (Cebus capucinus). Am. J. Primatol. 57, 189– 202.\n(doi:10.1002/ajp.10042)\n69 Silk, J. B., Cheney, D. L. & Seyfarth, R. M. 1996 The\nform and function of post-conflict interactions between\nfemale baboons. Anim. Behav. 52, 259 –268. (doi:10.\n1006/anbe.1996.0171)\n70 Palombit, R. A., Cheney, D. L. & Seyfarth, R. M. 1999\nMale grunts as mediators of social interaction with\nfemales in wild chacma baboons (Papio cynocephalus\nursinus). Behaviour 136, 221 –242. (doi:10.1163/\n156853999501298)\n71 Peters, G. & Tonkin-Leyhausen, B. A. 1999 Evolution\nof acoustic communication signals of mammals:\nfriendly close-range vocalizations in Felidae (Carnivora). J. Mamm. Evol. 6, 129–159. (doi:10.1023/\nA:1020620121416)\n72 Koda, H., Shimooka, Y. & Sugiura, H. 2008 Effects of\ncaller activity and habitat visibility on contact call rate of\nwild Japanese macaques (Macaca fuscata). Am. J.\nPrimatol. 70, 1055–1063. (doi:10.1002/ajp.20597)\n73 Marler, P. 1977 The evolution of communication. In How\nanimals communicate (ed. T. A. Sebeok), pp. 45–70.\nBloomington, IN: Indiana University Press.\n74 Marler, P. & Mitani, J. 1988 Vocal communication in\nprimates and birds: parallels and contrasts. In Primate\nvocal communication (eds D. Todt, P. Goedeking & D.\nSymmes), pp. 3–14. Berlin, Germany: Springer.\n75 Philips, M. & Austad, S. N. 1990 Animal communication\nand social evolution. In Interpretation and explanation in\nthe study of animal behavior, Vol. 1. Interpretation, intentionality and communication (eds M. Bekoff & D. Jamieson),\npp. 254–268. Boulder, CO: Westview.\nPrimate vocal complexity M. L. Gustison et al. 1857\nPhil. Trans. R. Soc. B (2012)76 Waser, P. M. 1982 The evolution of male loud calls\namong mangabeys and baboons. In Primate communication (eds C. T. Snowdon, C. H. Brown & M. R.\nPetersen), pp. 117 –143. Cambridge, UK: Cambridge\nUniversity Press.\n77 Janik, V. M. & Slater, P. J. B. 1997 Vocal learning in\nmammals. Adv. Stud. Behav. 26, 59–99. (doi:10.1016/\nS0065-3454(08)60377-0)\n78 Zuberbu ̈ hler, K. 2003 Referential signaling in nonhuman primates: cognitive precursors and limitations\nfor the evolution of language. Adv. Stud. Behav. 33,\n265 –307. (doi:10.1016/S0065-3454(03)33006-2)\n79 Seyfarth, R. M. & Cheney, D. L. 2010 Production, usage,\nand comprehension in animal vocalizations. Brain Lang.\n115, 92–100. (doi:10.1016/j.bandl.2009.10.003)\n80 Fant, G. 1960 Acoustic theory of speech production. With\ncalculations based on X-ray studies of Russian articulations.\n’s-Gravenhage, The Netherlands: Mouton.\n81 Fitch, W. T. 2000 The evolution of speech: a comparative review. Trends Cogn. Sci. 4, 258–267. (doi:10.1016/\nS1364-6613(00)01494-7)\n82 Hauser, M. D. 1992 Articulatory and social factors\ninfluence the acoustic structure of rhesus monkey vocalizations: a learned mode of production? J. Acoust. Soc.\nAm. 91, 2175–2179. (doi:10.1121/1.403676)\n83 Rendall, D., Rodman, P. S. & Emond, R. E. 1996 Vocal\nrecognition of individuals and kin in free-ranging rhesus\nmonkeys. Anim. Behav. 51, 1007–1015. (doi:10.1006/\nanbe.1996.0103)\n84 Fitch, W. T. 1997 Vocal tract length and formant frequency dispersion correlate with body size in rhesus\nmacaques. J. Acoust. Soc. Am. 102, 1213–1222.\n(doi:10.1121/1.421048)\n85 Fitch, W. T. & Giedd, J. 1999 Morphology and development of the human vocal tract: a study using magnetic\nresonance imaging. J. Acoust. Soc. Am. 106, 1511–\n1522. (doi:10.1121/1.427148)\n86 Fitch, W. T. & Kelley, J. P. 2000 Perception of vocal\ntract resonances by whooping cranes Grus americana.\nEthology 106, 559–574. (doi:10.1046/j.1439-0310.\n2000.00572.x)\n87 Lieberman, P. H., Klatt, D. H. & Wilson, W. H. 1969\nVocal tract limitations on the vowel repertoires\nof rhesus monkey and other nonhuman primates.\nScience 164, 1185–1187. (doi:10.1126/science.164.\n3884.1185)\n88 Snowdon, C. T. 2009 Plasticity of communication in\nnonhuman primates. Adv. Stud. Behav. 40, 239 –276.\n(doi:10.1016/S0065-3454(09)40007-X)\n89 Pepperberg, I. M. 1981 Functional vocalizations by\nan African grey parrot (Psittacus erithacus).\nZ. Tierpsychol. 55, 139–160. (doi:10.1111/j.14390310.1981.tb01265.x)\n90 Ralls, K., Fiorelli, P. & Gish, S. 1985 Vocalizations and\nvocal mimicry in captive harbor seals, Phoca vitulina.\nCan. J. Zool. 63, 1050 –1056. (doi:10.1139/z85-157)\n91 Konrad, R. & Geissmann, T. 2006 Vocal diversity and\ntaxonomy of Nomascus in Cambodia. Int. J. Primatol.\n27, 713 –745. (doi:10.1007/s10764-006-9042-3)\n92 Me ́ndez-Ca ́rdenas, M., Randrianambinina, B., Rabesandratana, A., Rasoloharijaona, S. & Zimmermann, E.\n2008 Geographic variation in loud calls of sportive\nlemurs (Lepilemur ssp.) and their implications for conservation. Am. J. Primatol. 70, 828 –838. (doi:10.1002/ajp.\n20554)\n93 Mitani, J. C., Hunley, K. L. & Murdoch, M. E. 1999 Geographic variation in the calls of wild chimpanzees: a\nreassessment. Am. J. Primatol. 47, 133–151. (doi:10.\n1002/(SICI)1098-2345(1999)47:2,133::AID-AJP4.3.\n0.CO;2-I)\n94 Moore, J. L., Manne, L., Brooks, T., Burgess, N. D.,\nDavies, R., Rahbek, C., Williams, P. & Balmford, A.\n2002 The distribution of cultural and biological diversity in Africa. Proc. R. Soc. Lond. B 269, 1645– 1653.\n(doi:10.1098/rspb.2002.2075)\n95 Slocombe, K. E. & Zuberbu ̈ hler, K. 2007 Chimpanzees\nmodify recruitment screams as a function of audience\ncomposition. Proc. Natl Acad. Sci. USA 104, 17 228–\n17 233. (doi:10.1073/pnas.0706741104)\n96 Slocombe, K. E., Kaller, T., Turman, L., Townsend, S.\nW., Papworth, S., Squibbs, P. & Zuberbu ̈ hler, K. 2010\nProduction of food-associated calls in wild male chimpanzees is dependent on the composition of the\naudience. Behav. Ecol. Sociobiol. 64, 1959 –1966.\n(doi:10.1007/s00265-010-1006-0)\n97 Papworth, S., Bo ̈ se, A., Barker, J., Schel, A. M. &\nZuberbu ̈ hler, K. 2008 Male blue monkeys alarm call\nin response to danger experienced by others. Biol.\nLett. 4, 472–475. (doi:10.1098/rsbl.2008.0299)\n98 Di Bitetti, M. S. 2005 Food-associated calls and audience effects in tufted capuchin monkeys, Cebus apella\nnigritus. Anim. Behav. 69, 911 –919. (doi:10.1016/j.\nanbehav.2004.05.021)\n99 Pollick, A. S., Gouzoules, H. & de Waal, F. B. M. 2005\nAudience effects on food calls in captive brown\ncapuchin monkeys, Cebus apella. Anim. Behav. 70,\n1273– 1281. (doi:10.1016/j.anbehav.2005.03.007)\n100 Zuberbu ̈ hler, K., Cheney, D. L. & Seyfarth, R. M. 1999\nConceptual semantics in a nonhuman primate. J. Comp.\nPsychol. 113, 33–42. (doi:10.1037/0735-7036.113.1.33)\n101 Doupe, A. J. & Kuhl, P. K. 1999 Birdsong and human\nspeech: common themes and mechanisms. Annu. Rev.\nNeurosci. 22, 567 –631. (doi:10.1146/annurev.neuro.\n22.1.567)\n102 Bouchet, H., Pellier, A., Blois-Heulin, C. & Lemasson,\nA. 2010 Sex differences in the vocal repertoire of adult\nred-capped mangabeys (Cercocebus torquatus): a multilevel acoustic analysis. Am. J. Primatol. 72, 360–375.\n(doi:10.1002/ajp.20791)\n103 Bohn, K. M., Schmidt-French, B., Schwartz, C.,\nSmotherman, M. & Pollak, G. D. 2009 Versatility and\nstereotypy of free-tailed bat songs. PLoS ONE 4,\n6746. (doi:10.1371/journal.pone.0006746)\n104 Hockett, C. F. 1960 The origin of speech. Sci. Am. 203,\n88–96. (doi:10.1038/scientificamerican0960-88)\n105 Cleveland, J. & Snowdon, C. T. 1982 The complex\nvocal repertoire of the adult cotton-top tamarin\n(Saguinus oedipus oedipus). Z. Tierpsychol. 58, 231 –\n270. (doi:10.1111/j.1439-0310.1982.tb00320.x)\n106 MacLanahan, E. B. & Green, K. M. 1977 The vocal\nrepertoire and an analysis of the contexts of vocalizations in Leontopithecus rosalia. In The biology and\nconservation of the Callitrichidae (ed. D. G. Kleiman),\npp. 251–269. Washington, DC: Smithsonian Institute.\n107 Aiello, L. C. & Dunbar, R. I. M. 1993 Neocortex size,\ngroup size, and the evolution of language. Curr. Anthropol. 34, 184 –193. (doi:10.1086/204160)\n108 Dunbar, R. I. M. & Dunbar, P. 1975 Social dynamics of\ngelada baboons. Basel, Switzerland: Karger.\n109 Richman, B. 1987 Rhythm and melody in gelada vocal\nexchanges. Primates 28, 199 –223. (doi:10.1007/\nBF02382570)\n110 Page, S. L., Chiu, C. & Goodman, M. 1999 Molecular\nphylogeny of Old World monkeys (Cercopithecidae) as\ninferred from g-globin DNA sequences. Mol. Phylogenet.\nEvol. 13, 348–359. (doi:10.1006/mpev.1999.0653)\n111 Bergman, T. J. & Kitchen, D. M. 2009 Comparing\nresponses to novel objects in wild baboons (Papio\nursinus) and geladas (Theropithecus gelada). Anim.\nCogn. 12, 63–73. (doi:10.1007/s10071-008-0171-2)\n1858 M. L. Gustison et al. Primate vocal complexity\nPhil. Trans. R. Soc. B (2012)112 Beehner, J. C., Bergman, T. J., Cheney, D. L., Seyfarth,\nR. M. & Whitten, P. L. 2006 Testosterone predicts\nfuture dominance rank and mating activity among\nmale chacma baboons. Behav. Ecol. Sociobiol. 59,\n469–479. (doi:10.1007/s00265-005-0071-2)\n113 le Roux, A., Beehner, J. C. & Bergman, T. J. 2011 Female\nphilopatry and dominance patterns in wild geladas.\nAm. J. Primatol. 73, 422–430. (doi:10.1002/ajp.20916)\n114 Snyder-Mackler, N., Bergman, T. J. & Beehner, J. C. In\npress. Defining higher levels in a gelada multilevel\nsociety. Int. J. Primatol. (doi:10.1007/s10764-0129584-5)\n115 Kawai, M., Ohsawa, H., Mori, U. & Dunbar, R. 1983\nSocial organization of gelada baboons: social units\nand definitions. Primates 24, 13–24. (doi:10.1007/\nBF02381450)\n116 Bergman, T. J. 2010 Experimental evidence for limited\nvocal recognition in a wild primate: implications for the\nsocial complexity hypothesis. Proc. R. Soc. B 277,\n3045–3053. (doi:10.1098/rspb.2010.0580)\n117 le Roux, A. & Bergman, T. J. 2012 Indirect rival assessment in a social primate, Theropithecus gelada. Anim.\nBehav. 83, 249 –255. (doi:10.1016/j.anbehav.2011.10.\n034)\n118 Dunbar, R. I. M. 1984 Reproductive decisions: an economic analysis of gelada baboon social strategies.\nPrinceton, NJ: Princeton University Press.\n119 Mori, U. 1979 Reproductive behaviour. In Ecological\nand sociological studies of gelada baboons (ed. M.\nKawai), pp. 183– 199. Tokyo: Kodansha.\n120 Dunbar, R. I. M. 1977 Feeding ecology of gelada\nbaboons: a preliminary report. In Primate ecology (ed.\nT. H. Clutton-Brock), pp. 250–273. London, UK:\nAcademic Press.\n121 Dunbar, R. I. M. & Bose, U. 1991 Adaptation to grasseating in gelada baboons. Primates 32, 1–7. (doi:10.\n1007/BF02381596)\n122 Iwamoto, T. 1993 The ecology of Theropithecus gelada.\nIn Theropithecus: the rise and fall of a primate genus\n(ed N. G. Jablonski), pp. 441– 452. Cambridge, UK:\nCambridge University Press.\n123 Fischer, J., Hammerschmidt, K., Cheney, D. L. & Seyfarth, R. M. 2001 Acoustic features of female chacma\nbaboon barks. Ethology 107, 33–54.\n124 Owren, M. J., Seyfarth, R. M. & Cheney, D. L. 1997 The\nacoustic features of vowel-like grunt calls in chacma\nbaboons (Papio cyncephalus ursinus): implications for production processes and functions. J. Acoust. Soc. Am. 101,\n2951–2963. (doi:10.1121/1.418523)\n125 Rendall, D., Seyfarth, R. M., Cheney, D. L. & Owren,\nM. J. 1999 The meaning and function of grunt variants\nin baboons. Anim. Behav. 57, 583– 592. (doi:10.1006/\nanbe.1998.1031)\n126 Fischer, J., Hammerschmidt, K., Cheney, D. L. & Seyfarth, R. M. 2002 Acoustic features of male baboon\nloud calls: influences of context, age, and individuality.\nJ. Acoust. Soc. Am. 111, 1465–1974. (doi:10.1121/1.\n1433807)\n127 Altmann, S. A. 1998 Foraging for survival: yearling baboons\nin Africa. Chicago, IL: University of Chicago Press.\n128 Altmann, S. A. & Altmann, J. 1970 Baboon ecology.\nChicago, IL: University of Chicago Press.\n129 Norton, G. W., Rhine, R. J., Wynn, G. W. & Wynn, R. D.\n1987 Baboon diet: a five-year study of stability and variability in the plant feeding and habitat of the yellow\nbaboon (Papio cynocephalus) of Mikumi National Park,\nTanzania. Folia Primatol. 48, 78–120. (doi:10.1159/\n000156287)\n130 Rowell, T. E. 1966 Forest living baboons in Uganda.\nJ. Zool. 149, 344 –364. (doi:10.1111/j.1469-7998.\n1966.tb04054.x)\n131 Hall, K. R. L. & DeVore, I. 1965 Baboon social behavior. In Primate social behavior (eds I. DeVore & K. R. L.\nHall), pp. 53–110. New York, NY: Holt, Rinehart &\nWinston.\n132 Aich, H., Moos-Heilen, R. & Zimmermann, E. 1990\nVocalizations of adult gelada baboons (Theropithecus\ngelada): acoustic structure and behavioural context.\nFolia Primatol. 55, 109– 132. (doi:10.1159/000156508)\n133 Lehner, P. N. 1996 Handbook of ethological methods.\nCambridge, UK: Cambridge University Press.\n134 Cheney, D. L., Seyfarth, R. M. & Silk, J. B. 1995 The\nrole of grunts in reconciling opponents and facilitating\ninteractions among adult female baboons. Anim.\nBehav. 50, 249–257. (doi:10.1006/anbe.1995.0237)\n135 Richman, B. 1976 Some vocal distinctive features used\nby gelada monkeys. J. Acoust. Soc. Am. 60, 718– 776.\n(doi:10.1121/1.381144)\n136 Fischer, J., Kitchen, D. M., Seyfarth, R. M. & Cheney,\nD. L. 2004 Baboon loud calls advertise male quality:\nacoustic features and their relation to rank, age, and\nexhaustion. Behav. Ecol. Sociobiol. 56, 140 –148.\n(doi:10.1007/s00265-003-0739-4)\n137 Kitchen, D. M., Cheney, D. L. & Seyfarth, R. M. 2005\nMale chacma baboons (Papio hamadryas ursinus) discriminate loud call contests between rivals of different\nrelative ranks. Anim. Cogn. 8, 1– 6. (doi:10.1007/\ns10071-004-0222-2)\n138 Wittig, R. M., Crockford, C., Seyfarth, R. M. &\nCheney, D. L. 2007 Vocal alliances in chacma baboons\n(Papio hamadryas ursinus). Behav. Ecol. Sociobiol. 61,\n899 –909. (doi:10.1007/s00265-006-0319-5)\n139 Andrew, R. J. 1976 Use of formants in the grunts of\nbaboons and other nonhuman primates. Ann. NY\nAcad. Sci. 280, 673– 693. (doi:10.1111/j.1749-6632.\n1976.tb25530.x)\n140 Palagi, E., Leone, A., Mancini, G. & Ferrari, P. F. 2009\nContagious yawning in gelada baboons as a possible\nexpression of empathy. Proc. Natl Acad. Sci. USA 106,\n19 262– 19 267. (doi:10.1073/pnas.0910891106)\n141 Dunbar, R. I. M. 1993 Coevolution of neocortical size,\ngroup size and language in humans. Behav. Brain Sci.\n16, 681 –693. (doi:10.1017/S0140525X00032325)\n142 Schreier, A. L. & Swedell, L. 2009 The fourth level of\nsocial structure in a multi-level society: ecological and\nsocial functions of clans in hamadryas baboons.\nAm. J. Primatol. 71, 948 –955. (doi:10.1002/ajp.20736)\n143 Aureli, F., Preston, S. D. & de Waal, F. 1999 Heart rate\nresponses to social interactions in free-moving rhesus\nmacaques (Macaca mulatta): a pilot study. J. Comp. Psychol. 113, 59–65. (doi:10.1037/0735-7036.113.1.59)\n144 Dunbar, R. I. M. 2010 The social role of touch in\nhumans and primates: behavioural function and neurobiological mechanisms. Neurosci. Biobehav. Rev. 34,\n260 –268. (doi:10.1016/j.neubiorev.2008.07.001)\n145 Keverne, E. B., Martensz, N. D. & Tuite, B. 1989 Betaendorphin concentrations in cerebrospinal fluid of\nmonkeys are influenced by grooming relationships.\nPsychoneuroendocrinology 14, 155 –161. (doi:10.1016/\n0306-4530(89)90065-6)\nPrimate vocal complexity M. L. Gustison et al. 1859\nPhil. Trans. R. Soc. B (2012)", "affiliations": [{"country": "United States", "discipline": "Biology", "university": "University of Michigan"}, {"country": "United States", "discipline": "Psychology", "university": "University of Michigan"}, {"country": "South Africa", "discipline": "Zoology", "university": "University of the Free State"}], "species_categories": ["Primate"], "specialized_species": ["geladas", "chacma baboons"], "computational_stages": ["Meaning Identification"], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882666", "updated_at": "2026-01-13T16:08:14.185737", "committed_at": "2026-01-13T13:56:31.738454"}
{"id": "582bfd51-8d4d-4c45-be29-3104800fc8d8", "title": "Cued and detached representations in animal cognition", "authors": ["G\\\"{a}rdenfors,  Peter"], "year": "1995", "journal": "Behavioural Processes", "abstract": "", "doi": "10.1016/0376-6357(95)00043-7", "analysis_notes": "ELSEVIER Behavioural Processes 35 (1996) 263-273\nBEHAVI~URAL\nPROCESSES\nCued and detached representations in animal cognition\nPeter Giidenfors *\nCognitive Science, Lund University, Kungshuse!, S-222 22 Lund. Sweden\nAccepted 6 March 1995\nAbstract\nThis paper analyzes the function of certain aspects of cognition, like planning, deceiving, self-awareness, and\ncommunication. I distinguish between two kinds of representations of information. A cued representation stands\nfor something that is present in the current situation. Detached representations stand for objects or events that\nare neither present in the situation nor triggered by some recent situation. The inner environment of an animal is\ndefined as the collection of all detached representations. The fundamental difference between signals and\nsymbols is that the reference of a symbol is a detached representation, while a signal refers to a cued\nrepresentation. Detached representations make planning possible. I distinguish between immediate planning,\nwhere plans are made for present needs, and anticipatory planning, where future needs are predicted. The\nevolution of self-consciousness is outlined as a series of steps. The first is when other agents are seen as having\nan inner environment of their own. This is when deception becomes possible. A further step is when the agent\nrealizes that the other agents’ representations of the external world includes a representation of the inner\nenvironment of the agent itself. Then the agent can become self-conscious since it can form representations of\nits own representations.\nKeywords: Mental representation; Animal cognition; Planning; Deception; Symbols; Self-awareness\nL’homo tient debout. Saccouple, en toute saison, face a face. A le pouce opposable. Omnivore.\nCapable d’attention, me^me h des objets absents. Sous le nom de pen&e, reflexion, obsessions, etc., il\npeut rPver durablement pendant la veille, combiner ses r&es h ses perceptions, en tirer des projets\nd’actes, des coordinations de mouvements, we sorte de re’organisation des instincts, des d&sirs, etc. II\nmodifie le milieu. II accumule, conserve, pre’voit, innove; il a des moyens de parvenir.\nPaul ValCry, Mauvaises Pens&es et Autres\n* E-mail: Peter.Gardenfors@fil.lu.se\n0376.6357/96/$ I5.00 0 1996 Elsevier Science B.V. All rights reserved\nSST)10376.6357(95)00043-7264 P. Giirdenjbrs / Behavinural Processes 35 (1996) 263-273\n1. The notion of a representation: Why a snake can’t think of a mouse\nWhen analyzing the cognitive functions of the ‘higher’ animal species, we often ascribe them a\nform of consciousness that includes functions like imagining, planning, deceiving, choosing, being\naware of other minds, and maybe even being self-conscious. Our naive understanding of such\ncognitive functions derives from our understanding of the corresponding human functions.\nIn this paper, I want to examine these features of cognition from an evolutionary perspective.\nRather than directly comparing, e.g., animal planning with human planning, I will ask, firstly, what\ncould be the evolutionary value of having a capability for planning, and, secondly, what other\ncognitive functions are required for such a capacity to evolve. My focus in this paper will be to\nanalyze the evolutionary jbzctions of certain aspects of cognition rather than to study their\nneurophysiological foundations or their behavioral correlates.\nI will argue that in order to understand the functions of most of the higher forms of cognition, one\nmust rely on an analysis of how animals represent various things, in particular the surrounding world\nand its possibilities. However, the very notion of a mental representation is one of the enigmas of\ncontemporary cognitive science.\nRoitblat (1982, p. 354) characterizes representations, at the most general level, as those things\n“that allow past experience to affect later behavior”. This definition seems to be too liberal since it\nincludes, as Roitblat himself recognizes, even the behaviorists’ approach. Whiten and Byrne’s\nproposal is equally liberal: “By ‘representation’ we mean simply a neurally coded counterpart of\nsome aspect of the world.“(Whiten and Byrne, 1988: p. 235).\nYet another definition is proposed by Vauclair (1990, p. 3 12): “Representation is an individual\nphenomenon by which an organism structures its knowledge with regards to its environment. This\nknowledge can take two basic forms: either reference to internal substitutes (e.g., indexes or images)\nor use of external substitutes (e.g., symbols, signals, or words)“. Again, I find the general\ncharacterization too encompassing. However, Vauclair presents Hackett’s notion of ‘displacement’\n(Hackett, 1960) and von Glasersfeld’s criticism of it in his discussion of animal communication (von\nGlasersfeld, 19771, which comes close to the proposal made here (see Section 7.\nI have no elaborated theory of representation to present, but a distinction that seems to capture an\nimportant aspect is that between transduced and inferred information (compare Fodor, 1986). Some\nkinds of animal behavior, like phototaxis, are determined directly by psychophysical mechanisms that\ntransduce information about the environment. In such cases no representations are involved. In other\ncases, the animal uses the incoming information as cues to ‘perceptual inferences’, which add\ninformation to what is obtained by the psychophysical transducers. That which adds information to\nsensory input I propose to call a representation ‘.\nIn order to illustrate the distinction between transduced and inferred information, let me present an\nexample borrowed from Sjijlander (1993, pp. 3-4) of how the different kinds of information will\naffect animal behavior. It seems that a snake does not have a central representation of a mouse but\n’ Fodor (1986, pp. IS- 16) argues that transduced information is equivalent to information about nomic properties. He\nprefers non-nomicness as a characterization of representations since “there is independent reason to suppose that nomicness\nis the more fundamental notion: unlike transduction nomicness is a concept that we need outside the information sciences”.\n(p. 16) I don’t accept this argument, since I, among other things, don’t share the scientific realism that underlies his notion of\nnomicness. Hence I stick to transducibility.P. G~rden~ors/Behavioural Processes 35 (1996) 263-273 265\nrelies solely on transduced information. The snake exploits three different sensory systems in relation\nto prey, such as a mouse. To strike the mouse, the snake uses its visual system (or thermal sensors).\nWhen struck, the mouse normally does not die immediately, but runs away for some distance. To\nlocate the mouse, once the prey has been struck, the snake uses its sense of smell. The search\nbehaviour is exclusively wired to this modality. Even if the mouse happens to die right in front of\nsnake’s eyes, it will still follow the smell trace of the mouse in order to find it. Finally, after the\nmouse has been located, the snake must find its head in order to swallow it. This could obviously be\ndone with the aid of smell or sight, but in snakes this process uses only tactile information. Thus the\nsnake uses three separate modalities to catch and eat a mouse. It has no central representation of a\nmouse since there is no communication between the three systems (except that one takes over when\nthe other finishes).\nCompare this with a cat chasing a mouse! The cat relies on a combination of information from\nseveral sensors: eyes, ears, nose, paws and maybe even whiskers. It can predict that the mouse will\nappear at the other side of a curtain when it disappears on one side. It can ‘infer’ information about\nthe mouse even if there is no immediate sensory information, for example when it is waiting outside a\nmouse-hole. In this sense the cat has a central representation of a mouse that is, at least to some\nextent, independent of the information transduced from any of the sensory modalities. In more\ntechnical terminology borrowed from Piaget, one can say that the cat has achieved object permanence. In contrast, the snake has no unified representation of a mouse (if it is appropriate to say that it\nhas a representation at all).\nOne conclusion to draw from this comparison between the cognitive powers of a snake and a cat is\nthat a central representation is tightly connected with cross-modality, i.e., that information received\nvia one modality is coordinated with information from other modalities. Davenport (1976) presents\nsome major results on cross-modal perception in apes and monkeys (see also Murray, 1990). He has\nthe following remarks on the evolutionary value of cross-modality: “First, it appears that multimodal\ninformation extraction of environmental information is likely to result in more veridical perception,\nand may facilitate cognitive functioning. Second, in my view, cross-modal perception requires the\nderivation of modality-free information, a ‘representation’. That an organism can have the same\nrepresentations, concepts or percepts, regardless of the method of peripheral reception, confers great\nadvantage on that animal in coping with the demands of living (Davenport, 1976, p. 147)“.\nCategorization is, in general, exploiting representations. When, for example, a bird not only sees a\nparticular object, but sees it as food, the bird’s brain is adding information about the perceived object\nthat, e.g., leads to the conclusion that the object can be swallowed. Since information is added,\nmistakes become possible, i.e., the inferences drawn from the representation may turn out to be wrong\n(“Pardon me”, said the the hedgehog and climbed off the scrubbing-brush). When 1 speak of\ninferences, I am in no way implying that they are made in an explicit form, symbolic or otherwise\n(see Gardenfors, 1994). Nor am I assuming that the animal is, in any sense, aware of the\nrepresentation, only that there is some generalizing factor that determines its behavior.\n2. Cued vs. detached representations: Why a chimp can make a tool\nMy primary aim in this article is not to demarcate representations from non-representations.\nHowever, I want to emphasize that there are different kinds of representations. The central thesis of266 P. Giirdenj~rs/Behuuiourcrl Processes 35 (1996) 263-273\nthis paper is that in order to give an accurate analysis of many phenomena in animal and human\ncognition, it is necessary to distinguish between two kinds of representations: cued and detached.\nA cued representation stands for something that is present in the current external situation of the\nrepresenting organism. A cat that hears a crunching sound in the closet and comes to believe that\nthere is a mouse there is using its perceptual stimuli as a cue for its mouse representation. In general,\nthe represented object need not be actually present in the situation, but the representation must have\nbeen triggered by something in a recent situation. Delayed responses, in the behaviorist’s sense, are\nbased on cued representations according to this characterization.\nIn contrast, detached representations may stand for objects or events that are neither present in the\ncurrent situation nor triggered by some recent situation. A detached representation thus requires no\nperceptual cue in order to be activated. A memory of something, that can be evoked independently of\nthe context where the memory was created, would be an example of a detached representation. For\nanother example, consider a chimpanzee, who performs the following sequence of actions: walks\naway from a termite hill, breaks a twig, peels its leaves off to make a stick, returns to the termite hill,\nand uses the stick to ‘fish’ for termites. This behavior seems impossible to explain unless it is\nassumed that the chimp has a detached representation of a stick and its use.\nI am not claiming that it is possible to draw a sharp line between cued and detached representations. There are degrees of detachment, and, as will be seen below, there are different types of\ndetachment. However, I still believe that the rough distinction between the two major kinds of\nrepresentations is instrumental in that it directs our attention to key features of the representational\nforms.\nA closely related distinction is proposed by Gopnik (1982, p. 378) who wants to “distinguish\nrepresentations in which there is some direct causal connection between the states from those in which\nthere is no direct causal connection”. In most cases this will give the same results as distinguishing\nbetween cued and detached representations. However, there are many kinds of causal links which are\nnot separated by Gopnik, for example the distinction between transduced and inferred information.\nFurthermore, I will try to show that it is fruitful to separate different kinds of ‘detachment’. I thus\nbelieve that my analysis is more fine-grained than what would have resulted from applying Gopnik’s\ndistinction.\nA caveat concerning my use of the notion of representation is that I view representations as\ntheoretical terms, in the way conceived of in philosophy of science (e.g., Sneed, 1971). Representations are theoretical idealizations, similar to ‘forces’ in Newtonian mechanics, that are introduced to\npredict and explain empirical generalizations (see Lachman and Lachman, 1982).\n3. The inner environment: Why lizards don’t dream\nWhat is the main advantage of detached representations in comparison to cued ones? In order to\nanswer this question, I will elaborate on an idea introduced by Craik (1943, p. 61): “If the organism\ncarries a ‘small-scale model’ of external reality and of its own possible actions within its head, it is\nable to try out various alternatives, conclude which are the best of them, react to future situations\nbefore they arise, utilize the knowledge of past events in dealing with the present and future, and in\nevery way to react in a much fuller, safer and more competent manner to the emergencies which face\nit”.P. Giirdenfors/ Brhmiourul Processes 35 (1996) 263-273 261\nUnder the heading of the inner environment, this kind of ‘small-scale model’ has been made\npopular by Dennett (1978): “the inner environment is simply any internal region that can affect and\nbe affected by features of potential behavioral control systems” (p. 79). Such an environment is\nnecessary for representing objects (like food and predators), places (where food or shelter can be\nfound), actions (and their consequences), etc., even when these things are not perceptually present.\nThe evolution of this kind of representational power will clearly increase the survival value of the\nanimal.\nAs a tentative definition, the inner environment of an animal will in this paper be identified with\nthe system of all detached representations of the animal and their interrelations. In particular, the\ndynamic features of the objects represented are included in the inner environment. Such features are\nessential for inferring consequences of possible actions. Again, I am not assuming that the animal is\naware of its inner environment, or of the processes utilizing this construct. This would amount to\nself-awareness, as will be discussed in Section 6.\nLike all theories of mind, the inner environment is a metaphor. Metaphors are neither true nor\nfalse, but they can be more or less productive as heuristics for developing more precise theories. In\nwhat follows, I want to show that the metaphor of the inner environment can help us explain the\nevolutionary value of several cognitive functions.\nIt seems that many species of animals have inner environments. For example, the searching\nbehavior of rats is best explained if it is assumed that they have some form of ‘spatial maps’ in their\nheads. Evidence for this, based on their ability to find optimal paths in mazes, was collected by\nTolman as early as the 1930s (see Tolman, 1948). However, his results were swept under the carpet\nfor many years since they were clear anomalies for the behaviorist paradigm. Vauclair (1987)\nprovides a more recent analysis of the notion of a ‘cognitive mapping’.\nIt is difficult to assess when the inner environment first appeared in the animal kingdom, but a wild\nguess is that it is coordinated with the development of the neocortex, i.e., roughly with the appearance\nof mammals. However, it is only with the development of cross-modal representations that we obtain\nadvanced forms of an inner environment (Davenport, 1976, Murray, 1990). Sjijlander (1993) notes\nthat mammals play, but reptiles don’t. There is also evidence of dreaming, which clearly presumes\nan inner environment, only among the mammals (see Fagen, 1981). Thus dogs can dream about\nhunting, but lizards cannot.\nAlso, birds seem to have cognitive capacities that presuppose something like an inner environment\n(interestingly enough, it is only mammals and birds who have a constant body temperature). For\nexample, their advanced spatial representations are well documented. It should be noted though, that\neven if several other taxa have spatial abilities, by being able to utilize landmarks etc., this does not\nentail that they have an inner environment. One operational test for the existence of a spatial inner\nenvironment is the ability to take shortcuts when previous hinders are removed.\nMy aim in the remainder of the paper is to establish that existence of an inner environment is a\nprerequisite for the evolution of many higher cognitive functions. The functions I will consider are\nplanning, deception, self-awareness, and linguistic communication.\n4. Planning: Why the squirrel does not make any provisions for the winter\nOne of the main evolutionary advantages of an inner environment is that it frees an animal who is\nseeking a solution to a problem from dangerous trial-and-error behavior. Jeannerod ( 1994, p. 2) says268 P. Giirdenfors/ Behavioural Processes 35 (1996) 263-273\nthat “actions are driven by an internally represented goal rather than directly by the external world”.\nBy exploiting its inner environment, the animal can simulate a number of different actions in order to\n‘see’ their consequences and evaluate them. After these simulations, it can choose the most\nappropriate action to perform in theeouterenviromuent. Of course, the success of the simulations\ndepends on how well the mner envtronment is matched to the perceptions of the outer. A monkey\nwho imagines a branch where there is none is soon a dead monkey - evolutionary selection pressures\nwill, in the long run, result in a sufficient correspondence between the two environments.\nThe ability to envision various actions and their consequences is a necessary requirement for an\nanimal to be capable of planning. Following Gulz (1991, p. 46), I will use the following criterion: An\nanimal is planning its actions if it has a representation of a goal and a start situation and it is capable\nof generating a representation of partially ordered set of actions for itself for getting from start to goal.\nThe representations of the goal and the actions must be detached, otherwise the animal has no choice.\nIn brief, planning presupposes an inner environment.\nThere are several clear cases of planning among primates and less clear cases in other species (see,\ne.g. Chapters 5, 7, 8 and 9 in Ellen and Thinus-Blanc, 1987, and pp. 58-61 in Gulz, 1991). The\ntermite-fishing chimpanzee mentioned earlier is one such example. By the way, this is an example of\nplanned tool-making.\nHowever, all evidence for planning in non-human animals concerns planning for present needs.\nApes and other animals plan because they are hungry or thirsty, tired or frightened. Oakley (1961 p.\n187) notes: “Sultan, the chimpanzee observed by Kohler, was capable of improvising tools in certain\nsituations. Tool-making occurred only in the presence of a visible reward, and never without it. In the\nchimpanzee the mental range seems to be limited to present situations, with little conception of past or\nfuture”.\nHumans seem to be the only animal that can plan for future needs. Gulz (1991, p. 55) calls\nplanning for present needs immediate planning while planning for the future is called anticipatory\nplanning. Humans can predict that they will be hungry tomorrow and save some food, and we realize\nthat the winter will be cold, so we start building a shelter already in the summer. The crucial\ndistinction is that for an animal to be capable of anticipatory planning it must have a detached\nrepresentation of its fiture needs. In contrast, immediate planning only requires a cued representation\nof the current need. There is nothing in the available evidence concerning animal planning,\nnotwithstanding all its methodological problems, that suggests that any species other than Homo\nsapiens has detached representations of their desires.\nBut, isn’t the squirrel who is gathering and storing food for the winter engaged in anticipatory\nplanning? No, it is not planning at all. It has no detached representation of the winter, let alone its\nneeds during the winter. The gathering behavior is routine behavior of an instinctual nature that\nappears stereotypically without sensitivity to varying circumstances. For example, if one fills the\nsquirrel’s stores, it still continues gathering until the ‘urge’ is gone.\n5. Deception: Why the partridge feigning a broken wing isn’t fooling the fox\nI want to analyze the evolution of self-consciousness as a series of comparatively small steps. A\ngood planner must consider the actions of other individuals (in particular if the planner belongs to a\nsocial species). A special case of representations in the inner environment concerns the minds of otherP. Girdenfors/ Behuvioural Procrsses 35 (I 996) 263-273 269\nindividuals. In my opinion, the first step in the evolution of self-consciousness is when other agents\nare not only seen as acting things, but as having an inner environment of their own, with beliefs,\ndesires, etc.\nIt is only when this representational capacity is accomplished that deception becomes possible.\nDeception, in the intentional sense, presumes a representation of other minds. To see this, let us turn\nto the worthwhile survey of tactical deception in primates by Whiten and Byrne (1988). After their\ninitial attempt to define ‘tactical deception’ was criticized in the commentary, they ended up with the\nfollowing definition (1988, p. 271): “Acts from the normal repertoire of the AGENT, deployed such\nthat another individual is likely to misinterpret what the acts signify, to the advantage of the\nAGENT’ ’ .\nThe key word in this definition is ‘deployed’. When this word refers to human behavior, it refers to\nan intentional act. I submit that the ordinary use of deception presupposes that the deceiver has some\nrepresentation of how the individual to be deceived will interpret the deceiving act. In other words,\ndeception presupposes that the inner environment of the deceiver contains some form of representution of the inner environment of the target individual. Note that deception presumes all the cognitive\nfunctions of (immediate) planning, and some more, i.e., an inner environment containing a model of\nthe inner environment of other individuals. Thus, this analysis predicts that deception will occur later\nthan planning in the evolution of cognitive functions. This thesis is most naturally interpreted as a\nstatement about phylogeny, but can also be given an ontogenetical meaning.\nWhiten and Byrne (1988) present a series of examples of potential cases of deception among\nprimates. Most examples come from field observations of chimpanzees and baboons *. However,\nalmost all evidence is based on more or less anecdotal material. Lacking controlled experiments, it is\ntherefore strongly debatable whether the evidence can establish that deception in the intentional sense\noccurs among animals other than humans (see Bennett, 1988).\nHowever, there are cases when it is clear that deception is not taking place: The partridge feigning\na broken wing to lure away the fox from her chicks is not fooling the fox. ‘Fooling’ presumes an\nintention to make somebody else misinterpret the fooling act. There is no evidence that the partridge\nhas any representation of what the fox thinks. She merely acts instinctively when the fox approaches\nand can hence not have any intention to fool.\n6. Self-awareness: Why baboons don’t wear lipstick\nDeception, in the full intentional sense, presupposes that the deceiver has a representation of the\ndeceived one’s inner environment. On this level, an animal can have goals concerning the intentions\nof other individuals, e.g., want somebody to believe that an attack would fail. This is an example of a\nsecond-order intention.\n2 Gallup (1988, p. 255) notes that “the absence of any evidence of deception in orangutans, who, like chimpanzees, can\nalso correctly decipher mirrored information about themselves, is not surprising in so much as they lead a rather solitary\nexistence in the first place. In fact, I have even conjectured [...I that the reason orangutans are so reclusive may be because\nthey have learned that other orangutans cannot be trusted!“.270 P. Giirdenfors/Behuuioural Processes 35 (1996) 263-273\nBut a smart agent will not be duped: he will realize that somebody is trying to deceive him and\ncounteract. Hence, the really smart deceiver will foresee the reasoning of such a smart agent (see\nDennett, 1988). The important aspect of this escalation in smartness is that it can only work if the\npotential deceiver realizes that the agent he wants to deceive not only has her own representations of\nthe external world, but that her inner world contains a representation of the deceiver himself.\nDo animals other than humans have self-awareness? Gallup’s experiments (Gallup, 1977) show\nthat chimpanzees and orangutans, but no other primates, can recognize themselves in mirrors ‘. And\nwhen it comes to recognizing oneself in a photograph, only chimpanzees seem to be successful.\nBodily decorations only make sense when you have some form of awareness of your own body.\nSuch decorations occur in all human cultures, but in no other species in an intentional way. Thus,\nbaboons could never come up with the idea of using lipstick.\nBut recognizing oneself in a mirror or in a photograph only requires awareness of one’s own body,\nnot of one’s own mind. The final step in the evolution of higher-level inner representation is small but\ncrucial for self-awareness in its proper sense: I must realize that the inner environment of my\nopponent does not only contain a representation of myself as a bodily agent, but as an agent with\ninner representations as well. I propose that it is only after this insight that the agent can become\nself-conscious in the sense that it can form representations of its own representations. Some support\nfor this evolutionary point can also be obtained from recent results in developmental psychology (see\ne.g. Wimmer and Hard, 1991 and Gopnik, 1993).\nAs a final step, self-awareness can then develop as a shortcut in the representations involved in the\ndeception game: I can, in my inner environment, have a representation of my own inner environment.\nHowever, I submit that this kind of self-awareness could never develop without the previous\nestablishment of a representation of the inner environment of other individuals. In other words, I\nclaim that an ‘I’-experience must be preceded by a ‘you’-experience (see also Mead, 1934,\nGardenfors, In Press, b, and Gomez, 1994). This position contradicts the traditional Cartesian view on\nmind where humans are supposed to have direct access to their thoughts 4.\n7. Language: Why bees don’t tell stories to one another\nThinking does not presume a language. Humans, as well as animals, can simulate sequences of\nactions in their inner environments. Such simulations are, among other things, necessary for planning.\nI shall argue that language is a very late phenomenon on the evolutionary scene. As I have tried to\n3 Epstein, Lanza and Skinner (Epstein et al., 1980) performed a similar experiment intending to show that also pigeons\ncan learn the same kind of behavior. Davis (1989) argues, in my opinion convincingly, that their experiment does not show\nthat pigeons have any form of self-awareness.\n4 Gopnik (1993) calls this “the illusion of expertise.” She writes: “The commonsense picture proposes that we have\nintentional psychological states, then we have psychological experiences of the intentionality of those states, then we observe\nour own behavior that follows those states, and finally, we attribute the states to others with similar behavior. I suggest a\ndifferent sequence: First we have psychological states, observe the behaviors and experiences they lead to in ourselves and\nothers, construct a theory about the causes of those behaviors and experiences that postulates intentionality, and then, in\nconsequence, we have experiences of the intentionality of those states” (1993, p.12).P. Giirdenfors / Behuuiourul Procrsses 35 (1996) 263-273 271\nshow in the previous sections, an individual can have a great deal of cognitive functions, including\nself-awareness, without having a symbolic language 5.\nIn contrast, I submit that language presumes the existence of an intricate inner environment. In\norder to make this clear, I will propose a definition of the distinction between signals and symbols.\nBoth signals and symbols are tools of communication. The fundamental difference between them is\nthat the reference of a symbol is a detached representation, while a signal refers to a cued\nrepresentation. In other words, a signal refers to something in the outer environment, while a symbol\nrefers to the inner environment. Language consists of symbols - it can be used to talk about things\nnot present in the current situation. This idea can be traced back to Hackett’s (Hackett, 1960) notion\nof ‘displacement’. Sjalander (1993, pp. 5-6) expresses the point as follows: “The predominant\nfunction of language is to communicate about that which is not here and not now. A dog can ‘say’: I\nam angry, I want water, I want to go out, I like you, etc. But it has no communicative means enabling\nit to ‘say’: I was angry yesterday, nor can it ‘say’: I will be angry if you lock me up tonight again,\nand I will chew up the carpet. Likewise, the dog can ‘say’: There is a rat here! but it cannot ‘say’:\nThere is a rat in the next room.\n[ . . . 1 Clearly, if you live in the present, communicating mainly about how you feel and what you\nwant to do in the moment, the biological signals inherent in each species are sufficient”.\nSymbols refering to something in one person’s inner environment can be used to communicate as\nsoon as the listeners have, or are prepared to add, the corresponding references in their inner\nenvironments. For a mode1 theoretic account of how such communication can be established, see\nGardenfors ( 1993).\nMany animals have intricate systems of signals, for example, the dances of bees. However, even if\ntheir dances seem to have a kind of grammar, it still consists only of signals. The bees categorize, in\na sophisticated way, places where nectar can be found. The crucial point is that they only use their\ndances in a situated manner, and thus the dances are not symbols according to my criterion. The same\npoint is made by von Glasersfeld (1976, p. 222): “In my terms, the bees do not qualify for\nsymbolicity, because they have never been observed to communicate about distances, directions, food\nsources, etc., without actually coming from, or going to, a specific location”.\nIn spite of all attempts to teach apes various forms of symbolic codes (see e.g. Savage-Rumbaugh\nand Rumbaugh, 19931, humans seem to be the only animals that use language in a fully detached way.\nEven though the pygmy chimpanzee Kanzi’s performance is quite impressive, his use of symbols is\ndependent on the context: they mainly express requests to “direct teacher’s attention to places, things\nand activities” (Savage-Rumbaugh et al., 1985, p. 658). Human children, in contrast, very early use\nlanguage outside the context of request. Vauclair (1990, p. 319) notes that “the use of symbols by\napes is closely tied to the achievement of immediate goals, because the referents occur in the context\nof behavior on their objects”. This is congenial with Gulz’ ( 1991) conclusion that only humans are\nanticipatory planners. My conjecture is that this capability is required for the complete detachment of\nlanguage. We are still waiting for Kanzi to tell us a story by the camp fire.\n’ A similar point is made by Donald (1991). In Gardenfors (In Press, a), I write: “We all have the experience of\nsomething like an omnipresent inner monologue (or dialogue) while we are engaged in thinking. I believe that this\nexperience is deceptive. Firstly, we can ‘think’ without language. Consider, for example, the previously mentioned mental\nsimulation of a high jumper. Secondly, and more importantly, the inner speech is best interpreted as just parts of the\nsimulafions in the inner environment. The inner soliloquy is part of what we perceive in the inner environment”.272 P. Giirdenfors / Behoviourul Processes 35 (1996) 263-273\n8. Conclusion: The detachment of mind\nMy main point in this paper has been to introduce the distinction between cued and detached\nrepresentations. Using this distinction as an analytic tool, I have tried to provide an outline of the\n‘later’ parts of the evolution of cognition. I have tried to show that the notion of an inner environment\ncan serve as a basis for all higher cognitive functions like planning, deception, self-awareness, and\nlanguage.\nEach of these functions is based on different kinds of assumptions concerning the detached\nrepresentations that are involved. Anticipatory planning, in contrast to immediate planning, presumes\na detachment of the representation of the needs of the individual. For deception one must postulate an\ninner environment that contains representations of other individuals’ inner environments. Self-awareness assumes detached representations of one’s own inner environment. Finally, the referents of\nlinguistic symbols are to be found in the inner environment, in contrast to signals which refer to\nthings in the actual outer environment.\nIf the behaviorists were right, it would be questionable whether we would need the notion of\nrepresentation at all (see Epstein, 1982). In my opinion, however, there is convincing evidence that\nthe behaviorists are wrong and that animals have not only cued representations but also detached\nones. I have defined the inner environment of an animal as the collection of all its detached\nrepresentations. As I have tried to show, the general trend in the evolution of cognition is that more\nand more representations become detached. This will, by large, lead to increasing cognitive flexibility.\nIn other words, the evolution of cognition is the story of the detachment of mind.\nAcknowledgements\nResearch for this article has been supported by the Swedish Council for Research in the Humanities\nand Social Sciences. I wish to thank Christian Balkenius, Patrick Bateson, Lukas Biiiik, Henrik\nGedenryd, Paul Hemeren, Robert Pallbo, Joelle Proust, John Stewart, Michel Vancassel, Jacques\nVauclair, and in particular Jean-Marie Vidal for helpful comments and criticism.\nReferences\nBennett, J., 1988. Thoughts about thoughts. Behavioral and Brain Sciences 11, pp. 246-247.\nCraik, K., 1943. The Nature of Explanation. Cambridge University Press, Cambridge.\nDavenport, R.K., 1976. Cross-modal perception in apes. In: S.R. Hamad, H.D. Steklis, and J. Lancaster (Editors), Origins\nand Evolution of Language and Speech, Annals of the New York Academy of Science 280, pp. 143- 149.\nDavis, L.H., 1989. Selfconsciousness in chimps and pigeons. Philosophical Psychology 2, pp. 249-259.\nDennett, D., 1978. Brainstorms: Philosophical Essays on Mind and Psychology. MIT Press, Cambridge, MA.\nDennett, D., 1988. Why creative intelligence is hard to find. Behavioral and Brain Sciences 11, p. 253.\nDonald, M., 1991. Origins of the Modem Mind. Harvard University Press, Cambridge, MA.\nEllen, P. and Thinus-Blanc, C., eds., 1987. Cognitive Processes and Spatial Orientation in Animal and Man: Volume I\nExperimental Animal Psychology and Ethology, Martinus Nijhoff Publishers, Dordrecht.\nEpstein, R., 1982. Representation: A concept that fills no gaps. Behavioral and Brain Sciences 5, pp. 377-378.\nEpstein, R., Lanza, R.P. and Skinner, B.F., 1980. Self-awareness in the pigeon. Science 212, pp. 695-696.\nFagen, R., 198 1. Animal. Play Behavior. Oxford University Press, Oxford.P. Giirdenf)rs/Beh~uiourctl Processes 35 (1996) 263-273 273\nFodor, J.A., 1986. Why paramecia don’t have mental representations. Midwest Studies in Philosophy IO, pp. 3-23.\nGallup, G.G., 1977. Self-recognition in primates. American Psychologist 32, pp. 329-338.\nGallup, G.G., 1988. Toward a taxonomy of mind in primates. Behav. Brain Sci. 11, 255-256.\nGardenfors, P., 1993. The emergence of meaning. Ling. Phil. 16, pp. 285-309.\nGardenfors, P., 1994. How logic emerges from the dynamics of information. In: J. van Eijck and A. Visser (Editors), Logic\nand Information Flow, MIT Press, Cambridge, MA, pp. 49-77.\nGardenfors, P., In Press, a. Speaking about the inner environment. To appear in Of Thoughts and Words, Sture Allen\n(Editor), Imperial College Press, London.\nGardenfors, P., In Press, b. Language and the evolution of cognition. Paper presented at the colloquium Les Sciences de la\nCognition: Des modeles computationels a la philosophie de l’esprit, Lyon, December 1994.\nGlasersfeld, E. von, 1976. The development of language as purposive behavior. In: S.R. Hamad, H.D. Steklis, and J.\nLancaster (Editors), Origins and Evolution of Language and Speech, Annals of the New York Academy of Science 280,\npp. 212-226.\nGlasersfeld, E. von, 1977. Linguistic communication: theory and definition. In: D.M. Rumbaugh (Editor), Language\nLearning by a Chimpanzee: The LANA Project, Academic Press, New York, pp. 55-71.\nGomez, J.C., 1994. Mutual awareness in primate communication: A Gricean approach. In: Self-awareness in Animals and\nHumans, S.T. Parker, R.W. Mitchell, and M.L. Boccia (Editors), Cambridge University Press, Cambridge, pp. 61-80.\nGopnik, M., 1982. Some distinctions among representations. Behavioral and Brain Sciences 5, pp. 378-379.\nGopnik, A., 1993. How we know our minds: The illusion of first-person knowledge of intentionality. Behavioral and Brain\nSciences 16, pp. 1- 14.\nGulz, A., 1991. The Planning of Action as a Cognitive and Biological Phenomenon, Lund University Cognitive Studies 2,\nLund.\nHackett, C.F., 1960. The origin of speech. Scientific American 203(3), pp. 88-96.\nJeanne&, M., 1994. The representing brain, neural correlates of motor intention and imagery. Behavioral and Brain\nSciences 17, pp. 187-202.\nLachman, R. and Lachman, J.L., 1982. Memory representations in animals: Some metatheoretical issues. Behavioral and\nBrain Sciences 5, pp. 380-38 I.\nMead, G.H., 1934. Mind, Self, and Society. University of Chicago Press, Chicago.\nMurray, E.A., 1990. Representational memory in nonhuman primates. In: Neurobiology of Comparative Cognition, R.P.\nKesner and D.S. Olton (Editors), Lawrence Erlbaum Associates, Hillsdale, NJ, pp. 127- 155.\nOakley, K.P., 1961. On man’s use of fire, with comments on tool-making and hunting. In: S.L. Washburn (Editor), Social\nLife of Early Man, Aldine Publishing Co., Chicago, pp. 176-193.\nRoitblat, H.L., 1982. The meaning of representation in animal memory. Behavioral and Brain Sciences 5, pp. 353-372.\nSavage-Rumbaugh, E.S., Rumbaugh, D.M., and McDonald, K., 1985. Language learning in two species of apes.\nNeuroscience and Biobehavioral Review 9, pp. 653-665.\nSavage-Rumbaugh, E.S., and Rumbaugh, D.M., 1993. The emergence of language. In: K.R. Gibson and T. Ingold (Editors),\nTools, Language and Cognition in Human Evolution, Cambridge University Press, Cambridge, pp. 86- 108.\nSjolander, S., 1993. Some cognitive breakthroughs in the evolution of cognition and consciousness, and their impact on the\nbiology of language. Evolution and Cognition 3, pp. l-10.\nSneed, J., 197 1. The Logical Structure of Mathematical Physics, Reidel, Dordrecht.\nTolman, E.C., 1948. Cognitive maps in rats and men. Psychological Review 55, pp. 189-208.\nVauclair, J., 1987. A comparative approach to cognitive mapping. In: P. Ellen and C. Thinus-Blanc (Editors), Cognitive\nProcesses and Spatial Orientation in Animal and Man: Volume I Experimental Animal Psychology and Ethology,\nMartinus Nijhoff Publishers, Dordrecht, pp. 89-96.\nVauclair, J., 1990. Primate cognition: From representation to language. In: S.T. Parker and K.R. Gibson (Editors),\n‘Language’ and intelligence in monkeys and apes, Cambridge University Press, Cambridge, pp. 312-329.\nWhiten, A. and Byrne, R.W., 1988. Tactical deception in primates. Behavioral and Brain Sciences I 1, pp. 233-73.\nWimmer, H. and Hartl, M., 1991. Against the Cartesian view on mind: Young children’s difficulty with own false beliefs.\nBritish Journal of Developmental Psychology 9, pp. 125- 138.", "affiliations": [{"country": "Sweden", "discipline": "Cognitive Science", "university": "Lund University"}], "species_categories": ["Terrestrial Mammal", "Bird", "Other"], "specialized_species": ["chimpanzee", "cat", "mouse", "squirrel", "partridge", "fox", "baboons", "orangutan", "dog", "rat"], "computational_stages": [], "linguistic_features": ["Specialization", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882671", "updated_at": "2026-01-13T16:12:58.082241", "committed_at": "2026-01-13T13:58:09.672071"}
{"id": "20f930b5-ba0d-4167-9354-41445187a10b", "title": "Why Are No Animal Communication Systems Simple Languages?", "authors": ["Beecher,  Michael D."], "year": "2021", "journal": "Frontiers in Psychology", "abstract": "", "doi": "10.3389/fpsyg.2021.602635", "analysis_notes": "REVIEW\npublished: 19 March 2021\ndoi: 10.3389/fpsyg.2021.602635\nEdited by:\nIrene M. Pepperberg,\nHarvard University, United States\nReviewed by:\nCarel ten Cate,\nLeiden University, Netherlands\nSlawomir Wacewicz,\nNicolaus Copernicus University\nin Torun, Poland ´\nErich David Jarvis,\nDuke University, United States\n*Correspondence:\nMichael D. Beecher\nbeecher@uw.edu\nSpecialty section:\nThis article was submitted to\nEvolutionary Psychology,\na section of the journal\nFrontiers in Psychology\nReceived: 03 September 2020\nAccepted: 18 February 2021\nPublished: 19 March 2021\nCitation:\nBeecher MD (2021) Why Are No\nAnimal Communication Systems\nSimple Languages?\nFront. Psychol. 12:602635.\ndoi: 10.3389/fpsyg.2021.602635\nWhy Are No Animal Communication\nSystems Simple Languages?\nMichael D. Beecher1,2\n*\n1 Department of Psychology, University of Washington, Seattle, WA, United States, 2 Department of Biology, University\nof Washington, Seattle, WA, United States\nIndividuals of some animal species have been taught simple versions of human language\ndespite their natural communication systems failing to rise to the level of a simple\nlanguage. How is it, then, that some animals can master a version of language, yet\nnone of them deploy this capacity in their own communication system? I first examine\nthe key design features that are often used to evaluate language-like properties of natural\nanimal communication systems. I then consider one candidate animal system, bird\nsong, because it has several of the key design features or their precursors, including\nsocial learning and cultural transmission of their vocal signals. I conclude that although\nbird song communication is nuanced and complex, and has the acoustic potential\nfor productivity, it is not productive – it cannot be used to say many different things.\nFinally, I discuss the debate over whether animal communication should be viewed as a\ncooperative information transmission process, as we typically view human language, or\nas a competitive process where signaler and receiver vie for control. The debate points\nto a necessary condition for the evolution of a simple language that has generally been\noverlooked: the degree of to which the interests of the signaler and receiver align. While\nstrong cognitive and signal production mechanisms are necessary pre-adaptations for\na simple language, they are not sufficient. Also necessary is the existence of identical or\nnear-identical interests of signaler and receiver and a socio-ecology that requires highlevel cooperation across a range of contexts. In the case of our hominid ancestors, these\ncontexts included hunting, gathering, child care and, perhaps, warfare. I argue that the\nkey condition for the evolution of human language was the extreme interdependency\nthat existed among unrelated individuals in the hunter-gatherer societies of our hominid\nancestors. This extreme interdependency produced multiple prosocial adaptations for\neffective intragroup cooperation, which in partnership with advanced cognitive abilities,\nset the stage for the evolution of language.\nKeywords: animal communication, language evolution, animal cognition, animal language studies, information\nINTRODUCTION\nResearch programs on animal communication systems in nature have proceeded essentially\nindependently of research programs endeavoring to teach language to animals. This is surprising\nin light of the early, well-known efforts to relate these two research streams, especially by Hockett\n(1960) and Marler (1961). These efforts spurred two questions. First, can animals be taught human\nFrontiers in Psychology | www.frontiersin.org 1 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nlanguage, even a simplified version? Second, do the natural\ncommunication systems of any animals rise to the level of\nsimple language? Research since then has indicated that these\ntwo questions may have different answers: I would suggest a\nprovisional yes to the first, and a provisional no to the second.\nIf this view is correct, it raises a further question: why, then,\nif some animals can master a version of language, don’t they\nuse this capacity in their natural communication system? In\nthis paper I address this paradox, and make some suggestions\ntoward its resolution.\nMy paper is divided into four parts. First I consider the main\n“design features” of language proposed by Hockett as a basis\nfor evaluating language-like properties of animal communication\nsystems. Hockett concluded that some animal communication\nsystems have some of these design features, but none of them\nhave all the design features, especially the key ones. I will\ndesignate an animal communication system as a ‘simple language’\nsystem using a variation on the definition of Hewes (1973):\n“language [is] any system of animal communication which\nexhibits most of the design features set forth by Hockett” (Hewes,\n1973, p. 5). I narrow this definition by identifying four design\nfeatures – semanticity, arbitrariness, learnability and cultural\ntransmission, and productivity – as necessary for the system to be\nclassified as a simple language. Second, I discuss bird song, a case\nwhere several but not all of the key design features are present. I\nwill focus on one specific case of a song-based communication\nsystem that is clearly complex and nuanced, but nevertheless\nlacks three key design features, semanticity, arbitrariness and\nproductivity. Third, I consider the debate, not yet fully concluded,\nover whether animal communication should be conceived of as a\nprocess of information transfer or as manipulation of receiver by\nthe signaler. The debate is germane to our more specific question\nbecause it provides a clue as to why we find no simple languages\namong animals despite the apparent capacity for it in at least\nsome of them. Finally, I suggest that although there appear to be\nat least some animals with the cognitive capacity for a languagelike communication system, none of them have a social system\nwith extreme interdependency among individuals on the scale of\nthat which existed in the hominid hunter-gatherer system. I argue\nthat this extreme interdependency was a necessary condition for\nthe evolution of human language.\nDESIGN FEATURES OF LANGUAGE\nIn this section I consider the extent to which the most\nimportant design features of human language are found in animal\ncommunication systems. I use Hockett’s (1960) design features\nas a basis for comparison of natural animal communication\nsystems with human language. Although Hockett’s design\nfeatures may have limited use as a theoretical framework for\nmodern evolutionary linguistics (Wacewicz and Zywiczy ˙ nski ´ ,\n2015), it is a useful starting point for the comparative analysis\nof this paper. I have winnowed Hockett’s original design features\ndown to the few I consider the most fundamental ones that\ncan be used to directly compare human language with animal\ncommunication systems.\nSpecialization: The Purpose of Linguistic\nSignals Is Communication and Not Some\nOther Biological Function\nSpecialization, in Hockett’s sense, is the first defining feature of\na communication system, no matter how simple or complex it\nmight be. Otte (1974) defines communication signals as traits\n“fashioned or maintained by natural selection because they\nconvey information to other organisms”(Otte, 1974, p. 385).\nI discuss the vigorous debate over the ‘information’ aspect\nof this definition in Section “Communication: Information or\nInfluence? Mutual Benefit or Manipulation?”, but debaters on\nboth sides would agree that this definition captures the key\ndifference between true communication signals on the one hand,\nand tactical behaviors or inadvertent cues on the other. For\nexample, while we might describe an individual delivering a\nblow to a potential opponent as ‘sending a message,’ we mean\nthis only in a metaphorical sense. This behavior is primarily\ntactical, that is, the individual delivering the blow will directly\nbenefit it if its opponent responds by backing down. If instead of\ndelivering a blow the individual had said “I’m going to kill you,”\nor growled, or barked, or hissed, we would recognize these as true\ncommunication signals, having been shaped by natural selection\nfor the purpose of (literally) sending a message, and requiring\nadaptations in the receiver as well.\nHockett listed prevarication – the ability to transmit\nmisinformation, i.e., to lie or deceive – as one of his many\ndesign features, albeit a minor one, a corollary almost. In\nSection “Communication: Information or Influence? Mutual\nBenefit or Manipulation?”, I will argue that we should consider\nprevarication to be a fundamental, indeed foundational feature\nof animal communication systems: communication in animals\nis shaped by the tension between the sender’s and receiver’s\ninterests, and truth in communication is not a given, but rather,\nwhen it occurs, hard won.\nSemanticity: Specific Signals Are Directly\nTied to Certain Meanings\nTo say that a communication system is semantic is to say that\nit uses signals to represent particular things or actions. A wellknown example in animals are alarm signals given in response to\ndifferent predators. We can say in such cases that each of these\nsignals represents one of several different predators, or more\nprecisely, the appearance on the scene of one of these predators.\nFor example, vervet monkeys have three different alarm calls for\nthree different classes of predators: raptors, terrestrial mammals\nand snakes, predators which depend on an element of surprise\nto capture the monkey. In response to an aerial predator, such\nas a martial eagle, a monkey emits ‘cough’ calls and sender and\nreceivers take shelter in dense bushes or near the core of a tree.\nIn response to leopards, a monkey emits a ‘bark’ call and the\nmonkeys climb up to the tip of tree branches where leopards\ncannot safely go. Finally, if a monkey spots a dangerous snake,\nsuch as a python, it emits a ‘chutter’ call and the group gathers\naround the snake, standing upright and harassing it until it leaves\nthe area. Although the vervets use these same signals in other\ncontexts (e.g., intergroup fights) to represent different things,\nFrontiers in Psychology | www.frontiersin.org 2 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nthe modification of signal meaning in different contexts occurs\nin human language as well, and does not negatively impact the\nrepresentational quality of these signals (Seyfarth et al., 1990;\nPrice et al., 2015). Indeed, it is not unusual for an animal to use\na particular signal to mean different things in different contexts\n(Smith, 1997), similar to some words meaning totally different\nthings within different sentences.\nNevertheless, I will argue later in this paper that the\nsemanticity of animal communication systems is limited:\nalthough some things are represented by animal signals, the\nnumber of things is generally small. Attempts to catalog the\nnumber of different things signaled in animal communication\nsystems typically top out at 25 or so (vervet monkeys, Struhsaker,\n1967; Japanese macaques, Green, 1975; review in Hauser, 2000).\nThe limitation does not appear to be due to production\nconstraints (the ability to produce enough distinct signals or\nto recombine enough of them to enlarge the signal set) or to\nperceptual-cognitive constraints.\nArbitrariness: Languages Are Made Up\nof Arbitrary Symbols Which Have No\nIntrinsic or Logical Connection to What\nThey Represent\nA distinctive feature of human language is that not only are\nwords semantic, they are arbitrarily so. We could equally well\ncall dogs ‘cats’ and cats ‘dogs,’ or any other two words, so long\nas sender and receiver knew the convention, a point illustrated by\nthe existence of the many different languages of the world. These\nsignals seem totally arbitrary with respect to what they signify,\nand in theory they could be interchanged without problems, so\nlong as senders and receivers were both aware of the convention.\nHow about animal signals? It appears that in theory we could\ninterchange the vervet alarm signals without problems, provided\nof course that the receivers were aware of the ‘convention’ (i.e.,\nwere hard-wired appropriately). Identity signals – indicating\nspecies or individual identity, and occasionally group or kinship –\nare perhaps the most common animals signals that unequivocally\nhave the arbitrariness feature.\nBut many, perhaps most, animal signals are not arbitrary.\nSignals used in agonistic and mate attraction contexts are\ntypically “more of ” signals, i.e., more effective signals are louder,\nlonger, bigger, brighter, flashier, designed to impress or to shock\nand awe. I am unaware of any clear example where the reverse\nis true, where the more effective signal is the one that is less\nconspicuous, for example, a softer sound, a more subdued color,\na less vigorous display. An apparent exception might be the\n‘quiet song’ sung by many songbirds in intense conflict situations,\nbut this typically happens only when the bird is close to its\nopponent so that the quiet song is audible to the receiver (Searcy\net al., 2014); ‘normal’ song is loud because it is a long-distance\nsignal. Moreover, quiet song is typically different in other respects\nbesides loudness, for example, having some elements seen only in\nquiet song, such as very high frequency elements.\nOther animal signals are simple extensions or slight\nmodifications of tactical behaviors, e.g., of attack behavior in\nagonistic situations. For example, a threat signal in many\nmammals is the open mouth display, where the teeth, the\ncanines notably, are prominently displayed. Ethologists called\nthis a ‘ritualized’ display (Lorenz, 1966), i.e., one that has\nbeen modified by natural selection to be a display, since the\nmouth is held open, and attack withheld, rather than being\nthe beginning of an actual attack. Another common threat\nsignal is the raising of the hair or feathers, making the animal\nappear larger. Again, while these actions are plausibly considered\nritualized displays, they are not arbitrary signals. If they were,\nyou would also find cases where animals threaten by closing\ntheir mouths, or by making themselves appear small. In short,\nanimal signals functioning to impress an opponent or potential\nmating partner are usually inherently impressive, not arbitrarily\nselected to represent threat or desirability. Any naïve observer\nviewing a ritualized dominance interaction between two wolves\n(or dogs) would have no difficulty determining which animal was\ndominant and which was subordinate. An upright animal, with its\nhair raised, its tail raised, and staring at its opponent inherently\nappears dominant, whereas one with a flattened, slinking body,\nhair down, tail down, and looking away from the opponent,\ninherently appears subordinate.\nMany epigamic signals – signals designed to attract a mate\nand induce her to mate – are bright, striking ornaments, often\nones that function like supernormal stimuli (e.g., the tail of\nthe long-tailed widowbird, Andersson, 1982). Many epigamic\nsignals are energetically expensive and highly skilled behaviors,\nsuch as the complex male courtship dances of wolf spiders and\njumping spiders (Hebets and Uetz, 1999; Elias et al., 2012). The\nmotor performance revealed in these sorts of displays likely\nreflect whole-organism performance relating to survival, and thus\nshould be good indicators of individual signaler quality. There is\nconsiderable evidence that females choose mates in nature based\nupon their evaluations of male motor performance (reviewed\nin Byers et al., 2010). The relevant point here is that these\nsignals are not arbitrary, but inherently reflect the trait signaled:\nsignaler quality.\nEven in the example par excellence of communication of\ninformation about the external world – the honeybee dance\nlanguage – the signals are not quite so arbitrary as generally\nassumed. For example, if the dance is done outside the hive,\nwhere the sun is visible, the bee dances with respect to the\nactual position of the sun, rather than with respect to the vertical\n(Gould, 1975). That is, outside the hive, the symbology is not truly\narbitrary. Moreover, the distance to the target is represented by\nthe duration of the straight run – the further the distance, the\nlonger the run – so this is at least partially non-arbitrary as well.\nAlthough the words in human language are arbitrary – the\nexistence of different languages is the clearest evidence on\nthis point – they may be expressed in such a way to amplify\nor otherwise modify their meaning, as for example a loudly\nshouted “no” indicating stronger conviction. But what would\nbe considered an extra-linguistic feature for humans is often\nthe primary message in animals. For example, the initial stage\nof a battle between two male red deer consists of a roaring\ncontest (Clutton-Brock and Albon, 1979). This vocal signaling\nduel does far more than simply establish that each animal is a\nmale conspecific ready to defend or fight for the harem – this\nFrontiers in Psychology | www.frontiersin.org 3 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nundoubtedly was perceived by both parties before the contest\nbegan – rather, how loud and how long an individual roars\nestablishes how motivated and formidable he is, and is used by\nthe receiver to decide whether to continue the fight or depart.\nSimilarly, the plumage ornaments and courtship dance of a male\ngolden-collared manakin do far more than simply identify species\nand sex – that is simply the necessary first step – the brightness\nof the ornament and the skill of the dance determine whether the\nreceiver, the female, will choose to mate with this particular male\nor continue her search for the best possible mate (Stein and Uy,\n2006; Barske et al., 2011).\nIn summary, although we have examples of animal signals that\nare totally arbitrary, many others – perhaps most? – are not. I\nwould add that to date we have found nothing comparable to the\nmany different human languages, which are a consequence of the\narbitrariness feature. We do find geographical dialects in animals\n(e.g., Marler and Tamura, 1964; Wright and Dahlin, 2018), but\nas the name implies, these are relatively minor variations on\nthe basic signal set, nothing like the wholesale variation seen in\nhuman languages.\nLearnability and Cultural Transmission\nHuman language is both learned and taught. Most animal\ncommunication systems are neither. A well-known exception to\nthis generalization are the learned vocal communication signals\nof several taxa, most notably the oscine passerines (songbirds),\nhummingbirds and parrots among birds, and cetaceans and at\nleast some bat species among mammals (reviews in Janik, 2014;\nKnornschild, 2014; Nowicki and Searcy, 2014). Evidence for\nvocal learning and cultural transmission in some other birds\nand mammals as well (Walcott et al., 2006; Kroodsma et al.,\n2013; Stoeger and Manger, 2014; Garland and McGregor, 2020;\nBarker et al., 2021) suggests that this ability may lie closer to\nthe surface than is generally assumed, but at least at the present\ntime, vocal learning is thought to be rare in animals. Later in this\npaper I return to the best-studied example of vocal learning, song\nlearning in songbirds.\nWhere the communication signals are learned, we should\nexpect to find dialects, geographical variation in the signals.\nThe occurrence of dialects is one criterion for identifying\nthe occurrence of learning and potentially evidence for the\narbitrariness design feature. An example that may illustrate\nthe arbitrary nature of dialects is the recently-discovered\nmodification of the song in eastern white-throated sparrows to\nresemble the typical song of western white-throated sparrows.\nInvestigators have traced this change to eastern birds learning\nthe western version of the song on the migration grounds, where\nindividuals of the two populations mix (Otter et al., 2020). Most\neastern birds now sing the ‘western’ version of the song on\nthe breeding grounds, illustrating that the details of the song\nstructure are not crucial for its function. Although Otter et al.\n(2020) suggest that this change might have been driven by a\npreference on the part of eastern females, they give no evidence\nfor this hypothesis, nor plausible basis for it.\nPerhaps even rarer in animal communication systems than\nlearning is teaching. The commonly accepted criteria for\ndemonstrating teaching in non-human animals are that (1)\nteachers should modify their behavior in the presence of the\nlearner, (2) this change in behavior should result in no immediate\nbenefit to the teacher, and (3) the learner should acquire a\nbehavior quicker or better as a result (Caro and Hauser, 1992).\nIn song-learning studies the birds from whom the young bird\nlearns its song are conventionally referred to as ‘tutors,’ and\nalthough live birds are invariably more effective song tutors\nthan recorded song (review in Beecher, 2017), the term ‘tutor’\nis used purely as matter of convenience. In fact, in the most\ncommon context for song learning in nature, young birds learn\nfrom older birds who are or will be their territorial rivals, a\nvery different context from language learning in young humans,\nwhere ‘tutors’ are typically relatives or other interested parties\nwho ultimately (but not immediately) benefit from tutoring.\nNevertheless, even in the common songbird case where the young\nbird learns from territorial rivals, bird song tutoring would fit\nall three criteria for teaching if in fact the older bird reduces\nhis usual aggression when a young bird appears on his territory,\nincreases his counter-singing with the young bird in such a way\nas to facilitate learning, and benefits down the road from this\ntutoring (for example, the two cooperate in mutual defense of\ntheir territories, or against predators, or refrain from extra-pair\nmating with one another’s mates). We have indirect evidence\nfor song learning/teaching in song sparrows: mutual survival\nis greater in young birds and their primary tutor-neighbor\n(the one from whom they learn most of their songs) the more\nsongs the two of them ultimately share, i.e., the more songs\nthe tutee learned from the tutor, or the tutor taught the tutee\n(Beecher et al., 2020).\nProductivity: By Combining a Small\nNumber of Meaningless Units Into\nLarger Meaningful Signals, a Sender Is\nCapable of Producing Meaningful\nStatements About Virtually Anything\nThe sense in which I am using this term is captured by\nHauser (2000, p. 448): “the power of [human] language comes\nfrom our capacity to take meaningless syllables and combine\nthem into an unbounded number of meaningful words, and\nthen take these words and combine them into an unbounded\nnumber of meaningful expressions (Chomsky, 1986; StuddertKennedy, 1998).” I will define productivity as recombining\na smaller number of basic signal units to produce a larger\nnumber of signals, and thus, messages. Indeed, semanticity\n(representation) and productivity are probably the two central\nfeatures of human language: by combining basic phonetic units\ninto larger meaningful units, and combining these units further\nvia syntactical rules, we can say almost anything.\nAnimal communication systems are not productive in this\nsense, and this is the primary reason we do not refer to them\nas languages. We would be impressed if a vervet could say\nsomething like “Grab your infant and run from the leopard\ncoming from the west but watch out for the python who\nlikes to hide in the bushes just to the east of you.” A human\ncan say this kind of thing easily, combining a relatively small\nnumber of atomic units (phonemes) into very large number of\nFrontiers in Psychology | www.frontiersin.org 4 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nbasic signals (words) and combining these into a very large set\nof possible communications. I note that while there is some\ncontroversy in phonetics about exactly what are the units of\nproductive combination, there is agreement that all natural\nlanguages (including sign language) are made up of meaningless\natomic units that are combined into larger meaningful wholes\n(Zuidema and de Boer, 2009).\nInstead of productivity, we could describe the communication\nsystem in terms of information capacity. The information\ncapacity of human language is essentially infinite, in the sense\nthat, in theory, we can communicate virtually anything. Our\nmotor, sensory and cognitive capacities obviously will reduce\nhow much information actually gets transmitted and received.\nBut still, the fact is that we can transmit an enormous amount\nof information with language. Attempts to measure information\ncapacity or information transmission in animals, on the other\nhand, have given rather modest results. Two estimates of the\ninformation about distance and direction in the honeybee dance\nlanguage have given a high value of 14.9 bits (Gould, 1975)\nand a low value of 7.4 bits (Schürch and Ratnieks, 2015). My\ngroup has estimated the information capacity of the call signature\nsystem that parents of the colonial cliff swallow use to find their\noffspring in their large breeding colonies (Medvin et al., 1993).\nWe estimated the capacity as 8.76 bits, and the estimate would be\nsomewhat larger if we included information that can be derived\nfrom visual differences among cliff swallow chicks (Stoddard and\nBeecher, 1983). The information capacity of human language of\ncourse is orders of magnitude larger than this.\nWe certainly find the potential for productivity in bird\nsong. For example, most songbirds have multiple songs (song\n‘repertoires’), and the different songs are made up of different\nsyllables or notes in different orders, and these smaller units can\nbe used in more than one song. Still, although the units are there,\nand although songbirds may possess the cognitive capacity to\ncomprehend hierarchical structuring in vocal signals (Gentner\net al., 2006; but see van Heijningen et al., 2009), they do not\nuse these capacities to form different songs representing different\nthings. As Hauser (2000, p. 450) puts it, “in contrast to the\nrecombination of words into sentences by humans, the output of\nsongbird recombination does not change its meaning.” A minor\nexception are some songbirds who use some song types in a\nterritorial defense context and others in a mate attraction context\n(e.g., Byers, 1996). As discussed in the next section, theories on\nthe function of song repertoires abound, but they all agree that\nthe different songs function simply to provide diversity, rather\nthan to represent different things.\nSumming Up\nTable 1 summarizes the conclusions of this section. The natural\ncommunication systems of animals fall short of human language\non a number of the key design features of language. They\ncome closest on semanticity, where signals sometimes represent\nthings in the external world or within the signaler, and the\nsignals are sometimes truly arbitrary. However, more commonly\nanimal signals are not arbitrary but inherently meaningful,\ne.g., an animal making itself appear large is more frightening\nthan an animal making itself appear small. Most animal\ncommunication signals and responses are neither learned nor\nculturally transmitted. And, so far as we know, no animal\ncommunication has the sine qua non of language: productivity.\nBIRD SONG: COMPLEXITY WITHOUT\nPRODUCTIVITY\nThe oscine passerines (songbirds) are one of the rare animal taxa\nin which individuals learn their vocal communication signals.\nIn most animals, these vocal signals are ‘hard-wired,’ that is,\nthey develop normally whether or not the animal is exposed to\nthem early in life. It has long been noted that vocal learning in\nsongbirds has many similarities to language learning in humans\n(Marler, 1970; Doupe and Kuhl, 1999). These similarities include\nthe following. (1) The young bird needs to be exposed to normal\nspecies vocal signals in order to produce them as an adult. (2)\nThe sensory phase of song learning precedes the motor phase.\n(3) Auditory feedback (which can be abolished by deafening) is\nTABLE 1 | Key design features of communication systems (after Hockett, 1960, pruned and combined).\nFound in\nanimals?\nDesign feature Comment\nYes Specialization. The purpose of linguistic signals is communication and not some\nother biological function.\nTrue of animal communication systems, but this is essentially by\ndefinition.\nYes but\nlimited\nSemanticity. Specific signals are directly tied to certain meanings. Clear example are the alarm calls given to different classes of\npredators in a number of species. But the number of different things\nsignaled is typically very small.\nYes but\nrare\nArbitrariness. There is an arbitrary relationship between a signal and its\nmeaning. There is no inherent relationship between the form of a signal and\nwhat it refers to.\nAnimal signals are sometimes arbitrary. Often they have inherent\nmeaning that can be readily perceived by a naïve observer, e.g.,\nsignals used in mate attraction or agonistic encounters that are\ndesigned to impress or shock and awe.\nYes but\nrare\nLearnability and Cultural transmission. Human language is learnable, teachable and culturally transmitted.\nBird song appears to be one of the few animal examples that\npasses at least two of these criteria (teaching still not established).\nNo Productivity (based on Arbitrariness, Discreteness and Duality of patterning):\nlanguage made up of small meaningless units which can be combined into\nmany larger meaningful units which can be combined to say virtually anything.\nSome animals appear to have the motor and cognitive capacity for\na productive, language-like communication system but they do not\nuse this capacity to develop language-like communication systems.\nFrontiers in Psychology | www.frontiersin.org 5 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nnecessary for the translation of memorized sensory input into\nmotor production. (4) Vocal learning is most efficient in (and\nsometimes restricted to) a sensitive period early in life. (5) There\nare specialized parts of the brain dedicated to the vocal control\nsystem. (6) Song is socially learned and culturally transmitted,\nand in at least some cases it may be actively taught (e.g., CarousoPeck and Goldstein, 2019; Beecher et al., 2020). While notable\ndifferences exist among songbird species with regard to the\nnormal progression of song learning (Beecher and Brenowitz,\n2005), these six features are essentially true for all of the many\nsongbirds that have been studied to date.\nDespite the notable parallels between bird song learning\nand human language learning, none of the many studies\nendeavoring to teach a version of human language to animals\nhave focused on songbirds. This is all the more surprising\ngiven the language learning shown by Alex the African Gray\nParrot, a member of another avian taxon with vocal learning, the\npsittacines (Pepperberg, 1981, 1987). Moreover, songbirds have\nstrong cognitive capacities, a highly-developed vocal production\nmechanism, and a vocabulary of basic sound units in their\nsong that rivals or exceeds the basic sound units of human\nlanguage. There are even songbird species that can mimic human\nspeech sounds (e.g., Hill Mynah birds). On the face of it, all the\nrequisites would seem to be there to support a simple language\nin a songbird.\nWhat Is the Function of a Song\nRepertoire?\nIn contrast to well-studied white-crowned sparrows and zebra\nfinches, in most songbird species an individual bird will sing\nmultiple songs (has a song ‘repertoire’). For example, song\nsparrows typically have nine (plus or minus two or so) very\ndifferent songs. Each of these songs is made up of 5 or 6 distinct\nelements, and the order of these elements is important (Horning\net al., 1993). The songs do not have individual signatures and\nthe nine or so songs in a song sparrow’s repertoire are as\ndifferent among themselves as would be a collection of songs\ntaken at random one from each of nine or so different birds\n(Beecher et al., 1994). Song sparrows are somewhere on the\nmiddle of the song repertoire complexity scale: many species\nhave larger and even more complex song repertoires. The key\npoint for this discussion is that song repertoires provide clear\npotential for productivity, as song sparrows and many other\nsongbirds have as many or more distinct units in their vocal\ncommunication systems (e.g., about 100 in indigo buntings,\nThompson, 1970; and in swamp sparrows, Marler and Pickert,\n1984) as there are in human language (a typical language has\n40–45 phonemes).\nThe most popular hypothesis about song repertoires for north\ntemperate zone songbirds – where only males sing – is that\nthey are an epigamic signal produced by males to attract females\nand that larger repertoires are more attractive than smaller\nones (Catchpole, 1987; Searcy and Yasukawa, 1996; MacDougallShackleton, 1997; Collins, 2004). Focusing on just the wellstudied song sparrow, the evidence for this hypothesis is mixed\n(Searcy, 1984; Reid et al., 2004; Hill C. E. et al., 2011). The\nhandicap principle, discussed in the next section, would suggest\nthat if large song repertoires are preferred, it is because they are an\nindicator of some aspect of male quality. Reid et al. (2005) found\nsupport for this idea: song repertoire size in male song sparrows\ncorrelated with enhanced cell-mediated immune response (CMI)\nand relative heterozygosity. Anderson et al. (2017) hypothesized\nthat female song sparrows might prefer large-repertoire males\nbecause this feature is an indicator the overall learning ability\nof the male. However, they found no correlations between\nrepertoire size (or two other measures of song learning ability)\nwith an overall measure of learning ability (based on five different\nlearning tasks). I should note, however, that a correlation of vocal\nlearning ability with both overall learning ability and mating\nsuccess has been found in another songbird, the Satin Bowerbird,\na vocal mimic: in this case the vocal learning ability is the ability\nof males to mimic the calls of other local bird species, both the\nnumber of species mimicked, and the accuracy of the mimicry\n(Coleman et al., 2007; Keagy et al., 2009).\nAccording to another hypothesis, song repertoires play\na role in territorial competition, which in north temperate\nzone songbirds, where only males sing, is largely male-male\ncompetition, but outside the north temperate zone where both\nsexes sing, is pair-pair competition (e.g., Levin, 1996; Langmore,\n1998; Logue and Gammon, 2004). There are several hypotheses\nas to how repertoires might work in the territorial competition\ncontext. Song is used by most territorial songbirds at least in\npart as a keep-out signal, to ‘post’ their territory. Kroodsma\n(1988) argues that the vocal diversity provided by a repertoire\nfunctions to hold the attention of territorial competitors by\ndishabituating them to the territory owner’s singing, i.e., by\nholding their attention. As one piece of evidence, he points to\na positive correlation between repertoire size and population\ndensity in marsh wren populations, and also to the finding that\nbirds in denser populations cycle through their songs faster,\nagain a behavior that should reduce habituation (Kroodsma,\n1977). In contrast, song sparrows sing their much smaller\nrepertoires with eventual variety, i.e., singing each one of\ntheir song types many times before switching to another\ntype, and this would seem to argue against the dishabituation\nhypothesis. In western, resident populations of song sparrows,\nsong repertoires may function primarily to provide a bird with\nsongs matching all (or most) of his neighbors, and thus potential\nindividualized replies to each one of them (Beecher et al., 1997;\nand see next section).\nAlthough as this brief discussion indicates, the theoretical\ndebate has not yet concluded, the take-away point is that\nnone of these hypotheses view song repertoires as a form of\nsemantic communication. Rather they view repertoires as having\na direct effect on the receiver (dishabituation), or as permitting\nindividualized replies to multiple neighbors, or as quantitative\nsignals with inherent rather than semantic meaning, that is, more\nsongs (or more song syllables) are simply more effective.\nI should add that most single-song species appear to have\nthe potential to develop song repertoires yet do not tap into\nthis potential. For example, when examined over an entire\npopulation, indigo buntings have a repertoire of over a 100\ndistinct song syllables, yet a given individual uses just 6–8 of\nFrontiers in Psychology | www.frontiersin.org 6 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nthese in the single song it develops (Rice and Thompson, 1968;\nThompson, 1969; Baker and Boylan, 1995).\nAn Example: Communication in a\nNegotiation Context\nAlthough the different songs in a bird’s repertoire do not have\ndifferent meanings, a bird having a song repertoire can still use\nthe different songs to communicate in more subtle, nuanced\nways than might at first be suspected. In this section I describe\none such case: how song sparrows use the songs in their song\nrepertoire to negotiate territorial disputes. The general point I will\nmake is that their communication system is surprisingly complex\nand versatile, despite being neither semantic nor productive.\nAlthough I will not attempt to generalize to all songbirds given\nthe incredible diversity of the song communication systems seen\nin this group (Beecher and Brenowitz, 2005), I suspect that this\nconclusion – complexity without productivity – applies broadly\nto songbirds, and perhaps to all animals.\nSong sparrows have a territorial system like that found in\nmany animals and typical of many songbirds. An individual\ncarves out a territory where the mated pair will nest and\nraise their young, doing most of their feeding on the territory.\nSuitable habitat is typically densely occupied by conspecifics,\nso territorial disputes can arise during both the establishment\nand maintenance stages. The relationship between territorial\nneighbors can become relatively non-hostile once established,\nhowever, on the principle that the enemy you know is better\nthan the enemy you don’t know, generally referred to as the\n‘Dear Enemy’ relationship (Fisher, 1954; Akçay et al., 2009,\n2010; Beecher and Akçay, 2014). Because in territorial animals,\nneighbors have no fences, neighbors need to renegotiate territory\nboundaries from time to time. Negotiation can progress into\nfighting but avoiding fighting may benefit both parties and this\ncommon interest favors reliable signaling. Therefore, as I will\ndiscuss in Section “Communication: Information or Influence?\nMutual Benefit or Manipulation?”, we should expect to find some\ndegree of honest communication concerning not only fighting\nability (resource-holding potential) but also motivation to fight\n(e.g., at a particular point in time, one party may have more to\nlose than the other).\nSong sparrows in western, resident populations use their\nrepertoires in a complex way to carry out territory negotiations.\nAlthough they will engage in serious fights, established neighbors\nuse their signaling system to avoid fighting if possible. Before\nfighting they typically give their high-level threat signals, wing\nwaves and soft song (Searcy and Beecher, 2009; Searcy et al., 2014;\nAkçay et al., 2015a). But before reaching this stage, they use the\nsongs in their repertoires to escalate or de-escalate the dispute\nfollowing a set of ‘conventions’ predicated on which songs the two\nbirds happen to share (Beecher et al., 1996, 2000; Burt et al., 2001,\n2002; Beecher and Campbell, 2005; Akçay et al., 2011; Templeton\net al., 2012; Akçay et al., 2013, 2015b). Because western song\nsparrows learn songs from their neighbors in the area to which\nthey disperse after fledging, a bird typically shares some of his\nsongs with each of his immediate neighbors. The set of songs\nhe shares with one neighbor is typically different from the set\nhe shares with another. A partial example is shown in Figure 1.\nFor example, if we represent the different songs of a bird with\ndifferent capital letters, and the shared songs of neighbors with\nthe same capital letter, then Bird 1 might share his song types\nA, B, and C with his neighbor Bird 2, his song types C, D, and\nE with another neighbor, his song types E and F with a third\nneighbor, and finally G, H, and I with no neighbors (e.g., the\nbird he learned these songs from may have died). A typical\nterritorial negotiation might occur as follows. Suppose Bird 1’s\nmate finds an ideal place to build her nest just over the previouslyestablished boundary with Bird 2. Bird 1, aiming to establish this\nnew boundary, moves to that point and sings at his neighbor.\nTypically the two birds would still be a considerable distance\napart at this point and out of sight of one another (territories are\nlarge and song is a long-distance signal). Although Bird 1 could\nsing any one of his 9 songs to Bird 2, in this circumstance he\nwould typically ‘address’ Bird 2 by singing one of their shared\ntypes, A, B, or C. Let us say bird 1 sings B. Bird 2 can escalate\nby replying with his B’ (i.e., his most similar song to Bird 1’s B).\nThis ‘type match’ is a low-level threat signal and would be the\nfirst step in escalation. Alternatively, he could ‘confirm’ without\nescalating by replying with A’ or C’ (‘repertoire matches’, Beecher\net al., 1996). Note that this type of reply is only possible if Bird 2\nknows Bird 1 well enough to know which songs they share and\nwhich songs they don’t. Finally, rather than type-matching or\nrepertoire-matching, Bird 2 can de-escalate by singing one of his\nunshared types, e.g., D, E, F, G, H or I. Singing an unshared type\nis better than not singing at all because it signals that although\nthe singer is not engaging, he is on territory and has heard his\nneighbor; it is a signal likely used for example when the bird is\nbusy feeding recently-fledged young. If Bird 2 does type match\nbird 1 (sings B’), Bird 1 in turn can continue to sing that song\ntype (‘stay on type’), or he can de-escalate by switching to another\nshared song (A or C, ‘repertoire match’), or de-escalate further by\nswitching to an unshared type (e.g., D or E), or disengage totally\nby stopping singing.\nEach ‘convention’ – type matching, repertoire matching,\nstaying on type, switching to an unshared type – has a distinct\nsignaling function in this graded signaling system, with both type\nmatching and staying on type when type-matched signaling a\nreadiness to escalate, repertoire matching signaling recognition of\nthe sender and engagement but stopping short of escalation, and\nswitching to an unshared type signaling de-escalation. The system\nwhile not in itself resolving anything, does give the neighbors\ntime to defuse the situation or work out a compromise. Note,\nhowever, that the semantic content is limited. No particular song\nin the repertoire means a particular thing. A song’s meaning is\ndefined entirely by the context of who the receiver is, and even\nthen there are essentially only three meanings, roughly ‘back off,’\n‘I hear you and know who you are,’ and ‘I’m busy now.’\nSumming Up\nSongbirds check several of the design feature boxes and they\nwould appear to have the potential to use their songs in a\nproductive way, i.e., to use their signaling system to say many\nthings. However, despite considerable debate concerning the\nfunction of song repertoires, the different repertoire hypotheses\nall agree on one point: that the function of the vocal diversity\nFrontiers in Psychology | www.frontiersin.org 7 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nFIGURE 1 | Partial song repertoires of two neighboring birds. Shared songs are shown in the top three rows, and four of their unshared songs in the bottom two\nrows (they are arbitrarily paired). Frequency scale: 0–10 kHz. Songs are 2–3 s long.\nis diversity per se, not the transmission of different messages\nwith different songs. Perhaps even more surprising, many singlesong species have large song syllable repertoires an individual\ncould tap into, but instead each individual uses just several\nof these syllables to develop its single song. No songbird\nrearranges its multiple song syllables into different songs that\nsignal different things. I echo here the conclusion of Fitch and\nJarvis (2013, p. 502): although songbirds (and parrots) have vocal\nlearning and a complex vocal repertoire, they do not “use their\nsongs to communicate combinatorial propositional meanings,\ni.e., semantics.”. Songbirds may use their repertoires in subtle,\nnuanced ways, as with the song sparrow hierarchical signaling\nsystem I described above, but what the system achieves seems\nbetter described as the management of behavioral conflict than\nas an impressive transmission of information. That is, the system\nmay function well, but it does not function like a language.\nCOMMUNICATION: INFORMATION OR\nINFLUENCE? MUTUAL BENEFIT OR\nMANIPULATION?\nIn this section I discuss the debate within the field about\nthe fundamental nature of animal communication. I believe\nthis debate has provided us with a key to understanding\nwhy we find no examples of a simple language among the\nmany communication systems of non-human animals, and true\nlanguage only in the human animal.\nWe can trace the real beginning of the field of animal\ncommunication to the classical ethologists (e.g., Tinbergen,\n1952). The ethologists provided detailed descriptions of animal\nsignaling systems in nature, developed theories about the\nunderlying proximate causes (e.g., sign stimuli, innate release\nmechanisms, and fixed action patterns) and evolutionary\nprocesses (e.g., ritualization), and most relevant here, established\nthe view of animal communication as – like human language –\nan information transfer process. On the question of the function\nof animal signaling systems, they took a group-selectionist\nperspective: the benefit that a signaling system provided went not\nto signaler or receiver per se, but to the species (see Tinbergen,\n1964 definition in Table 2).\nFollowing the revolution of the 1960’s and 1970’s first known\nas sociobiology (Wilson, 1975) and subsequently as behavioral\necology (Krebs and Davies, 1978), natural selection came to be\nviewed as acting on individuals, rather than species or groups\n(Williams, 1966). For some researchers, the shift from naïve\ngroup selection to individual selection did not entail a significant\nchange in view: it was simply assumed that signaler and receiver\nFrontiers in Psychology | www.frontiersin.org 8 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nTABLE 2 | Definitions.\nTinbergen, 1964 “One party. . . emits a signal, while the other party. . . responds in such a way that the welfare of the species is\npromoted.”\nMarler, 1968 In “true communication. . . both parties seek to maximize the efficiency of information transfer.”\nOtte, 1974, p. 385 Signals: “behavioral, physiological, or morphological characteristics fashioned or maintained by natural selection\nbecause they convey information to other organisms”\nDawkins and Krebs, 1978, p. 283 “Communication is said to occur when an animal, the actor, does something which appears to be the result of selection\nto influence the sense organs of another animal, the reactor, so that the reactor’s behavior changes to the advantage of\nthe actor.”\nGreen and Marler, 1979, p. 73 “Communication consists of the transmission of information from one animal to another.”\nKrebs and Dawkins, 1984, p. 401 They call the sender role the ‘manipulator’ and the receiver role the ‘mind-reader.’ “The manipulator role is selected to\nalter the behavior of others to its advantage, the mind-reader role to anticipate the future behavior of others.”\nSmith, 1997, p. 11 Communication: “any sharing of information between entities—in social animals, between individual animals”\nBradbury and Vehrencamp, 1998, p. 3 True communication: “information exchange from which both sender and receiver benefit.”\nMaynard Smith and Harper, 2003, p. 3 A signal is “any act or structure that alters the behavior of other organisms, which evolved because of that effect, and\nwhich is effective because the receiver’s response has also evolved.”\nOwren et al., 2010, p. 771 Animal Signaling: “the use of specialized, species-typical morphology or behavior to influence the current or future\nbehavior of another individual.”\nboth benefited from the transmission of information, and so\nthis basic parallel with human language was maintained (see\nTable 2 definitions of Marler, 1968; Otte, 1974). The assumption\nof mutual benefit seemed natural in cases where sender and\nreceiver have a strong common interest, e.g., the honeybee ‘dance\nlanguage’ where scout and recruit are both working toward the\nsame end, to provide food for their relatives in the hive. But as\ninvestigators began considering the many cases where signaler\nand receiver have conflicting interests, such as in agonistic\nencounters over an indivisible resource, they began to question\nthe mutual-benefit, information transmission view. They asked\ntwo questions about such cases. First, do both parties have to\nbenefit? Second, do we need to even talk about ‘information\ntransmission’? Isn’t the signaler simply selected to manipulate\n(or influence) the behavior of the receiver to its advantage? The\nmanipulation viewpoint was famously developed by Dawkins and\nKrebs (1978) who argued that rather than expecting signalers to\nsignal honestly, we should expect them to manipulate the receiver\nto their own advantage, e.g., to convince opponents to retreat, or\npotential partners to mate with them.\nSince the Dawkins and Krebs (1978) paper, the debate\nhas continued as to whether it is justified or productive to\nconceptualize animal signaling as an information transmission\nprocess in which both parties benefit. Simplifying somewhat,\nI will distinguish between the Information Transmission and\nManipulation approaches to animal communication. Strong\narguments on the manipulation side since Dawkins and Krebs\n(1978) include Krebs and Dawkins (1984), Owings and Morton\n(1998), Scott-Phillips (2008), Rendall et al. (2009), and Owren\net al. (2010). Strong arguments on the information side over this\nsame period include Green and Marler (1979), Smith (1997),\nBradbury and Vehrencamp (1998), Searcy and Nowicki (2005),\nCarazo and Font (2010), Seyfarth et al. (2010), and Wiley (2013).\nDefinitions from some of these sources are included in Table 2.\nIn conceiving of signaling as manipulation, Dawkins and\nKrebs (1978) essentially treated the communication interaction\nlike a zero-sum game. This seems reasonable in cases like disputes\nover an indivisible resource (a food item, a territory, and a\nmate), and also in epigamic selection, where a male tries to\npersuade a female to mate with him now rather than to continue\nsearching for a possibly better male. Although the manipulation\nview was enlightening in many respects, as originally presented\nit had a serious weakness: it gave no agency to the receiver.\nWhile it was sensible to expect signalers to signal for their own\nbenefit, why should we expect receivers to be passive in these\nevolutionary scenarios, especially if being manipulated by the\nsignaler is costly? Rather, we should expect receivers to show\n‘sales resistance’ to signals that carry misinformation or are pure\npropaganda (“I am the best,” “I will fight you to death”). Indeed,\nreceivers can do more than simply ignore signals that do not\nbenefit them: they can require signals that do benefit them, even\nif those signals are costly to the sender. For example, in many\nspecies males must sing or call to attract a female for mating. If\nthe male does not vocalize, potential female receivers will simply\nnot engage. Moreover, these vocal signals may attract predators,\na cost borne by the signaler but not the receiver. Indeed, the\nmost effective or most-preferred signals may be the most costly,\ne.g., most conspicuous not just to the intended receiver but to\npredators as well. This is the case for a male túngara frog (Ryan\nand Rand, 1990). Males attract females to mate with a ‘whine’\ncall or a ‘whine-chuck’ call. When a male adds chucks to his\ncalls, he not only attracts more females, but also predators: frogeating bats that home in specifically on the chucks. Similarly, a\ncalling male field cricket attracts more females than does a silent\nmale, but he also attracts more parasitoid flies, and louder calls\nattract both more females and more parasitoid flies (Cade, 1975).\nIn some populations the rate of fly parasitism is so high that\nmales have lost the ability to sing (Zuk et al., 2006). As another\nexample, territorial animals often vocalize as a “keep-out” signal.\nWhen a territorial songbird is deprived of its voice, however,\npotential rivals show up and proceed to take over its territory\n(e.g., McDonald, 1989).\nIf we reframe our view of the communication system as\nbeginning with the implicit requirement that the receiver imposes\non the signaler—to signal—rather than with the signal itself, it\nis apparent that receivers can be conceived of as manipulating\nFrontiers in Psychology | www.frontiersin.org 9 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nsignalers, and in the ‘receiver manipulation’ view, the potential\ncosts to the sender are secondary to the potential benefits to\nthe receiver. A possible benefit for the female túngara frog –\nthe receiver in our example – might be a shorter search time in\nnavigating to the male who adds the more localizable chucks to\nhis calls, perhaps lessening her vulnerability to predation.\nThe receiver manipulation view prompts us to consider how\nthe receiver might demand a more honest signal. There are two\nrelated possibilities. First, the receiver can selectively attend to\nsignals that are inherently honest due to physical constraints. For\nexample, in many frogs and toads, size is the most important\nweapon in male battles over mating opportunities and size\nis reliably predicted by the pitch of the animal’s vocalization:\nlarger animals give lower-pitched calls. Davies and Halliday\n(1978) showed that playback of low-pitched calls was sufficient\nto discourage smaller males from entering into battle with\nan apparently larger male. A second way to require a more\nreliable signal has generally been discussed under the rubric\nof the ‘handicap’ principle. This principle was first proposed\nby Zahavi (1975), modified and formalized by Grafen (1990),\ngiven the intuitively pleasing graphical formulation by Johnstone\n(1997) shown in Figure 2, and is still being subjected to\nfurther modification and clarification (e.g., Penn and Számadó,\n2018). But the basic principle is straight-forward, and can be\nverbalized as follows: signals whose degree of expression is\ndependent on the health, general condition or vigor of the\nsignaler are inherently honest expressions of that individual’s\nquality. For a high-quality signaler, a ‘bigger’ signal is a smaller\nhandicap (less costly, or more affordable) than it is for a\nlow-quality signaler, thus ‘big’ signals are reliable signals of\nFIGURE 2 | Johnstone’s graphical model of the Handicap principle. The basic\nassumption is that it costs a high-quality signaler less to signal at its optimum\nlevel than it costs a low-quality signaler to signal at that level. The optimum or\nequilibrium level (where the difference between the costs and benefits of\nsignaling are greatest) for the low quality signaler is lower (opt low) than that\nfor the high-quality signaler (opt high). Thus the signaling level is a reliable\nindicator of signaler quality.\nsignaler quality. One of the clearest demonstrations of honesty\nin an epigamic signal was carried out by Petrie and her\ncolleagues on that poster animal for epigamic signaling, the\npeacock. Petrie and colleagues demonstrated that in their peacock\npopulation, females preferred a mate with more eyespots in his\nfeather train (whether the difference was natural, or produced\nby experimental manipulation), and that females mated with\nmales with more eyespots had more young surviving to a\nyear of age than females mated to males with fewer eyespots\n(Petrie et al., 1991; Petrie, 1994; Petrie and Halliday, 1994).\nAlthough the generality of these results has been questioned by\nstudies on other populations (Takahashi et al., 2008; Dakin and\nMontgomerie, 2011), the example provides a clear illustration\nof the predictions generated by the handicap principle, and how\nthey should be tested.\nThe handicap principle should maintain some degree of\nhonesty in any signaling system where signaler and receiver have\nnon-identical interests, such as virtually all mating and agonistic\ncontexts. A low-quality individual can only ‘lie’ by diverting\nenergy into signal development and expression that it needs for\nmaintenance, and so as Searcy and Nowicki (2005) succinctly put\nit, lying becomes more costly than signaling honestly. Searcy and\nNowicki suggest that ‘reliable’ is a better word here than ‘honest,’\nfor several reasons. First, as with reliability testing in science\nand elsewhere, we understand that although perfect reliability is\nunattainable, partial reliability may be good enough. In contrast,\n‘honesty’ is generally taken to mean absolute honesty. Second,\nreliability of a signal is empirically measurable. Thus instead\nof debating whether an animal signal is informative or not,\nwe can measure if it predicts something important about the\npresent state of affairs or future events. Thus for example, in\nan agonistic situation a ‘threat signal’ should predict subsequent\nescalation, and the strongest ‘threat’ signal should predict attack\n(Searcy and Beecher, 2009).\nSumming Up: Two Perspectives\nHistorically, the Information Transmission and Manipulation\nviews of animal communication systems have been presented\nas in opposition. I suggest that in fact they are simply different\nperspectives on the same process. Once we give the receiver\nagency, and accept that manipulation is a two-way or reciprocal\nprocess in animal communication, we see that the two views have\nmore in common than was at first thought. This rapprochement\nis nicely captured in the evolution of Dawkins and Krebs’s papers\non the topic. In their original paper, Dawkins and Krebs (1978)\nfocused on signalers and argued that “natural selection favors\n[signalers] who successfully manipulate [receivers] whether or\nnot this is to the advantage of the manipulated individuals.”\nHowever, 6 years later in a follow-up paper (Krebs and Dawkins,\n1984) they expanded their view to include receiver interests,\nnoting that receivers would be favored to resist manipulation\nand to attempt to “read the minds” of signalers. Finally, Krebs\n(1991), discussing Zahavi’s handicap principle, concluded that\nthe manipulation and honest signaling views are probably\nnot incompatible: “Dawkins and Krebs (1978) discussed a\ncoevolutionary process without specifying an end point, whereas\nZahavi was concerned mainly with the end-point itself, so it is\nFrontiers in Psychology | www.frontiersin.org 10 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\npossible to imagine an evolutionary arms race of manipulation\nand sales resistance which end up with honest signaling”\n(Krebs, 1991, p. 67).\nFigure 3 is a schematic representation of what I will call the\nReciprocal Manipulation view. It shows communication taking\nplace on a battleground in which signaler and receiver are each\nselected to manipulate the other, the battle being settled in the\nlong run with the compromise of mostly-honest (reliable) signals.\nThe “management-assessment” theory of Owings and Morton\n(1997, 1998) is quite similar to the Reciprocal Manipulation\nview. Their theory captures the dynamics of signalers attempting\nto manage receivers and receivers assessing signalers. In their\nwords “the process of assessment is more active than has been\ngenerally recognized, and is responsible for the ‘informational’\ncouplings between individuals” (1997, p. 359). However, receivers\ndo more than just assess signalers, they manipulate them as\nwell, requiring them to signal in the first place, and requiring\na relatively honest signal as a prerequisite for responding to\nthe signal. The Reliable Signaling view of Searcy and Nowicki\n(2005) is essentially identical to the Reciprocal Manipulation\nview, with the superficial difference that the former focuses on\nthe information transmission aspect (reliable signaling) while\nthe latter focuses on the manipulation aspect (the conflicting\nmotivations of signaler and receiver).\nThe Reciprocal Manipulation and Information Transmission\nviews each seem most helpful in different circumstances\n(Table 3). Where the interests and thus motivations of the two\nparties differ, the Reciprocal Manipulation highlights the clash.\nIn contrast, where the interests and motivations of the two\nparties are more in line, the Information Transmission viewpoint\nfocuses on the essence of the interaction. Indeed, where the\noverlap of sender and receiver interests is considerable, as\nfor example between related individuals, or mates caring for\noffspring, or individuals in a social group where individuals are\nFIGURE 3 | Schematic suggesting the opposing pressures favoring signaler\nover receiver or vice-versa. Where interests of signaler and receiver are\ncoincident or nearly so (light gray to white) reliable communication will occur.\nAt the extremes of the space (darker), where interests of one or the other of\nthe two parties predominates, signaling will be disfavored. In the intermediate\n(gray) region, one party may benefit more than the other, but signaling may still\nbe ‘reliable enough.’\nstrongly interdependent, reliable, mutually beneficial signals will\nbe favored. But even where the interests of sender and receiver\nare partially opposed, selection acting on both parties will move\nthem to the region where both parties benefit on average, and\nsignals will still be reliable, if less so. This game theory dynamic\nhas been clearly laid out elsewhere (Maynard Smith and Harper,\n2003; Godfrey-Smith, 2013).\nI believe that the clash between these views of animal\ncommunication has ultimately led us to a clearer view of\nanimal communication systems than the original humanoriented information transmission view. Most animal\ncommunication systems are somewhere on the continuum\nfrom pure manipulation to pure communication, from arms race\n(where sender and receiver have different interests, each selected\nto behave so as to benefit themselves) to pure information\ntransmission (where sender and receiver have identical interests,\nand where signals benefit or cost both parties in the same way or\nto the same degree). A fuller development of these ideas can be\nfound in Beecher (2020).\nIn conclusion, I have argued that we should expect that natural\ncommunication systems will generally be reliable, even if not\nperfectly honest, with signaler and receiver both benefiting on\naverage. However, returning to the main theme of this paper,\nthere is no reason to expect such systems to blossom into\nsimple languages unless signalers and receivers have identical\nor near-identical interests, and if the ecological selective context\nrequires strong cooperation. There are cognitive prerequisites\nas well – otherwise one might predict that honeybees should\nhave a simple language – but the brake on the evolution to\nlanguage-like signaling systems in species with the requisite\ncognitive capacity is provided by the generally divergent\ninterests of signaler and receiver. Otherwise, bonobos, dolphins\nand some other vertebrates who seem to have the necessary\ncognitive prerequisites would have a more language-like natural\ncommunication systems than they do.\nWHY ARE THERE NO NATURAL\nLANGUAGE SYSTEMS IN ANIMALS?\nResearch on teaching animals simple human language indicate\nthat at least some animals appear to have the cognitive capacity to\ndecode language or language-like expressions. Herman’s dolphins\ncould comprehend a sign language command such as “take\nthe ball to the hoop” and to distinguish it from a similar but\nsyntactically different command like “take the hoop to the ball”\n(Herman, 2010). Kanzi the bonobo could respond correctly\nto novel verbal commands such as “Can you put the pine\nneedles in the refrigerator?” (Savage-Rumbaugh et al., 1993).\nPepperberg (1981, 1987) and Pailian et al. (2020) have shown\nthat African gray parrots can follow verbal directions to solve\ndifficult problems, including some that challenge humans. Yet\ndespite having the apparent capacities, at least to some extent,\nno non-human animal uses even a rudimentary language in its\nday-to-day existence. This includes groups like the songbirds that\nseem to have a crucial design feature, the learning and cultural\ntransmission of a complex set of vocal signals. Some animals\nFrontiers in Psychology | www.frontiersin.org 11 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nTABLE 3 | Differences between reciprocal manipulation and information transmission perspectives.\nPerspective\nReciprocal manipulation Information transmission\nFocus on which aspect of the coevolutionary process? On the process itself On the end point of the process\nMost useful when sender and receiver interests are: Divergent Coincident\nFocus on what variable? Differing motivations of sender and receiver Information transmitted from sender to receiver\nappear to be smart enough, or capable enough to handle a simple\nlanguage, but we have yet to discover an animal communication\nsystem – in nature – that rises to this level. Thus it appears that\nsome missing element other than cognitive or motor limitations\nhas blocked language evolution in non-human animals. Although\nit is possible that yet some other cognitive limitation has not\nbeen clearly identified (Hauser et al., 2002; Pinker and Jackendoff,\n2005), I focus in this final section on a candidate for the missing\nelement that is not purely a cognitive mechanism.\nA clue as to the missing element comes from the honeybee\n‘dance language.’ Despite a relatively simple nervous system,\nhoneybees are able not only to transmit precise information\nabout events in the external world, but also to use this system\nin two very different contexts (when talking about the location of\ndesirable food sources or about the location of suitable hive sites).\nThe key ingredient for the evolution of this system, I would argue,\nis zero conflict of interest between sender and receiver. Both scout\nand recruit are sister sterile workers and they are both working\nto feed sisters and brothers slated to be future reproductives.\nHumans also evolved in a social system featuring extraordinary\nlevels of cooperation, but significantly this cooperation was not\nrestricted to close relatives, as it is in the honeybees and other\nsocial insects, ruling out kin selection as a sufficient explanation\n(but see Fitch, 2004).\nI will reframe the question from “why not them?” to the\nquestion of “why us” (phrasing suggested by Hrdy, 2009)?\nHow did the human animal become the one species to evolve\nlanguage? As I argued in the previous section, the field has\narrived at a consensus concerning the factors that shape animal\ncommunication systems: the pressure for sender and receiver\neach to shape the interaction to its benefit inevitably both\nstimulates and constrains the evolution of the communication\nsystem. Very unusual circumstances are required for a true\nlanguage system to evolve. Three essential conditions have to\nbe met. First, the species must have the underlying cognitive\ncapacity. Honeybees may lack this, but some other animals may\nhave it. Second, and this is the clue provided by honeybees, sender\nand receiver must have identical or near identical interests. Third,\nindividuals must have a compelling need to transmit information\nacross multiple contexts. These are precisely the conditions that\nexisted in pre-human and early human hunter-gatherer societies,\nthe context in which humans and our hominid precursors spent\nsome 95% of our evolutionary history. The description of the\nprototypical hunter-gatherer society that follows is based on\ninformation from a number of sources (including Boehm, 1999;\nBowles, 2006; Hrdy, 2009; Hill K. et al., 2011; Knight and Power,\n2011; Lee, 2018).\nOur hunter-gather ancestors lived in small social groups\nwhere individuals were strongly interdependent, and cooperation\nacross multiple contexts was essential for survival. Most highly\ncooperative animal societies such as the eusocial insects are\ntypically just very large families, but the human hunter-gatherer\nsocieties we know – and which we assume to be typical of\nthe ancestral type – consisted of members of several kin lines.\nThus human societies then – and now as well – required\nextensive cooperation among unrelated individuals. Humans are\nthe supreme cooperators in the animal world, but because this\ncooperation is not supported by high kin relatedness, it has\nto withstand a strong undercurrent of individual competition.\nWe sometimes lose sight of the human affinity for withingroup cooperation because of its paradoxical coexistence with\nintense between-group competition and tribalism. Irreconcilable\nconflicts within ancestral hunter-gatherer groups surely occurred,\nbut were often resolved by individuals leaving one group for\nanother (hunter-gatherer societies being classic examples of\nfission-fusion societies).\nStudents of human evolution, while differing as to what were\nthe key selective contexts, or the key adaptations, all agree that\nhuman evolution has been characterized by remarkable levels\nof within-group cooperation among unrelated individuals, on\na scale not seen in any non-human animal. Several contexts\nstand out as crucial for the high level of cooperation found\nin hunter-gather societies. They begin, of course, with hunting\nand gathering. Effective group hunting (usually done by men)\nrequires sharing of information about distant prey and discussion\nof strategies for capturing prey. In essentially the same way,\ngathering of plants and fruits (usually done by women) requires\nthe ability to track the growing schedules and locations of many\nplants and fruits in the area and the ability to discuss and\ncoordinate foraging activities efficiently. Furthermore, huntergatherer societies periodically have to pick up and move to a\nnew, more abundant locale. These moves require discussion and\ngroup consensus, with input from all parties, especially older,\nmore experienced men and women.\nA second, equally important axis of cooperation is childraising. Humans are unique among primates in the time and\ncost required to raise an offspring. Humans solved this problem\nby involving the whole group in the process. Hrdy (2009) has\npointed out that this pattern of cooperative breeding sets humans\napart from the exclusive mother-centered parenting of our closest\nrelatives, the great apes. In these early human societies, many\nindividuals played a role in the cooperative care. For starters, the\nwhole group participated in that food brought back to the camp\nwas typically shared among all individuals, without reference\nFrontiers in Psychology | www.frontiersin.org 12 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nto their role in procuring the food. Then unlike most mammals,\nthe father participated in child care alongside the mother. Other\nrelatives were routinely involved in direct child care, especially\nolder siblings and grandparents, often aunts and uncles too, and\nsometimes non-relatives as well.\nFinally, within-group cooperation is essential for success in\nbetween-group competition, warfare in particular. This aspect of\nour hunter-gather heritage is strongly debated in anthropology.\nUsing the terms of Lee (2018), the Peaceful school views\nsignificant inter-group competition as not beginning until the\nAgricultural era, when property gave humans something to fight\nover. The Bellicose school (e.g., Kelly, 2000; Gat, 2015) believes\ninter-group competition dates further back in our evolutionary\npast. But whenever it started, warfare would certainly promote\nadaptations for within-group cooperation.\nIn recent years various investigators have proposed key\nadaptations that may have allowed human societies to achieve\nthis high level of cooperation in the absence of the glue of a very\nhigh level of kinship. Although there is not complete agreement\nas to which of these adaptations were most crucial, taken together\nthey coalesce into a suite of psychological adaptations that\npromote prosocial within-group interactions within a context\nof near-complete interdependence. Indeed, Tomasello et al.\n(2012) have dubbed this the Interdependence hypothesis. The\nspecific adaptations include: shared intentionality (Tomasello\net al., 2005), egalitarianism (Boehm, 1999), social learning\nand communication (Herrmann et al., 2007), intersubjectivity\nand empathy (Hrdy, 2009), moral intuitions (Haidt, 2012),\nadaptations for teaching and receiving teaching, and thus cultural\ntransmission (Sterelny, 2012; Henrich, 2016; Whiten, 2017),\nproactive aggression (Wrangham, 2018) and self-domestication\n(Wrangham, 2019). These adaptations of our social mind appear\nto be what set us apart from the other great apes, who it\nhas been argued are otherwise just as cognitively advanced\n(Herrmann et al., 2007). This suite of adaptations has enabled\nus to live in complex, cooperative societies. Despite our equally\nextraordinary proactive (deliberate and planned) aggressive\ntendencies, directed typically at out-groups, as in wars, pogroms,\ncrusades and the like (Wrangham, 2018), no other social animal\nhas achieved the level of within-group docility and cooperation\nwithout high within-group relatedness that is found in the human\nspecies. I note that Knight (2018) has an advanced an argument\nsimilar to the one I have presented here.\nLanguage unquestionably represents the pinnacle of evolved\nanimal communication systems, and as noted at the beginning\nof this section, attempts to teach language to animals have\nnot significantly changed this view. Language is often given\npride of place in human evolution. In this view the other\nadaptations mentioned above came only after some form of\nlanguage was in place. I favor the view of Hrdy (2009), that this\nmay well reverse cause and effect. The evolution of language\nmay have only become possible when the posited unique suite of\nprosocial, communicative and mind-reading adaptations were in\nplace. The crucial importance of communication in the strongly\ninterdependent social system of early humans would have created\nthis prosocial suite of adaptations, and would have laid the\ngroundwork for evolving a true language.\nAUTHOR CONTRIBUTIONS\nThe author confirms being the sole contributor of this work and\nhas approved it for publication.\nACKNOWLEDGMENTS\nMany thanks to editor IP, three reviewers, John Byers, Doug\nMock, Trish Schwagmeyer, and Bill Searcy for their very\nthoughtful reviews of the manuscript.\nREFERENCES\nAkçay, Ç, Anderson, R. C., Nowicki, S., Beecher, M. D., and Searcy, W. A. (2015a).\nQuiet threats: soft song as an aggressive signal in birds. Anim. Behav. 105,\n267–274. doi: 10.1016/j.anbehav.2015.03.009\nAkçay, Ç, Campbell, S. E., and Beecher, M. D. (2015b). The fitness consequences of\nhonesty: under-signalers have a survival advantage in song sparrows. Evolution\n69, 3186–3193. doi: 10.1111/evo.12818\nAkçay, Ç, Reed, V. A., Campbell, S. E., Templeton, C. N., and Beecher, M. D.\n(2010). Indirect reciprocity: song sparrows distrust aggressive neighbors based\non eavesdropping. Anim. Behav. 80, 1041–1047. doi: 10.1016/j.anbehav.2010.\n09.009\nAkçay, Ç, Tom, M. E., Campbell, S. E., and Beecher, M. D. (2013). Song\ntype matching is an honest early threat signal in a hierarchical animal\ncommunication system. Proc. R. Soc. Lond. B Biol. Sci. 280:20122517. doi:\n10.1098/rspb.2012.2517\nAkçay, Ç, Tom, M. E., Holmes, D., Campbell, S. E., and Beecher, M. D.\n(2011). Sing softly and carry a big stick: signals of aggressive intent in\nsong sparrows. Anim. Behav. 82, 377–382. doi: 10.1016/j.anbehav.2011.\n05.016\nAkçay, Ç, Wood, W. E., Searcy, W. A., Templeton, C. N., Campbell, S. E., and\nBeecher, M. D. (2009). Good neighbour, bad neighbour: song sparrows retaliate\nagainst aggressive rivals. Anim. Behav. 78, 97–102. doi: 10.1016/j.anbehav.2009.\n03.023\nAnderson, R. C., Searcy, W. A., Peters, S., Hughes, M., DuBois, A. L., and\nNowicki, S. (2017). Song learning and cognitive ability are not consistently\nrelated in a songbird. Anim. Cogn. 20, 309–320. doi: 10.1007/s10071-016-\n1053-7\nAndersson, M. (1982). Female choice selects for extreme tail length in a widowbird.\nNature 299, 818–820. doi: 10.1038/299818a0\nBaker, M. C., and Boylan, J. T. (1995). A catalog of song syllables of indigo and\nlazuli buntings. Condor 97, 1028–1040. doi: 10.2307/1369541\nBarker, A. J., Veviurko, G., Bennett, N. C., Hart, D. W., Mograby, L., and Lewin,\nG. R. (2021). Cultural transmission of vocal dialect in the naked mole-rat.\nScience 371, 503–507. doi: 10.1126/science.abc6588\nBarske, J., Schlinger, B. A., Wikelski, M., and Fusani, L. (2011). Female choice\nfor male motor skills. Proc. R. Soc. Lond., B Biol. Sci. 278, 3523–3528. doi:\n10.1098/rspb.2011.0382\nBeecher, M. D. (2017). Birdsong learning as a social process. Anim. Behav. 124,\n233–246. doi: 10.1016/j.anbehav.2016.09.001\nBeecher, M. D. (2020). “Animal communication,” in Oxford Encyclopedia of the\nHistory of Psychology, ed. W. Pickren (Oxford, UK: Oxford University Press).\nBeecher, M. D., and Akçay, Ç (2014). “Friends and enemies: how social dynamics\nshape communication and song learning in song sparrows,” in Animal Behavior,\ned. K. Yakusawa (Santa Barbara, CA: Praeger), 33–61.\nBeecher, M. D., Akçay, Ç, and Campbell, S. E. (2020). Birdsong learning is mutually\nbeneficial for tutee and tutor in song sparrows. Anim. Behav. 166, 281–288.\ndoi: 10.1016/j.anbehav.2020.05.015\nFrontiers in Psychology | www.frontiersin.org 13 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nBeecher, M. D., and Brenowitz, E. A. (2005). Functional aspects of song learning in\nsongbirds. Trends Ecol. Evol. 20, 143–149. doi: 10.1016/j.tree.2005.01.004\nBeecher, M. D., and Campbell, S. E. (2005). The role of unshared songs in singing\ninteractions between neighbouring song sparrows. Anim. Behav. 70, 1297–1304.\ndoi: 10.1016/j.anbehav.2005.03.008\nBeecher, M. D., Campbell, S. E., and Burt, J. M. (1994). Song perception in the\nsong sparrow: birds classify by song type but not by singer. Anim. Behav. 47,\n1343–1351. doi: 10.1006/anbe.1994.1182\nBeecher, M. D., Campbell, S. E., Burt, J. M., Hill, C. E., and Nordby, J. C. (2000).\nSong type matching between neighboring song sparrows. Anim. Behav. 59,\n21–27. doi: 10.1006/anbe.1999.1276\nBeecher, M. D., Nordby, J. C., Campbell, S. E., Burt, J. M., Hill, C. E., and\nO’Loghlen, A. L. (1997). “What is the function of song learning in songbirds?,”\nin Communication. Perspectives in Ethology, Vol. 12, eds D. H. Owings, M. D.\nBeecher, and N. S. Thompson (New York, NY: Plenum Press), 77–97. doi:\n10.1007/978-1-4899-1745-4_4\nBeecher, M. D., Stoddard, P. K., Campbell, S. E., and Horning, C. L. (1996).\nRepertoire matching between neighbouring song sparrows. Anim. Behav. 51,\n917–923. doi: 10.1006/anbe.1996.0095\nBoehm, C. (1999). Hierarchy in the Forest: The Evolution of Egalitarian Behavior.\nCambridge, MA: Harvard University Press.\nBowles, S. (2006). Group competition, reproductive leveling, and the evolution of\nhuman altruism. Science 314, 1569–1572. doi: 10.1126/science.1134829\nBradbury, J. W., and Vehrencamp, S. L. (1998). The Principles of Animal\nCommunication. Sunderland, MA: Sinauer Associates.\nBurt, J. M., Bard, S. C., Campbell, S. E., and Beecher, M. D. (2002). Alternative\nforms of song matching in song sparrows. Anim. Behav. 63, 1143–1151. doi:\n10.1006/anbe.2002.3011\nBurt, J. M., Campbell, S. E., and Beecher, M. D. (2001). Song type matching as\nthreat: a test using interactive playback. Anim. Behav. 62, 1163–1170. doi:\n10.1006/anbe.2001.1847\nByers, B. E. (1996). Messages encoded in the songs of chestnut-sided warblers.\nAnim. Behav. 52, 691–705. doi: 10.1006/anbe.1996.0214\nByers, J., Hebets, E., and Podos, J. (2010). Female mate choice based upon male\nmotor performance. Anim. Behav. 79, 771–778. doi: 10.1016/j.anbehav.2010.\n01.009\nCade, W. (1975). Acoustically orienting parasitoids: fly phonotaxis to cricket song.\nScience 190, 1312–1313. doi: 10.1126/science.190.4221.1312\nCarazo, P., and Font, E. (2010). Putting information back into biological\ncommunication. J. Evol. Biol. 23, 661–669. doi: 10.1111/j.1420-9101.2010.\n01944.x\nCaro, T. M., and Hauser, M. D. (1992). Is there teaching in nonhuman animals?\nQ. Rev. Biol. 67, 151–174.\nCarouso-Peck, S., and Goldstein, M. H. (2019). Female social feedback reveals\nnon-imitative mechanisms of vocal learning in zebra finches. Curr. Biol. 29,\n631–636.e633. doi: 10.1016/j.cub.2018.12.026\nCatchpole, C. K. (1987). Bird song, sexual selection and female choice. Trends Ecol.\nEvol. 2, 94–97. doi: 10.1016/0169-5347(87)90165-0\nChomsky, N. (1986). Knowledge of Language: Its Nature, Origin, and Use.\nNew York, NY: Praeger.\nClutton-Brock, T. H., and Albon, S. D. (1979). The roaring of red deer and\nthe evolution of honest advertisement. Behaviour 69, 145–170. doi: 10.1163/\n156853979X00449\nColeman, S. W., Patricelli, G. L., Coyle, B., Siani, J., and Borgia, G. (2007). Female\npreferences drive the evolution of mimetic accuracy in male sexual displays.\nBiol. Lett. 3, 463–466. doi: 10.1098/rsbl.2007.0234\nCollins, S. A. (2004). “Vocal fighting and flirting: the functions of birdsong,”\nin Nature’s Music: The Science of Birdsong, ed. P. M. H. Slabbekoorn\n(New York, NY: Academic Press), 39–79. doi: 10.1016/b978-012473070-0/\n50005-0\nDakin, R., and Montgomerie, R. (2011). Peahens prefer peacocks displaying more\neyespots, but rarely. Anim. Behav. 82, 21–28. doi: 10.1016/j.anbehav.2011.\n03.016\nDavies, N. B., and Halliday, T. R. (1978). Deep croaks and fighting assessment in\ntoads Bufo bufo. Nature 274, 683–685. doi: 10.1038/274683a0\nDawkins, R., and Krebs, J. R. (1978). “Animal Signals: information or\nmanipulation?,” in Behavioural Ecology: An Evolutionary Approach, eds J. R.\nKrebs and N. B. Davies (Oxford: Blackwell), 282–309.\nDoupe, A. J., and Kuhl, P. K. (1999). Birdsong and human speech: common themes\nand mechanisms. Annu. Rev. Neurosci. 22, 567–631. doi: 10.1146/annurev.\nneuro.22.1.567\nElias, D. O., Maddison, W. P., Peckmezian, C., Girard, M. B., and Mason,\nA. C. (2012). Orchestrating the score: complex multimodal courtship in\nthe Habronattus coecatus group of Habronattus jumping spiders (Araneae:\nSalticidae). Biol. J. Linn. Soc. 105, 522–547. doi: 10.1111/j.1095-8312.2011.\n01817.x\nFisher, J. B. (1954). “Evolution and bird sociality,” in Evolution as Process,\neds J. Huxley, A. C. Hardy, and E. B. Ford (London: Allen & Unwin),\n71–83.\nFitch, W. T. (2004). “Evolving honest communication systems: kin delection and\n‘mother tongues’,” in Evolution of Communication Systems: A Comparative\nApproach, eds D. K. Oller and U. Griebel (Cambridge, MA: MIT Press),\n275–296.\nFitch, W. T., and Jarvis, E. (2013). “Birdsong and other animal models for\nhuman speech, song, and vocal learning,” in Language, Music, and the Brain:\nA Mysterious Relationship, ed. M. A. Arbib (Cambridge, MA: MIT Press).\nGarland, E. C., and McGregor, P. K. (2020). Cultural transmission, evolution, and\nrevolution in vocal displays: insights from bird and whale song. Front. Psychol.\n11:544929. doi: 10.3389/fpsyg.2020.544929\nGat, A. (2015). Proving communal warfare among hunter-gatherers: the\nquasi-rousseauan error. Evol. Anthropol. 24, 111–126. doi: 10.1002/evan.\n21446\nGentner, T. Q., Fenn, K. M., Margoliash, D., and Nusbaum, H. C. (2006). Recursive\nsyntactic pattern learning by songbirds. Nature 440, 1204–1207. doi: 10.1038/\nnature04675\nGodfrey-Smith, P. (2013). “Information and influence in sender-receiver models,\nwith applications to animal behavior,” in Animal Communication Theory:\nInformation and Influence, ed. U. E. Stegmann (Cambridge: Cambridge\nUniversity Press).\nGould, J. L. (1975). Honey bee recruitment: the dance-language controversy.\nScience 189, 685–693. doi: 10.1126/science.1154023\nGrafen, A. (1990). Biological signals as handicaps. J. Theor. Biol. 144, 517–546.\ndoi: 10.1016/s0022-5193(05)80088-8\nGreen, S. (1975). “Variation of vocal pattern with social situation in the Japanese\nmacaque (Macaca fuscata): a field study,” in Primate Behavior, ed. L. A.\nRosenblum (New York, NY: Academic Press), 1–102. doi: 10.1016/b978-0-12-\n534004-5.50006-3\nGreen, S., and Marler, P. (1979). “The analysis of animal communication,” in Social\nBehavior and Communication, eds P. Marler and G. Vandenbergh (New York,\nNY: Plenum), 73–158. doi: 10.1007/978-1-4615-9116-0_3\nHaidt, J. (2012). The Righteous Mind: Why Good People are Divided by Politics and\nReligion. New York, NY: Pantheon.\nHauser, M. D. (2000). A primate dictionary? Decoding the function and meaning\nof another species’ vocalizations. Cogn. Sci. 24, 445–475. doi: 10.1207/\ns15516709cog2403_5\nHauser, M. D., Chomsky, N., and Fitch, W. T. (2002). The faculty of language:\nwhat is it, who has it, and how did it evolve? Science 298, 1569–1579. doi:\n10.1126/science.298.5598.1569\nHebets, E. A., and Uetz, G. W. (1999). Female responses to isolated\nsignals from multimodal male courtship displays in the wolf spider\ngenusSchizocosa(Araneae: Lycosidae). Anim. Behav. 57, 865–872. doi: 10.1006/\nanbe.1998.1048\nHenrich, J. (2016). The Secret of our Success: How Culture is Driving Human\nEvolution, Domesticating our Species, and Making us Smarter. Princeton, NJ:\nPrinceton University Press.\nHerman, L. M. (2010). What laboratory research has told us about dolphin\ncognition. Int. J. Comp. Psychol. 23, 310–330.\nHerrmann, E., Call, J., Hernandez-Lloreda, M. V., Hare, B., and Tomasello,\nM. (2007). Humans have evolved specialized skills of social cognition: the\ncultural intelligence hypothesis. Science 317, 1360–1366. doi: 10.1126/science.\n1146282\nHewes, G. W. (1973). Primate communication and the gestural origin of language.\nCurr. Anthrop. 14, 5–24.\nHill, C. E., Akçay, Ç, Campbell, S. E., and Beecher, M. D. (2011). Extrapair\npaternity, song and genetic quality in song sparrows. Behav. Ecol. 22, 73–81.\ndoi: 10.1093/beheco/arq171\nFrontiers in Psychology | www.frontiersin.org 14 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nHill, K., Walker, R. S., Božicevi ˇ c, M., Eder, J., Headland, T., Hewlett, B., et al. (2011). ´\nCo-residence patterns in hunter-gatherer societies show unique human social\nstructure. Science 331, 1286–1289. doi: 10.1126/science.1199071\nHockett, C. F. (1960). The origin of speech. Sci. Am. 203, 88–111.\nHorning, C. L., Beecher, M. D., Stoddard, P. K., and Campbell, S. E. (1993). Song\nperception in the song sparrow: importance of different parts of the song in song\ntype classification. Ethology 94, 46–58. doi: 10.1111/j.1439-0310.1993.tb00546.x\nHrdy, S. B. (2009). Mothers and Others: The Evolutionary Origins of Mutual\nUnderstanding. Cambridge, MA: Harvard University Press.\nJanik, V. M. (2014). Cetacean vocal learning and communication. Curr. Opin.\nNeurobiol. 28, 60–65. doi: 10.1016/j.conb.2014.06.010\nJohnstone, R. A. (1997). “The evolution of animal signals,” in Behavioural Ecology:\nAn Evolutionary Approach, eds J. Krebs and R. Davies (Oxford: Blackwell),\n155–178.\nKeagy, J., Savard, J.-F., and Borgia, G. (2009). Male satin bowerbird problemsolving ability predicts mating success. Anim. Behav. 78, 809–817. doi: 10.1016/\nj.anbehav.2009.07.011\nKelly, R. (2000). Warless Societies and the Origin of War. Ann Arbor: Uinversity of\nMichigan Press.\nKnight, C. (2018). “Pressure for trust-based efficiency shaped the evolution of\nlanguage,” in The Evolution of Language: Proceedings of the 12th International\nConference (EVOLANGXII), eds C. Christine, F. Molly, L. Hannah, M. Luke, R.\nAndrea, and V. Tessa.\nKnight, C., and Power, C. (2011). “Social conditions for the evolutionary emergence\nof language,” in Handbook of Language Evolution, ed. K. G. M. Tallerman\n(Oxford: Oxford University Press), 346–349.\nKnornschild, M. (2014). Vocal production learning in bats. Curr. Opin. Neurobiol.\n28, 80–85. doi: 10.1016/j.conb.2014.06.014\nKrebs, J. R. (1991). “Animal communication: ideas derived from Tinbergen’s\nactivities,” in The Tinbergen Legacy, eds M. D. Dawkins, T. R. Halliday, and\nR. Dawkins (London: Chapman & Hall), 60–74. doi: 10.1007/978-0-585-35\n156-8_5\nKrebs, J. R., and Davies, R. (1978). Behavioural Ecology: An Evolutionary Approach.\nOxford: Blackwell.\nKrebs, J. R., and Dawkins, R. (1984). “Animal signals: mind-reading and\nmanipulation,” in Behavioural Ecology: An Evolutionary Approach, 2nd Edn, eds\nJ. R. Krebs and R. Davies (Oxford: Blackwell), 380–402.\nKroodsma, D., Hamilton, D., Sánchez, J. E., Byers, B. E., Fandiño-Mariño, H.,\nStemple, D. W., et al. (2013). Behavioral evidence for song learning in the\nsuboscine bellbirds (Procnias spp.; Cotingidae). Wilson J. Ornithol. 125, 1–14.\ndoi: 10.1676/12-033.1\nKroodsma, D. E. (1977). Correlates of song organization among North American\nwrens. Am. Nat. 111, 995–1008. doi: 10.1086/283228\nKroodsma, D. E. (1988). “Contrasting styles of song development and their\nconsequences among passerine birds,” in Evolution and Learning, eds R. C.\nBolles and M. D. Beecher (Hillsdale, NJ: Lawrence Erlbaum Associates),\n157–184.\nLangmore, N. E. (1998). Functions of duet and solo songs of female birds. Trends\nEcol. Evol. 13, 136–140. doi: 10.1016/s0169-5347(97)01241-x\nLee, R. L. (2018). Hunter-gatherers and human evolution: new light on old\ndebates. Annu. Rev. Anthrop. 47, 513–531. doi: 10.1146/annurev-anthro102116-041448\nLevin, R. N. (1996). Song behaviour and reproductive strategies in a duetting\nwren, Thryothorus nigricapillus: II. Playback experiments. Anim. Behav. 52,\n1107–1117. doi: 10.1006/anbe.1996.0258\nLogue, D. M., and Gammon, D. E. (2004). Duet songs and sex roles during territory\ndefence in a tropical bird, the black-bellied wren. Anim. Behav. 68, 721–731.\ndoi: 10.1016/j.anbehav.2003.10.026\nLorenz, K. Z. (1966). The psychobiological approach: methods and results–\nEvolution of ritualization in the biological and cultural spheres. Philos. Trans.\nR. Soc. Lond. B Biol. Sci 251, 273–284. doi: 10.1098/rstb.1966.0011\nMacDougall-Shackleton, S. A. (1997). Sexual selection and the evolution of song\nrepertoires. Curr. Ornithol. 14, 81–124. doi: 10.1007/978-1-4757-9915-6_3\nMarler, P. (1961). The logical analysis of animal communication. J. Theor. Biol. 1,\n295–317. doi: 10.1016/0022-5193(61)90032-7\nMarler, P. (1968). “Visual systems,” in Animal Communication, ed. T. A. Sebeok\n(Bloomington, IN: Indiana University Press), 103–126.\nMarler, P. (1970). Birdsong and speech development: could there be parallels? Am.\nSci. 58, 669–673.\nMarler, P., and Pickert, R. (1984). Species-universal microstructure in the learned\nsong of the swamp sparrow (Melospiza georgiana). Anim. Behav. 32, 673–689.\ndoi: 10.1016/s0003-3472(84)80143-8\nMarler, P., and Tamura, M. (1964). Culturally transmitted patterns of vocal\nbehavior in sparrows. Science 146, 1483–1486. doi: 10.1126/science.146.3650.\n1483\nMaynard Smith, J., and Harper, D. (2003). Animal Signals. Oxford: Oxford\nUniversity Press.\nMcDonald, M. V. (1989). Function of song in Scott’s seaside sparrow. Anim. Behav.\n38, 468–485. doi: 10.1016/s0003-3472(89)80040-5\nMedvin, M. B., Stoddard, P. K., and Beecher, M. D. (1993). Signals for parentoffspring recognition: a comparative analsysis of the begging calls of cliff\nswallows and barn swallows. Anim. Behav. 45, 841–850. doi: 10.1006/anbe.1993.\n1105\nNowicki, S., and Searcy, W. A. (2014). The evolution of vocal learning. Curr. Opin.\nNeurobiol. 28, 48–53. doi: 10.1016/j.conb.2014.06.007\nOtte, D. (1974). Effects and functions in the evolution of signaling systems. Annu.\nRev. Ecol. Syst. 5, 385–417. doi: 10.1146/annurev.es.05.110174.002125\nOtter, K. A., Mckenna, A., LaZerte, S. E., and Ramsay, S. M. (2020). Continentwide shifts in song dialects of white-throated sparrows. Curr. Biol. 30, 1–5.\ndoi: 10.1016/j.cub.2020.05.084\nOwings, D. H., and Morton, E. S. (1997). “The role of information in\ncommunication: an assessment/management approach,” in Communication,\neds D. H. Owings, M. D. Beecher, and N. S. Thompson (New York, NY: Plenum\nPress), 359–390. doi: 10.1007/978-1-4899-1745-4_12\nOwings, D. H., and Morton, E. S. (1998). Animal Vocal Communication: A New\nApproach. Cambridge: Cambridge University Press.\nOwren, M. J., Rendall, D., and Ryan, M. J. (2010). Redefining animal signaling:\ninfluence versus information in communication. Biol. Philos. 25, 755–780. doi:\n10.1007/s10539-010-9224-4 Corpus ID: 13443399,\nPailian, H., Carey, S. E., Halberda, J., and Pepperberg, I. M. (2020). Age and\nspecies comparisons of visual mental manipulation ability as evidence for\nits development and evolution. Sci. Rep. 10:7689. doi: 10.1038/s41598-020-\n64666-1\nPenn, D. J., and Számadó, S. (2018). The handicap principle: how an erroneous\nhypothesis became a scientific principle. Biol. Rev. 95, 267–290. doi: 10.1111/\nbrv.12563\nPepperberg, I. M. (1981). Functional vocalizations by an African grey parrot\n(Psittacus erithacus). Z. Tierpsychol. 55, 139–160. doi: 10.1111/j.1439-0310.\n1981.tb01265.x\nPepperberg, I. M. (1987). Acquisition of the same/different concept by an African\ngrey parrot (Psittacus erithacus): learning with respect to categories of color,\nshape, and material. Anim. Learn. Behav. 15, 423–432. doi: 10.3758/bf032\n05051\nPetrie, M. (1994). Improved growth and survival of offspring of peacocks with more\nelaborate trains. Nature 371, 598–599. doi: 10.1038/371598a0\nPetrie, M., Halliday, T., and Sanders, C. (1991). Peahens prefer peacocks with\nelaborate trains. Anim. Behav. 41, 323–331. doi: 10.1016/s0003-3472(05)\n80484-1\nPetrie, M., and Halliday, T. R. (1994). Experimental and natural changes in the\npeacock’s (Pavo cristatus) train can affect mating success. Behav. Ecol. Sociobiol.\n35, 213–217. doi: 10.1007/bf00167962\nPinker, S., and Jackendoff, R. (2005). The faculty of language: what’s special about\nit? Cognition 95, 201–236. doi: 10.1016/j.cognition.2004.08.004\nPrice, T., Wadewitz, P., Cheney, D., Seyfarth, R., Hammerschmidt, K., and Fischer,\nJ. (2015). Vervets revisited: a quantitative analysis of alarm call structure and\ncontext specificity. Sci. Rep. 5:13220. doi: 10.1038/srep13220\nReid, J. M., Arcese, P., Cassidy, A. L. E. V., Hiebert, S. M., Smith, J. N. M.,\nStoddard, P. K., et al. (2004). Song repertoire size predicts initial mating success\nin male song sparrows, Melospiza melodia. Anim. Behav. 68, 1055–1063. doi:\n10.1016/j.anbehav.2004.07.003\nReid, J. M., Arcese, P., Cassidy, A. L. E. V., Hiebert, S. M., Smith, J. N. M., Stoddard,\nP. K., et al. (2005). Fitness correlates of song repertoire size in free-living\nsong sparrows (Melospiza melodia). Am. Nat. 165, 299–310. doi: 10.2307/34\n73407\nFrontiers in Psychology | www.frontiersin.org 15 March 2021 | Volume 12 | Article 602635\nBeecher Animal Communication and Simple Language\nRendall, D., Owren, M. J., and Ryan, M. J. (2009). What do animal signals mean?\nAnim. Behav. 78, 233–240. doi: 10.1016/j.anbehav.2009.06.007\nRice, J. O., and Thompson, W. L. (1968). Song development in the indigo bunting.\nAnim. Behav. 16, 462–469. doi: 10.1016/0003-3472(68)90041-9\nRyan, M. J., and Rand, A. S. (1990). The sensory basis of sexual selection for\ncomplex calls in the Túngara frog, Physalaemus pustulosus (sexual selection for\nsensory exploitation). Evolution 44, 305–314. doi: 10.1111/j.1558-5646.1990.\ntb05200.x\nSavage-Rumbaugh, E. S., Murphy, J., Sevcik, R. A., Brakke, K. E., Williams, S. L.,\nand Rumbaugh, D. M. (1993). Language comprehension in ape and child.\nMonogr. Soc. Res. Child Dev. 58, 1–222.\nSchürch, R., and Ratnieks, F. W. (2015). The spatial information content of the\nhoney bee waggle dance. Front. Ecol. Evol. 3:22. doi: 10.3389/fevo.2015.00022\nScott-Phillips, T. C. (2008). Defining biological communication. J. Evol. Biol. 21,\n387–395. doi: 10.1111/j.1420-9101.2007.01497.x\nSearcy, W. A. (1984). Song repertoire size and female preferences in song sparrows.\nBehav. Ecol. Sociobiol. 14, 281–286. doi: 10.1007/bf00299499\nSearcy, W. A., Akçay, Ç, Nowicki, S., and Beecher, M. D. (2014). Aggressive\nsignaling in song sparrows and other songbirds. Adv. Study Behav. 46, 89–125.\ndoi: 10.1016/b978-0-12-800286-5.00003-1\nSearcy, W. A., and Beecher, M. D. (2009). Song as an aggressive signal in songbirds.\nAnim. Behav. 78, 1281–1292. doi: 10.1016/j.anbehav.2009.08.011\nSearcy, W. A., and Nowicki, S. (2005). The Evolution of Animal Communication.\nPrinceton, NJ: Princeton University Press.\nSearcy, W. A., and Yasukawa, K. (1996). “Song and female choice,” in Ecology and\nEvolution of Acoustic Communication in Birds, eds D. E. M. Kroodsma and H.\nEdward (London: Cornell University Press), 454–473.\nSeyfarth, R. M., Cheney, D. L., Bergman, T., Fischer, J., Zuberbühler, K., and\nHammerschmidt, K. (2010). The central importance of information in studies\nof animal communication. Anim. Behav. 80, 3–8. doi: 10.1016/j.anbehav.2010.\n04.012\nSeyfarth, R. M., Cheney, D. L., and Marler, P. (1990). Monkey responses\nto three different alarm calls: evidence of predator classification and\nsemantic communication. Science 210, 801–803. doi: 10.1126/science.74\n33999\nSmith, W. J. (1997). “The behavior of communicating, after twenty years,” in\nCommunication, eds D. H. Owings, M. D. Beecher, and N. S. Thompson\n(New York, NY: Plenum), 7–53. doi: 10.1007/978-1-4899-1745-4_2\nStein, A. C., and Uy, J. A. C. (2006). Plumage brightness predicts male mating\nsuccess in the lekking golden-collared manakin, Manacus vitellinus. Behav. Ecol.\n17, 41–47. doi: 10.1093/beheco/ari095\nSterelny, K. (2012). The Evolved Apprentice: How Evolution Made Humans Unique.\nCambridge, MA: The MIT Press.\nStoddard, P. K., and Beecher, M. D. (1983). Parental recognition of offspring in the\ncliff swallow. Auk 100, 795–799. doi: 10.1093/auk/100.4.795\nStoeger, A., and Manger, P. (2014). Vocal learning in elephants: neural bases and\nadaptive context. Curr. Opin. Neurobiol. 28, 101–107. doi: 10.1016/j.conb.2014.\n07.001\nStruhsaker, T. T. (1967). “auditory communication among vervet monkeys\n(Cercopithecus aethiops),” in Social Communication Among Primates, ed. S. A.\nAltmann (Chicago, IL: Chicago University Press), 281–324.\nStuddert-Kennedy, M. (1998). “The particulate origins of language generativity:\nfrom syllable to gesture,” in Approaches to the Evolution of Language: Social\nand Cognitive Bases, eds J. Hurford, M. Studdert-Kennedy, and C. Knight\n(Cambridge: Cambridge University Press), 202–221.\nTakahashi, M., Arita, H., Hiraiwa-Hasegawa, M., and Hasegawa, T. (2008). Peahens\ndo not prefer peacocks with more elaborate trains. Anim. Behav. 75, 1209–1219.\ndoi: 10.1016/j.anbehav.2007.10.004\nTempleton, C. N., Akçay, Ç, Campbell, S. E., and Beecher, M. D. (2012). Soft song\nis a reliable signal of aggressive intent in song sparrows. Behav. Ecol. Sociobiol.\n66, 1503–1509. doi: 10.1007/s00265-012-1405-5\nThompson, W. L. (1969). Song recognition by territorial male buntings (Passerin\nA). Anim. Behav. 17, 658–663. doi: 10.1016/S0003-3472(69)80008-4\nThompson, W. L. (1970). Song variation in a population of indigo buntings. Auk\n87, 58–71. doi: 10.2307/4083658\nTinbergen, N. (1952). Derived activities: their causation, biological significance,\norigin and emancipation during evolution. Q. Rev. Biol. 27, 1–32. doi: 10.1086/\n398642\nTinbergen, N. (1964). “The evolution of signaling devices,” in Social Behavior and\nEvolution Among Vertebrates, ed. W. Etkin (Chicago, IL: University of Chicago\nPress), 206–230.\nTomasello, M., Carpenter, M., Call, J., Behne, T., and Moll, H. (2005).\nUnderstanding and sharing intentions: the origins of cultural cognition. Behav.\nBrain Sci. 28, 675–691. doi: 10.1017/s0140525x05000129\nTomasello, M., Melis, A. P., Tennie, C., Wyman, E., and Herrmann, E. (2012).\nTwo key steps in the evolution of human cooperation: the interdependence\nhypothesis. Curr. Anthropol. 53, 673–692. doi: 10.1086/668207\nvan Heijningen, C. A. A., de Visser, J., Zuidema, W., and ten Cate, C. (2009). Simple\nrules can explain discrimination of putative recursive syntactic structures by a\nsongbird species. Proc. Natl. Acad. Sci. U.S.A. 106, 20538. doi: 10.1073/pnas.\n0908113106\nWacewicz, S., and Zywiczy ˙ nski, P. (2015). Language evolution: why Hockett’s ´\ndesign features are a non-starter. Biosemiotics 8, 29–46. doi: 10.1007/s12304-\n014-9203-2\nWalcott, C., Mager, J. N., and Piper, W. (2006). Changing territories, changing\ntunes: male loons, Gavia immer, change their vocalizations when they change\nterritories. r Anim. Behav. 71, 673–683. doi: 10.1016/j.anbehav.2005.07.011\nWhiten, A. (2017). Social learning and culture in child and chimpanzee. Annu. Rev.\nPsychol. 68, 129–154. doi: 10.1146/annurev-psych-010416-044108\nWiley, R. H. (2013). “Communication as a transfer of information: measurement,\nmechanism, and meaning,” in Animal Communication Theory: Information and\nInfluence, ed. U. Stegmann (Cambridge: Cambridge University Press), 113–129.\ndoi: 10.1017/cbo9781139003551.007\nWilliams, G. C. (1966). Adaptation and Natural Selection. Princeton, NJ: Princeton\nUniversity Press.\nWilson, E. O. (1975). Sociobiology. Cambridge, MA: Harvard University Press.\nWrangham, R. W. (2018). Two types of aggression in human evolution. Proc. Natl.\nAcad. Sci. U.S.A. 115, 245–253. doi: 10.1073/pnas.1713611115\nWrangham, R. W. (2019). Hypotheses for the evolution of reduced reactive\naggression in the context of human self-domestication. Front. Psychol. 10:1914.\ndoi: 10.3389/fpsyg.2019.01914\nWright, T. F., and Dahlin, C. R. (2018). Vocal dialects in parrots: patterns and\nprocesses of cultural evolution. Emu 118, 50–66. doi: 10.1080/01584197.2017.\n1379356\nZahavi, A. (1975). Mate selection- a selection for handicap. J. Theor. Biol. 53,\n205–214. doi: 10.1016/0022-5193(75)90111-3\nZuidema, W., and de Boer, B. (2009). The evolution of combinatorial phonology.\nJ. Phon. 37, 125–144. doi: 10.1016/j.wocn.2008.10.003\nZuk, M., Rotenberry, J. T., and Tinghitella, R. M. (2006). Silent night: adaptive\ndisappearance of a sexual signal in a parasitized population of field crickets.\nBiol. Lett. 2, 521–524. doi: 10.1098/rsbl.2006.0539\nConflict of Interest: The author declares that the research was conducted in the\nabsence of any commercial or financial relationships that could be construed as a\npotential conflict of interest.\nCopyright © 2021 Beecher. This is an open-access article distributed under the terms\nof the Creative Commons Attribution License (CC BY). The use, distribution or\nreproduction in other forums is permitted, provided the original author(s) and the\ncopyright owner(s) are credited and that the original publication in this journal\nis cited, in accordance with accepted academic practice. No use, distribution or\nreproduction is permitted which does not comply with these terms.\nFrontiers in Psychology | www.frontiersin.org 16 March 2021 | Volume 12 | Article 602635", "affiliations": [{"country": "United States", "discipline": "Biology", "university": "University of Washington"}, {"country": "United States", "discipline": "Psychology", "university": "University of Washington"}], "species_categories": ["Bird", "Primate", "Marine Mammal", "Insect", "Other"], "specialized_species": ["African Gray Parrot", "Vervet Monkey", "Blue Jay", "Song Sparrow", "Indigo Bunting", "Western White-Throated Sparrow", "Eastern White-Throated Sparrow", "Honeybee", "Dolphin", "Bonobo"], "computational_stages": ["Data Collection", "Meaning Identification"], "linguistic_features": ["Semanticity", "Arbitrariness and Duality of Patterns", "Learnability", "Specialization", "Prevarication", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882680", "updated_at": "2026-01-13T16:08:31.573857", "committed_at": "2026-01-13T13:59:17.790612"}
{"id": "1523cda7-9791-41ca-83c3-d189b767235a", "title": "Dialects in Japanese Monkeys: Vocal Learning and Cultural Transmission of Locale-specific Vocal Behavior?", "authors": ["Green,  Steven"], "year": "1975", "journal": "Zeitschrift f\\", "abstract": "", "doi": "10.1111/j.1439-0310.1975.tb02006.x", "analysis_notes": "Differences were detected by ear in vocalizations made during artificial feeding of Japanese monkey troops at three locations. Tape recording and sound spectrographic analysis confirmed a distinctive vocal pattern specific to each site and used only in the provisioning situation. The 3 different acoustic morphologies are variations on a shared tonal theme. Vocal learning by Macaca fuscata may have occurred separately at each site regulated by species-wide constraints on vocal production.\n\n", "affiliations": [{"country": "United States", "discipline": "Biology", "university": "The Rockefeller University"}], "species_categories": ["Primate"], "specialized_species": ["Japanese monkey"], "computational_stages": [], "linguistic_features": [], "status": "saved", "created_at": "2026-01-13T12:49:59.882685", "updated_at": "2026-01-13T16:13:03.371034", "committed_at": "2026-01-13T14:01:24.790310"}
{"id": "c65da50d-b901-4513-aa6a-bdd11d7a7cf7", "title": "Do common ravens yell because they want to attract others?", "authors": ["Heinrich,  B.", "Marzluff,  J.M."], "year": "1991", "journal": "Behavioral Ecology and Sociobiology", "abstract": "", "doi": "10.1007/bf00172134", "analysis_notes": "Behav Ecol Sociobiol (1991) 28:13-21 Behavioral Ecology\nand Sociobiology\n© Springer-Verlag 1991\nDo common ravens yell because they want to attract others ?\nB. Heinrich and J.M. Marzluff\nDepartment of Zoology, University of Vermont, Burlington, VT 05405, USA\nReceived January 24, 1990 / Accepted July 28, 1990\nSummary. The formation of groups at food bonanzas\nresults from a variety of mechanism, which include recruitment by signalling and information parasitism. Recruitment is distinguished from information parasitism\non functional grounds: attraction of a crowd is termed\nrecruitment if the signaler's fitness is enhanced by the\nattraction of others but termed parasitism if the signaler's fitness is reduced by the attraction of others. We\nhere show, however, that in Common Ravens, Corvus\ncorax, the proximate reasons for giving recruitment signals are probably other than for attracting a crowd. In\nthe forests of the northeastern United States, non-breeding, vagrant ravens commonly aggregate in large\nnumbers at carcasses where they neutralize the defense\nof territorial adults. We attempted to mimic this situation with a captive flock of juveniles and a pair of resident adults in order to determine the proximate factors\ntriggering \"yells\", vocalizations which attract nearby ravens to large animal carcasses. Our experiments indicate\nthat yells are given primarily by hungry birds. However,\nyelling is strongly modified by status. Within the vagrant\ncrowd, status is labile. When successive dominants were\nremoved, replacements immediately took their place.\nFurthermore, when the dominants were re-introduced\nto the flock they always suffered significant losses of\nstatus and ceased yelling. The territorial male has, and\nconstantly maintains, the highest status within (but not\nnecessarily outside) his territory, and here he rarely yells.\nIn sharp contrast, within the vagrant crowd of unmated\nbirds it is the highest-status birds that are the most likely\nto yell when approaching food. Furthermore, the dominant vagrants (as well as adults) suppress yelling in subordinates. We conclude that ravens yell proximately to\nadvertise their status at food, and that recruitment is\nonly one of several ultimate advantages of the behavior.\nIntroduction\nMany species of animals aggregate in large numbers at\nlocalized food bonanzas. Groups can be assembled by\nOffprint request to .' B. Heinrich\na wide varietiy of mechanisms. For example, on the\nplains of Africa thousands of beetles are attracted to\na single dung pile where they compete intensely (Heinrich and Bartholomew 1978). They are presumably attracted by the smell of the dung itself. Vultures are attracted to carcasses by seeing others spiralling down to\nthem (K6nig 1983). A food bonanza may also be discovered by a group, that then feeds as a group (Balda\nand Bateman 1971). In addition, and perhaps most interestingly, animals may be attracted by signals given by\nthose discovering food. Specific attraction signals include the \"chirrup\" calls of House sparrows (Elgar\n1986), the \"whinny\" calls of spider monkeys (Chapman\nand Lefebvre 1990), the undulating flights of ospreys\n(Greene 1987), and the \"yells\" of ravens (Heinrich 1988,\n1989). Sometimes unsuccessful foragers also follow successful ones using subtle and largely unknown cues\n(Ward and Zhahavi 1973; Rabenold 1987 a; Krebs 1974;\nBrown 1986). In the latter cases information may be\nwithheld, and/or following may be suppressed (Waltz\n1983; Rabenold 1987b).\nWhether or not recruitment or information parasitism occurs is often a controversial topic, because to\nmany it raises the question of whether the signallers try\nto call in others or whether instead they are being exploited. But part of the controversy is artificial because\nthe distinction between proximate and ultimate causes\nof attraction signals have commonly not been made.\nMuch confusion has arisen because it is generally assumed that the two coincide. In other words, it is usually\nassumed that when animals recruit they give signals\n\"to\" attract others. Likewise, if information is parasitized it is usually assumed that the signals are not given\n\"to\" attract others. It is not necessary to impart volition\nto animals giving recruitment signals and then use this\nas the basis for distinguishing recruitment from parasitism. Attraction of a crowd can yield a great variety of\ndifferent costs and benefits. But the balance must be\npositive for attraction signals to evolve. Recruitment is\ndistinguished from parasitism on this purely functional\nground by investigating the ultimate consequences of\ngroup formation. Recruitment results when assembled\ngroups increase the signaler's fitness. Parasitism results\nwhen assembled groups decrease the signaler's fitness. \n14\nBy removing volition from the equation of whether\nor not recruitment occurs, we are faced with a second\nquestion: What is/are the proximate reason(s) for giving\nsignal(s) that result in recruitment (or parasitism)? Presumably any of a number of signals originally used and\nperhaps still functional for other purposes can be used\nand even modified to function as recruitment signals.\nTherefore, the proximate reason a recruitment signal is\ngiven is not necessarily to attract others. Recruitment\nsignals evolve because they enhance fitness and it is not\nnecessary for a signaler to realize this function. Only\nwhen the proximate reasons for giving recruitment signals include the attraction of others is the signaler behaving in an apparently purposeful manner that previous\nworkers implied was necessary for one to use the term\n\"recruitment.\" Costa Rican spider monkeys provide a\npossible example of recruitment where proximate and\nultimate reasons for signaling coincide. These monkeys\nadjust their group size to match resource availability\nby uttering \"whinny\" calls when groups are small relative to resource abundance and by withholding calls\nwhen enlarged group size results in heightened competition (Chapman and Lefebvre 1990). In the above and\nmany other cases of documented recruitment, scenarios\nof kin selection or reciprocity could explain the attraction of others, where the animals may proximately\n\"want\" to recruit. However, as discussed elsewhere\n(Heinrich 1988, 1989), this ultimate adaptive advantage\nis unlikely for ravens because of their vagrancy.\nHere we report on an experimental study designed\nto decipher the proximate factors eliciting the \"yell\"\nvocalization of Common Ravens (Corvus corax). This\nvocalization is given by immature vagrants near food\nwhich attracts other nearby vagrants (Heinrich 1988).\nElsewhere we investigated the ultimate function of group\nformation and concluded that it increases the signaler's\nfitness because crowds are able to overpower territorial\nadults and access defended foods unavailable to single\nravens (Heinrich 1988, 1989; Marzluff and Heinrich in\nprep.). Given our functional definitions, group formation by attraction to yells therefore constitutes recruitment, not parasitism. The results reported herein allow\nus to determine the motivation of the signaler thereby\ngaining a broader understanding of recruitment in this\nspecies.\nMethods\nApparatus and subjects. On 29 and 31 December 1988 we captured\n20 immature ravens (6 yearlings and 14 juveniles) and placed them\nin the main aviary of our aviary complex (Fig. 1). These immatures\nwere part of a group of approximately 50 ravens that were foraging\nat a dead cow in the mountains of western Maine within 20 meters\nof the aviary. Birds were captured in a walk-in trap, aged by mouth\nand plumage coloration, and marked with uniquely numbered and\ncolored patagial tags on both wings (see Heinrich, 1988 for details\nof the study area and capture and marking techniques). Laparotomies on December 8, 1989, indicated a sex ratio of 6 c?/14%\nImmatures quickly adapted to their new surroundings. They\nroosted as a communal group in a covered shed, fed as a group\nat liberally supplied carcasses and slaughter house offal (birds were\nf R'OO~T ~ ~\nAWAB¥ )\n, x ~xi x\"\nga\n/ OBBERVATION HUT :=: ;..\\\n?-k\n[ ) TERRITORIAL\n~ ADULTS\nFig. 1. Aviary complex where experiments were conducted. Twenty\nimmatures resided in the main aviary and a pair of adults defended\n1 peripheral aviary. The entire complex is interconnected and arms\ncan be opened or shut off by raising or lowering gates with guy\nwires operated from inside the observation hut. Due to terrain\n(hut is at the apex of a knoll) and vegetation (a spruce thicket\nlies between 2 peripheral aviaries) birds in the peripheral aviaries\ncan only see the lower quarter of the main aviary and vice versa.\nX's mark locations of food during experiments. The aviary complex\nis from 4-7 m in height and contains 50 vertical perches and 26\nhorizontal ones scattered throughout\nnever without food for more than 3 days during the first 3 months),\nbathed in the snow, allopreened and fought. Qualitatively, their\nbehavior was identical to the behavior of free-living immatures\nwe continued to monitor.\nOn 2 January we captured 3 adults and placed them in one\nof the peripheral aviaries of the complex (Fig. 1). 2 of these adults\nallopreened regularly, called in synchrony, and mirrored each\nother's actions suggesting to us (and another experienced with ravens, E. Gwinner) that they were an established pair. The third\nbird was released after 2 days of ostracism by the \"pair\". The\npair was fed ad libitum in their aviary and quickly began to defend\nits boundaries from free-living wild birds and from juveniles wandering in the arm between the main aviary and the adult aviary.\nThe adults asserted their dominant status by giving bowing ceremonies, thick-head postures, and ear-tuft intimidation displays (Gwinher 1964; Heinrich 1988) to any intruders.\nWe allowed our captive immatures to find food bonanzas\n(hunks of meat and carcasses ranging in size from squirrels to\ndeer) randomly located throughout the aviary complex for 3\nmonths prior to the experiment we discuss here. During this time\nwe determined dominance-subordination relationships by ad libirum observations of dyads during foraging (Altman 1974). The\ndominant of an interaction was the bird that forced the other to\nback away from confrontation in the fuzzy-headed submission posture (Heinrich 1988).\nA stable dominance hierarchy quickly developed among our\ncaptive immatures. It was clear from the first few days of captivity\nthat a few immatures consistently dominated all the other birds.\nOver a 3 month period (30 December-16 March) a hierarchy developed which we have broken into 4 categories: 1) 3 dominants who\nrarely deferred to others, 2) 6 subdominants who deferred to a\nminority of birds primarily dominants and other subdominants,\n3) 5 intermediates who won roughly 40% of their encounters, and\n4) 6 subordinates who rarely defeated any other bird. There was\nan obvious alpha male (RB) who only lost 2 encounters (both\nto the beta male) and had uncontested access to food at any time.\nOur method of determining the dominance hierarchy minimizes\nthe number of times individuals lose to lower ranking birds (Appleby 1983), however some nonlinearity was evident as one subordinate consistently defeated an intermediate and a lower ranking \n15\n0 40'\nZ\n~ 35- Z ..j\n~ ~ ~o.\n~ ~ 25- .J\n20.\n>-~m ~5\"\nL~ IL\n0 0 10-\nn,- n\"\nuJ uJ 5-\n~ rn\n:~ ~ 0-\n~ ~)\nz Z\nmmYELLS\n~;3 YELLERS\nZERO TWO FOUR\nDAYS WITHOUT FOOD\nFig. 2. The influence of increasing hunger on the number of yellers\nand yelling rates by immatures. Height of boxes indicate means.\nError bats are 1 SEM. Means are derived from the total response\nof the group to each of 5 food locations during each of 8 group\ncompositions (N=40 for 2 and 4 days without food, N=39 for\nzero days without food because of one missing observation)\nsubdominant defeated a higher ranking one. Despite the circular\ntriads created by these reversals, Appleby's (I 983) method indicates\nthat this hierarchy was significantly linear (linearity coefficient,\nK=0.93, X2 = 157, df= 27, P<0.001).\nExperimentalprotocol. From 23 March until 6 July 1989 we systematically varied composition of the immature group, the location\nof food, and the hunger level of immatures in order to determine\nhow these three factors influenced yelling. Two observers watched\nbirds thyough two-way mirrors with 10-power binoculars from an\nobservation hut 10 meters from the main aviary (Fig. 2). We recorded the identity of yellers and their rate of yelling (number\nof yells in randomly selected i rain intervals), who initially approached and contacted food, how long before food was contacted\nand consumed, and whether food was defended. Vocalizations were\nrecorded on a Sony TCM-5000 cassette recorder using a Senheiser\nME-88 microphone.\nWe could not accurately count yelling rates for all birds in\nan experiment. However, we could easily and unambiguously assign birds to primary or secondary yelling status. In an experiment\nthere were usually 1 or 2 primary yellers who yelled nearly constantly and maintained consistently high rates of yelling throughout\na majority of phases (different locations of food) of the experiment.\nPrimary yellers accounted for a majority of the yells uttered. However, in most experiments 3-10 secondary yellers yelled 1 or a\nfew times.\nWe employed a hierarchical experimental design to test the\ninfluence of the 3 factors. Group composition was the main blocking factor and consisted of 4 independent levels. Hunger was a\nthree-level repeated measure nested within each group. Location\nwas a five-level repeated measure within each hunger level. Each\ngroup was replicated twice resulting in 8 experiments. Each experiment consisted of 3 runs on 3 separate days (one for each hunger\nlevel) and on each day responses were measured in 5 phases (one\nfor each food location). One phase was omitted from analysis\n(\" Split Group\" when birds were satiated and the alpha was removed) because birds could not be segregated in the aviary arm.\nGroup composition was modified by removing dominant birds\nfrom the immature group. The first group composition included\nall birds. Our first manipulation was to remove the alpha male\nand his consort. After 7-10 days of allowing the remaining immatures to establish a dominance hierarchy (all birds simply shifted\nup one position) we tested this new group and then removed its\nalpha male. Again 1 week was allowed for reshuffling (all shifted\none position), birds were retested, and the alpha male removed.\nThus by removing three alpha males in succession we created 4\ngroup compositions. The response of birds in each composition\nwas replicated after a 14 day ad libitum feeding period by reintroducing each male in the reverse order from the order of removal.\nHunger level was repeated within each replicate of group composition. We modified hunger level by removing all food from\nsatiated birds for varying lengths of time. Responses of satiated\nbirds in each group were measured after they had fed ad libitum\nfor 2-6 days and still had food left on the day of the test. This\nresponse was contrasted to the response of birds on the second\nand fourth day without food. The order of application of hunger\nlevel to groups was randomized. In order to reduce accumulation\nof carryover effects between hunger treatments on different groups\nwe repeatedly satiated the birds during the 7-10 day period of\nreshuffling after an alpha male was removed.\nFood (5-15 kg hunks of meat) location was a second repeated\nmeasure because the immatures were exposed to each food location\non every day of the experiment. Each day we measured the calling\nresponse of immatures under 5 conditions. 1) Baseline = Before we\nplaced food in the aviary. 2) Group Approach = As immatures approached freely accessible food in the main aviary or just inside\nthe arm leading to the adult aviary. 3) Behind Screen=As they\napproached inaccessible food behind a lowered screen door separating the main aviary from the arm. 4) With Adults=As they\napproached inaccessible food in the adults' aviary behind a lowered\nscreen door. 5) Split Group=We captured approximately half of\nthe immatures in the arm of the complex by closing the screen\ndoor as the group began to enter. The rest of the group remained\nin the main aviary. Our intent was to separate the alpha male\nfrom the beta male. Food was placed in the main aviary or in\nthe arm so that ~[ group could get to it but the other group could\nonly see the food. After the group with access approached and\nbegan to eat, the meat was removed and placed with the other\ngroup until they approached and began to eat. Behaviors of all\nbirds as either group approached constituted the response for this\ntreatment.\nAdditional observations, as indicated, were made on birds in\nthe wild in the study area near the aviary, and on hand-reared\nbirds.\nResults\nOverall ANO VA\nHunger and location of food significantly influenced\nyelling rate and the number of birds yelling (Table 1).\nImmatures yelled more frequently as their level of\nhunger increased (Fig. 2). Satiated birds rarely yelled.\nOnly 50% of experiments with satiated birds produced\nany yelling. In contrast, after 4 days without food all\nexperiments had yellers, over a third of the group yelled,\nand many of the birds yelled continuously. The rate of\nyelling increased 16-fold every 2 days immatures were\nwithout food. As soon as foraging began, even after\n4 days without food, yelling subsided and was typically\nextinguished 10 min after the onset of eating. The major\ninfluence of food location on yelling was a decline in\nthe number of yellers and their rate of yelling when food\nwas located in the adults' aviary (Fig. 3). This food was\napproximately 0.5 m from the screen partition and when\nimmatures approached it the adults flew up to meet them\nwith ear-tuft intimidation displays and harsh calls that\nare often given by free-living adults when we trespass\nin their territories and when they fly over our captive\nadults. Yelling was most frequent when some or all birds\nhad access to the food and adults were out of view (Split\nApproach and Group Approach). However, inaccessible \n16\nT~ble 1. Analysis of variance results for the influence of 3 factors on yelling rate and\nthe number of yellers in an experiment\nYells/min Number of birds yelling\nF DF P F DF P\nMain effects\nHunger 16.5 2.8 0.001 18.5 2.8 0.001\nPlacement of food 4.8 4,16 0.01 7.9 4,16 0.001\nGroup composition 0.1 3,4 0.98 0.3 3,4 0.80\nInteractions\nHunger x Group 0.3 6,8 0.90 0.2 6,8 0.96\nHunger x Placement 4.5 8,32 0.001 3.8 8.32 0.003\nGroup x Placement 0.2 12,16 0.99 0.3 12,16 0.96\nGroup × Hunger\nx Placement 0.9 24,32 0.57 0.7 24,32 0.80\nSATIATED\n0 o 0\nZ 2 DAYS WITHOUT FOOD 3 25 2 DAYS WITHOUT FOOD\nz 15\n~o ~ 20. _a n-\n.a~ ~-~ ~ lo- ,,o\nO 8 O'\n8~ o ~-~, 50- 4 s u OD 04o. iioiii0 I~1~ ~Z\n~ ~ 30-\n<\n< 20-\n10-\n0 .%=¢,, ~,~,~¢~ .~,% ~ .¢ _~\n• ~.~ ~'4 ......... ~? ~ ~ t,9~,,~ \"'~Ol..~',q -~'O/~'Z~ \"~O,V;~,~]~ _ ~'V ~,~'~ V~ -- ~'~ .~ ~ ~, ,:,~ ~,~%,,%~,~ ~'#\n~'~\nPLACEMENT OF FOOD GROUP COMPOSITION ~/\nFig. 3. The influence of food placement on yelling by immatures.\nFood placements are defined in Methods. Average response+l\nSEM are indicated at 3 hunger levels. Total responses of birds\nat each location for each level of hunger are averaged over N= 8\ngroup compositions (N= 7 for split group, satiated because of missing observation)\nFig. 4. Influence of group composition on yelling by immatures.\n(Responses of immatures are averaged over 5 food locations during\n2 replicates of group composition to give N= 10 for each group\nat each of 3 hunger levels N= 9 for treatment with alpha removed\nand immatures satiated due to missing data). Means ÷ 1 SEM are\nshown\nfood also elicited frequent yelling when adults were not\npresent (compare Behind Screen to With Adults).\nHunger and placement of food had a significant interaction effect (Table 1). As hunger increased, yelling\nincreased, in all locations. However, the relative reduction in yelling when food was placed with adults became\nmore noticable as hunger increased (Fig. 3). After 4 days\nwithout food, yelling was even triggered by the sight\nof the observers entering the observation hut without\nplacing food in the aviary. (We suspect the birds were\nyelling in response to the expectation of food, inasmuch\nas fledged young yell when they see their parents approach.)\nGroup composition was not significantly related to\nyelling (Table 1, Fig. 4). However, dominance did influence yelling and hunger mediated this influence (Fig. 5). \nZ\n~ 100\n~ 80'\n,\n0 60 ~\n~ 40 ¢\nz 20\n~ 0\nSATIATED\n-I -] -\nI\n~ =\nI,I\n,\n-- i O~ ~\n0 •\n:~ 0\no ~'\nB C\n2 DAYS 4 DAYS\nWITHOUT FOOD WITHOUT FOOD\n-- ~\n~ K ~ ~\nFig. 5. Change in yelling and changing composition of yellers (with\nrespect to dominance) as a function of hunger. The percentage\nof all birds in a given class that yelled or were silent at 3 hunger\nlevels are shown. Percentages of yellers in each status class were\ndetermined by summing the number of yellers per dominance class\nacross the 8 tests of group composition and dividing this sum\nby the total birds in each class summed across the 8 experiments.\nChanges in status through the course of experimentation were accounted for which resulted in a total of 144 subordinates, 120\nintermediates, 114 subdominants, and 66 dominants across the 8\nexperiments. Filled bars primary yeller; hatched bars secondary\nyeller; open bars did not yell in experiment\nDuring experiments with satiated birds there were few\nprimary yellers and these were usually low ranking birds\nand never dominants (Fig. 5 A). The few dominants that\ndid yell did so only occasionally. As hunger increased\nnearly all dominants yelled and after four days without\nfood most primary yellers were high ranking birds\n(Fig. 5 B, C).\nDominant immatures suppress yelling by subordinates\nDuring the first replicate of the group composition manipulations subordinates yelled more frequently as dominants were removed (Fig. 6). When the alpha was removed, 4 new birds yelled for the first time including\nthe new dominant who did not yell in experiment 1 and\n2 intermediates who, after the alpha's removal, had risen\nin status. After removing the beta in addition to the\nalpha, 6 additional birds yelled for the first time. These\nwere primarily subordinates. Lastly, after the gamma\nwas removed still 1 more subordinate yelled. In total,\n19 of 20 birds yelled, but over half of these did not\nyell until 1 or more of their superiors were removed\nfrom the group. One subordinate never yelled.\nIt appears that alpha birds actively suppress the yelling of other dominants. A dramatic example of suppression occurred in experiment 2. The birds headed down\nthe arm toward the adults' aviary and the beta male\nyelled 8 times during the first minute. The alpha, who\nhad been silent, then attacked the beta, pinned him to\nthe snow and jabbed him with his bill. For the remainder\nof the experiment the beta was silent and the alpha yelled\nan average of 18.4 times/rain. More typically, suppression by the alpha was not physically forced upon other\ndominants and was only obvious when the dominants\nwere separated as we did in our Split Group treatment.\n17\n--~ 20 m~\n-~-\n01'- 15-\nD\n~_~\n,oil.\no\n.-~\nZ\nDOMINANTS ~\nSUBDOMINANTS ~ -\nINTERMEDIATES ~\nALL ALPHA ALPHA& ALPHA,\nPRESENT REMOVED BETA BETA &\nREMOVED GAMMA\nREMOVED\nGROUP COMPOSITION\n-2O\nO\nOc\n.15 mc\n• 10 ~ -<\nNz\nC g ~-K\nrrl\n0\nFig. 6. Number and status of birds yelling for the first time when\nwe varied group composition in the first replicate (experiments\n1-4). The line graph gives the cumulative number of birds that\nhad yelled at some point during experimentation. The bar graph\nindicates the composition of the new yellers accumulated in the\nline graph each time an alpha was removed. (Status categories\nrefer to status prior to the experiment)\nDuring this phase of experiment 1 we succeeded in getting the alpha and beta on opposite sides of the screen\ndoor. Although these birds were in visual and vocal contact within a few meters of each other the beta's behavior\nimmediately shifted when he was protected from the alpha and assumed the top position within his subgroup.\nInstead of waiting for the alpha to lead the way to food,\nthe beta was the first to eat and he yelled and attacked\nothers as he approached the food (Fig. 7A). However,\nhe never yelled when in the same subgroup with the\nalpha.\nIn experiment 2, the alpha was removed leaving the\nbeta in charge and he yelled regardless of who was in\nhis presence (Fig. 7 B). We were not able to isolate the\ngamma in this experiment and he remained silent in the\npresence of the beta. We did succeed in isolating the\ndelta and he took charge of his subgroup and yelled\nonly when isolated from the beta and gamma.\nIn experiment 3, the alpha and beta were removed\nand the gamma finally yelled as he assumed the alpha\nrole in the group (Fig. 7 C). As in experiment 2, the delta\nyelled only when isolated from the gamma. The delta\ncontinued yelling after the alpha, beta, and gamma were\nremoved (Fig. 7D). In this last experiment, however, the\ndelta and epsilon both yelled and even yelled without\nconflict when perched side by side.\nIn the first 3 experiments we can make 6 independent\ncomparisons of yelling by dominants when in the alpha's\ngroup versus when not in his group. 3 of these are comparisons of yelling within an experiment when dominants never yelled unless they were out of the alpha's\ngroup (then they averaged 8 yells/rain, SD = 5). Yelling\nby dominants in the experiments following removal of\nthe current alpha versus yelling in the previous experiment with the alpha provide three more comparisons.\nDominants did not yell with the alpha, but averaged \n18\nLu\nz\n30-\n25\"\n20\"\n15\"\n10\"\n5\"\n0\n'!t 1\nR\n0 ~\nm ALL BIRDS IN CONTACT 100 ]\n~2~ SCREEN BETWEEN /\nDOMINANT and 801 SUBDOMINANT ~D m i R B, O REMOVED 60[ All Birds Present ~ I-\n(Expo 1) A uJZ ~\no8 40\nn.,,\nul 20 n\n0\nil °\nAlpha Removed\n(Exp. 2)\n11 B\n8\n10-Alpha and Beta\nRemoved\n5-\n0\n10-\n52\n0\n(Exp.3)R R ~\nAlpha, Beta and\nGamma Removed\n5) ~Exp. R R\n7\nc\n13 43\no\n%,°% %o,\nINDIVIDUALS YELLING\nFig. 7. Yelling by (5) most dominant immatures as a function of\ndays without food and who they are in contact with. Lower ranking\ndominants begin to yell as top ranking dominants are removed\nor when they are prevented from contact with the dominant when\nthey are behind screen doors (shaded bars). Yell rates for each\nmale are averages+ ISD for 1 min samples during focal observations of each male. Number of such samples for each male is given\nabove error bar\n6.1 yells/rain (SD=I.9) in the subsequent experiment.\nTogether these 6 comparisons allow us to conclude that\nalphas suppress yelling by the other dominants (Wilcoxon T=0, P=0.031).\nGiven the significant suppression of yelling by alphas\nwe were surprised by the lack of a significant increase\nin the number of yellers as successive dominants were\nI BEFORE REMOVAL\n~ AFTER REINTRODUCTION\nDEFENDED APPROACHED\nFIRST\nBEHAVIOR OF ALPHA MALES\nFig. 8. Defense and first approach to food items by alpha males\n(3) while in the group (filled bars') and when reintroduced (hatched\nbars). Only approaches to food by hungry birds (3-4 days without\nfood) are included. Samples are derived from N= 13 approaches\nbefore removal and N=46 after reintroduction. Note apparent\nloss of both status (defense) and \"bravery\" (willingness to approach first)\nremoved (Table 1, Fig. 4). In the first replicate of group\ncomposition the percentage of immatures yelling increased from 40% when all birds were present, to 50%\nafter the alpha was removed, to 88% after the beta was\nremoved, and it remained at 88% after the gamma was\nremoved. However, when the dominant birds were reintroduced the percentage of the group yelling remained\nhigh varying only between 75% and 83%, rather than\nreturning to previous levels.\nThe continued yelling of many birds after the dominants were reintroduced was likely due to status shifts.\nThe moment we placed previous dominants back into\nthe main aviary they were chased and attacked by the\nnew alpha and beta birds. Evidently, the returnees were\nrecognized as intruders and not as formerly dominant\ngroup members (free-living vagrants that visit the aviary\nare also responded to with threatening postures). Returning dominants did not reclaim their prior status.\nEach dropped at least 3 places in the hierarchy (Table 2).\nTable 2. Changes in the status of top ranking birds after the alpha, beta, and gamma\nwere removed from the main aviary. Each dominant was the alpha bird just prior to\nhis removal and each dropped in status after reintroduction. All 3 dominants were housed\ntogether in a peripheral aviary during removal. RB was the first removed and last reintroduced and was out of the main aviary for 76 days. GB was out for 55 days. GY was\nout for 28 days\nPrior to experiments\n(30 Dec- 16 March)\nDuring reintroduction\n(26 MayM6 July)\nCode N Percentage of Rank Rank Percentage of N\ninteractions won interactions won\nRB 118\nGB 75\nGY 96\nBR 75\nYW 120\nBrW 85\nB 114\nRY 61\n98.3 1 4 67.3 110\n88.0 2 7 38.5 78\n74.0 3 6 55.8 95\n57.3 4 1 100.0 41\n74.2 5 5 75.9 108\n70.6 6 8 50.0 58\n50.0 7 2 95.8 48\n68.9 8 3 72.7 77 \nZ\nuJ\n30\n20\n15\n10\n5.\nO-\n• ll BEFORE REMOVAL\n~ AFTER REINTRODUCTION\nBIRD 1 BIRD 2 BIRD 3\nFig. 9. Yelling rates by 3 alpha males while in the group (filled\nbars) and when reintroduced. Yelling was only measured as hungry\nbirds (4 days without food) approached food. Note elevated zero\nline: none yelled after reintroduction. Yell rates before removal\nare averages (+ I SD) from N=16 (RB), N=13 (GB), and N=8\n(GY) 1 min samples during focal observations of each male\n19\n25-\n20- • l\nz\n~5\nIJJ\nn 10\ncO\n..I\n,,, 5\n>- .. ~\n0 ---\nNO 5MIN 30MIN NO 5MIN 30MIN\nFOOD AFTER AFTER FOOD AFTER AFTER\n2-3 FEEDING FEEDING 2-3 FEEDING FEEDING\nH H\nFig. 10. The influence of hunger on yelling (observer not visible)\nby 10 hand-reared fledglings (approximately 2 months old at start\nof tests). Boxes indicate rates of yelling per 10 birds averaged over\n4 tests spanning 11 days. Each test lasted 1 day and included responses before and after 2 feedings. All 10 nestlings were observed\nyelling during the course of a test. Error bars are +/-1 SD\nEspecially surprising was the change in RB's status. As\nthe former alpha he was extremely dominant but upon\nreintroduction he was consistently displaced by 3 birds\nfor nearly 2 months.\nAssociated with drop in the former alpha birds' stares was a change in their foraging behavior and yelling.\nReintroduced former dominants rarely were the first to\napproach food and were even less frequently defensive\nof food they approached (Fig. 8). Neither of the 3 former\nalpha birds yelled during the experiment following reintroduction (Fig. 9). Only after 2 months did RB occasionally yell when he approached food. Reintroduced\nalphas did not regain the status and did not continue\nto behave tyrannically at food nor suppress others from\nyelling.\nOntogeny of yelling\nYelling in response to hunger develops early in life. We\nhand-reared 10 nestlings in the spring of 1989. On four\noccasions we allowed them to go through a series of\nhunger-feeding cycles (Fig. 10). Nestlings began to make\nyell-like calls (Fig. 11 A) after 2-3 h without food, however, within a few minutes of eating yelling was silenced.\nThe rate of yelling declined significantly as a function\nof time since feeding (Kruskal-Wallis W= 10.2 P=0.006)\nThe transition from hoarse begging calls to clear yells\noccurs over a 3 month period (Fig. 11 A).\nVariation in yelling\n2 sources of variation in yells were apparent. First, individuals produced yells differing in tone (Fig. 11 B). Second, yells given by dominants as they approached food\ndiffered from yells given in less aggressive situations\n(Fig. 1 l C). Aggressive yells were of short duration and\nsharp, sounding like an emphatic \"who!\". Yells given\nby hungry, but non-aggressive birds were more drawn\nKHz\n4\n3\n2\n1\no\nKHz\n4\n3\n2\n1\n0\nKHz\n;\n0\nA Hand-reared Juveniles\n,¸,\n~ ~ r~'~', ~ ~1 ~'~' ~ ~ ~\n,, I i , ~!,., , ,,I ....\n'.~.'\"i \"l'/\"'~' ' \" '~,'. ~ ,4i~,,~.l,i~',,' ~' ~,,'i 1~,~;\n5/9/89 5/21/89\nB Individual Variation\n?i~lli~lll~l/~l ,l~,i,,~,,, ~,, ,\n6/21/89 ~8/2/89\n! ~1~ ~ i 11 II,\n' I\n,,?~\ni~ \"~i '~ I\nI 41 L!~I\n• I~ /~'3t!~I '\nBr Y Br B\nScale: } 1see. ~\nC Contexts\n=~t=\n, = ~,~\n'~ll~\"~ ~'~l!O(('t ~(i~' [~l ~\n~'il'i ~ ~Jl'tl l'~ll =~1 '¢ ~t~tV~l ~,\n~11, tl ~ ,i\ni~' ~ ~'~ t #ll,~ ,~\n~ i'~,\nW54 RYR\nd :~1\n~ ]~!t I,\n\" f\n~t ~\" ~I~ r\nR B Begging R B' ~on\nAggressive Nest\nYell\nFig. 11. Sonograms of yells. (A Ontogeny of the yell. Left=raspy\ncalls on 9 May, I week before fledging. Center=21 June, 7 weeks\nafter fledging. Right=2 August, 9 weeks of age. B Variations in\nthe yell of 4 different individuals. C Left = submissive begging near\ndominant adults. Center=the aggressive \"who!\" yell and (for\nright) female yelling on nest. Right=plaintive begging near\nscreened-in meat\nOutside Birds --\nPlaintive Yells\nout and plaintive sounding. Adults rarely yelled, however, as in many corvids, adult females use calls similar\nto juvenile begging calls when receiving food from their\nmates (Fig. 11 C; Goodwin 1986). Yells given by adult\nfemales on the nest also were drawn out. \n20\n5O\nLL 40\n0\n~..~ 30\nuJ\n~ 20\nD\n~'u~ >- 10\n0\n/ .\n/ \\\n\" ....-O / \"~\n• A ~ \"~\" •\nABCD\nArrival of Perched in First Birds Crowd Crowd\nBirds from Trees Before Approaching Beginning Feeding\nRoost Feeding Food To Feed\nFig. 12. Temporal changes in yelling by\nfree-ranging birds at 4 carcasses in 1989.\nA Approximately 30 birds feeding on a\ncow on 8 April. B Approximately 20\nbirds feeding on a moose on 11 April. C\nApproximately 30 birds feeding on a\ndeer and a bear on 8 Nov. D\nApproximately 50 birds feeding on a\ncow on 23 Nov. These 4 observations\nwere made 1 to 3 days after a large\ncrowd gathered at each bait. Time span\nof observations varies depending on\ndisturbance during arrival (Times from\narrival at feeding site to crowd eating:\nA=37 rain, B=2 h 20 min, C=1 h\n7 rain, D = 53 min)\nComparisons to free-living birds\nBehavior in the aviary closely matched that observed\nin nature. In the field, dominant ravens also were responsine for the marjority of yelling. 8 tagged birds were\nobserved yelling at carcasses. All yelled as they approached food, displaced another bird, and took over\na choice feeding spot. Yelling by wild ravens typically\npeaks as they begin to feed approximately 0.5-1 h after\nbirds arrive from their nocturnal roost (Fig. 12). During\npeak yelling, most yells are short, sharp \"who!\" yells\ngiven by birds claiming prime feeding spots. Prior to\nfeeding, most yells are long, loud and given by unidentified perched birds.\nThe status and behavior of our captive immatures\npersisted after they were reintroduced into the wild 1\nyear after their original capture. We observed 3 dominants, 4 subdominants, 2 intermediates, and 3 subordinates for a 2 week period after their release. These birds\nforaged at carcasses along with 10-30 wild vagrants and\na pair of resident adults. The dominants and subdominants deferred to few birds and held choice feeding positions. The intermediates and subordinates deferred to\nmost birds they encountered, fed infrequently, and rarely\ncontrolled foods.\nDiscussion\nIn the forests of northeastern North America, ravens\ngenerally forage for carcasses and other food (Bruggers\n1988) in the winter by flying singly or in pairs. However,\nlarge numbers of vagrant, nonbreeding birds are commonly found at food bonanzas. One of the vocalizations\ncommonly heard from vagrants at the aggregations in\nthe \"yell,\" and playbacks of this call are highly effective\nin attracting those ravens which are already aggregated\nin the surrounding forest (or passing through) near a\nfood bonanza (Heinrich 1985, 1988). Grouping is adaptive because it allows vagrants, who are subordinate to\nterritorial adults, to access and profitably forage on defended foods (Heinrich 1988 b, 1989; Marzluff and Heinrich in prep.).\nIn nature commonly only one or a few birds of any\nfeeding crowd yell before feeding begins (Heinrich 1989).\nWhich birds yell? Our field and aviary observations suggest that the first yellers of the morning are hungry birds\nthat experienced poor feeding on preceding days. These\nbirds give loud, drawn out yells while perched in trees\naround a carcass. When feeding begins yelling reaches\na peak as many birds descend to the ground and walk\nup to claim their feeding positions. Dominant juveniles\ngive the majority of yells and they walk with erect\nfeathers, spread their shoulders and take the prime feeding spots. Our experiments indicate that these dominant\nimmatures suppress the yelling of the closest subdominant immatures.\nProximate reasons for yelling\nAs we argued in the Introduction it is necessary to understand the proximate basis of recruitment signals, such\nas the yell. Our results suggest that hunger and status\nadvertisement are the primary proximate factors causing\nyelling. Overpowering territorial adults is not a proximate reason for yelling as yells were rarely given by\nimmatures in the presence of adults. In addition, if attraction of others was a proximate reason for yelling\nthen dominant vagrants would not be expected to inhibit\nsubordinates from calling. Instead, dominants should\npunish subordinates for not calling, as occurs in spider\nmonkeys (Chapman and Lefebvre 1990). We conclude\nthat the accumulation of ravens at the site of yelling\nrepresents recruitment because attraction of ravens by\nyelling enhances the fitness of the signaler, but assembling a crowd is not a proximate reason for yelling.\nThe ontogeny of yelling can be traced to the nestling\nstage. Sonograms of individual birds beginning while\nthey are still in the nest indicate a progression from\nrasping disharmonic calls to the loud harmonic yells typically heard at food (Fig. 11). Thus, initially the birds\nyell proximately in response to the presence of food (or\nthe expectation of food), provided they are hungry. The\nfollowing winter (and winters) they continue to do the\nsame, except now the yell is restrained by social superiors.\nAdaptive significance of yelling\nMost species of birds produce begging calls as nestlings\nwhen they are fed. However, these are lost shortly after\nindependence from parental care. We know of no other\ncases where begging calls develop into louder, more easily located calls indicative of food. Presumably this is\nrare because in most cases it is disadvantageous to \n21\nbroadcast the presence of food. On the contrary, it is\nadvantageous for vagrant ravens to advertise the location of food because most foods are defended and therefore unavailable until a crowd assembles and overpowers\nthe defending territory owners.\nYelling may be of further adaptive significance as\na status signal. As has previously been determined\n(Gwinner 1964), captive ravens kept within a flock form\nand maintain a linear dominance hierarchy, and social\ndominance in these birds is an important correlate of\npair formation. At least in part, the food bonanzas on\nwhich ravens specialize serve as a site where dominance\nis established, reinforced and/or maintained by fighting\nand by appropriate signalling of both dominance and\nsubmission. It therefore seems likely that the yelling we\nobserved in our captive birds is related to status signalling that might ultimately translate to mate and food\nacquisition.\nIf yelling by immatures ultimately functions in their\ngaining access to defended foods, it may at first appear\ncurious that they did not yell in the presence of the\nadults. Indeed the adults inhibited, rather than facilitated, yelling. However, the presence of defensive adults\nmay not trigger yelling because adults attack yelling vagrants, thus discouraging their display of status and reducing recruitment to the food the adults try to defend.\nHow can a signal that is proximally given as a show\nof hunger and status be ultimately functional also in\nrecruitment? The show of status ultimately functions in\nsexual selection (Gwinner 1964; Komers and Dhindsa\n1989). However, since the same display yields other advantages related to feeding and gaining access to food,\nit has likely become amplified rather than compromised\nthrough evolution. Presumably this is rare because in\nmost cases it is disadvantageous to broadcast the presence of food. However, it is convenient for ravens to\nadvertise status at food, and it is advantageous for vagrant ravens to advertise the location of food, because\nmost foods are defended and therefore unavailable until\na crowd assembles and overpowers the defending territory owners. As a result, even though yelling is stimulated\nby hunger and status it has likely been embellished by\nnatural selection because of the benefits of group foraging. It seems unlikely that a display audible for several\nkilometers, such as the yell, would have evolved solely\nas a status signal. Quieter vocalizations or posturing,\nseem more likely because they would suffice for the first\nfunction. In typical jury-rigged fashion natural selection\nhas embellished an existing behavior to serve a new function rather than create a new behavior. As a result, the\nproximate and ultimate reasons for yelling do not coincide.\nAcknowledgements. This study was made possible due to the generous help of an \"army\" of volunteers (in Heinrich, 1989) who\nhelped to build the facilities.\nWe thank Henry and Lee Disotto, Bill Adams, Danny Danforth, David Lidstone, the Wojcik clan, Harry Wycoff, Steve Freschett, and Rick Ashton for their assistance capturing and marking\nravens. Patty Rabenold generously aided in one raven roundup\nand helped us do the laparotomies. Mike Pratt, Dwight Cram,\nFrank and Don Castonguay, Peter Cross, and Wendy Howes\nhelped supply raven food. David Perez tended the captive ravens\nin our absence. Jeffrey Cynx provided sonograms. We are indebted\nto David Lidstone, and Bill and Butch Adams, for cutting and\nhauling carcasses when temperatures dipped below zero. Colleen\nMarzluff aided in all phases of this research making it both possible\nand enjoyable. Joseph Schall, Kevin McGowan, and 3 anonymous\nreviewers provided helpful comments on a draft of the manuscript.\nFunding was provided by the National Science Foundation, Grant\nBNS-8819705.\nReferences\nAltman J (1974) Observational study of behavior: sampling methods. Behaviour 49 : 227-267\nAppleby MC (1983) The probability of linearity in hierarchies.\nAnim Behav 31:600-608\nBalda RP, Bateman GC (1974) Flocking and annual cycle of the\npinon jay, Gymnorhinus cyanocephalus. Condor 73 : 287-302\nBrown C (1986) Cliff swallow colonies as information centers. Science NY 234:83-85\nBruggers JD (1988) The behavior and ecology of the common\nraven in Northeastern Minnesota. Ph D thesis, University of\nMinnesota, Minneapolis\nChapman CA, Lefebvre L (1990) Manipulating foraging group\nsize: spider monkey food calls at fruiting trees. Anim Behav\n39 : 891-896\nElgar MA (1986) House sparrows establish foraging flocks by giving chirrup calls if the resource is divisible. Anita Behav 34:169-\n174\nGreene E (1987) Individuals in an osprey colony discriminate between high and low quality information. Nature (Lond)\n329: 239-241\nGwinner E (1964) Untersuchungen fiber das Ausdrucks- und Sozialverhalten des Kolkraben (Corvus corax corax L.). Z Tierpsychol 21 : 657-748\nHeinrich B (1988) Winter foraging at carcasses by three sympatric\ncorvids, with emphasis on recruitment by the raven, Corvus\ncorax. Behav Ecol Sociobiol 23:141-156\nHeinrich B (1989) Ravens in winter. Summit Books of Simon &\nSchuster, New York\nHeinrich B, Bartholomew GA (1978) Roles of endothermy and\nsize in inter- and intraspecific composition for elephant dung\nin an African dung beetle, Searabaeus laevistriatus. Physiol Zool\n52: 484~494\nK6nig C (1983) Interspecific and intraspecific competition for food\namong old world vultures. In: Wilbur SR, Jackson JA (eds)\nVulture biology and management. University of California\nPress Berkeley, pp 153-171\nKomers PE, Dhindsa MS (1989) Influence of dominance and age\non mate choice in black-billed magpies: an experimental study.\nAnim Behav 37: 645-655\nKrebs JR (1974) Colonial nesting and social feeding as strategies\nfor exploiting food resources in the great blue heron (Ardea\nherodios). Behaviour 51 : 99-134\nRabenold PP (1987a) Recruitment to food in black vultures: evidence for following from communal roosts. Anim Behav\n35:1775-1785\nRabenold PP (1987b) Roost attendance and aggression in black\nvultures. The Auk 104: 647-653\nStiehl RB (1978) Aspects of the ecology of the common raven\nin Harney Basin, Oregon. Ph D thesis. Portland State University, Portland\nWaltz EC (1983) On tolerating followers in information-centers,\nwith comments on testing the adaptive significance of coloniality. Colonial Waterbirds 6:31-36\nWard P, Zahavi A (1973) The importance of certain assemblages\nof birds as \"information centers\" for food finding. Ibis\n115:517-534 ", "affiliations": [{"country": "United States", "discipline": "Zoology", "university": "University of Vermont"}, {"university": "", "country": "", "discipline": ""}], "species_categories": ["Bird"], "specialized_species": ["Common Ravens"], "computational_stages": ["Meaning Identification"], "linguistic_features": ["Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882689", "updated_at": "2026-01-13T16:09:59.473866", "committed_at": "2026-01-13T14:02:22.706836"}
{"id": "051f43fe-c2f3-46c2-a04d-fe5aef700e0b", "title": "The Chick-a-Dee Call System of the Mexican Chickadee", "authors": ["Ficken,  Millicent Sigler", "Hailman,  Elizabeth D.", "Hailman,  Jack P."], "year": "1994", "journal": "The Condor", "abstract": "", "doi": "10.2307/1369065", "analysis_notes": "The Chick-a-Dee Call System of the Mexican Chickadee\nAuthor(s): Millicent Sigler Ficken, Elizabeth D. Hailman and Jack P. Hailman\nSource:\nThe Condor , Feb., 1994, Vol. 96, No. 1 (Feb., 1994), pp. 70-82\nPublished by: Oxford University Press\nStable URL: https://www.jstor.org/stable/1369065\nREFERENCES\nLinked references are available on JSTOR for this article:\nhttps://www.jstor.org/stable/1369065?seq=1&cid=pdf-\nreference#references_tab_contents\nYou may need to log in to JSTOR to access the linked references.\nJSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide\nrange of content in a trusted digital archive. We use information technology and tools to increase productivity and\nfacilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.\nYour use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at\nhttps://about.jstor.org/terms\nOxford University Press is collaborating with JSTOR to digitize, preserve and extend access to\nThe Condor\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsThe Condor 96:70-82\n? The Cooper Ornithological Society 1994\nTHE CHICK-A-DEE CALL SYSTEM OF THE MEXICAN CHICKADEE1\nMILLICENT SIGLER FICKIEN\nDepartment of Biological Sciences, University of Wisconsin-Milwaukee, Milwaukee, WI 53211\nELIZABETH D. HAILMAN\nDepartment of Dairy Science, University of Wisconsin-Madison, Madison, WI 53706\nJACK P. HAILMAN\nDepartment of Zoology, University of Wisconsin-Madison, Madison, WI 53706\nAbstract. Chick-a-dee calls of the Mexican Chickadee (Parus sclateri) are composed of\ncombinations of three common note types (A, C and D) and one very rare type (B). Calls\nhave the invariant sequence of notes A-B-C-D, where any note type may be omitted, given\nonce or repeated a variable number of times before transiting to the next type. The B and\nC notes are phonologically similar to the B and C notes of chick-a-dee calls of the Black-\ncapped Chickadee (P. atricapillus), but the A note is markedly different and the D note\nsomewhat different from equivalent notes of the congener. A total of 2,071 calls recorded\nyielded 60 different call types, and Zipf-Mandelbrot plots show that the call system is \"open\";\nas the sample size is increased new call types will be found without demonstrable bound.\nIn relatively undisturbed contexts (with mate on territory, in fall flocks, alone in fall) birds\ngave mainly [A][D] calls with lesser numbers of [A] and [C] calls, where brackets indicate\nvariable repetition of note types. In disturbed contexts (mobbing plastic Great Horned Owl,\nmobbing speaker playing calls of the Northern Pygmy-Owl, observer sitting under the nest\ncavity) the birds gave more [C] calls with [A][C] as well. In the longest mobbing session to\nowl calls, birds gave mainly [A] calls when approaching, switched to [C] calls while flying\nabout the speaker, and then resumed [A] calls and moved offwhen the playback was stopped.\nOutside of human language, this is the second truly combinatorial system of vocal com-\nmunication found in animals, the first being chick-a-dee calls of the Black-capped Chickadee.\nThis study provides the first data substantiating quantitative differences in calls from different\ncontexts, an important step toward understanding what kinds of information combinatorial\nchick-a-dee calls encode.\nKey words: Parus sclateri; Mexican Chickadee; vocalizations; calls; syntax; mobbing;\nflocks.\nINTRODUCTION\nAll tit species of the subgenus Poecile (genus Par-\nus) appear to give combinatorial \"chick-a-dee\"\ncalls (Hailman 1989), but this complicated call\nsystem has heretofore been analyzed quantita-\ntively only in the Black-capped Chickadee, P.\natricapillus (Hailman et al. 1985, 1987; Hailman\nand Ficken 1986). Chick-a-dee calls of the Mex-\nican Chickadee (P. sclateri) were first recorded\nby Dixon and Martin (1979), whose spectro-\ngrams (their figures la and b, p. 422) show two\nkinds of notes. Ficken (1990a) found that in a\nsample of over 1,000 recorded calls, four types\nof notes were given but one of them only rarely\n(see also Ficken and Nocedal 1992). The present\nstudy, based on further field work including\nmobbing experiments, (1) describes the acous-\ntical features and analyzes the syntactical struc-\nture of the Mexican Chickadee's calls, (2) co\npares these results with those from Black-cap\nChickadees, and (3) documents differences\ncalling in different contexts.\nChick-a-dee calls are of special interest be\ncause these compose the only presently doc\nmented combinatorial system of animal com\nmunication outside of human language.\nBlack-capped Chickadee uses four note ty\n(Ficken et al. 1978) in combination to create hu\ndreds of different call types (Hailman et al. 19\nThe note types (designated A, B, C and D) oc\nin the fixed sequence A-B-C-D, where any n\ntype may be omitted, given once, or repeat\nvariable number of times before transiting to\nnext note type within the call. This straight\nward phonological syntax was shown to be l\nically explicit by writing a \"characteristic fu\ntion\" (correctly working algorithm) for a Tur\nmachine (Hailman and Ficken 1986). Howeve\nsystematic departures from first-order MarReceived 12 March 1993. Accepted 9 August 1993.\n[70]\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsMEXICAN CHICKADEE CALLS 71\nchains of transitions between note types show\nthat far more complicated rules underlie the pre-\ncise structure of calls (Hailman et al. 1987). De-\nspite extensive analyses of syntactical structure,\nthe communicative significance of chick-a-dee\ncalls remains elusive. The present study of the\nMexican Chickadee provides not only the first\ncomparative data on syntax in another species\nbut also an important first step toward under-\nstanding differences in calls in different behav-\nioral contexts.\nMETHODS\nAll recordings were made at or in the vicinity of\nRustler Park in the Chiricahua Mountains (Co-\nchise County) in southeastern Arizona. Record-\nings were made by M.S.F. in October 1985, and\nMay and October 1986 (Ficken 1990a); further\nfield work by the three authors together was con-\nducted in April 1990 and March 1991, by M.S.F.\nin May 1991, and by the three authors together\nin April 1992.\nCalls were divided into four principal contexts\nof recording: (1) with mate on the breeding ter-\nritory, (2) in mixed-species flocks in the fall, (3)\nwhen disturbed by the presence of an observer\nnear the nest, and (4) when mobbing a speaker\nplaying the call of a Northern Pygmy-Owl, Glau-\ncidium gnoma. In addition, small samples of vo-\ncalizations were taped in two other contexts: (5)\nlone birds in the fall and (6) mobbing a plastic\nmodel of a Great Horned Owl, Bubo virginianus.\nThe mobbing experiments using owl tapes were\nconducted at five different sites. The partially\ndiurnal Northern Pygmy-Owl takes small birds\nand is common in the study site; during one ex-\nperiment, an owl answered the playback from\nacross a canyon. In two experiments tapes were\nplayed back from a Marantz PMD 430 Profes-\nsional cassette recorder through a Realistic Min-\nimus-0.6 amplified speaker near the ground on\na log or stump. In the other three experiments,\ntapes were played back from a Sony Walkman\nProfessional cassette recorder through a Sony\nSRS-27 amplified speaker. All playbacks attract-\ned a number of small forest species besides Mex-\nican Chickadees.\nMost of the recordings were made on a Sony\nWalkman Professional cassette tape recorder\n(details in Ficken 1990a, 1990b), with further\nrecordings of mobbing experiments made with\na Sony 8 mm camcorder. Tapes were analyzed\nby M.S.F. with a Kay 7800 Digital Sona-Graph\n(150 Hz filter band width). Note types (described\nin the Results) were classified by eye and written\non data sheets. In all, 2,045 calls were analyzed\n(a few occurred in other contexts with insufficient\nsample sizes for analysis). Data on the note com-\nposition and context of each call were read into\na database and made accessible to mainframes\nand microcomputers for analyses. Analyses were\nbasically a subset of those performed on calls of\nBlack-capped Chickadees by Hailman et al.\n(1985), designed by J.P.H. and programmed by\nE.D.H. Most of the special analytical programs\nwere written in PASCAL and run on microcom-\nputers.\nContingency tables were analyzed statistically\nusing \"computer-intensive\" methods of the pub-\nlicly available software MONTE CARLO RXC\nwritten for the Apple Macintosh by W. R. Engels\nof the University of Wisconsin-Madison, De-\npartment of Genetics. Such analyses provide a\nmore sensitive and accurate assessment than Chi-\nsquare methods often applied to such data (En-\ngels 1988). At least 1,000 trials were run for a\ngiven test to create the distribution against which\nthe data were compared. Sequential analysis by\nthe method of Markov chains was done with\nUNCERT, publicly available software for DOS\ncomputers copyrighted by E.D.H. and J.P.H.\nRESULTS\nPHONOLOGY\nChick-a-dee call systems as a whole are doubtle\nhomologous among species possessing them. Tw\nof the Mexican Chickadee's note types differ\nsomewhat in acoustical structure from those of\nthe Black-capped Chickadee, so they might not\nbe homologous. Unlike the basically chevron-\nshaped A note of the Black-capped Chickadee,\nthe Mexican Chickadee's A note (Fig. 1) is fre-\nquency modulated at a high rate, giving it a buzz-\ning aspect to the human ear. Buzzing notes char-\nacterize other vocalizations of the Mexican\nChickadee as well (Dixon and Martin 1979; Fick-\nen 1990a, 1990b). The A note usually sweeps\ndownward in frequency during its duration (Fig.\n1) but the magnitude of the decline is variable.\nDixon and Martin (1979, Fig. la) showed a call\nwith three A notes that lacked this frequency\ndownsweep completely, and there seems to be a\ncontinuum in the slope of the downsweep. The\nA note was common (1965 notes recorded), com-\nprising 28.4% of all notes.\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms72 M. S. FICKEN, E. D. HAILMAN AND J. P. HAILMAN\na b\n8r\n?~iC . . ,\"?. i :'\nI ... . ....V4\n. 2A\n0\n0 0.5 1 1.5Time (s)\nc d\n8-\nZiM 6 V~i?t~:\nYC i\n\"P . ,.:. . . . .:,\nTime (s)\nFIGURE 1. Sound spectrograms illustrating the A and D notes of chick-a-dee calls of the Mexican\nselected to illustrate some of the phonological variation found in notes. The frequency and time sca\nsame for all spectra. (a) Commonest of all calls is the call type AD, with typical down-slurred A n\nthe banded structure of the D note. (b) A call showing the typical A/D contraction of the final A\nnotes of calls containing both types. (c) The contracted A/D may begin a call; notice the noisy\nstructure of the D notes. (d) Rare phonological structures occur, as in this call with an A-like introd\nfollowed by an A/D-like structure of long A component and short D component.\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsMEXICAN CHICKADEE CALLS 73\nTABLE 1. Durations, highest frequencies, and lowest frequencies of note types in ch\nMexican Chickadee. Entries are mean + standard deviation (sample size).\nCall type: duration Fig. No. of Duration Lowest Highest\nNote(s) call type (msec) frequency (kHz) frequency (kHz)\nSingle A - 151 + 35 (13) 5.7 + 0.7 (13) 8.0 + 0.5 (13)\n\"Low frequency\" A 2a 208 ? 28 (14) 3.4 + 0.2 (14) 6.3 ? 0.6 (14)\nAA: 331 + 92 (16) -\nFirst A 127 + 53 (16) 5.5 + 0.6 (16) 8.1 + 0.6 (16)\nSecond A 120 + 35 (16) 5.7 ? 0.8 (15) 7.3 + 1.8 (16)\nAA/D: 521 ? 118 (20) lb\nFirst A 170 ? 32 (20) 5.8 + 0.4 (20) 8.4 ? 0.2 (20)\nSecond A (of A/D) 50 ? 31 (20) 4.2 + 0.7 (18) 8.2 ? 0.3 (20)\nD (of A/D) 212 ? 67 (20) 3.2 + 0.3 (19) 6.2 + 0.5 (18)\nA/D: 425 ? 107 (17) -\nA (of A/D) 100 ? 76 (17) 4.4 ? 0.6 (16) 8.3 ? 0.2 (16)\nD (of A/D) 319 + 95 (17) 3.2 + 0.2 (17) 6.4 ? 0.5 (12)\nA/D D: 690 ? 181 (18) Ic\nA (of A/D) 87 ? 59 (18) 4.3 ? 0.7 (15) 8.2 ? 0.3 (16)\nFirst D (of A/D) 245 ? 117 (18) 3.1 + 0.3 (14) 5.6 + 0.3 (15)\nSecond D 270 ? 85 (18) 2.9 ? 0.4 (14) 5.5 + 0.3 (15)\n[C] (First of a series) 2e 23 ? 2 (14) 2.8 ? 0.3 (14) 7.6 + 0.1 (13)\nThe Mexican Chickadee's D note more closely\nresembles that of the Black-capped Chickadee,\nand is typically the longest note-type in duration\n(Fig. 1)-even longer than that of the Black-\ncapped Chickadee. The D note varies from hav-\ning a distinctly banded frequency structure (Fig.\nla) to being nearly uniformly noisy (Fig. Ic). The\nMexican Chickadee's D note often has an onset\n\"spike\" of higher frequency (also evident in spec-\ntrograms of Dixon and Martin 1979, and Ficken\n1990a). The 1,080 D notes recorded comprise\n15.6% of the sample. When A and D notes occur\nin the same call (always in the order A-D), they\nmay be independently uttered (Fig. 1 a), or more\ntypically the last A in a sequence merges with\nthe first D note to form a sort of contracted note\nwe designate by \"A/D\" (Figs. ib, c). The A part\nof this contraction is variable in duration, but\nusually much shorter than a typical A. Rarely,\npeculiar phonations occur in recordings, as in\nFigure 1 d where an A-like note occurs before an\nA/D-like contraction.\nIt might be that some variations in A notes\nare communicatively significant. Single A notes,\nnot combined with other As or other note types,\nare particularly variable. Among the 6,918 notes\nrecorded, 34 single A notes of unusually low\nacoustical frequency were found (Fig. 2a). These\nmay represent a rare but distinct subtype of A\nnotes, treated here as A notes but deserving of\nfurther study. The Mexican Chickadee also com-\nmonly utters high frequency notes that resemble\nbrief A notes (Fig. 2b) but are much shorter and\nnever combined with other notes into multi-note\ncalls. These notes appear to be related to or var-\niants of \"tseets,\" of which Ficken (1990a) re-\ncorded only six examples. These A-like notes are\nnot included in the analyses below.\nThe B note, which was very rare (3 occurrences\nin 6,918 notes), is chevron-shaped (Fig. 2d) and\nsimilar to the B note of the Black-capped Chick-\nadee. The C note, which was the commonest type\n(3,870 recorded, comprising 55.9% of all notes),\nis a \"noisy chevron\" (Figs. 2c, d), again similar\nto the C note of the Black-capped Chickadee.\nThe C notes were usually uttered in distinct cou-\nplets (Fig. 2e), another variation of phonology\nworthy of further study.\nThe duration of a given type of note varies, in\nsome cases markedly (Table 1), depending upon\nthe type of call and where the note falls within\nthe call. Internote intervals vary from about 50\nto 90 msec for various types, but the only sys-\ntematic variation found was a bimodal distri-\nbution of C-C intervals (shorter intervals within\nthan between couplets). The interval between the\nlast note of one call and the first note of the next\nis one to two orders of magnitude longer than\ninternote intervals within calls, thus defining the\ncall as a natural unit of phonation.\nNotes of the Mexican Chickadee (especially\nthe A and D notes) are noticeably longer than\nthose of the Black-capped Chickadee (Table 1)\nwhereas the number of notes in a call is notice-\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms74 M. S. FICKEN, E. D. HAILMAN AND J. P. HAILMAN\na b\n8\nN%\n0 --~\nC 4 . -r . _i\"..a)\n0 0.5 1 1.5\nTime (s)\n8 c d e\n__ fill it ( ?i, ~if | , , \"\" . K4 i\"\n)21 \" '' .. ,\n-L 2-\n0~\nu.2 AGOC B 000000 cc cc cc cc\n. , : i ? . ! \"' ? ?::- ?'?\" ? . ,.??: ? '.: ?. ' . . : .. . ' . i\n0 0.5 1 1.5\nTime (s)\nFIGURE 2. Spectrograms illustrating other notes of chick-a-dee calls (cf. Fig. 1). The frequency and time scales\nare the same for all spectra. (a) A low-frequency A note that may represent a special subtype. (b) High-frequency\nnotes resembling abbreviated A notes, which appear to be \"tseet\" notes related to flight intention. (c) An A note\nwith two C notes. (d) The rare B note followed by a series of C notes. (e) The couplet structure of C notes, found\nonly in calls composed of this note type alone.\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsMEXICAN CHICKADEE CALLS 75\nAD\nBEGIN END\nCALL CALL\n(silence) (silence)\nB c\nFIGURE 3. Kinematic graph of first-or\nletters A, B, C and D are approximatel\n(except that the rare B would not be\nproportional to the probabilities of tra\nwould have invisibly thin lines are om\nrepetitions of the same note type.\nably fewer than in the other speci\na-dee calls of the Mexican Chickadee are from\none to at least 14 notes in length, which is a\nsmaller maximum note-length than in calls of\nthe Black-capped Chickadee. The longest in\nHailman et al. (1985) was 24 notes, and that\nsample did not include predator contexts, where\ncalls are apparently often longer (Apel 1985).\nTable 1 contains several examples of how the\nplacement of a note affects its duration. For ex-\nample, the A note of single-A calls is longer than\neither note of an AA call, but not as long as the\nfirst A that is followed by an A/D contraction to\ncompose a call. Similarly the D part of an A/D\ncontraction is shorter if the contraction is pre-\nceded by an A note than if the contraction is\nitself the entire call. The frequency characteris-\ntics of notes may also vary somewhat according\nto their placement within calls (Table 1).\nSYNTAX\nMarkov chain analysis showed that the sequence\nof notes within a call follows the same rule as in\nthe Black-capped Chickadee: note types always\noccur in the order A-B-C-D (no exceptions in\n2,071 calls), where any note type may be omitted\nentirely, given once, or repeated a variable num-\nber of times. The first-order Markov chain (Fig.\n3) reveals the principal syntactic structure. Calls\nbegin with A or C (less than 1% begin with B or\nD). If beginning with A, that note-type repeats,\ntransits to D, or ends the call; if transiting to D,\nthat note repeats or ends the call. If the call begins\nwith C, that note most commonly repeats, or\nends the call.\nFrom Figure 3 one may infer that calls will\ncommonly have the structure [A], [C] or [A][D],\nwhere the enclosure of the note type in square\nbrackets denotes possible repetition. Other call\nstructures should be much rarer. Categories such\nas [A][D] are termed sequence types, and each\nmay include many distinct call types such as AD,\nAAD, AAAAD, ADD, ADDDD, and so on.\nThere are 15 such sequence types possible, but\nbecause of the rarity of B notes five of these did\nnot occur in the record: [B], [B][D], [A][B][C],\n[B][C][D], and [A][B][C][D]. The commonest se-\nquence types were: 735 [A][D] calls, 664 [C] and\n517 [A], as expected from Figure 3. Two se-\nquence types occurred with sufficient frequency\nto be of interest: 88 [A][C] and 30 [C][D]. The\nremaining types were very rare: 7 [D], 2 [A][C][D],\nand 1 each [A][B], [B][C], and [A][B][D].\nThe departure of Mexican Chickadee calls from\na first-order Markov process was small. The\nmaximum uncertainty possible with four note-\ntypes is log2 4 = 2 bits/note, but the unequal\nfrequencies of note types yielded a zero-order\nMarkov chain of only 1.21 bits/note. First-order\nanalysis reveals a large drop to only 0.36 bit/\nnote, which would be a true first-order Markov\nprocess only if all uncertainty were removed.\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms76 M. S. FICKEN, E. D. HAILMAN AND J. P. HAILMAN\nSecond-order analysis showed a small drop to\n0.21 bit/note, meaning that long-range con-\nstraints are relatively unimportant in the calls.\nPut differently, the next note to occur can be\npredicted well from the previous one but know-\ning longer ordered-strings of previous notes hardly\nimproves predictability.\nOPENNESS\nA major finding in the Black-capped Chickadee\nwas that the call system is \"open\" (Hailman et\nal. 1985): as the sample size of calls is increased,\nthe number of different call types increases with-\nout demonstrable bound. A call type is defined\nas any different combination of notes; thus A,\nCC, AC, AAACC and ACCCCCC are all differ-\nent call types. In this study we found 60 different\ncall types in the 2,071 calls recorded, and as in\nthe Black-capped Chickadee these call types var-\nied widely in frequency of occurrence. For ex-\nample, there were 783 calls of the type AD but\nonly one of the type ADDDD.\nThe test for openness is made by a Zipf-Man-\ndelbrot plot of the probability of occurrence (P)\nas a function of occurrence rank (r) on log axes.\nMandelbrot's (1953) formula P = i(r + k)s for\na fitted function has three constants: the intercept\n(i), curvature factor (k) and asymptotic slope (s),\nwhich is always negative. To show openness it\nis not necessary to provide a fitted function but\nmerely to show that the plotted curve reaches a\nnon-zero asymptotic slope. Figure 4 shows this\nproperty for the Mexican Chickadee, both with\nall data combined (top curve) and plotted sep-\narately by the six contexts. Even the curves them-\nselves for the different contexts are remarkably\nsimilar, reaching about the same asymptotic\nslopes at their right-hand sides. The curves dem-\nonstrate that the call system of the Mexican\nChickadee, like that of the Black-capped Chick-\nadee, is open and hence more new call types will\nbe found if the sample is increased.\nDIFFERENCES AMONG CONTEXTS\nThe distribution of calls among the sequence types\ndiffered according to context of recording (Fig.\n5). For purposes of statistical comparison among\ncontexts, calls were considered in five categories:\n[A], [C], [A][D], [A][C] and \"other\" (all the re-\nmaining sequence types combined). As each re-\ncording context was independent of the others,\nevery possible pair of contexts was compared in\na 2 x 5 contingency table using the Monte Carlo\ntechnique (see Methods). All pairs of contexts\ndiffered significantly (P's < 0.001) except two\ninvolving the small sample size of lone birds: th\ndifference from \"with mate\" is marginal (P\n0.06) and from \"fall flocks\" non-significant (P\n0.19).\nWhen undisturbed on territory with the mate,\nalmost three-quarters of calls were of the [A][D]\nsequence type (Fig. 5a). When in mixed-species\nfall flocks (Fig. 5b) or alone (Fig. 5c), only about\nhalf of calls were [A][D], with [A] and [C] calls\nmaking up most of the other half. In the former\ncase, there were also a few calls of the [A][C] type\nand other types. When there was an external dis-\nturbance (right column of diagrams in Fig. 5),\nthe distribution of sequence types was markedly\ndifferent, with [C] and [A][C] together always\nmaking up at least half of all calls. When dis-\nturbed by a Great Horned Owl model, birds gave\nmany [A][C] calls (Fig. 5d). When mobbing a\nNorthern Pygmy-Owl tape, [A] and [C] calls were\ncommoner (Fig. 5e), and when disturbed by the\nobserver sitting about 6 m from the nest, [C] calls\npredominated (Fig. 5f).\nOWL-TAPE PLAYBACK EXPERIMENTS\nMobbing experiments provide a means of study\ning calls in detail because there is a specific locu\nin space to which the mobbing birds attend an\nall individuals present behave similarly. Exper-\niments were conducted at five sites from March\nto May of various years. The experiments, using\nplayback tapes of Northern Pygmy-Owl calls,\ngenerally attracted one pair of Mexican Chick-\nadees, often with small songbirds of other spe-\ncies. The chickadees gave 20 to 50 calls and then\ndeparted with the playback still running. One\nexperiment brought in several chickadees for a\nlong period, and the results are analyzed sepa-\nrately below. The results of the other four ex-\nperiments are shown in Figure 6, which plots the\ncumulative frequency of each call sequence type\nthrough the experiment.\nEvery experiment shown in Figure 6 yielded\na similar but unique set of results. The experi-\nment of 22 March was made about half-way on\nthe road to Rustler Park. This playback probably\nevoked calls from a single bird, which did not\nclosely approach the speaker. In all four exper-\niments one sequence type predominated, and that\ntype of call was given at an approximately equal\nrate (constant slopes in Fig. 6) throughout the\nexperiment. The predominant type was [A][D]\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsMEXICAN CHICKADEE CALLS 77\n1\nALL CALLS\n1.---....... \"(N=2071)\n\" .001 C~ bmate\nS... . o..0 .0001\n. \"O\" -. flock0 'O(N=1013)alone\nt (N=35)\nI)\n0 observer\n\" r (N=443)O\n-.. pygmyA horned (N=263)(N=36)\n1 10 100\nr (occu\nFIGURE 4. Zipf-Mand\nvalues are labeled only\nthe curves for clarity\nthat curves reach an\nfound as the sample s\nin the March and A\nthe experiments con\n[C] calls were comm\nand [A][D] occurred\nand three sequenc\nexperiment: [C][D]\n[A][C][D] in April. O\nsuggested that the [C\nwere most agitated\nto the speaker. The\nments may therefo\nduring the nestin\n(March and April).\nOne exper\nrespects. Fi\nMexican Ch\nof the prec\ninstead of\nbirds conti\nthat we co\nstill presen\nAnd third,\nwas record\nBirds bega\nmainly [A]\nbegan givin\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms78 M. S. FICKEN, E. D. HAILMAN AND J. P. HAILMAN\nUNDISTURBED DISTURBED\na. d. [A]\n[A] ~ [A][D] [C]i\nplastic\nwith mate [A][D] greatwith mate horned [A][C]\non territory owl\n(N=238) (N=36)\nb. e.\n[A]` [A][D]~ [A]\n[A][D]\n[A][C]\nc. f. [A][D] otherm d A[A][C]\nsC [A]]\nin fall [C] at the nest\n(N=35) (N=443)\nFIGURE 5. Pie diagrams of the distributions of call\nsample sizes over all diagrams is less than the total nu\nin any of the six contexts shown.)\nat approximately the same rate (same slopes i\nFig. 7). As they moved still closer, birds bega\ngiving [A][D] calls as well, until assembled at th\nspeaker site. Here they stopped giving [A] cal\naltogether (zero slope in figure) and soon afte\nstopped giving [A][D], while abruptly increasin\nthe rate of [C] calls (steep slope in Fig. 7). Whe\nplayback was terminated, calling immediately\nchanged again, with [A] calls immediately re-\nsuming (steep slope) and [C] calls becoming rar\n(changing to a noticeably\ning ceased as the birds we\nThese results were consistent with those re-\ncorded when birds were intensely disturbed by\nan observer sitting under the nest hole (Fig. 5f,\nabove), where they also gave mainly [C] calls.\nVideotapes of the owl-playback experiment of\nFigure 7 show that [C] calls were given primarily\nby perched birds that were pivoting on a branch,\nalthough they were sometimes given in flight. (It\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsMEXICAN CHICKADEE CALLS 79\n> 15 20\nZ 22 March [A[D 14 April [A[D]\nsite 2\nw\nuJ 10 PU- I d [C][D]\n10 ? [A], [\nFa 0o\n[C]\n1 20' '[A ] 0 [A][B][D] A [A][C]Dl ]\n0 10 20 0 10 20 30 40\nS30 15\nz 15 May [C] 15 May [C]site 1 site 2\na\nu 20 10 -\nu! I[A][C]\nF 10 ~ [A], [AI[C] & [AI[D] 5\n? - 0[A]\n0 0\n0 10 20 30 40 0 10 20\nSUCCESSIVE CALLS SUCCESSIVE CALLS\nFIGURE 6. Cumulative frequency plots of call sequence types\non 22 March) while mobbing a speaker playing back sounds\nexperiments were dominated by [A][D] calls whereas May trial\nis often difficult to tell from the videotape which\ncall is being given by which bird.) Calls contain-\ning the A note were given during approach (and\nretreat) from the site, but there is a difference\nbetween [A] and [A][D] calls. In mobbing trials,\n[A] calls were most often strings such as AA,\nAAA, and AAAA, unlike single A notes given\nin other contexts; furthermore, A-strings given\nin mobbing trials seemed sometimes to be given\nin flight. By contrast, [A][D] calls were given only\nby perched birds. These birds were moving to-\nward the site in short flights, but seemed never\nto utter any call containing a D note while ac-\ntually in flight.\nDISCUSSION\nCOMPARISONS WITH THE BLACK-CAPPED\nCHICKADEE\nThe overall structure of chick-a-dee calling in the\nMexican Chickadee is similar to that of the Black-\ncapped Chickadee (Hailman et al. 1985). Ther\nare four note types, they are combined into unit\ncalls with very short internote intervals com\npared with intervals between calls, and they oc\ncur in the invariable sequence A-B-C-D within\ncalls, where any note type may be omitted en-\ntirely, given once, or repeated a variable numbe\nof times. The note types are structurally simila\nin the two chickadees, with B and C notes bein\nnearly identical. The calls are given by both sex\nes, throughout the year, and in a wide variety of\ncontexts. In both species the [A][D] sequence typ\nis the commonest overall. Both call systems ar\nopen to new call types as the sample size increas\nes, and are the only communication systems out-\nside of human language to be proven open.\nThe chick-a-dee calls of the two species do\ndiffer, however, in many ways. The A notes o\nthe Mexican Chickadee are markedly differen\nfrom those of the Black-capped Chickadee, and\neven the D notes are dissimilar (as noted by Dix\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms80 M. S. FICKEN, E. D. HAILMAN AND J. P. HAILMAN\nplayback\nbirds birds moving mobbing stopped\napproaching i closer i speaker\n50\n14 April I I [C]site 1\nU\nZ 40 I\no? Ei ! [A]OII I I A\nS30 I I\n20 '\n[A][D]\n10I I I----lE\n[A][C]\n20 40 60 80 100\nSUCCESSIVE CALLS\nFIGURE 7. Cumulative frequency plots (as in Fig. 6) of a particularly long mobbing session with at l\nMexican Chickadees calling. Birds first gave [A] calls at a distance, then added [C] calls when drawin\nand finally abandoned the former entirely when near the speaker. When the owl tape was turned off\nabruptly resumed.\non and Martin 1979). In both cases, though, the\nnote types may reflect origins from a common\nancestral source: the Black-capped Chickadee's\nA note is a single chevron, the Mexican Chick-\nadee's a continuous chain of short chevrons run\ntogether (Fig. 1, above) so as to sound distinctly\nbuzzing to the human ear. Similarly, the D notes\nof both species are the longest note type, cover\na wide frequency spectrum, and may be distinctly\nbanded into emphasized frequency components\nor more uniformly distributed to compose a noisy\nnote.\nMajor differences are in duration, with the A\nnotes of the Mexican Chickadee being highly\nvariable in duration according to the other note\ntypes with which they occur (means from 120 to\n170 msec in Table 1, for A notes not contracted\nwith D's). By comparison, the A notes of the\nBlack-capped Chickadee are uniformly shorter\nat about 45 msec (Hailman et al. 1985: 195, Ta-\nble 1). Similarly, the Mexican Chickadee's un-\ncontracted D note averages 270 msec (Table 1,\nabove), whereas the Black-capped Chickadee's\nD notes average about 130 msec (Hailman et al.\n1985: 195, Table 1).\nThe rarity of B notes renders the Mexican\nChickadee's calls less diverse than those of its\ncongener, and the total note length of calls is\nmuch shorter. The more variable duration of the\nMexican Chickadee's notes may in some sense\nreplace the more variable number of note repe-\ntitions given by the Black-capped Chickadee. The\nrarity of B notes and the shorter note length of\ncalls means that the Mexican Chickadee's utter-\nances tend to be syntactically simpler, although\nnot necessarily semantically simpler (especially\nif duration of notes encodes useful information).\nGood contextual analyses of Black-capped\nChickadee calls have not been published, but\nsome comparison of mobbing situations between\nthe two species may be made preliminarily. The\nMexican Chickadee utters primarily [C] or [A][C]\ncalls when greatly disturbed or mobbing (Figs.\n5-7, above). An unpublished thesis of Apel (1985)\nshowed that Black-capped Chickadees give pri-\nmarily [D] calls or other sequence types contain-\ning D notes. Similarly, Lambrechts and J. P.\nHailman (in prep.) found that the Black-capped\nChickadees mobbing a stuffed owl near the nest\ngave elevated proportions of [D] and [A][B][D]\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/termsMEXICAN CHICKADEE CALLS 81\ncalls, with hardly any calls of any kind containing\nC notes. There are important differences in the\ndetailed contexts among these three studies, but\nthe difference in results is so striking as to suggest\na fundamentally different semantic structure in\nthe two chickadee species. By Marler's (1955)\nclassic criterion that mobbing calls should con-\nsist of short, broad frequency notes repeated, both\nchickadee species qualify. The Mexican Chick-\nadee's D notes may be too long for effectively\nrapid repetition, whereas its C note more nearly\nmeets the required characteristics. However, the\nC note of the Black-capped Chickadee is very\nsimilar to that of the Mexican Chickadee, so it\nremains unclear why the former species do not\nseem to employ C notes in its mobbing calls. In\nany case, the former impression that D and\nD-like notes were the \"mobbing calls\" of Parus\n(e.g., Thielcke 1968) is too simple a view of the\ncomplex vocalizations of tits.\nSEMANTICS\nWhat chick-a-dee calls \"mean\" (what kind of\ninformation they encode) is a formidable prob-\nlem because of the complexity of the calling sys-\ntem and the fact that chick-a-dee calls occur in\nvirtually every definable context. At one extreme\nis the possibility that chick-a-dee syntax is sim-\nply some by-product of phonation, such that all\ncalls are semantically equivalent, carrying little\nmore information than the species identity and\nposition in space of the caller. At the other ex-\ntreme is the possibility that each of the hundreds\nof call types has its own distinct meaning, like\nwords in a dictionary. Hailman et al. (1985, 1987)\nfavored an intermediate view for the Black-\ncapped Chickadee, suggesting that each note type\nmeans something different and repetitions of note\ntypes within calls serve as modifiers denoting\n\"intensity.\" The present results on the Mexican\nChickadee support this hypothesis by the find-\nings of distinctly different suites of sequence types\nin different contexts (Fig. 5, above) and details\nof calls given during mobbing situations (e.g.,\nFig. 7, above). Comparable contextual differ-\nences have yet to be reported for the Black-\ncapped Chickadee.\nEven though different suites of sequence types\ncharacterize different contexts, the fact that the\nsame note types, sequence types and call types\ncan occur in different contexts suggests that note\ntypes encode information common to a variety\nof situations. Hailman et al. (1985, 1987) sug-\ngested that this encoded information related pri-\nmarily to the position and movements of the\ncaller in space, especially relative to external ob-\njects such as conspecifics, the nest, a human ob-\nserver, or a potential predator. The present re-\nsults on the Mexican Chickadee support that view\nand give it further substance. In contexts where\nbirds are moving through the environment with\nlittle obvious disturbance except that caused by\nconspecifics, Mexican Chickadees utter primar-\nily [A] and [A][D] calls (Fig. 5a-c, above). These\nsame two sequence types characterize birds mov-\ning toward the site of an owl playback (Figs. 6\nand 7, above), and sometimes when leaving the\nsite (Fig. 7). The D note is always given while\nperched whereas the A note seems to be given\nsometimes in flight as well.\nA preliminary interpretation may therefore be\nformulated as follows. A notes indicate a rest-\nlessness (a bird ready to fly or already in flight)\nwhereas a D note indicates that the caller is\nperched and hence indexes its location in space.\nThe [A] sequence type in undisturbed birds con-\nsists mainly of single A notes, but in birds ap-\nproaching a mobbing site AA and AAA call types\nare especially common. Thus, the repetition of\nA might indicate speed of movement or high\n\"intensity\" of restlessness. The [C] calls of the\nMexican Chickadee are given most commonly\nin disturbed situations (Fig. 5d-f, above), where\n[A][C] calls are also common. Furthermore, when\nintensely mobbing an owl playback, the birds\ngave nearly pure [C] calls (Fig. 7), as they did to\nthe human observer at the nest (Fig. 5f). The C\nnote is most often given by a perched bird that\nis pivoting while it calls, but may sometimes be\ngiven in flight. In the Black-capped Chickadee a\nC note given in flight has been correlated prelim-\ninarily with a sudden swerve or change in direc-\ntion (Hailman et al. 1985), but our videotapes\ncannot document the same phenomenon for cer-\ntain in the Mexican Chickadee. That [C] calls,\nand even a few [A][C] calls, occur in relatively\nundisturbed situations (Figs. 5a-c) may indicate\nmild disturbance by conspecifics. Therefore, C\nnotes seem to indicate a disturbing stimulus and\nthe tendency to change direction, so that when\ncombined with A notes in [A][C] calls further\nindicate a tendency to move some distance, as\nwhen flying past a playback speaker or owl mod-\nel.\nIn summary, the relatively simple structure of\nMexican Chickadee calls provides a clearer pic-\nture of the information encoded by note types\nthan is currently available from data on Black-\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms82 M. S. FICKEN, E. D. HAILMAN AND J. P. HAILMAN\ncapped Chickadees. Basically, A notes indicate\na tendency to move some distance in space, C\nnotes denote a disturbing stimulus and a ten-\ndency to alter direction, and D notes connote a\nperched bird. (The B note of the Mexican Chick-\nadee cannot be analyzed because of its rarity).\nRepetitions of notes within calls indicate the \"in-\ntensity\" of the behavior that correlates with the\nnote types. Whether or not combinations of these\nnotes into sequence types such as [A][C], [A][D]\nor [C][D] encode something more than the con-\ncatenation of the separate meanings of the notes\nis a derivative question of considerable difficulty\nthat cannot be addressed with present data.\nACKNOWLEDGMENTS\nWe thank Sally Spofford for suggesting study sites. We\nused the facilities of the Southwest Research Station\nof the American Museum of Natural History and thank\nthe staff of that institution.\nLITERATURE CITED\nAPEL, K. M. 1985. Antipredator behavior in the Black-\ncapped Chickadee (Parus atricapillus). Ph.D.diss.,\nUniversity of Wisconsin, Milwaukee, WI.\nDIXON, K. L., AND D. J. MARTIN. 1979. Notes on the\nvocalizations of the Mexican Chickadee. Condor\n81:421-423.\nENGELS, W. R. 1988. Monte Carlo RxC contingency\ntable test. Computer software for Apple Macintosh\nwith on-line documentation. Dept. of Genetics,\nUniv. of Wisconsin, Madison, WI.\nFICKEN, M. S. 1990a. Vocal repertoire of the Mexican\nChickadee. I. Calls. J. Field Ornithol. 61:380-387.\nFICKEN, M. S. 1990b. Vocal repertoire of the Mexican\nChickadee. II. Song and song-like vocalizations.\nJ. Field Ornithol. 61:388-395.\nFICKEN, M. S., R. W. FICKEN, AND S. R. WITKIN. 1978.\nThe vocal repertoire of the Black-capped Chick-\nadee. Auk 95:34-48.\nFICKEN, M. S., AND J. NOCEDAL. 1992. Mexican\nChickadee, p. 1-11. In A. Poole, P. Stettenheim,\nand F. Gills [eds.], The birds of North America,\nno. 8. American Ornithologists' Union and Acad-\nemy of Natural Sciences, Washington, DC and\nPhiladelphia.\nHAILMAN, J. P. 1989. The organization of major vo-\ncalizations in the Paridae. Wilson Bull. 101:305-\n343.\nHAILMAN, J. P., AND M. S. FICKEN. 1986. Combi-\nnatorial animal communication with computable\nsyntax: chick-a-dee calling qualifies as 'language'\nby structural linguistics. Anim. Behav. 34:1899-\n1901.\nHAILMAN, J. P., M. S. FICKEN, AND R. W. FICKEN.\n1985. The 'chick-a-dee' calls ofParus atricapillus:\na recombinant system of animal communication\ncompared with written English. Semiotica 56:191-\n224.\nHAILMAN, J. P., M. S. FICKEN, AND R. W. FICKEN.\n1987. Constraints on the structure of combina-\ntorial \"chick-a-dee\" calls. Ethology 75:62-80.\nMANDELBROT, B. 1953. Contribution A la thborie\nmath6matique des jeux de communication. Publ.\nL'Inst. Stat. L'Univ. Paris 2:5-50.\nMARLER, P. 1955. Characteristics of some animal\ncalls. Nature 176:6-8.\nTHIELCKE, G. 1968. Gemeinsames der Gattung Par-\nus. Ein bioakustischer Beitrag zur Systematik. Vo-\ngelwelt (Beihefte) 1:147-164.\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 19:02:43 UTC��������������\nAll use subject to https://about.jstor.org/terms", "affiliations": [{"country": "United States", "discipline": "Biology", "university": "University of Wisconsin-Milwaukee"}, {"country": "United States", "discipline": "Dairy Science", "university": "University of Wisconsin-Milwaukee"}, {"country": "United States", "discipline": "Zoology", "university": "University of Wisconsin-Milwaukee"}], "species_categories": ["Bird"], "specialized_species": ["Mexican Chickadee", "Black-capped Chickadee", "Northern Pygmy-Owl", "Great Horned Owl"], "computational_stages": [], "linguistic_features": ["Discreteness and Syntax", "Openness", "Semanticity"], "status": "saved", "created_at": "2026-01-13T12:49:59.882698", "updated_at": "2026-01-13T16:10:07.111345", "committed_at": "2026-01-13T14:03:58.572177"}
{"id": "177fb068-8599-4697-9230-2fd9bfc42901", "title": "Pygmy marmosets,  Cebuella pygmaea,  modify vocal structure in response to changed social environment", "authors": ["Elowson,  A.Margaret", "Snowdon,  Charles T."], "year": "1994", "journal": "Animal Behaviour", "abstract": "", "doi": "10.1006/anbe.1994.1175", "analysis_notes": "Abstract. Pygmy marmosets displayed plasticity in vocal structure over a 5-month study of nine individuals. Changes in acoustical structure of a contact call, the trill, were investigated when two unfamiliar, captive populations of monkeys were placed together in a common acoustical environment. Monkeys representing four age categories (infant, juvenile, subadult and adult) were studied in three time blocks: 9 weeks of no acoustical interaction, the first 4 weeks after contact and 6-10 weeks after contact. Analyses of variance showed that the monkeys made coextensive shifts in two frequency measures (bandwidth and peak frequency) making parallel vocal changes rather than converging on or diverging from one another's call form. Call duration initially showed distinct population differences that disappeared after acoustic contact between the populations. Comparable analyses of trills given by pygmy marmosets that did not experience novel social companions did not show significant changes. These results suggest greater vocal plasticity across age ranges than has been hitherto described for a non-human primate and suggest the importance of social factors in vocal architecture.\n", "affiliations": [{"country": "United States", "discipline": "Psychology", "university": "University of Wisconsin–Madison"}, {"country": "", "discipline": "", "university": ""}], "species_categories": ["Primate"], "specialized_species": ["Pygmy marmosets"], "computational_stages": [], "linguistic_features": [], "status": "saved", "created_at": "2026-01-13T12:49:59.882703", "updated_at": "2026-01-13T16:13:15.270057", "committed_at": "2026-01-13T14:05:13.799884"}
{"id": "28e069de-ac2d-4fe9-b14d-147c3ca10bc7", "title": "The faculty of language: what is it, who has it, and how did it evolve?", "authors": ["Hauser, Marc D", "Chomsky, Noam", "Fitch, W Tecumseh"], "year": "2002", "journal": "science", "abstract": "", "doi": "", "analysis_notes": "R E V I E W : N E U R O S C I E N C E\nThe Faculty of Language: What Is It, Who Has\nIt, and How Did It Evolve?\nMarc D. Hauser,1 * Noam Chomsky,2 W. Tecumseh Fitch1\nWe argue that an understanding of the faculty of language requires substantial\ninterdisciplinary cooperation. We suggest how current developments in linguistics can\nbe profitably wedded to work in evolutionary biology, anthropology, psychology, and\nneuroscience. We submit that a distinction should be made between the faculty of\nlanguage in the broad sense (FLB)and in the narrow sense (FLN). FLB includes a\nsensory-motor system, a conceptual-intentional system, and the computational\nmechanisms for recursion, providing the capacity to generate an infinite range of\nexpressions from a finite set of elements. We hypothesize that FLN only includes\nrecursion and is the only uniquely human component of the faculty of language. We\nfurther argue that FLN may have evolved for reasons other than language, hence\ncomparative studies might look for evidence of such computations outside of the\ndomain of communication (for example, number, navigation, and social relations).\nIf a martian graced our planet, it would be\nstruck by one remarkable similarity among\nEarth’s living creatures and a key difference.\nConcerning similarity, it would note that all\nliving things are de-\nsigned on the basis of\nhighly conserved de-\nvelopmental systems\nthat read an (almost)\nuniversal language en-\ncoded in DNA base\npairs. As such, life is\narranged hierarchical-\nly with a foundation\nof discrete, unblend-\nable units (codons, and,\nfor the most part,\ngenes) capable of com-\nbining to create increas-\ningly complex and vir-\ntually limitless varieties\nof both species and in-\ndividual organisms. In\ncontrast, it would notice\nthe absence of a univer-\nsal code of communi-\ncation (Fig. 1).\nIf our martian nat-\nuralist were meticu-\nlous, it might note\nthat the faculty medi-\nating human communication appears remark-\nably different from that of other living crea-\ntures; it might further note that the human\nfaculty of language appears to be organized\nlike the genetic code— hierarchical, genera-\ntive, recursive, and virtually limitless with\nrespect to its scope of expression. With these\npieces in hand, this martian might begin to\nwonder how the genetic code changed in such\na way as to generate a vast number of mutu-\nally incomprehensible communication sys-\ntems across species while maintaining clarity\nof comprehension within a given species. The\nmartian would have stumbled onto some of\nthe essential problems surrounding the\nquestion of language evolution, and of how\nhumans acquired the faculty of language.\nIn exploring the problem of language evo-\nlution, it is important to distinguish between\nquestions concerning language as a commu-\nnicative system and questions concerning the\ncomputations underlying this system, such as\nthose underlying recursion. As we argue be-\nlow, many acrimonious debates in this field\nhave been launched by a failure to distinguish\nbetween these problems. According to one\nview (1), questions concerning abstract com-\nputational mechanisms are distinct from\nthose concerning communication, the latter\ntargeted at problems at the interface between\nabstract computation and both sensory-motor\nand conceptual-intentional interfaces. This\nview should not, of course, be taken as a\nclaim against a relationship between compu-\ntation and communication. It is possible, as\nwe discuss below, that key computational\ncapacities evolved for reasons other than\ncommunication but, after they proved to have\nutility in communication, were altered be-\ncause of constraints imposed at both the pe-\nriphery (e.g., what we can hear and say or see\nand sign, the rapidity with which the auditory\ncortex can process rapid temporal and spec-\n1 Department of Psychology, Harvard University,\nCambridge, MA 02138, USA. 2 Department of Linguis-\ntics and Philosophy, Massachusetts Institute of Tech-\nnology, Cambridge, MA 02138, USA.\n*To whom correspondence should be addressed. E-\nmail: mdhauser@wjh.harvard.edu\nFig. 1. The animal kingdom has been designed on the basis of highly conserved developmental systems that read an almost\nuniversal language coded in DNA base pairs. This system is shown on the left in terms of a phylogenetic tree. In contrast, animals\nlack a common universal code of communication, indicated on the right by unconnected animal groups. [Illustration: John Yanson]\nS C I E N C E ’ S C O M P A S S ● R E V I E W\nwww.sciencemag.org SCIENCE VOL 29822 NOVEMBER 2002 1569\ntral changes) and more central levels (e.g.,\nconceptual and cognitive structures, pragmat-\nics, memory limitations).\nAt least three theoretical issues cross-cut\nthe debate on language evolution. One of the\noldest problems among theorists is the\n“shared versus unique” distinction. Most cur-\nrent commentators agree that, although bees\ndance, birds sing, and chimpanzees grunt,\nthese systems of communication differ qual-\nitatively from human language. In particular,\nanimal communication systems lack the rich\nexpressive and open-ended power of human\nlanguage (based on humans’ capacity for re-\ncursion). The evolutionary puzzle, therefore,\nlies in working out how we got from there to\nhere, given this apparent discontinuity. A sec-\nond issue revolves around whether the evo-\nlution of language was gradual versus salta-\ntional; this differs from the first issue because\na qualitative discontinuity between extant\nspecies could have evolved gradually, involv-\ning no discontinuities during human evolu-\ntion. Finally, the “continuity versus exapta-\ntion” issue revolves around the problem of\nwhether human language evolved by gradual\nextension of preexisting communication sys-\ntems, or whether important aspects of lan-\nguage have been exapted away from their\nprevious adaptive function (e.g., spatial or\nnumerical reasoning, Machiavellian social\nscheming, tool-making).\nResearchers have adopted extreme or in-\ntermediate positions regarding these basically\nindependent questions, leading to a wide\nvariety of divergent viewpoints on the evo-\nlution of language in the current literature.\nThere is, however, an emerging consensus\nthat, although humans and animals share a\ndiversity of important computational and\nperceptual resources, there has been sub-\nstantial evolutionary remodeling since we\ndiverged from a common ancestor some 6\nmillion years ago. The empirical challenge\nis to determine what was inherited un-\nchanged from this common ancestor, what\nhas been subjected to minor modifications,\nand what (if anything) is qualitatively new.\nThe additional evolutionary challenge is to\ndetermine what selectional pressures led to\nadaptive changes over time and to under-\nstand the various constraints that channeled\nthis evolutionary process. Answering these\nquestions requires a collaborative effort\namong linguists, biologists, psychologists,\nand anthropologists.\nOne aim of this essay is to promote a\nstronger connection between biology and\nlinguistics by identifying points of contact\nand agreement between the fields. Al-\nthough this interdisciplinary marriage was\ninaugurated more than 50 years ago, it has\nnot yet been fully consummated. We hope\nto further this goal by, first, helping to\nclarify the biolinguistic perspective on lan-\nguage and its evolution (2–7). We then\nreview some promising empirical ap-\nproaches to the evolution of the language\nfaculty, with a special focus on\ncomparative work with non-\nhuman animals, and conclude\nwith a discussion of how in-\nquiry might profitably advance,\nhighlighting some outstanding\nproblems.\nWe make no attempt to be\ncomprehensive in our coverage of\nrelevant or interesting topics and\nproblems. Nor is it our goal to\nreview the history of the field.\nRather, we focus on topics that\nmake important contact between\nempirical data and theoretical po-\nsitions about the nature of the lan-\nguage faculty. We believe that if\nexplorations into the problem of\nlanguage evolution are to progress,\nwe need a clear explication of the\ncomputational requirements for\nlanguage, the role of evolutionary\ntheory in testing hypotheses of\ncharacter evolution, and a research\nprogram that will enable a produc-\ntive interchange between linguists\nand biologists.\nDefining the Target: Two\nSenses of the Faculty of\nLanguage\nThe word “language” has highly divergent\nmeanings in different contexts and disci-\nplines. In informal usage, a language is un-\nderstood as a culturally specific communica-\ntion system (English, Navajo, etc.). In the\nvarieties of modern linguistics that concern\nus here, the term “language” is used quite\ndifferently to refer to an internal component\nof the mind/brain (sometimes called “internal\nlanguage” or “I-language”). We assume that\nthis is the primary object of interest for the\nstudy of the evolution and function of the\nlanguage faculty. However, this biologically\nand individually grounded usage still leaves\nmuch open to interpretation (and misunder-\nstanding). For example, a neuroscientist\nmight ask: What components of the human\nnervous system are recruited in the use of\nlanguage in its broadest sense? Because any\naspect of cognition appears to be, at least in\nprinciple, accessible to language, the broadest\nanswer to this question is, probably, “most of\nit.” Even aspects of emotion or cognition not\nreadily verbalized may be influenced by lin-\nguistically based thought processes. Thus,\nthis conception is too broad to be of much\nuse. We therefore delineate two more restrict-\ned conceptions of the faculty of language, one\nbroader and more inclusive, the other more\nrestricted and narrow (Fig. 2).\nFaculty of language— broad sense\n(FLB). FLB includes an internal computa-\ntional system (FLN, below) combined with\nat least two other organism-internal sys-\nFig. 2. A schematic representation of organism-external and -internal factors related to the faculty of language.\nFLB includes sensory-motor, conceptual-intentional, and other possible systems (which we leave open); FLN\nincludes the core grammatical computations that we suggest are limited to recursion. See text for more\ncomplete discussion.\nS C I E N C E ’ S C O M P A S S\n22 NOVEMBER 2002 VOL 298SCIENCE www.sciencemag.org1570\ntems, which we call “sensory-motor” and\n“conceptual-intentional.” Despite debate on\nthe precise nature of these systems, and\nabout whether they are substantially shared\nwith other vertebrates or uniquely adapted\nto the exigencies of language, we take as\nuncontroversial the existence of some bio-\nlogical capacity of humans that allows us\n(and not, for example, chimpanzees) to\nreadily master any human language without\nexplicit instruction. FLB includes this ca-\npacity, but excludes other organism-\ninternal systems that are necessary but not\nsufficient for language (e.g., memory, res-\npiration, digestion, circulation, etc.).\nFaculty of language—narrow sense\n(FLN). FLN is the abstract linguistic compu-\ntational system alone, independent of the oth-\ner systems with which it interacts and inter-\nfaces. FLN is a component of FLB, and the\nmechanisms underlying it are some subset of\nthose underlying FLB.\nOthers have agreed on the need for a\nrestricted sense of “language” but have sug-\ngested different delineations. For example,\nLiberman and his associates (8) have argued\nthat the sensory-motor systems were specifi-\ncally adapted for language, and hence should\nbe considered part of FLN. There is also a\nlong tradition holding that the conceptual-\nintentional systems are an intrinsic part of\nlanguage in a narrow sense. In this article, we\nleave these questions open, restricting atten-\ntion to FLN as just defined but leaving the\npossibility of a more inclusive definition\nopen to further empirical research.\nThe internal architecture of FLN, so con-\nceived, is a topic of much current research\nand debate (4). Without prejudging the is-\nsues, we will, for concreteness, adopt a par-\nticular conception of this architecture. We\nassume, putting aside the precise mecha-\nnisms, that a key component of FLN is a\ncomputational system (narrow syntax) that\ngenerates internal representations and maps\nthem into the sensory-motor interface by the\nphonological system, and into the conceptu-\nal-intentional interface by the (formal) se-\nmantic system; adopting alternatives that\nhave been proposed would not materially\nmodify the ensuing discussion. All approach-\nes agree that a core property of FLN is recur-\nsion, attributed to narrow syntax in the con-\nception just outlined. FLN takes a finite set of\nelements and yields a potentially infinite ar-\nray of discrete expressions. This capacity of\nFLN yields discrete infinity (a property that\nalso characterizes the natural numbers). Each\nof these discrete expressions is then passed to\nthe sensory-motor and conceptual-intentional\nsystems, which process and elaborate this\ninformation in the use of language. Each\nexpression is, in this sense, a pairing of sound\nand meaning. It has been recognized for thou-\nsands of years that language is, fundamental-\nly, a system of sound-meaning connections;\nthe potential infiniteness of this system has\nbeen explicitly recognized by Galileo, Des-\ncartes, and the 17th-century “philosophical\ngrammarians” and their successors, notably\nvon Humboldt. One goal of the study of FLN\nand, more broadly, FLB is to discover just\nhow the faculty of language satisfies these\nbasic and essential conditions.\nThe core property of discrete infinity is\nintuitively familiar to every language user.\nSentences are built up of discrete units: There\nare 6-word sentences and 7-word sentences,\nbut no 6.5-word sentences. There is no long-\nest sentence (any candidate sentence can be\ntrumped by, for example, embedding it in\n“Mary thinks that . . .”), and there is no non-\narbitrary upper bound to sentence length. In\nthese respects, language is directly analogous\nto the natural numbers (see below).\nAt a minimum, then, FLN includes the ca-\npacity of recursion. There are many organism-\ninternal factors, outside FLN or FLB, that im-\npose practical limits on the usage of the system.\nFor example, lung capacity imposes limits on\nthe length of actual spoken sentences, whereas\nworking memory imposes limits on the com-\nplexity of sentences if they are to be under-\nstandable. Other limitations—for example, on\nconcept formation or motor output speed—\nrepresent aspects of FLB, which have their own\nevolutionary histories and may have played a\nrole in the evolution of the capacities of FLN.\nNonetheless, one can profitably inquire into the\nevolution of FLN without an\nimmediate concern for these\nlimiting aspects of FLB. This\nis made clear by the observa-\ntion that, although many\naspects of FLB are shared\nwith other vertebrates, the\ncore recursive aspect of FLN\ncurrently appears to lack any\nanalog in animal communi-\ncation and possibly other do-\nmains as well. This point,\ntherefore, represents the\ndeepest challenge for a com-\nparative evolutionary ap-\nproach to language. We be-\nlieve that investigations of\nthis capacity should include\ndomains other than commu-\nnication (e.g., number, social\nrelationships, navigation).\nGiven the distinctions\nbetween FLB and FLN and\nthe theoretical distinctions\nraised above, we can define\na research space as sketched\nin Fig. 3. This research\nspace identifies, as viable,\nproblems concerning the\nevolution of sensory-motor\nsystems, of conceptual-in-\ntentional systems, and of\nFLN. The comparative ap-\nproach, to which we turn\nnext, provides a framework\nfor addressing questions\nabout each of these com-\nponents of the faculty of\nlanguage.\nThe Comparative\nApproach to Language\nEvolution\nThe empirical study of the\nevolution of language is be-\nset with difficulties. Lin-\nguistic behavior does not\nfossilize, and a long tradi-\nFig. 3. Investigations into the evolution of the faculty of language\nare confronted with a three-dimensional research space that\nincludes three comparative-evolutionary problems cross-cut by\nthe core components of the faculty of language. Thus, for each\nproblem, researchers can investigate details of the sensory-motor\nsystem, the conceptual-intentional system, FLN, and the interfac-\nes among these systems.\nS C I E N C E ’ S C O M P A S S\nwww.sciencemag.org SCIENCE VOL 29822 NOVEMBER 2002 1571\ntion of analysis of fossil skull shape and\ncranial endocasts has led to little consensus\nabout the evolution of language (7, 9). A\nmore tractable and, we think, powerful ap-\nproach to problems of language evolution is\nprovided by the comparative method, which\nuses empirical data from living species to\ndraw detailed inferences about extinct ances-\ntors (3, 10 –12). The comparative method was\nthe primary tool used by Darwin (13, 14) to\nanalyze evolutionary phenomena and contin-\nues to play a central role throughout modern\nevolutionary biology. Although scholars in-\nterested in language evolution have often ig-\nnored comparative data altogether or focused\nnarrowly on data from nonhuman primates,\ncurrent thinking in neuroscience, molecular\nbiology, and developmental biology indicates\nthat many aspects of neural and developmen-\ntal function are highly conserved, encourag-\ning the extension of the comparative method\nto all vertebrates (and perhaps beyond). For\nseveral reasons, detailed below, we believe\nthat the comparative method should play a\nmore central role in future discussions of\nlanguage evolution.\nAn overarching concern in studies of lan-\nguage evolution is with whether particular\ncomponents of the faculty of language\nevolved specifically for human language and,\ntherefore (by extension), are unique to hu-\nmans. Logically, the human uniqueness claim\nmust be based on data indicating an absence\nof the trait in nonhuman animals and, to be\ntaken seriously, requires a substantial body of\nrelevant comparative data. More concretely,\nif the language evolution researcher wishes to\nmake the claim that a trait evolved uniquely\nin humans for the function of language pro-\ncessing, data indicating that no other animal\nhas this particular trait are required.\nAlthough this line of reasoning may ap-\npear obvious, it is surprisingly common for a\ntrait to be held up as uniquely human before\nany appropriate comparative data are avail-\nable. A famous example is categorical per-\nception, which when discovered seemed so\nfinely tuned to the details of human speech as\nto constitute a unique human adaptation (15,\n16). It was some time before the same under-\nlying perceptual discontinuities were discov-\nered in chinchillas and macaques (17, 18),\nand even birds (19), leading to the opposite\nconclusion that the perceptual basis for cate-\ngorical perception is a primitive vertebrate\ncharacteristic that evolved for general audito-\nry processing, as opposed to specific speech\nprocessing. Thus, a basic and logically in-\neliminable role for comparative research on\nlanguage evolution is this simple and essen-\ntially negative one: A trait present in nonhu-\nman animals did not evolve specifically for\nhuman language, although it may be part of\nthe language faculty and play an intimate role\nin language processing. It is possible, of\ncourse, that a trait evolved in nonhuman an-\nimals and humans independently, as analogs\nrather than homologs. This would preserve\nthe possibility that the trait evolved for lan-\nguage in humans but evolved for some other\nreason in the comparative animal group. In\ncases where the comparative group is a non-\nhuman primate, and perhaps especially chim-\npanzees, the plausibility of this evolutionary\nscenario is weaker. In any case, comparative\ndata are critical to this judgment.\nDespite the crucial role of homology in\ncomparative biology, homologous traits are not\nthe only relevant source of evolutionary data.\nThe convergent evolution of similar characters\nin two independent clades, termed “analogies”\nor “homoplasies,” can be equally revealing\n(20). The remarkably similar (but nonhomolo-\ngous) structures of human and octopus eyes\nreveal the stringent constraints placed by the\nlaws of optics and the contingencies of devel-\nopment on an organ capable of focusing a sharp\nimage onto a sheet of receptors. Detailed anal-\nogies between the parts of the vertebrate and\ncephalopod eye also provide independent evi-\ndence that each component is an adaptation for\nimage formation, shaped by natural selection.\nFurthermore, the discovery that remarkably\nconservative genetic cascades underlie the de-\nvelopment of such analogous structures pro-\nvides important insights into the ways in\nwhich developmental mechanisms can\nchannel evolution (21). Thus, although po-\ntentially misleading for taxonomists, anal-\nogies provide critical data about adaptation\nunder physical and developmental con-\nstraints. Casting the comparative net more\nbroadly, therefore, will most likely reveal\nlarger regularities in evolution, helping to\naddress the role of such constraints in the\nevolution of language.\nAn analogy recognized as particularly rele-\nvant to language is the acquisition of song by\nbirds (12). In contrast to nonhuman primates,\nwhere the production of species-typical vocal-\nizations is largely innate (22), most songbirds\nlearn their species-specific song by listening to\nconspecifics, and they develop highly aberrant\nsong if deprived of such experience. Current\ninvestigation of birdsong reveals detailed and\nintriguing parallels with speech (11, 23, 24).\nFor instance, many songbirds pass through a\ncritical period in development beyond which\nthey produce defective songs that no amount of\nacoustic input can remedy, reminiscent of the\ndifficulty adult humans have in fully mastering\nnew languages. Further, and in parallel with the\nbabbling phase of vocalizing or signing human\ninfants (25), young birds pass through a phase\nof song development in which they spontane-\nously produce amorphous versions of adult\nsong, termed “subsong” or “babbling.” Al-\nthough the mechanisms underlying the acquisi-\ntion of birdsong and human language are clear-\nly analogs and not homologs, their core com-\nponents share a deeply conserved neural and\ndevelopmental foundation: Most aspects of\nneurophysiology and development—including\nregulatory and structural genes, as well as neu-\nron types and neurotransmitters—are shared\namong vertebrates. That such close parallels\nhave evolved suggests the existence of impor-\ntant constraints on how vertebrate brains can\nacquire large vocabularies of complex, learned\nsounds. Such constraints may essentially force\nnatural selection to come up with the same\nsolution repeatedly when confronted with sim-\nilar problems.\nTesting Hypotheses About the\nEvolution of the Faculty of Language\nGiven the definitions of the faculty of lan-\nguage, together with the comparative frame-\nwork, we can distinguish several plausible\nhypotheses about the evolution of its various\ncomponents. Here, we suggest two hypothe-\nses that span the diversity of opinion among\ncurrent scholars, plus a third of our own.\nHypothesis 1: FLB is strictly homologous\nto animal communication. This hypothesis\nholds that homologs of FLB, including FLN,\nexist ( perhaps in less developed or otherwise\nmodified form) in nonhuman animals (3, 10,\n26). This has historically been a popular hy-\npothesis outside of linguistics and closely\nallied fields, and has been defended by some\nin the speech sciences. According to this\nhypothesis, human FLB is composed of the\nsame functional components that underlie\ncommunication in other species.\nHypothesis 2: FLB is a derived, uniquely\nhuman adaptation for language. According\nto this hypothesis, FLB is a highly complex\nadaptation for language, on a par with the\nvertebrate eye, and many of its core compo-\nnents can be viewed as individual traits that\nhave been subjected to selection and perfect-\ned in recent human evolutionary history. This\nappears to represent the null hypothesis for\nmany scholars who take the complexity of\nlanguage seriously (27, 28). The argument\nstarts with the assumption that FLB, as a\nwhole, is highly complex, serves the function\nof communication with admirable effective-\nness, and has an ineliminable genetic compo-\nnent. Because natural selection is the only\nknown biological mechanism capable of gen-\nerating such functional complexes [the argu-\nment from design (29)], proponents of this\nview conclude that natural selection has\nplayed a powerful role in shaping many as-\npects of FLB, including FLN, and, further,\nthat many of these are without parallel in\nnonhuman animals. Although homologous\nmechanisms may exist in other animals, the\nhuman versions have been modified by nat-\nural selection to the extent that they can be\nreasonably seen as constituting novel traits,\nperhaps exapted from other contexts [e.g.,\nsocial intelligence, tool-making (7, 30 –32)].\nS C I E N C E ’ S C O M P A S S\n22 NOVEMBER 2002 VOL 298SCIENCE www.sciencemag.org1572\nHypothesis 3: Only FLN is uniquely human.\nOn the basis of data reviewed below, we hy-\npothesize that most, if not all, of FLB is based\non mechanisms shared with nonhuman animals\n(as held by hypothesis 1). In contrast, we sug-\ngest that FLN—the computational mechanism\nof recursion—is recently evolved and unique to\nour species (33, 34). According to this hypoth-\nesis, much of the complexity manifested in\nlanguage derives from complexity in the pe-\nripheral components of FLB, especially those\nunderlying the sensory-motor (speech or sign)\nand conceptual-intentional interfaces, com-\nbined with sociocultural and communicative\ncontingencies. FLB as a whole thus has an\nancient evolutionary history, long predating the\nemergence of language, and a comparative\nanalysis is necessary to understand this com-\nplex system. By contrast, according to recent\nlinguistic theory, the computations underlying\nFLN may be quite limited. In fact, we propose\nin this hypothesis that FLN comprises only the\ncore computational mechanisms of recursion as\nthey appear in narrow syntax and the mappings\nto the interfaces. If FLN is indeed this restrict-\ned, this hypothesis has the interesting effect of\nnullifying the argument from design, and thus\nrendering the status of FLN as an adaptation\nopen to question. Proponents of the idea that\nFLN is an adaptation would thus need to supply\nadditional data or arguments to support this\nviewpoint.\nThe available comparative data on animal\ncommunication systems suggest that the faculty\nof language as a whole relies on some uniquely\nhuman capacities that have evolved recently in\nthe approximately 6 million years since our\ndivergence from a chimpanzee-like common\nancestor (35). Hypothesis 3, in its strongest\nform, suggests that only FLN falls into this\ncategory (34). By this hypothesis, FLB contains\na wide variety of cognitive and perceptual\nmechanisms shared with other species, but only\nthose mechanisms underlying FLN—particu-\nlarly its capacity for discrete infinity—are\nuniquely human. This hypothesis suggests that\nall peripheral components of FLB are shared\nwith other animals, in more or less the same\nform as they exist in humans, with differences\nof quantity rather than kind (9, 34). What is\nunique to our species is quite specific to FLN,\nand includes its internal operations as well as its\ninterface with the other organism-internal sys-\ntems of FLB.\nEach of these hypotheses is plausible to\nsome degree. Ultimately, they can be distin-\nguished only by empirical data, much of which\nis currently unavailable. Before reviewing some\nof the relevant data, we briefly consider some\nkey distinctions between them. From a compar-\native evolutionary viewpoint, an important\nquestion is whether linguistic precursors were\ninvolved in communication or in something\nelse. Proponents of both hypotheses 1 and 2\nposit a direct correspondence, by descent with\nmodification, between some trait involved in\nFLB in humans and a similar trait in another\nspecies; these hypotheses differ in whether\nthe precursors functioned in communication.\nTable 1. A sampler of empirical approaches to understanding the evolution of the faculty of language, including both broad (FLB) and narrow (FLN)\ncomponents.\nEmpirical problem Examples References\nFLB—sensory-motor system\nVocal imitation and invention Tutoring studies of songbirds, analyses of vocal dialects in whales, spontaneous imitation\nof artificially created sounds in dolphins\n(11, 12, 24, 65)\nNeurophysiology of\naction-perception systems\nStudies assessing whether mirror neurons, which provide a core substrate for the\naction-perception system, may subserve gestural and ( possibly) vocal imitation\n(67, 68, 71)\nDiscriminating the sound patterns\nof language\nOperant conditioning studies of the prototype magnet effect in macaques and starlings (52, 120)\nConstraints imposed by vocal tract\nanatomy\nStudies of vocal tract length and formant dispersion in birds and primates (54–61)\nBiomechanics of sound production Studies of primate vocal production, including the role of mandibular oscillations (121, 122)\nModalities of language production\nand perception\nCross-modal perception and sign language in humans versus unimodal communication in\nanimals\n(3, 25, 123)\nFLB—conceptual-intentional system\nTheory of mind, attribution of\nmental states\nStudies of the seeing/knowing distinction in chimpanzees (84, 86–89)\nCapacity to acquire nonlinguistic\nconceptual representations\nStudies of rhesus monkeys and the object/kind concept (10, 76, 77, 124)\nReferential vocal signals Studies of primate vocalizations used to designate predators, food, and social\nrelationships\n(3, 78, 90, 91, 93,\n94, 97)\nImitation as a rational, intentional\nsystem\nComparative studies of chimpanzees and human infants suggesting that only the latter\nread intentionality into action, and thus extract unobserved rational intent\n(125–127)\nVoluntary control over signal\nproduction as evidence of\nintentional communication\nComparative studies that explore the relationship between signal production and the\ncomposition of a social audience\n(3, 10, 92, 128)\nFLN—recursion\nSpontaneous and training methods\ndesigned to uncover constraints\non rule learning\nStudies of serial order learning and finite-state grammars in tamarins and macaques (114, 116, 117,\n129)\nSign or artificial language in\ntrained apes and dolphins\nStudies exploring symbol sequencing and open-ended combinatorial manipulation (130, 131)\nModels of the faculty of language\nthat attempt to uncover the\nnecessary and sufficient\nmechanisms\nGame theory models of language acquisition, reference, and universal grammar (72–74)\nExperiments with animals that\nexplore the nature and content\nof number representation\nOperant conditioning studies to determine whether nonhuman primates can represent\nnumber, including properties such as ordinality and cardinality, using such\nrepresentations in conjunction with mathematical operands (e.g., add, divide)\n(102–106, 132)\nShared mechanisms across\ndifferent cognitive domains\nEvolution of musical processing and structure, including analyses of brain function and\ncomparative studies of music perception\n(133–135)\nS C I E N C E ’ S C O M P A S S\nwww.sciencemag.org SCIENCE VOL 29822 NOVEMBER 2002 1573\nAlthough many aspects of FLB very likely\narose in this manner, the important issue for\nthese hypotheses is whether a series of gradual\nmodifications could lead eventually to the ca-\npacity of language for infinite generativity. De-\nspite the inarguable existence of a broadly\nshared base of homologous mechanisms in-\nvolved in FLB, minor modifications to this\nfoundational system alone seem inadequate to\ngenerate the fundamental difference—discrete\ninfinity—between language and all known\nforms of animal communication. This claim is\none of several reasons why we suspect that\nhypothesis 3 may be a productive way to char-\nacterize the problem of language evolution.\nA primary issue separating hypotheses 2\nand 3 is whether the uniquely human capac-\nities of FLN constitute an adaptation. The\nviewpoint stated in hypothesis 2, especially\nthe notion that FLN in particular is a highly\nevolved adaptation, has generated much en-\nthusiasm recently [e.g., (36)], especially\namong evolutionary psychologists (37, 38).\nAt present, however, we see little reason to\nbelieve either that FLN can be anatomized\ninto many independent but interacting traits,\neach with its own independent evolutionary\nhistory, or that each of these traits could have\nbeen strongly shaped by natural selection,\ngiven their tenuous connection to communi-\ncative efficacy (the surface or phenotypic\nfunction upon which selection presumably\nacted).\nWe consider the possibility that certain spe-\ncific aspects of the faculty of language are\n“spandrels”—by-products of preexisting con-\nstraints rather than end products of a history of\nnatural selection (39). This possibility, which\nopens the door to other empirical lines of inqui-\nry, is perfectly compatible with our firm support\nof the adaptationist program. Indeed, it follows\ndirectly from the foundational notion that adap-\ntation is an “onerous concept” to be invoked\nonly when alternative explanations fail (40).\nThe question is not whether FLN in toto is\nadaptive. By allowing us to communicate an\nendless variety of thoughts, recursion is clearly\nan adaptive computation. The question is\nwhether particular components of the function-\ning of FLN are adaptations for language, spe-\ncifically acted upon by natural selection—or,\neven more broadly, whether FLN evolved for\nreasons other than communication.\nAn analogy may make this distinction\nclear. The trunk and branches of trees are\nnear-optimal solutions for providing an indi-\nvidual tree’s leaves with access to sunlight.\nFor shrubs and small trees, a wide variety of\nforms (spreading, spherical, multistalked,\netc.) provide good solutions to this problem.\nFor a towering rainforest canopy tree, how-\never, most of these forms are rendered im-\npossible by the various constraints imposed\nby the properties of cellulose and the prob-\nlems of sucking water and nutrients up to the\nleaves high in the air. Some aspects of such\ntrees are clearly adaptations channeled by\nthese constraints; others (e.g., the popping of\nxylem tubes on hot days, the propensity to be\ntoppled in hurricanes) are presumably un-\navoidable by-products of such constraints.\nRecent work on FLN (4, 41–43) suggests\nthe possibility that at least the narrow-syntactic\ncomponent satisfies conditions of highly effi-\ncient computation to an extent previously unsus-\npected. Thus, FLN may approximate a kind of\n“optimal solution” to the problem of linking\nthe sensory-motor and conceptual-intentional\nsystems. In other words, the generative process-\nes of the language system may provide a\nnear-optimal solution that satisfies the interface\nconditions to FLB. Many of the details of lan-\nguage that are the traditional focus of linguistic\nstudy [e.g., subjacency, Wh- movement, the\nexistence of garden-path sentences (4, 44)] may\nrepresent by-products of this solution, gener-\nated automatically by neural/computational\nconstraints and the structure of FLB—\ncomponents that lie outside of FLN. Even\nnovel capacities such as recursion are imple-\nmented in the same type of neural tissue as the\nrest of the brain and are thus constrained by\nbiophysical, developmental, and computation-\nal factors shared with other vertebrates. Hy-\npothesis 3 raises the possibility that structural\ndetails of FLN may result from such preexisting\nconstraints, rather than from direct shaping by\nnatural selection targeted specifically at com-\nmunication. Insofar as this proves to be true,\nsuch structural details are not, strictly speaking,\nadaptations at all. This hypothesis and the\nalternative selectionist account are both viable\nand can eventually be tested with comparative\ndata.\nComparative Evidence for the Faculty\nof Language\nStudy of the evolution of language has accel-\nerated in the past decade (45, 46). Here, we\noffer a highly selective review of some of\nthese studies, emphasizing animal work that\nseems particularly relevant to the hypotheses\nadvanced above; many omissions were nec-\nessary for reasons of space, and we firmly\nbelieve that a broad diversity of methods and\nperspectives will ultimately provide the rich-\nest answers to the problem of language evo-\nlution. For this reason, we present a broader\nsampler of the field’s offerings in Table 1.\nHow “special” is speech? Comparative\nstudy of the sensory-motor system. Starting with\nearly work on speech perception, there has been\na tradition of considering speech “special,” and\nthus based on uniquely human mechanisms\nadapted for speech perception and/or produc-\ntion [e.g., (7, 8, 47, 48)]. This perspective has\nstimulated a vigorous research program study-\ning animal speech perception and, more recent-\nly, speech production. Surprisingly, this re-\nsearch has turned up little evidence for uniquely\nhuman mechanisms special to speech, despite a\npersistent tendency to assume uniqueness even\nin the absence of relevant animal data.\nOn the side of perception, for example,\nmany species show an impressive ability to\nboth discriminate between and generalize\nover human speech sounds, using formants as\nthe critical discriminative cue (17–19, 49 –\n51). These data provide evidence not only of\ncategorical perception, but also of the ability\nto discriminate among prototypical exem-\nplars of different phonemes (52). Further, in\nthe absence of training, nonhuman primates\ncan discriminate sentences from two different\nlanguages on the basis of rhythmic differenc-\nes between them (53).\nOn the side of production, birds and non-\nhuman primates naturally produce and per-\nceive formants in their own species-typical\nvocalizations (54 –59). The results also shed\nlight on discussions of the uniquely human\nstructure of the vocal tract and the unusual\ndescended larynx of our species (7, 48, 60),\nbecause new evidence shows that several oth-\ner mammalian species also have a descended\nlarynx (61). Because these nonhuman species\nlack speech, a descended larynx clearly has\nnonphonetic functions; one possibility is ex-\naggerating apparent size. Although this par-\nticular anatomical modification undoubtedly\nplays an important role in speech production\nin modern humans, it need not have first\nevolved for this function. The descended lar-\nynx may thus be an example of classic Dar-\nwinian preadaptation.\nMany phenomena in human speech percep-\ntion have not yet been investigated in animals\n[e.g., the McGurk effect, an illusion in which\nthe syllable perceived from a talking head rep-\nresents the interaction between an articulatory\ngesture seen and a different syllable heard; see\n(62)]. However, the available data suggest a\nmuch stronger continuity between animals and\nhumans with respect to speech than previously\nbelieved. We argue that the continuity hypoth-\nesis thus deserves the status of a null hypothe-\nsis, which must be rejected by comparative\nwork before any claims of uniqueness can be\nvalidated. For now, this null hypothesis of no\ntruly novel traits in the speech domain appears\nto stand.\nThere is, however, a striking ability tied to\nspeech that has received insufficient atten-\ntion: the human capacity for vocal imitation\n(63, 64). Imitation is obviously a necessary\ncomponent of the human capacity to acquire\na shared and arbitrary lexicon, which is itself\ncentral to the language capacity. Thus, the\ncapacity to imitate was a crucial prerequisite\nof FLB as a communicative system. Vocal\nimitation and learning are not uniquely hu-\nman. Rich multimodal imitative capacities\nare seen in other mammals (dolphins) and\nsome birds ( parrots), with most songbirds\nexhibiting a well-developed vocal imitative\nS C I E N C E ’ S C O M P A S S\n22 NOVEMBER 2002 VOL 298SCIENCE www.sciencemag.org1574\ncapacity (65). What is surprising is that mon-\nkeys show almost no evidence of visually\nmediated imitation, with chimpanzees show-\ning only slightly better capacities (66). Even\nmore striking is the virtual absence of evi-\ndence for vocal imitation in either monkeys\nor apes (3). For example, intensively trained\nchimpanzees are incapable of acquiring any-\nthing but a few poorly articulated spoken\nwords, whereas parrots can readily acquire a\nlarge vocal repertoire. With respect to their\nown vocalizations, there are few convincing\nstudies of vocal dialects in primates, thereby\nsuggesting that they lack a vocal imitative\ncapacity (3, 65). Evidence for spontaneous\nvisuomanual imitation in chimpanzees is not\nmuch stronger, although with persistent train-\ning they can learn several hundred hand\nsigns. Further, even in cases where\nnonhuman animals are capable of im-\nitating in one modality (e.g., song\ncopying in songbirds), only dolphins\nand humans appear capable of imita-\ntion in multiple modalities. The de-\ntachment from modality-specific in-\nputs may represent a substantial\nchange in neural organization, one\nthat affects not only imitation but\nalso communication; only humans\ncan lose one modality (e.g., hear-\ning) and make up for this deficit by\ncommunicating with complete com-\npetence in a different modality (i.e.,\nsigning).\nOur discussion of limitations is\nnot meant to diminish the impressive\nachievements of monkeys and apes,\nbut to highlight how different the\nmechanisms underlying the produc-\ntion of human and nonhuman primate\ngestures, either vocally expressed or\nsigned, must be. After all, the aver-\nage high school graduate knows up to\n60,000 words, a vocabulary achieved\nwith little effort, especially when\ncontrasted with the herculean efforts\ndevoted to training animals. In sum,\nthe impressive ability of any normal\nhuman child for vocal imitation may\nrepresent a novel capacity that\nevolved in our recent evolutionary\nhistory, some time after the diver-\ngence from our chimpanzee-like an-\ncestors. The existence of analogs in\ndistantly related species, such as\nbirds and cetaceans, suggests consid-\nerable potential for the detailed com-\nparative study of vocal imitation. There are,\nhowever, potential traps that must be avoid-\ned, especially with respect to explorations of\nthe neurobiological substrates of imitation.\nFor example, although macaque monkeys\nand humans are equipped with so-called\n“mirror neurons” in the premotor cortex that\nrespond both when an individual acts in a\nparticular way and when the same individual\nsees someone else act in this same way (67,\n68), these neurons are not sufficient for imi-\ntation in macaques, as many have presumed:\nAs mentioned, there is no convincing evi-\ndence of vocal or visual imitation in mon-\nkeys. Consequently, as neuroimaging studies\ncontinue to explore the neural basis of imita-\ntion in humans (69 –71), it will be important\nto distinguish between the necessary and suf-\nficient neural correlates of imitation. This is\nespecially important, given that some recent\nattempts to model the evolution of language\nbegin with a hypothetical organism that is\nequipped with the capacity for imitation and\nintentionality, as opposed to working out how\nthese mechanisms evolved in the first place\n[see below; (72–74)]. If a deeper evolution-\nary exploration is desired, one dating back to\na chimpanzee-like ancestor, then we need to\nexplain how and why such capacities\nemerged from an ancestral node that lacked\nsuch abilities (75) (Fig. 4).\nThe conceptual-intentional systems of non-\nlinguistic animals. A wide variety of studies\nindicate that nonhuman mammals and birds\nhave rich conceptual representations (76, 77).\nSurprisingly, however, there is a mismatch be-\ntween the conceptual capacities of animals and\nthe communicative content of their vocal and\nvisual signals (78, 79). For example, although a\nwide variety of nonhuman primates have access\nto rich knowledge of who is related to whom, as\nwell as who is dominant and who is subordi-\nnate, their vocalizations only coarsely express\nsuch complexities.\nStudies using classical training approach-\nes as well as methods that tap spontaneous\nabilities reveal that animals acquire and use a\nwide range of abstract concepts, including\ntool, color, geometric relationships, food, and\nnumber (66, 76 – 82). More controversially,\nbut of considerable relevance to intentional\naspects of language and conditions of felici-\ntous use, some studies claim that animals\nhave a theory of mind (83– 85), including a\nsense of self and the ability to represent the\nbeliefs and desires of other group members.\nOn the side of positive support, recent studies\nof chimpanzees suggest that they recognize\nthe perceptual act of seeing as a proxy for the\nmental state of knowing (84, 86, 87). These\nFig. 4. The distribution of imitation in the animal kingdom is patchy. Some animals such as songbirds,\ndolphins, and humans have evolved exceptional abilities to imitate; other animals, such as apes and\nmonkeys, either lack such abilities or have them in a relatively impoverished form. [Illustration: John Yanson]\nS C I E N C E ’ S C O M P A S S\nwww.sciencemag.org SCIENCE VOL 29822 NOVEMBER 2002 1575\nstudies suggest that at least chimpanzees, but\nperhaps no other nonhuman animals, have a\nrudimentary theory of mind. On the side of\nnegative support, other studies suggest that\neven chimpanzees lack a theory of mind,\nfailing, for example, to differentiate between\nignorant and knowledgeable individuals with\nrespect to intentional communication (88,\n89). Because these experiments make use of\ndifferent methods and are based on small\nsample sizes, it is not possible at present to\nderive any firm conclusions about the pres-\nence or absence of mental state attribution in\nanimals. Independently of how this contro-\nversy is resolved, however, the best evidence\nof referential communication in animals\ncomes not from chimpanzees but from a va-\nriety of monkeys and birds, species for which\nthere is no convincing evidence for a theory\nof mind.\nThe classic studies of vervet monkey\nalarm calls (90) have now been joined by\nseveral others, each using comparable meth-\nods, with extensions to different species (ma-\ncaques, Diana monkeys, meerkats, prairie\ndogs, chickens) and different communicative\ncontexts (social relationships, food, inter-\ngroup aggression) (91–97). From these stud-\nies we can derive five key points relevant to\nour analysis of the faculty of language. First,\nindividuals produce acoustically distinctive\ncalls in response to functionally important\ncontexts, including the detection of predators\nand the discovery of food. Second, the acous-\ntic morphology of the signal, although arbi-\ntrary in terms of its association with a partic-\nular context, is sufficient to enable listeners to\nrespond appropriately without requiring any\nother contextual information. Third, the num-\nber of such signals in the repertoire is small,\nrestricted to objects and events experienced\nin the present, with no evidence of creative\nproduction of new sounds for new situations.\nFourth, the acoustic morphology of the calls\nis fixed, appearing early in development, with\nexperience only playing a role in refining the\nrange of objects or events that elicit such\ncalls. Fifth, there is no evidence that calling is\nintentional in the sense of taking into account\nwhat other individuals believe or want.\nEarly interpretations of this work suggest-\ned that when animals vocalize, they are func-\ntionally referring to the objects and events\nthat they have encountered. As such, vervet\nalarm calls and rhesus monkey food calls, to\ntake two examples, were interpreted as word-\nlike, with callers referring to different kinds\nof predators or different kinds of food. More\nrecent discussions have considerably weak-\nened this interpretation, suggesting that if the\nsignal is referential at all, it is in the mind of\nthe listener who can extract information\nabout the signaler’s current context from the\nacoustic structure of the call alone (78, 95).\nDespite this evidence that animals can extract\ninformation from the signal, there are several\nreasons why additional evidence is required\nbefore such signals can be considered as pre-\ncursors for, or homologs of, human words.\nRoughly speaking, we can think of a partic-\nular human language as consisting of words and\ncomputational procedures (“rules”) for con-\nstructing expressions from them. The computa-\ntional system has the recursive property briefly\noutlined earlier, which may be a distinct human\nproperty. However, key aspects of words may\nalso be distinctively human. There are, first of\nall, qualitative differences in scale and mode of\nacquisition, which suggest that quite different\nmechanisms are involved; as pointed out above,\nthere is no evidence for vocal imitation in non-\nhuman primates, and although human children\nmay use domain-general mechanisms to ac-\nquire and recall words (98, 99), the rate at\nwhich children build the lexicon is so massively\ndifferent from nonhuman primates that one\nmust entertain the possibility of an indepen-\ndently evolved mechanism. Further-\nmore, unlike the best animal exam-\nples of putatively referential signals,\nmost of the words of human lan-\nguage are not associated with specif-\nic functions (e.g., warning cries, food\nannouncements) but can be linked to\nvirtually any concept that humans\ncan entertain. Such usages are often\nhighly intricate and detached from\nthe here and now. Even for the sim-\nplest words, there is typically no\nstraightforward word-thing relation-\nship, if “thing” is to be understood in\nmind-independent terms. Without\npursuing the matter here, it appears\nthat many of the elementary proper-\nties of words—including those that\nenter into referentiality—have only\nweak analogs or homologs in natural\nanimal communication systems, with\nonly slightly better evidence from the\ntraining studies with apes and dol-\nphins. Future research must therefore\nprovide stronger support for the pre-\ncursor position, or it must instead\nabandon this hypothesis, arguing that\nthis component of FLB (conceptual-\nintentional) is also uniquely human.\nDiscrete infinity and constraints\non learning. The data summarized thus far,\nalthough far from complete, provide overall\nsupport for the position of continuity between\nhumans and other animals in terms of FLB.\nHowever, we have not yet addressed one\nissue that many regard as lying at the heart of\nlanguage: its capacity for limitless expressive\npower, captured by the notion of discrete\ninfinity. It seems relatively clear, after nearly\na century of intensive research on animal\ncommunication, that no species other than\nhumans has a comparable capacity to recom-\nbine meaningful units into an unlimited vari-\nety of larger structures, each differing sys-\ntematically in meaning. However, little\nprogress has been made in identifying the\nspecific capabilities that are lacking in other\nanimals.\nFig. 5. Human and nonhuman animals exhibit the capacity to compute numerosities, including small precise\nnumber quantification and large approximate number estimation. Humans may be unique, however, in the ability\nto show open-ended, precise quantificational skills with large numbers, including the integer count list. In parallel\nwith the faculty of language, our capacity for number relies on a recursive computation. [Illustration: John Yanson]\nS C I E N C E ’ S C O M P A S S\n22 NOVEMBER 2002 VOL 298SCIENCE www.sciencemag.org1576\nThe astronomical variety of sentences any\nnatural language user can produce and under-\nstand has an important implication for lan-\nguage acquisition, long a core issue in devel-\nopmental psychology. A child is exposed to\nonly a small proportion of the possible sen-\ntences in its language, thus limiting its data-\nbase for constructing a more general version\nof that language in its own mind/brain. This\npoint has logical implications for any system\nthat attempts to acquire a natural language on\nthe basis of limited data. It is immediately\nobvious that given a finite array of data, there\nare infinitely many theories consistent with it\nbut inconsistent with one another. In the\npresent case, there are in principle infinitely\nmany target systems ( potential I-languages)\nconsistent with the data of experience, and\nunless the search space and acquisition mech-\nanisms are constrained, selection among\nthem is impossible. A version of the problem\nhas been formalized by Gold (100) and more\nrecently and rigorously explored by Nowak\nand colleagues (72–75). No known “general\nlearning mechanism” can acquire a natural\nlanguage solely on the basis of positive or\nnegative evidence, and the prospects for find-\ning any such domain-independent device\nseem rather dim. The difficulty of this prob-\nlem leads to the hypothesis that whatever\nsystem is responsible must be biased or con-\nstrained in certain ways. Such constraints\nhave historically been termed “innate dispo-\nsitions,” with those underlying language re-\nferred to as “universal grammar.” Although\nthese particular terms have been forcibly re-\njected by many researchers, and the nature of\nthe particular constraints on human (or ani-\nmal) learning mechanisms is currently unre-\nsolved, the existence of some such con-\nstraints cannot be seriously doubted. On the\nother hand, other constraints in animals must\nhave been overcome at some point in human\nevolution to account for our ability to acquire\nthe unlimited class of generative systems that\nincludes all natural languages. The nature of\nthese latter constraints has recently become\nthe target of empirical work. We focus here\non the nature of number representation and\nrule learning in nonhuman animals and hu-\nman infants, both of which can be investigat-\ned independently of communication and pro-\nvide hints as to the nature of the constraints\non FLN.\nMore than 50 years of research using clas-\nsical training studies demonstrates that ani-\nmals can represent number, with careful con-\ntrols for various important confounds (80). In\nthe typical experiment, a rat or pigeon is\ntrained to press a lever x number of times to\nobtain a food reward. Results show that ani-\nmals can hit the target number to within a\nclosely matched mean, with a standard devi-\nation that increases with magnitude: As the\ntarget number increases, so does variation\naround the mean. These results have led to\nthe idea that animals, including human in-\nfants and adults, can represent number ap-\nproximately as a magnitude with scalar vari-\nability (101, 102). Number discrimination is\nlimited in this system by Weber’s law, with\ngreater discriminability among small num-\nbers than among large numbers (keeping dis-\ntances between pairs constant) and between\nnumbers that are farther apart (e.g., 7 versus\n8 is harder than 7 versus 12). The approxi-\nmate number sense is accompanied by a sec-\nond precise mechanism that is limited to val-\nues less than 4 but accurately distinguishes 1\nfrom 2, 2 from 3, and 3 from 4; this second\nsystem appears to be recruited in the context\nof object tracking and is limited by working\nmemory constraints (103). Of direct rele-\nvance to the current discussion, animals can\nbe trained to understand the meaning of num-\nber words or Arabic numeral symbols. How-\never, these studies reveal striking differences\nin how animals and human children acquire\nthe integer list, and provide further evidence\nthat animals lack the capacity to create open-\nended generative systems.\nBoysen and Matsuzawa have trained\nchimpanzees to map the number of objects\nonto a single Arabic numeral, to correctly\norder such numerals in either an ascending or\ndescending list, and to indicate the sums of\ntwo numerals (104 –106). For example, Boy-\nsen shows that a chimpanzee seeing two or-\nanges placed in one box, and another two\noranges placed in a second box, will pick the\ncorrect sum of four out of a lineup of three\ncards, each with a different Arabic numeral.\nThe chimpanzees’ performance might sug-\ngest that their representation of number is like\nours. Closer inspection of how these chim-\npanzees acquired such competences, howev-\ner, indicates that the format and content of\ntheir number representations differ funda-\nmentally from those of human children. In\nparticular, these chimpanzees required thou-\nsands of training trials, and often years, to\nacquire the integer list up to nine, with no\nevidence of the kind of “aha” experience that\nall human children of approximately 3.5\nyears acquire (107). A human child who has\nacquired the numbers 1, 2, and 3 (and some-\ntimes 4) goes on to acquire all the others; he\nor she grasps the idea that the integer list is\nconstructed on the basis of the successor\nfunction. For the chimpanzees, in contrast,\neach number on the integer list required the\nsame amount of time to learn. In essence,\nalthough the chimpanzees’ understanding of\nArabic numerals is impressive, it parallels\ntheir understanding of other symbols and\ntheir referential properties: The system appar-\nently never takes on the open-ended genera-\ntive property of human language. This limi-\ntation may, however, reveal an interesting\nquirk of the child’s learning environment and\na difference from the training regime of ani-\nmals: Children typically first learn an arbi-\ntrary ordered list of symbols (“1, 2, 3, 4 . . . ”)\nand later learn the precise meaning of such\nwords; apes and parrots, in contrast, were\ntaught the meanings one by one without\nlearning the list. As Carey (103) has argued,\nthis may represent a fundamental difference\nin experience, a hypothesis that could be\ntested by first training animals with an arbi-\ntrary ordered list.\nA second possible limitation on the class\nof learnable structures concerns the kinds of\nstatistical inferences that animals can com-\npute. Early work in computational linguistics\n(108 –110) suggested that we can profitably\nthink about language as a system of rules\nplaced within a hierarchy of increasing com-\nplexity. At the lowest level of the hierarchy\nare rule systems that are limited to local\ndependencies, a subcategory of so-called\n“finite-state grammars.” Despite their attrac-\ntive simplicity, such rule systems are inade-\nquate to capture any human language. Natu-\nral languages go beyond purely local struc-\nture by including a capacity for recursive\nembedding of phrases within phrases, which\ncan lead to statistical regularities that are\nseparated by an arbitrary number of words or\nphrases. Such long-distance, hierarchical re-\nlationships are found in all natural languages\nfor which, at a minimum, a “phrase-structure\ngrammar” is necessary. It is a foundational\nobservation of modern generative linguistics\nthat, to capture a natural language, a grammar\nmust include such capabilities (Fig. 5).\nRecent studies suggest that the capacity to\ncompute transitional probabilities—an exam-\nple of a rule at the lowest level of the hierar-\nchy—might be available to human infants\nand provide a mechanism for segmenting\nwords from a continuous acoustic stream\n(111–113). Specifically, after familiarization\nto a continuous sequence of consonant-vowel\n(CV) syllables, where particular trigrams\n(three CVs in sequence, considered to be\n“words” in this context) have a high proba-\nbility of appearing within the corpus, infants\nare readily able to discriminate these tri-\ngrams from others that are uncommon.\nAlthough this ability may provide a mech-\nanism for word segmentation, it is appar-\nently not a mechanism that evolved unique-\nly in humans or for language: The same\ncomputation is spontaneously available to\nhuman infants for visual sequences and\ntonal melodies (113), as well as to nonhu-\nman primates (cotton-top tamarins) tested\nwith the same methods and stimuli (114 ).\nSimilarly, in the same way that human\ninfants appear capable of computing alge-\nbraic rules that operate over particular CV\nsequences (115), so too can cotton-top\ntamarins (116 ), again demonstrating that\nthe capacity to discover abstract rules at a\nS C I E N C E ’ S C O M P A S S\nwww.sciencemag.org SCIENCE VOL 29822 NOVEMBER 2002 1577\nlocal level is not unique to humans, and\nalmost certainly did not evolve specifically\nfor language.\nFitch and Hauser (117) recently complet-\ned a study comparing finite-state and phrase-\nstructure grammar acquisition in human\nadults and tamarins, using the same subjects\nand methods as the studies above. The\nphrase-structure rule tested was AnBn, where\nA and B were each represented by one of a\nset of eight different CVs. The rule therefore\nspecified both a set of consistent strings (n\nA’s must precede n B’s) and a set of incon-\nsistent strings; the latter consisted of viola-\ntions of order (B tokens precede A tokens) or\nof patterning (alternations of A’s and B’s\nsuch as ABAB). Results showed that human\nadults rapidly learned this rule implicitly,\ndistinguishing consistent and inconsistent\nstrings. Tamarins, in contrast, failed in three\nseparate experiments testing their ability to\nacquire this grammar, but they readily\nmastered a finite-state variant (ABn) imple-\nmented with the same stimuli and testing\nconditions. This suggests that tamarins have a\nlimited capacity to learn the type of long-\ndistance hierarchical dependencies necessary\nto achieve the class of phrase-structure gram-\nmars. If true, this limitation would place se-\nvere restrictions on their capacity to learn any\nnatural human language. It is currently un-\nclear whether this limitation generalizes to\nother animals, and whether it is similarly\nimposed on humans at different stages of\ndevelopment. Nonetheless, such experiments\nprovide an empirical approach to exploring\nkey differences between humans and animals\nrelevant to FLN.\nOur review has stressed the usefulness\nof animal data for theories about humans,\nbut this exchange need not be one-way. As\nthe research program we have sketched\nprogresses, more general principles about\ncognitive evolution may emerge. For exam-\nple, suppose we adopt the conception of\nhypothesis 3, oversimplifying radically,\nthat the interface systems—sensory-motor\nand conceptual-intentional—are given, and\nthe innovation that yielded the faculty of\nlanguage was the evolution of the compu-\ntational system that links them. The com-\nputational system must (i) construct an in-\nfinite array of internal expressions from the\nfinite resources of the conceptual-intention-\nal system, and (ii) provide the means to\nexternalize and interpret them at the senso-\nry-motor end. We may now ask to what\nextent the computational system is optimal,\nmeeting natural conditions of efficient\ncomputation such as minimal search and no\nbacktracking. To the extent that this can be\nestablished, we will be able to go beyond\nthe (extremely difficult, and still distant)\naccomplishment of finding the principles of\nthe faculty of language, to an understanding\nof why the faculty follows these particular\nprinciples and not others. We would then\nunderstand why languages of a certain class\nare attainable, whereas other imaginable\nlanguages are impossible to learn and sus-\ntain. Such progress would not only open the\ndoor to a greatly simplified and empirically\nmore tractable evolutionary approach to the\nfaculty of language, but might also be more\ngenerally applicable to domains beyond\nlanguage in a wide range of species—per-\nhaps especially in the domain of spatial\nnavigation and foraging, where problems of\noptimal search are relevant. For example,\nelegant studies of insects, birds, and pri-\nmates reveal that individuals often search\nfor food by an optimal strategy, one involv-\ning minimal distances, recall of locations\nsearched, and kinds of objects retrieved\n(77, 118, 119). Only after a concerted, mul-\ntidisciplinary attack on the problems of\nlanguage evolution, paralleling 40 years of\noptimal foraging research, will we learn\nwhether such similarities are more than\nsuperficial.\nConclusions\nWe conclude by making three points. First, a\npractical matter: Linguists and biologists,\nalong with researchers in the relevant branch-\nes of psychology and anthropology, can\nmove beyond unproductive theoretical debate\nto a more collaborative, empirically focused\nand comparative research program aimed at\nuncovering both shared (homologous or anal-\nogous) and unique components of the faculty\nof language. Second, although we have ar-\ngued that most if not all of FLB is shared with\nother species, whereas FLN may be unique to\nhumans, this represents a tentative, testable\nhypothesis in need of further empirical inves-\ntigation. Finally, we believe that a compara-\ntive approach is most likely to lead to new\ninsights about both shared and derived fea-\ntures, thereby generating new hypotheses\nconcerning the evolutionary forces that led to\nthe design of the faculty of language. Specif-\nically, although we have said relatively little\nabout the role of natural selection in shaping\nthe design features of FLN, we suggest that\nby considering the possibility that FLN\nevolved for reasons other than language, the\ncomparative door has been opened in a new\nand (we think) exciting way.\nComparative work has generally focused\non animal communication or the capacity to\nacquire a human-created language. If, how-\never, one entertains the hypothesis that recur-\nsion evolved to solve other computational\nproblems such as navigation, number quanti-\nfication, or social relationships, then it is\npossible that other animals have such abili-\nties, but our research efforts have been tar-\ngeted at an overly narrow search space (Fig.\n3). If we find evidence for recursion in ani-\nmals, but in a noncommunicative domain,\nthen we are more likely to pinpoint the mech-\nanisms underlying this ability and the selec-\ntive pressures that led to it. This discovery, in\nturn, would open the door to another suite of\npuzzles: Why did humans, but no other ani-\nmal, take the power of recursion to create an\nopen-ended and limitless system of commu-\nnication? Why does our system of recursion\noperate over a broader range of elements or\ninputs (e.g., numbers, words) than other ani-\nmals? One possibility, consistent with current\nthinking in the cognitive sciences, is that\nrecursion in animals represents a modular\nsystem designed for a particular function\n(e.g., navigation) and impenetrable with re-\nspect to other systems. During evolution, the\nmodular and highly domain-specific system\nof recursion may have become penetrable and\ndomain-general. This opened the way for hu-\nmans, perhaps uniquely, to apply the power\nof recursion to other problems. This change\nfrom domain-specific to domain-general may\nhave been guided by particular selective pres-\nsures, unique to our evolutionary past, or as a\nconsequence (by-product) of other kinds of\nneural reorganization. Either way, these are\ntestable hypotheses, a refrain that highlights\nthe importance of comparative approaches to\nthe faculty of language.\nReferences and Notes\n1. N. Chomsky, Aspects of the Theory of Syntax (MIT\nPress, Cambridge, MA, 1965).\n2. \u0002\u0002\u0002\u0002, Reflections on Language (Pantheon, New\nYork, 1975).\n3. M. D. Hauser, The Evolution of Communication (MIT\nPress, Cambridge, MA, 1996).\n4. R. Jackendoff, Foundations of Language (Oxford\nUniv. Press, New York, 2002).\n5. L. Jenkins, Biolinguistics (Cambridge Univ. Press,\nCambridge, 2000).\n6. E. H. Lenneberg, Biological Foundations of Language\n(Wiley, New York, 1967).\n7. P. Lieberman, The Biology and Evolution of Language\n(Harvard Univ. Press, Cambridge, MA, 1984).\n8. A. Liberman, Speech: A Special Code (MIT Press,\nCambridge, MA, 1996).\n9. W. T. Fitch, Trends Cognit. Sci. 4, 258(2000).\n10. D. L. Cheney, R. M. Seyfarth, How Monkeys See the\nWorld: Inside the Mind of Another Species (Univ. of\nChicago Press, Chicago, 1990).\n11. A. Doupe, P. Kuhl, Annu. Rev. Neurosci. 22, 567\n(1999).\n12. P. Marler, Am. Sci. 58, 669 (1970).\n13. C. Darwin, On the Origin of Species ( John Murray,\nLondon, 1859).\n14. \u0002\u0002\u0002\u0002, The Descent of Man and Selection in Rela-\ntion to Sex ( John Murray, London, 1871).\n15. A. M. Liberman, K. S. Harris, H. S. Hoffman, B. C.\nGriffith, J. Exp. Psychol. 54, 358(1957).\n16. A. M. Liberman, F. S. Cooper, D. P. Shankweiler, M.\nStuddert-Kennedy, Psychol. Rev. 74, 431 (1967).\n17. P. K. Kuhl, J. D. Miller, Science 190, 69 (1975).\n18. P. K. Kuhl, D. M. Padden, Percept. Psychophys. 32,\n542 (1982).\n19. K. R. Kluender, R. Diehl, P. R. Killeen, Science 237,\n1195 (1987).\n20. S. J. Gould, in Evolution, Brain and Behavior: Persis-\ntent Problems, R. B. Masterton, W. Hodos, H. Jerison,\nEds. (Wiley, New York, 1976), pp. 175–179.\n21. W. J. Gehring, Master Control Genes in Development\nand Evolution: The Homeobox Story (Yale Univ.\nPress, New Haven, CT, 1998).\n22. R. M. Seyfarth, D. L. Cheney, in The Design of Animal\nS C I E N C E ’ S C O M P A S S\n22 NOVEMBER 2002 VOL 298SCIENCE www.sciencemag.org1578\nCommunication, M. D. Hauser, M. Konishi, Eds. (MIT\nPress, Cambridge, MA, 1999), pp. 391– 418.\n23. P. Marler, J. Neurobiol. 33, 1 (1997).\n24. F. Nottebohm, in The Design of Animal Communi-\ncation, M. D. Hauser, M. Konishi, Eds. (MIT Press,\nCambridge, MA, 1999), pp. 63–110.\n25. L. A. Petitto, P. Marentette, Science 251, 1483\n(1991).\n26. K. R. Kluender, A. J. Lotto, L. L. Holt, in Listening to\nSpeech: An Auditory Perspective, S. Greenberg, W.\nAinsworth, Eds. (Erlbaum, Mahwah, NJ, in press).\n27. R. Jackendoff, Trends Cognit. Sci. 3, 272 (1999).\n28. S. Pinker, P. Bloom, Behav. Brain Sci. 13, 707 (1990).\n29. R. Dawkins, The Blind Watchmaker (Norton, New\nYork, 1986).\n30. D. Bickerton, Species and Language (Univ. of Chica-\ngo Press, Chicago, 1990).\n31. R. Dunbar, Grooming, Gossip and the Evolution of\nLanguage (Harvard Univ. Press, Cambridge, MA,\n1996).\n32. D. Kimura, Neuromotor Mechanisms in Human Com-\nmunication (Oxford Univ. Press, Oxford, 1993).\n33. N. Chomsky, Rules and Representations (Columbia\nUniv. Press, New York, 1980).\n34. M. D. Hauser, in Language, Brain, and Cognitive\nDevelopment: Essays in Honor of Jacques Mehler, E.\nDupoux, Ed. (MIT Press, Cambridge, MA, 2001), pp.\n417– 434.\n35. W. Enard et al., Nature 418, 869 (2002).\n36. J. Maynard Smith, E. Szathmary, The Major Transi-\ntions of Evolution (Freeman, Oxford, 1995).\n37. L. Barrett, R. Dunbar, J. Lycett, Human Evolutionary\nPsychology (Princeton Univ. Press, Princeton, NJ,\n2002).\n38. D. Buss, Evolutionary Psychology (Allyn & Bacon,\nLondon, 1999).\n39. S. J. Gould, R. C. Lewontin, Proc. R. Soc. London 205,\n281 (1979).\n40. G. C. Williams, Adaptation and Natural Selection\n(Princeton Univ. Press, Princeton, NJ, 1966).\n41. N. Chomsky, The Minimalist Program (MIT Press,\nCambridge, MA, 1995).\n42. C. Collins, Local Economy (MIT Press, Cambridge,\nMA, 1997).\n43. S. D. Epstein, N. Hornstein, Working Minimalism\n(MIT Press, Cambridge, MA, 1999).\n44. L. Haegeman, Introduction to Government & Binding\nTheory (Blackwell, Oxford, 1991).\n45. J. R. Hurford, M. Studdert-Kennedy, C. Knight, Eds.,\nApproaches to the Evolution of Language: Social and\nCognitive Bases (Cambridge Univ. Press, Cambridge,\n1998).\n46. A. Wray, Ed., The Transition to Language (Oxford\nUniv. Press, Oxford, 2002).\n47. A. Liberman, D. H. Whalen, Trends Cognit. Sci. 4,\n187 (2000).\n48. P. Lieberman, Uniquely Human (Harvard Univ. Press,\nCambridge, MA, 1991).\n49. R. J. Dooling, C. T. Best, S. D. Brown, J. Acoust. Soc.\nAm. 97, 1839 (1995).\n50. J. M. Sinnott, C. H. Brown, J. Acoust. Soc. Am. 102,\n588 (1997).\n51. M. S. Sommers, D. B. Moody, C. A. Prosen, W. C.\nStebbins, J. Acoust. Soc. Am. 91, 3499 (1992).\n52. K. R. Kluender, A. J. Lotto, L. L. Holt, S. L. Bloedel, J.\nAcoust. Soc. Am. 104, 3568(1998).\n53. F. Ramus, M. D. Hauser, C. T. Miller, D. Morris, J.\nMehler, Science 288, 349 (2000).\n54. W. T. Fitch, J. Acoust. Soc. Am. 102, 1213 (1997).\n55. \u0002\u0002\u0002\u0002, J. P. Kelley, Ethology 106, 559 (2000).\n56. M. D. Hauser, C. S. Evans, P. Marler, Anim. Behav. 45,\n423 (1993).\n57. M. J. Owren, R. Bernacki, J. Acoust. Soc. Am. 83,\n1927 (1988).\n58. M. J. Owren, J. Comp. Psychol. 104, 20 (1990).\n59. D. Rendall, M. J. Owren, P. S. Rodman, J. Acoust. Soc.\nAm. 103, 602 (1998).\n60. V. E. Negus, The Comparative Anatomy and Physi-\nology of the Larynx (Hafner, New York, 1949).\n61. W. T. Fitch, D. Reby, Proc. R. Soc. London Ser. B 268,\n1669 (2001).\n62. J. D. Trout, Psychol. Rev. 108, 523 (2000).\n63. M. Donald, in Approaches to the Evolution of Lan-\nguage: Social and Cognitive Bases, J. R. Hurford, M.\nStuddert-Kennedy, C. Knight, Eds. (Cambridge Univ.\nPress, Cambridge, 1998), pp. 44 – 67.\n64. M. Studdert-Kennedy, Hum. Neurobiol. 2, 191\n(1983).\n65. V. M. Janik, P. J. B. Slater, Anim. Behav. 60, 1 (2000).\n66. M. Tomasello, J. Call, Primate Cognition (Oxford\nUniv. Press, Oxford, 1997).\n67. G. Rizzolatti, M. A. Arbib, Trends Cognit. Sci. 2, 18 8\n(1998).\n68. G. Rizzolatti, L. Fadiga, L. Fogassi, V. Gallese, Arch.\nItal. Biol. 137, 169 (1999).\n69. T. Chaminade, A. N. Meltzoff, J. Decety, Neuroimage\n15, 318(2002).\n70. J. Decety, T. Chaminade, J. Grezes, A. N. Meltzoff,\nNeuroimage 15, 265 (2002).\n71. M. Iacoboni et al., Science 286, 2526 (1999).\n72. M. A. Nowak, N. L. Komarova, P. Niyogi, Science\n291, 114 (2001).\n73. M. A. Nowak, N. L. Komarova, Trends Cognit. Sci. 5,\n288 (2001).\n74. M. A. Nowak, J. B. Plotkin, V. A. Jansen, Nature 404,\n495 (2000).\n75. M. A. Nowak, N. L. Komarova, P. Niyogi, Nature 417,\n611 (2002).\n76. C. M. Heyes, F. Huber, The Evolution of Cognition\n(MIT Press, Cambridge, MA, 2000).\n77. S. Shettleworth, Cognition, Evolution and Behavior\n(Oxford Univ. Press, New York, 1998).\n78. D. L. Cheney, R. M. Seyfarth, in The Tanner Lectures\non Human Values, G. Peterson, Ed. (Univ. of Utah\nPress, Salt Lake City, UT, 1998), pp. 173–210.\n79. M. D. Hauser, Wild Minds: What Animals Really Think\n(Holt, New York, 2000).\n80. C. R. Gallistel, The Organization of Learning (MIT\nPress, Cambridge, MA, 1990).\n81. I. M. Pepperberg, The Alex Studies (Harvard Univ.\nPress, Cambridge, MA, 2000).\n82. D. Premack, Gavagai! or the Future History of the\nAnimal Language Controversy (MIT Press, Cam-\nbridge, MA, 1986).\n83. \u0002\u0002\u0002\u0002, G. Woodruff, Behav. Brain Sci. 4, 515\n(1978).\n84. D. Premack, A. Premack, Original Intelligence\n(McGraw-Hill, New York, 2002).\n85. D. C. Dennett, Behav. Brain Sci. 6, 343 (1983).\n86. B. Hare, J. Call, B. Agnetta, M. Tomasello, Anim.\nBehav. 59, 771 (2000).\n87. B. Hare, J. Call, M. Tomasello, Anim. Behav. 61, 139\n(2001).\n88. C. M. Heyes, Behav. Brain Sci. 21, 101 (1998).\n89. D. J. Povinelli, T. J. Eddy, Monogr. Soc. Res. Child\nDev. 247 (1996).\n90. R. M. Seyfarth, D. L. Cheney, P. Marler, Science 210,\n801 (1980).\n91. W. P. G. Dittus, Anim. Behav. 32, 470 (1984).\n92. C. S. Evans, P. Marler, in Comparative Approaches to\nCognitive Science, H. Roitblatt, Ed. (MIT Press, Cam-\nbridge, MA, 1995), pp. 241–282.\n93. J. Fischer, Anim. Behav. 55, 799 (1998).\n94. S. Gouzoules, H. Gouzoules, P. Marler, Anim. Behav.\n32, 182 (1984).\n95. M. D. Hauser, Anim. Behav. 55, 1647 (1998).\n96. C. N. Slobodchikoff, J. Kiriazis, C. Fischer, E. Creef,\nAnim. Behav. 42, 713 (1991).\n97. K. Zuberbuhler, D. L. Cheney, R. M. Seyfarth,\nJ. Comp. Psychol. 113, 33 (1999).\n98. P. Bloom, L. Markson, Trends Cognit. Sci. 2, 67\n(1998).\n99. P. Bloom, How Children Learn the Meanings of\nWords (MIT Press, Cambridge, MA, 2000).\n100. E. M. Gold, Inform. Control 10, 447 (1967).\n101. S. Dehaene, The Number Sense (Oxford Univ. Press,\nOxford, 1997).\n102. C. R. Gallistel, R. Gelman, Trends Cognit. Sci. 4, 59\n(2000).\n103. S. Carey, Mind Lang. 16, 37 (2001).\n104. S. T. Boysen, G. G. Bernston, J. Comp. Psychol. 103,\n23 (1989).\n105. N. Kawai, T. Matsuzawa, Nature 403, 39 (2000).\n106. T. Matsuzawa, Nature 315, 57 (1985).\n107. K. Wynn, Cognit. Psychol. 24, 220 (1992).\n108. N. Chomsky, Logical Structure of Linguistic Theory/\nExcerpted Manuscript (Plenum, New York, 1975).\n109. \u0002\u0002\u0002\u0002, IRE Trans. Inform. Theory 2 (no. 2), 113\n(1956).\n110. \u0002\u0002\u0002\u0002, G. Miller, Inform. Control 1, 91 (1958).\n111. Z. S. Harris, Language 31, 190 (1955).\n112. J. R. Saffran, R. N. Aslin, E. L. Newport, Science 274,\n1926 (1996).\n113. J. Saffran, E. Johnson, R. N. Aslin, E. Newport, Cog-\nnition 70, 27 (1999).\n114. M. D. Hauser, E. L. Newport, R. N. Aslin, Cognition\n78, B53 (2001).\n115. G. Marcus, S. Vijayan, S. Bandi Rao, P. M. Vishton,\nScience 283, 77 (1999).\n116. M. D. Hauser, D. Weiss, G. Marcus, Cognition 86,\nB15 (2002).\n117. W. T. Fitch, M. D. Hauser, in preparation.\n118. N. S. Clayton, A. Dickinson, Nature 395, 272 (1998).\n119. C. R. Gallistel, A. E. Cramer, J. Exp. Biol. 199, 211\n(1996).\n120. P. Kuhl, Percept. Psychophys. 50, 93 (1991).\n121. P. F. MacNeilage, Behav. Brain Sci. 21, 499(1998).\n122. M. Studdert-Kennedy, in Approaches to the Evolu-\ntion of Language: Social and Cognitive Bases, J. R.\nHurford, M. Studdert-Kennedy, C. Knight, Eds.\n(Cambridge Univ. Press, Cambridge, 1998), pp. 202–\n221.\n123. H. McGurk, J. MacDonald, Nature 264, 746 (1976).\n124. L. R. Santos, G. M. Sulkowski, G. M. Spaepen, M. D.\nHauser, Cognition 83, 241 (2002).\n125. G. Gergerly, H. Bekkering, I. Kiraly, Nature 415, 755\n(2002).\n126. A. N. Meltzoff, M. K. Moore, Infant Behav. Dev. 17,\n83 (1994).\n127. A. Whiten, D. Custance, in Social Learning in Ani-\nmals: The Roots of Culture, C. M. Heyes, J. B. G.\nGalef, Eds. (Academic Press, San Diego, CA, 1996),\npp. 291–318.\n128. P. Marler, S. Karakashian, M. Gyger, in Cognitive\nEthology: The Minds of Other Animals, C. Ristau, Ed.\n(Erlbaum, Hillsdale, NJ, 1991), pp. 135–186.\n129. H. S. Terrace, L. K. Son, E. M. Brannon, Psychol. Sci.,\nin press.\n130. L. M. Herman, D. G. Richards, J. P. Wolz, Cognition\n16, 129 (1984).\n131. E. S. Savage-Rumbaugh et al., Monogr. Soc. Res.\nChild Dev. 58 (1993).\n132. E. M. Brannon, H. S. Terrace, Science 282, 746\n(1998).\n133. F. Lerdahl, R. Jackendoff, A Generative Theory of\nTonal Music (MIT Press, Cambridge, MA, 1983).\n134. N. Wallin, B. Merker, S. D. Brown, The Origins of\nMusic (MIT Press, Cambridge, MA, 2000).\n135. R. Zatorre, I. Peretz, The Biological Foundations of\nMusic (National Academy Press, New York,\n2000).\n136. For comments on an earlier draft of the manuscript,\nwe thank D. Cheney, R. Jackendoff, L. Jenkins, M.\nNowak, M. Piatelli-Palmerini, S. Pinker, and R.\nSeyfarth.\nS C I E N C E ’ S C O M P A S S\nwww.sciencemag.org SCIENCE VOL 29822 NOVEMBER 2002 1579", "affiliations": [{"country": "United States", "discipline": "Psychology", "university": "Harvard University"}, {"country": "United States", "discipline": "Linguistics", "university": "Massachusetts Institute of Technology"}], "species_categories": [], "specialized_species": [], "computational_stages": [], "linguistic_features": ["Recursion", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.887501", "updated_at": "2026-01-13T16:13:18.264630", "committed_at": "2026-01-13T14:07:13.691442"}
{"id": "fd2be71a-9ed9-4fc9-b6f2-1cc40a3db9fa", "title": "Fast and accurate annotation of acoustic signals with deep neural networks", "authors": ["Steinfath, Elsa", "Palacios-Munoz, Adrian", "Rottsch{\\\"a}fer, Julian R", "Yuezak, Deniz", "Clemens, Jan"], "year": "2021", "journal": "Elife", "abstract": "", "doi": "", "analysis_notes": "*For correspondence:\nclemensjan@gmail.com\nCompeting interests: The\nauthors declare that no\ncompeting interests exist.\nFunding: See page 20\nReceived: 26 March 2021\nPreprinted: 29 March 2021\nAccepted: 04 October 2021\nPublished: 01 November 2021\nReviewing editor: Ronald L\nCalabrese, Emory University,\nUnited States\nCopyright Steinfath et al. This\narticle is distributed under the\nterms of the Creative Commons\nAttribution License, which\npermits unrestricted use and\nredistribution provided that the\noriginal author and source are\ncredited.\nFast and accurate annotation of acoustic\nsignals with deep neural networks\nElsa Steinfath1,2, Adrian Palacios-Mun˜ oz1,2, Julian R Rottscha¨fer1,2\n,\nDeniz Yuezak1,2, Jan Clemens1,3*\n1European Neuroscience Institute - A Joint Initiative of the University Medical\nCenter Go¨ttingen and the Max-Planck-Society, Go¨ttingen, Germany; 2\nInternational\nMax Planck Research School and Go¨ttingen Graduate School for Neurosciences,\nBiophysics, and Molecular Biosciences (GGNB) at the University of Go¨ttingen,\nGo¨ttingen, Germany; 3Bernstein Center for Computational Neuroscience,\nGo¨ttingen, Germany\nAbstract Acoustic signals serve communication within and across species throughout the animal\nkingdom. Studying the genetics, evolution, and neurobiology of acoustic communication requires\nannotating acoustic signals: segmenting and identifying individual acoustic elements like syllables\nor sound pulses. To be useful, annotations need to be accurate, robust to noise, and fast.\nWe here introduce DeepAudioSegmenter (DAS), a method that annotates acoustic signals across\nspecies based on a deep-learning derived hierarchical presentation of sound. We demonstrate the\naccuracy, robustness, and speed of DAS using acoustic signals with diverse characteristics from\ninsects, birds, and mammals. DAS comes with a graphical user interface for annotating song,\ntraining the network, and for generating and proofreading annotations. The method can be trained\nto annotate signals from new species with little manual annotation and can be combined with\nunsupervised methods to discover novel signal types. DAS annotates song with high throughput\nand low latency for experimental interventions in realtime. Overall, DAS is a universal, versatile, and\naccessible tool for annotating acoustic communication signals.\nIntroduction\nAnimals produce sounds to foster group cohesion (Haack et al., 1983; Janik and Slater, 1998;\nChaverri et al., 2013), to signal the presence of food, friend, or foe (Ca¨sar et al., 2013; Clay et al.,\n2012), and to find and evaluate mating partners (Baker et al., 2019; Behr and von Helversen,\n2004; Holy and Guo, 2005; Sangiamo et al., 2020). Studying acoustic communication not only provides insight into social interactions within and across species; it can also reveal the mechanisms driving complex behaviors: The genetics and evolution of signal production and recognition (Ding et al.,\n2016), the genes and circuits driving song learning (Kollmorgen et al., 2020), or the fast and precise sensorimotor transformations involved in vocal interactions (Coen et al., 2016; Cator et al.,\n2009; Fortune et al., 2011; Okobi et al., 2019). The first step in many studies of acoustic communication is song annotation: the segmentation and labeling of individual elements in a recording.\nAcoustic signals are diverse and range from the repetitive long-distance calling songs of crickets,\ngrasshoppers, and anurans (Gerhardt and Huber, 2002), the dynamic and context-specific courtship\nsongs of vinegar flies or rodents (Coen et al., 2014; Clemens et al., 2018; Neunuebel et al., 2015;\nSangiamo et al., 2020), to the complex vocalizations produced by some birds and primates\n(Lipkind et al., 2013; Weiss et al., 2014; Landman et al., 2020).\nThis diversity in signal structure has spawned a zoo of annotation tools (Arthur et al., 2013;\nCoffey et al., 2019; Tachibana et al., 2020; Goffinet et al., 2021; Koumura and Okanoya, 2016;\nCohen et al., 2020), but existing methods still face challenges: First, assessing vocal repertoires and\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 1 of 25\nTOOLS AND RESOURCES\ntheir relation to behavioral and neural dynamics (Clemens et al., 2018; Coffey et al., 2019;\nNeunuebel et al., 2015; Fortune et al., 2011; Okobi et al., 2019) requires annotations to be complete and temporally precise even at low signal levels, but annotation can fail when signals are weak\n(Coffey et al., 2019; Stern et al., 2017). Second, analyses of large datasets and experimental interventions during behavior (Fortune et al., 2011; Okobi et al., 2019; Bath et al., 2014; Tschida and\nMooney, 2012; Stowers et al., 2017) need annotations to be fast, but existing methods are often\nslow. Last, annotation methods should be flexible and adaptable (Ding et al., 2016; Ding et al.,\n2019; Clemens et al., 2018; Clemens and Hennig, 2013), but existing methods often work only for\nrestricted types of signals or adapting them to new signals requires tedious manual tuning\n(Clemens et al., 2018).\nIn brief, an accurate, fast, and flexible framework for annotating song across species is missing. A\ngeneral framework would not only improve upon existing methods but would also facilitate the\nstudy of species for which automated methods do not yet exist. Deep neural networks have\nemerged as powerful and flexible tools for solving data annotation tasks relevant for neuroscience\nsuch as object recognition, pose tracking, or speech recognition (Krizhevsky et al., 2012;\nGraves and Jaitly, 2014; Mathis et al., 2018; Pereira et al., 2019; Graving et al., 2019). These\nmethods are not only fast and accurate but also easily adapted to novel signals by non-experts since\nthey only require annotated examples for learning. Recently, deep neural networks have also been\nused for annotating animal vocalizations (Oikarinen et al., 2019; Coffey et al., 2019; Cohen et al.,\n2020; Sainburg et al., 2020; Arthur et al., 2021; Goffinet et al., 2021).\nWe here present a new deep-learning-based framework for annotating acoustic signals, called\nDeep Audio Segmenter (DAS). We test the framework on a diverse set of recordings from insects,\nbirds, and mammals, and show that DAS annotates song in single- and multi-channel recordings\nwith high accuracy. The framework produces annotations with low latency on standard PCs and is\ntherefore ideally suited for closed-loop applications. Small-to-moderate amounts of manual annotations suffice for adapting the method to a new species and annotation work can be simplified by\ncombining DAS with unsupervised methods. We provide DAS as an open-source software package\nwith a graphical user interface for manually annotating audio, training the network, and inferring and\nproofreading annotations. Integration into existing frameworks for signal analysis or experimental\ncontrol is possible using a programmatic interface. The code and documentation for DAS are available at https://janclemenslab.org/das/.\nResults\nArchitecture and working principle of DAS\nAcoustic signals are defined by features on multiple timescales—the fast harmonic oscillations of the\nsound carrier (<10 ms), modulations of amplitude (AM) and frequency (FM) (10–100 ms), and the\nsequencing of different AM and FM patterns into bouts, syllables, or phrases (10–1000 ms). These\npatterns are typically made explicit using a hand-tuned pre-processing step based on time-resolved\nFourier or wavelet transforms (Arthur et al., 2013; Van Segbroeck et al., 2017; Coffey et al.,\n2019; Oikarinen et al., 2019; Cohen et al., 2020). Most deep-learning-based methods then treat\nthis pre-defined spectrogram as an image and use methods derived from computer vision to extract\nthe AM and FM features relevant for annotation (Oikarinen et al., 2019; Coffey et al., 2019;\nCohen et al., 2020). Recurrent units are sometimes used to track the sound features over time\n(Cohen et al., 2020). This approach can produce accurate annotations but has drawbacks: First, the\nspectrogram constitutes a strong and proven pre-processing step, but it is unsuitable for some signal types, like short pulsatile signals. Second, the pre-processing transform is typically tuned by hand\nand may therefore require expert knowledge for it to produce optimal results. Lastly, the recurrent\nunits used in some methods (Cohen et al., 2020) excel at combining information over time to provide the context information necessary to annotate spectrally complex signals, but they can be hard\nto train and slow to run (Bai et al., 2018).\nDAS solves these limitations in three ways: First, the pre-processing step is optional. This makes\nDAS more flexible, since signals for which a time-resolved Fourier transform is not appropriate—for\ninstance, short pulsatile signals—can now also be processed. Second, the optional preprocessing\nstep is integrated and optimized with the rest of the network. This removes the need to hand-tune\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 2 of 25\nTools and resources Neuroscience\nthis step and allows the network to learn a preprocessing that deviates from a time-resolved Fourier\nor wavelet transform if beneficial (Choi et al., 2017). Integrating the preprocessing into the network\nalso increases inference speed due to the efficient implementation and hardware acceleration of\ndeep-learning frameworks. Third and last, DAS learns a task-specific representation of sound features using temporal convolutional networks (TCNs) (Bai et al., 2018; van den Oord et al., 2016;\nGuirguis et al., 2021; Figure 1—figure supplement 1A–E). At the core of TCNs are so-called\ndilated convolutions (Yu and Koltun, 2016). In standard convolutions, short templates slide over the\nsignal and return the similarity with the signal at every time point. In dilated convolutions, these templates have gaps, allowing to analyze features on longer timescales without requiring more parameters to specify the template. Stacking dilated convolutions with growing gap sizes results in a\nhierarchical, multi-scale representation of sound features, which is ideally suited for the hierarchical\nand harmonic structure of animal vocalizations.\nThe output of the deep neural network in DAS is a set of confidence scores for each audio sample, corresponding to the probability of each song type (Figure 1C). Annotation labels for the different song types are mutually exclusive and are produced by comparing the confidence score to a\nthreshold or by choosing the most probable song type. Brief gaps in the annotations are closed and\nshort spurious detections are removed to smoothen the annotation. For song types that are\ndescribed as events, like the pulses in fly song (Figure 1A), the event times are extracted as local\nmaxima that exceed a confidence threshold.\nDAS accurately annotates song from a diverse range of species\nFly courtship song\nWe first tested DAS on the courtship song of Drosophila melanogaster, which consists of two major\nmodes (Figure 1A): The sine song, which corresponds to sustained oscillations with a species-specific carrier frequency (150 Hz), and two types of pulse song, which consists of trains of short (5–10\nms) pulses with carrier frequencies between 180 and 500 Hz, produced with a species-specific interval (35–45 ms in D. melanogaster). Males dynamically choose the song modes based on sensory\nfeedback from the female (Coen et al., 2014; Clemens et al., 2018; Calhoun et al., 2019). Despite\nthe relative simplicity of the individual song elements, an accurate annotation of fly song is challenging because of low signal-to-noise ratio (SNR): The song attenuates rapidly with distance (BennetClark, 1998) and is highly directional (Morley et al., 2018), which can lead to weak signals if the\nmale is far from the microphone (Figure 1A). Moreover, the interactions between the flies introduce\npulsatile noise and complicate the accurate and complete annotation of the pulse song.\nWe first trained DAS to detect the pulse and the sine song recorded using a single microphone\n(data from Stern, 2014) and compared the performance of DAS to that of the current state-of-theart in fly song segmentation, FlySongSegmenter (FSS) (Arthur et al., 2013; Coen et al., 2014;\nClemens et al., 2018). Annotation performance was quantified using precision, the fraction of correct detections, and recall, the fraction of true song that is detected (Figure 1E,J, Figure 1—figure\nsupplement 1F,G). We counted detected pulses within 10 ms of a true pulse as correct detections.\nTen ms corresponds to 1/4th of the typical interval between pulses in a train and results are robust\nto the choice of this value (Figure 1—figure supplement 2A). DAS detects pulses with a high precision of 97% - only 3% of all detected pulses are false detections - and a high recall of 96% - it misses\nonly 4% of all pulses. This is a substantial improvement in recall over FSS, which has slightly higher\nprecision (99%) but misses 13% of all pulses (87% recall) (Figure 1D,E). In DAS, the balance between\nprecision and recall can be controlled via the confidence threshold, which corresponds to the minimal confidence required for labeling a pulse (Figure 1C): Lowering this threshold from 0.7 to 0.5\nyields a recall of 99% for pulse song with a modest reduction in precision to 95%. The performance\ngain of DAS over FSS for pulse stems from better recall at high frequencies (>400 Hz) and low SNR\n(Figure 1G,H). To assess DAS performance for sine song, we evaluated the sample-wise precision\nand recall. DAS has similar precision to FSS (92% vs 91%) but higher recall (98% vs. 91%) (Figure 1I,\nJ). Recall is higher in particular for short sine songs (<100 ms) and at low SNR (<1.0) (Figure 1L,M).\nThe performance boost for pulse and sine arises because DAS exploits context information, similar\nto how humans annotate song: For instance, DAS discriminates soft song pulses from pulsatile noise\nbased on the pulse shape but also because song pulses occur in regular trains while noise pulses do\nnot (Figure 1—figure supplement 2C). A comparison of DAS’ performance to that of human\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 3 of 25\nTools and resources Neuroscience\n0.1 s\nFrequency [Hz]\n0\n1\nConfidence\nDAS\nManual\nD\nI\nE\nPrecision [%]\nRecall [%]\nJ\n0 2 4\n0.0\n1.6\nPDF\n0.8\nF\n0 10 20 30 40\nTemporal error [ms]\n0.00\n0.03\n0.06 K\n200 400\nCarrier frequency [Hz]\n0\n50\n100\nRecall [%]\nG\n4 16\nPulse SNR\nH\nDAS\nFSS\nPulse\n500 1000 1500\nDuration [ms]\n0\n50\n100\nRecall [%]\nL\n1/2 2\nSine SNR\nM\nDAS\nFSS\nSine\nA\nTemporal error [ms]\nC\nRecall [%]\nPDF\nNo pulse Pulse\nNo pulse\nPulse\n0\n100\nNo sine Sine\nManual\nNo sine\nSine DAS\n0\n100\n%\n%\n70 80 90 100\n70\n80\n90\nDAS\nFSS\n70 80 90 100\n70\n80\n90\n100\nDAS\nFSS\n5066\n17\n21\n535\n94.8\n1.3\n0.4\n15.9\nConfidence\nscores\nB Raw audio\n100\nManual Precision [%]\nDAS\n0\n200\n400\n600\n-50\n0\ndB\n1\nHuman\nHuman\nFigure 1. DAS performance for fly song. (A) Fly song (black, top) with manual annotations of sine (blue) and pulse (red) song. The spectrogram (bottom)\nshows the signal’s frequency content over time (see color bar). (B) DAS builds a hierarchical presentation of song features relevant for annotation using\na deep neural network. The network consists of three TCN blocks, which extract song features at multiple timescales. The output of the network is a\nconfidence score for each sample and song type. (C) Confidence scores (top) for sine (blue) and pulse (red) for the signal in A. The confidence is\ntransformed into annotation labels (bottom) based on a confidence threshold (0.5 for sine, 0.7 for pulse). Ground truth (bottom) from manual\nannotations shown for comparison. (D) Confusion matrix for pulse from the test data set. Color indicates the percentage (see color bar) and text labels\nindicate the number of pulses for each quadrant. All confusion matrices are normalized such that columns sum to 100%. The concentration of values\nalong the diagonal indicates high annotation performance. (E) Precision-recall curve for pulse depicts the performance characteristics of DAS for\ndifferent confidence thresholds (from 0 to 1, black arrow points in the direction of increasing threshold). Recall decreases and precision increases with\nthe threshold. The closer the curve to the upper and right border, the better. The red circle corresponds to the performance of DAS for a threshold of\n0.7. The black circle depicts the performance of FlySongSegmenter (FSS) and gray circles the performance of two human annotators. (F) Probability\ndensity function of temporal errors for all detected pulses (red shaded area), computed as the distance between each pulse annotated by DAS and the\nnearest manually annotated pulse. Lines depict the median temporal error for DAS (red line, 0.3 ms) and FSS (gray line, 0.1 ms). (G, H) Recall of DAS\n(red line) and FSS (gray line) as a function of the pulse carrier frequency (G) and signal-to-noise ratio (SNR) (H). Red shaded areas show the distributions\nof carrier frequencies (G) and SNRs (H) for all pulses. DAS outperforms FSS for all carrier frequencies and SNRs. (I) Same as in D but for sine. Color\nindicates the percentage (see color bar) and text labels indicate seconds of sine for each quadrant. (J) Same as in E but for sine. The blue circle depicts\nthe performance for the confidence threshold of 0.5. (K) Distribution of temporal errors for all detected sine on- and offsets. Median temporal error is\n12 ms for DAS (blue line) and 22 ms for FSS (gray line). (L, M) Recall for DAS (blue line) and FSS (gray line) as a function of sine duration (L) and SNR (M).\nBlue-shaded areas show the distributions of durations and SNRs for all sine songs. DAS outperforms FSS for all durations and SNRs.\nThe online version of this article includes the following figure supplement(s) for figure 1:\nFigure supplement 1. DAS architecture and evaluation.\nFigure supplement 2. Performance and the role of context for annotating fly pulse song.\nFigure supplement 3. Performance for multi-channel recordings of fly courtship song.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 4 of 25\nTools and resources Neuroscience\nannotators reveals that our methods exceeds human-level performance for pulse and sine\n(Figure 1E,J, Table 1).\nTemporally precise annotations are crucial, for instance when mapping sensorimotor transformations based on the timing of behavioral or neuronal responses relative to individual song elements\n(Coen et al., 2014; Srivastava et al., 2017; Long and Fee, 2008; Benichov and Vallentin, 2020).\nWe therefore quantified the temporal error of the annotations produced by DAS. For pulse song,\nthe temporal error was taken as the distance of each pulse annotated by DAS to the nearest true\npulse. The median temporal error for pulse is 0.3 ms which is negligible compared to the average\nduration of a pulse (5–10 ms) or of a pulse interval (35–45 ms) (Deutsch et al., 2019). For sine song,\nthe median temporal error for on- and offsets was 12 ms, which is almost half of that of FSS (22 ms).\nSine song can have low SNR (Figure 1M) and fades in and out, making the precise identification of\nsine song boundaries difficult even for experienced manual annotators (see Figure 1A,C).\nRecording song during naturalistic interactions in large behavioral chambers often requires multiple microphones (Coen et al., 2014; Neunuebel et al., 2015). To demonstrate that DAS can process\nmulti-channel audio, we trained DAS to annotate recordings from a chamber tiled with nine microphones (Coen et al., 2014; Figure 1—figure supplement 3, Figure 1—figure supplement 1B).\nDAS processes multi-channel audio by using filters that take into account information from all channels simultaneously. As is the case for existing methods (Arthur et al., 2013), we achieved maximal\nperformance by training separate networks for the pulse and for the sine song (Table 2). In multichannel recordings, DAS annotates pulse song with 98% precision and 94% recall, and sine song\nwith 97% precision and 93% recall, and matches the performance of FSS (FSS pulse precision/recall\n99/92%, sine 95/93%) (Figure 1—figure supplement 3D–L). Annotations of multi-channel audio\nhave high temporal precision for pulse (DAS 0.3 ms, FSS 0.1 ms) and sine (DAS 8 ms, FSS 15 ms)\n(Figure 1—figure supplement 3E,J). Overall, DAS performs better or as well as the current state-ofthe-art method for annotating single and multi-channel recordings of fly song.\nMouse ultrasonic vocalizations\nMice produce ultrasonic vocalizations (USVs) in diverse social contexts ranging from courtship to\naggression (Sangiamo et al., 2020; Warren et al., 2020; Neunuebel et al., 2015). We tested DAS\nusing audio from an intruder assay, in which an anesthetized female was put into the home cage and\nthe USVs produced by a resident female or male were recorded (Ivanenko et al., 2020). The female\nUSVs from this assay typically consist of pure tones with weak harmonics and smooth frequency\nmodulations that are often interrupted by frequency steps (Figure 2A,B). The male USVs are similar\nbut also contain complex frequency modulations not produced by the females in this assay\n(Figure 2C,D). Recording noise from animal movement and interaction as well as the frequency\nsteps often challenge spectral threshold-based annotation methods and tend to produce false positive syllables (Tachibana et al., 2020; Coffey et al., 2019). Moreover, weak signals often lead to\nmissed syllables or imprecisely delimited syllables. We first trained and tested DAS on recordings of\na female mouse interacting with an anesthetized female intruder (Figure 2A). DAS annotates the\nfemale USVs with excellent precision (98%) and recall (99%) (Figure 2E) and low median temporal\nerror (0.3 ms) (Figure 2F). DAS is robust to noise: Even for weak signals (SNR 1/16) the recall is 90%\n(Figure 2G). These performance values are on par with that of methods specialized to annotate\nUSVs (Tachibana et al., 2020; Coffey et al., 2019; Van Segbroeck et al., 2017) (see Table 3). USVs\nof female and male residents have similar characteristics (Figure 2A,B) and the female-trained DAS\nnetwork also accurately annotated the male vocalizations (Figure 2H). Notably, even the male\nTable 1. Comparison to human annotators for fly song.\nSee also Figure 1E,J.\nAnnotator Sine recall [%] Sine precision [%] Pulse recall [%] Pulse precision [%]\nHuman A 89 98 99 93\nHuman B 93 91 98 88\nFSS 91 91 87 99\nDAS 98 92 96 97\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 5 of 25\nTools and resources Neuroscience\nsyllables with characteristics not seen in females in the paradigm were detected (Figure 2D). Overall,\nDAS accurately and robustly annotates mouse USVs and generalizes across sexes.\nTable 2. Precision, recall, and temporal error of DAS.\nPrecision and recall values are sample-wise for all except fly pulse song, for which it is event-wise. The number of classes includes the\n‘no song’ class. (p) Pulse, (s) Sine.\nSpecies Trained Classes Threshold Precision [%] Recall [%] Temporal error [ms]\nFly single channel Pulse (p) and sine (s) 3 0.7 97/92 (p/s) 96/98 (p/s) 0.3/12 (p/s)\nFly multi channel Pulse (p) 2 0.5 98 94 0.3\nFly multi channel Sine (s) 2 0.5 97 93 8\nMouse Female 2 0.5 98 99 0.3\nMarmoset five male-female pairs 5 0.5 85 91 4.4\nBengalese finch four males 49 (38 in test set) 0.5 97 97 0.3\nZebra finch one males 7 0.5 98 97 1.2\n40\n60\n80\n100\n120\n140\nFrequency [kHz]\n0\n1\nConfidence\nManual\nDAS\nNo song Song\nManual\nNo song\nSong\nDAS\n57.9\n0.3\n0.2\n13.0\n0 1 2 3 4\nTemporal error [ms]\n0.0\n0.5\n1.0\n1.5\nPDF\n1/16 1/4 1 4 16 64\nSignal-to-noise ratio\n0\n50\n100\nRecall [%]\nDAS\nSong\nNo song Song\nManual\n154.6\n0.4\n0.3\n24.1\n0\n100\n%\nƂ Ƃ ƃ\nC\nD\nE F H\nA\nB\nG\nNo song\nSong\nDAS\n0\n100\n%\n0.05 s 0.05 s\n-50\n0\ndB\nTrain , test Train , test Ƃ\nFigure 2. DAS performance for mouse ultrasonic vocalizations. (A) Waveform (top) and spectrogram (bottom) of USVs produced by a female mouse in\nresponse to an anesthetized female intruder. Shaded areas (top) show manual annotations. (B) Confidence scores (top) and DAS and manual\nannotations (bottom) for the female USVs in A. Brief gaps in confidence are filled smooth annotations. (C) Example of male USVs with sex-specific\ncharacteristics produced in the same assay. (D) Confidence scores (top) and DAS and manual annotations (bottom) for the male USVs in C from a DAS\nnetwork trained to detect female USVs. (E) Confusion matrix from a female-trained network for a test set of female USVs. Color indicates the\npercentage (see color bar) and text labels the seconds of song in each quadrant. (F) Distribution of temporal errors for syllable on- and offsets in female\nUSVs. The median temporal error is 0.3 ms for DAS (brown line) and 0.4 ms for USVSEG Tachibana et al., 2020, a method developed to annotate\nmouse USVs (gray line). (G) Recall of the female-trained network (brown line) as a function of SNR. The brown shaded area represents the distribution of\nSNRs for all samples containing USVs. Recall is high even at low SNR. (H) Confusion matrix of the female-trained DAS network for a test set of male\nUSVs (see C, D for examples). Color indicates the percentage (see color bar) and text labels the seconds of song in each quadrant.\nThe online version of this article includes the following figure supplement(s) for figure 2:\nFigure supplement 1. Performance for marmoset vocalizations.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 6 of 25\nTools and resources Neuroscience\nMarmoset vocalizations\nWe next examined the robustness of annotations produced by DAS to noisy recordings and variable\nvocalization types, by training a network to annotate vocalization from pairs of marmosets\n(Landman et al., 2020). The recordings contain lots of background noises like faint calls from nearby\nanimals, overdrive from very loud calls of the recorded animals, and large variability within syllable\ntypes (Figure 2—figure supplement 1A–D). Recently, a deep-learning-based method was shown to\nproduce good performance (recall 77%, precision 85%, 12.5 ms temporal error) when trained on\n16,000 syllables to recognize seven vocalization types (Oikarinen et al., 2019). We trained DAS on\n1/9th of the data (1800 syllables) containing four of the seven vocalization types. Despite the noisy\nand variable vocalizations, DAS achieves high syllable-wise precision and recall (96%, 92%, (Figure 2—figure supplement 1E,F)). Note that DAS obtains this higher performance at millisecond resolution (temporal error 4.4 ms, Figure 2—figure supplement 1G), while the method by\nOikarinen et al., 2019 only produces annotations with a resolution of 50 ms (Table 2).\nBird song\nBird song is highly diverse and can consist of large, individual-specific repertoires. The spectral complexity and large diversity of the song complicates the annotation of syllable types. Traditionally, syllable types are annotated based on statistics derived from the segmented syllable spectrogram.\nRecently, good annotation performance has been achieved with unsupervised methods\n(Sainburg et al., 2020; Goffinet et al., 2021) and deep neural networks (Koumura and Okanoya,\n2016; Cohen et al., 2020). We first trained DAS to annotate the song from four male Bengalese\nfinches (data and annotations from Nicholson et al., 2017). The network was then tested on a random subset of the recordings from all four individuals which contained 37 of the 48 syllable types\nfrom the training set (Figure 3A,B, Figure 3—figure supplement 1A,B). DAS annotates the bird\nsong with high accuracy: Sample-wise precision and recall are 97% and syllable on- and offsets are\ndetected with sub-millisecond precision (median temporal error 0.3 ms, Figure 3C). The types of\n98.5% the syllables are correctly annotated, with only 0.3% false positives (noise annotated as a syllable), 0.2% false negatives (syllables annotated as noise), and 1% type confusions (Figure 3D, Figure 3—figure supplement 1C–D). This results in a low sequence error (corresponding to the\nminimal number of substitutions, deletions, or insertions required to transform the true sequence of\nsyllables into the inferred one) of 0.012. Overall, DAS performs as well as specialized deep-learningbased methods for annotating bird song (Koumura and Okanoya, 2016; Cohen et al.,\n2020, Table 2).\nTable 3. Comparison to alternative methods.\nMethods used for comparisons: (1) Arthur et al., 2013, (2) Tachibana et al., 2020, (3) Oikarinen et al., 2019, (4) Cohen et al., 2020.\n(A,B) DAS was trained on 1825/15970 syllables which contained 4/7 of the call types from Oikarinen et al., 2019. (B) The method by\nOikarinen et al., 2019 produces an annotation every 50 ms of the recording - since the on/offset can occur anywhere within the\n50 ms, the expected error of the method by Oikarinen et al., 2019 is at least 12.5 ms. (C) The method by Oikarinen et al., 2019\nannotates 60 minutes of recordings in 8 minutes. (D) Throughput assessed on the CPU, since the methods by Arthur et al., 2013 and\nTachibana et al., 2020 do not run on a GPU. (E) Throughput assessed on the GPU. The methods by Cohen et al., 2020 and\nOikarinen et al., 2019 use a GPU.\nPrecision [%] Recall [%] Jitter [ms] Throughput [s/s]\nSpecies DAS Other DAS Other DAS Other DAS Other\nFly single (1) 97/92 (p/s) 99/91 96/98 (p/s) 87/91 0.3/12 (p/s) 0.1/22 15 4 (D)\nFly multi (1) 98 99 94 92 0.3 0.1 8 (p) 0.4 (p+s) (D)\nFly multi (1) 97 95 93 93 8.0 15.0 8 (s) 0.4 (p+s) (D)\nMouse (2) 98 98 99 99 0.3 0.4 12 4 (D)\nMarmoset (3) 96 85 (A) 92 77 (A) 4.4 12.5 (B) 82 7.5 (C, E)\nBengalese finch (4) 99 99 99 99 0.3 1.1 15 5 (E)\nZebra finch (4) 100 100 100 100 1.3 2.0 18 5 (E)\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 7 of 25\nTools and resources Neuroscience\nTo further demonstrate the robustness of DAS, we trained a network to annotate song from\nZebra finches. In Zebra finch males, individual renditions of a given syllable type tend to be more\nvariable (Fitch et al., 2002). Moreover, the particular recordings used here (Goffinet et al., 2021)\ncontain background noise from the bird’s movement. Despite the variability and noise, DAS annotates the six syllables from a male’s main motif with excellent precision and recall, and low temporal\nerror, demonstrating that DAS is robust to song variability and recording noise (Figure 3—figure\nsupplement 2).\nIn summary, DAS accurately and robustly annotates a wide range of signals—from the pulsatile\nsong pulses of flies to the spectrally complex syllables of mammals and birds. DAS therefore constitutes a universal method for annotating acoustic signals that is as good as or better than methods\nspecialized for particular types of signals (Table 2).\nDAS is fast\nTo efficiently process large corpora of recordings and to be suitable for closed-loop applications,\nDAS needs to infer annotations quickly. We therefore assessed the throughput and latency of DAS.\nThroughput measures the rate at which DAS annotates song and high throughput means that large\ndatasets are processed quickly. Across the five species tested here, DAS has a throughput of 8-82x\nrealtime on a CPU and of 24-267x on a GPU (Figure 4A). This means that a 60 min recording is\nannotated in less than five minutes on a standard desktop PC and in less than 1.5 minutes using a\nGPU, making the annotation of large datasets feasible (Figure 4—figure supplement 1A–H). The\ndifferences in throughput arise from the different sample rates and network architectures: The marmoset network is fastest because of a relatively shallow architecture with only 2 TCN blocks and a\nlow sampling rate (44.1 kHz). By contrast, the multi-channel Drosophila networks have the lowest\nthroughput because of multi-channel inputs (9 channels at 10.0 kHz) and a comparatively deep architecture with four TCN blocks (Table 4).\nA\n0.1 s\n0.5\n1.0\n2.0\n4.0\n8.0\nFrequency [kHz]\nB\nC\nDAS\nManual\n0 20\nDAS\n0\n10\n20\n30\nManual\n0 1 2 3 4\nTemporal error [ms]\n0.0\n1.0\n2.0\nPDF\nD\nSong\nNo song\n%\n-70\n0\ndB\n0.1\n1\n10\n100\nFigure 3. DAS performance for the song of Bengalese finches. (A) Waveform (top) and spectrogram (bottom) of the song of a male Bengalese finch.\nShaded areas (top) show manual annotations colored by syllable type. (B) DAS and manual annotation labels for the different syllable types in the\nrecording in A (see color bar). DAS accurately annotates the syllable boundaries and types. (C) Confusion matrix for the different syllables in the test\nset. Color was log-scaled to make the rare annotation errors more apparent (see color bar). Rows depict the probability with which DAS annotated each\nsyllable as any of the 37 types in the test dataset. The type of 98.5% of the syllables were correctly annotated, resulting in the concentration of\nprobability mass along the main diagonal. (D) Distribution of temporal errors for the on- and offsets of all detected syllables (green-shaded area). The\nmedian temporal error is 0.3 ms for DAS (green line) and 1.1 ms for TweetyNet Cohen et al., 2020, a method developed to annotate bird song (gray\nline).\nThe online version of this article includes the following figure supplement(s) for figure 3:\nFigure supplement 1. Performance for the song of Bengalese finches.\nFigure supplement 2. Performance for the song of a Zebra finch.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 8 of 25\nTools and resources Neuroscience\nA\nB\n1 channel 9 channels\nPulse Sine Pulse Sine Mouse B. finch\n1 channel\nAnnotate\nby hand\nFast-train\nAnnotate\nPredict on\nnew data\nCorrect\npredictions\nFull-train\nC EValidation loss\n0.3\n0.2\n0.1\n0.06\n0 5 10 15\nMinutes of training\n1.0\n10.0\n100.0\nThroughput\n1x realtime\n10x realtime\n40x realtime\n0\n10\n20\nLatency [ms]\nCPU\nGPU\nMarmoset Z. finch\n100x realtime\n1\n10\n100\n1000\nNumber of\nannotations\n1 channel 9 channels\nPulse Sine Pulse Sine Mouse B. finch\n1 channel\nD 1611\n632\n48\n22\n264 272\n44\n16\nMarmoset Z. finch\nFigure 4. DAS annotates song with high throughput and low latency and requires little data. (A, B) Throughput (A) and latency (B) of DAS (see also\nFigure 4—figure supplement 1). Throughput (A) was quantified as the amount of audio data in seconds annotated in one second of computation\ntime. Horizontal lines in A indicate throughputs of 1, 10, 40, and 100. Throughput is >8x realtime on a CPU (dark shades) and >24x or more on a GPU\n(light shades). Latency (B) corresponds to the time it takes to annotate a single chunk of audio and is similar on a CPU (dark shades) and a GPU (light\nshades). Multi-channel audio from flies was processed using separate networks for pulse and sine. For estimating latency of fly song annotations, we\nused networks with 25 ms chunks, not the 410 ms chunks used in the original network (see Figure 1—figure supplement 2). (C) Flow diagram of the\niterative protocol for fast training DAS. (D) Number of manual annotations required to reach 90% of the performance of DAS trained on the full data set\nshown in Figure 1, Figure 1—figure supplement 3, Figure 2, Figure 2—figure supplement 1, Figure 3, and Figure 3—figure supplement 2 (see\nalso Figure 4—figure supplement 3). Performance was calculated as the F1 score, the geometric mean of precision and recall. For most tasks, DAS\nrequires small to modest amounts of manual annotations. (E) Current best validation loss during training for fly pulse song recorded on a single channel\nfor 10 different training runs (red lines, 18 min of training data). The network robustly converges to solutions with low loss after fewer than 15 min of\ntraining (40 epochs).\nThe online version of this article includes the following figure supplement(s) for figure 4:\nFigure supplement 1. Throughput and latency of inference.\nFigure supplement 2. Reducing the chunk duration reduces latency and comes with minimal performance penalties.\nFigure supplement 3. DAS requires small to moderate amounts of data for training.\nFigure supplement 4. Example of fast training mouse USVs.\nFigure supplement 5. DAS performance is robust to changes in the structural parameters of the network.\nTable 4. Structural parameters of the tested networks.\nSpecies Rate [kHz] Chunk [samples] Channels STFT downsample Separable conv. TCN stacks Kernel size [samples] Kernel\nFly single channel 10.0 4096 1 - - 3 32 32\nFly multi channel (pulse) 10.0 2048 9 - TCN blocks 1+2 4 32 32\nFly multi channel (sine) 10.0 2048 9 - TCN blocks 1+2 4 32 32\nMouse 300.0 8192 1 16x - 2 16 32\nMarmoset 44.1 8192 1 16x - 2 16 32\nBengales finch 32.0 1024 1 16x - 4 32 64\nZebra finch 32.0 2048 1 16x - 4 32 64\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 9 of 25\nTools and resources Neuroscience\nA measure of speed crucial for closed-loop experiments is latency, which quantifies the time it\ntakes to annotate a chunk of song and determines the delay for experimental feedback. Latencies\nare short, between 7 and 15 ms (Figure 4B, Figure 4—figure supplement 1I–P) on CPUs and\nGPUs. One network parameter impacting latency is the chunk size—the duration of audio processed\nat once—and we find that for fly song, latency can be optimized by reducing chunk size with a minimal impact on accuracy (Figure 4—figure supplement 2). The low latency of annotation makes DAS\nwell suited for triggering realtime optogenetic or acoustic feedback upon the detection of specific\nvocalizations (Bath et al., 2014; Stowers et al., 2017).\nWe also compared the speed of DAS to that of other methods that were specifically developed\nto annotate the types of signals tested here. Since most existing methods are not suitable for estimating latency due to constraints in their design and interface, we only compared throughput. We\nfind that DAS achieves 3x to 10x higher throughput than existing methods (Table 2). This has three\nmain reasons: First, the relatively simple, purely convolutional architecture exploits the parallel processing capabilities of modern CPUs and GPUs. Second, Fourier or wavelet-like preprocessing steps\nare integrated into the network and profit from a fast implementation and hardware acceleration.\nThird, for multi-channel data, DAS combines information from all audio channels early, which\nincreases throughput by reducing the data bandwidth.\nOverall, DAS annotates audio with high throughput (>8x realtime) and low latency (<15 ms) and\nis faster than the alternative methods tested here. The high speed renders DAS suitable for annotating large corpora and for realtime applications without requiring specialized hardware.\nDAS requires little manual annotation\nTo be practical, DAS should achieve high performance with little manual annotation effort. We find\nthat DAS can be efficiently trained using an iterative protocol (Pereira et al., 2019, Figure 4C, Figure 4—figure supplement 4): Annotate a small set of recordings and train the network for a few\nepochs; then generate annotations on a larger set of recordings and correct these annotations.\nRepeat the predict-correct-train cycle on ever larger datasets until performance is satisfactory. To\nestimate the amount of manual annotations required to achieve high performance, we evaluated\nDAS trained on subsets of the full training data sets used above (Figure 4—figure supplement 3).\nWe then took the number of manual annotations needed to reach 90% of the performance of DAS\ntrained on the full data sets as an upper bound on the data requirements (Figure 4D). With a performance threshold of 90%, the resulting networks will produce sufficiently accurate annotations for\ncreating a larger body of training data with few corrections. Performance was taken as the F1 score,\nthe geometric mean of precision and recall. For single-channel recordings of fly song, fewer than 50\npulses and 20 sine songs are needed to reach 90% of the performance achieved with the full data\nset. For mouse vocalizations, DAS achieves 90% of its peak performance with fewer than 25 manually\nannotated syllables. Even for the six syllables from a zebra finch, DAS reaches the 90% threshold\nwith only 48 manually annotated syllables (eight per type). Manually annotating such small amounts\nof song for flies, mice, or zebra finches takes less than 5 min. Likewise, for the song of Bengalese\nfinches, 1–51 (median 8, mean 17) manual annotations are required per syllable type, with one outlier requiring 200 syllables (Figure 4—figure supplement 3C). Closer inspection reveals that the outlier results from an annotation error and consists of a mixture of three distinct syllable types\n(Figure 4—figure supplement 3D–F). Even with this outlier, only 626 manually annotated syllabes\n(424 without) are required in total to reach 90% of the test performance of a network trained on\n>3000 annotated syllables. Data requirements are higher for the multi-channel recordings of fly song\n(270 pulses and sine songs), and for the noisy and variable marmoset data (1610 annotations, 400\nper type), but even in these cases, the iterative training protocol can reduce the manual annotation\nwork.\nOverall, DAS requires small to moderate amounts of data for reaching high performance. High\nthroughput (Figure 4A) and small training data sets (Figure 4D) translate to short training times\n(Figure 4E). The single-channel data sets typically achieve 90% of the performance after less than 10\nmin of training on a GPU. Training on the full data sets typically finishes in fewer than five hours.\nThus, DAS can be adapted to novel species in short time and with little manual annotation work.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 10 of 25\nTools and resources Neuroscience\nDAS can be combined with unsupervised methods\nDAS is a supervised annotation method: It discriminates syllable types that have been manually\nassigned different labels during training. By contrast, unsupervised methods can determine in unlabelled data whether syllables fall into distinct types and if so, classify the syllables (Tabler et al.,\n2017; Coffey et al., 2019; Clemens et al., 2018; Goffinet et al., 2021; Sainburg et al., 2020;\nSangiamo et al., 2020; Arthur et al., 2021). While DAS does not require large amounts of manual\nannotations (Figure 4D), manual labeling of syllable types can be tedious when differences between\nsyllable types are subtle (Clemens et al., 2018) or when repertoires are large (Sangiamo et al.,\n2020). In these cases, combining DAS with unsupervised methods facilitates annotation work. To\ndemonstrate the power of this approach, we use common procedures for unsupervised classification,\nwhich consist of an initial preprocessing (e.g. into spectograms) and normalization (e.g. of amplitude)\nof the syllables, followed by dimensionality reduction and clustering (see Materials and methods)\n(Clemens et al., 2018; Sainburg et al., 2020; Sangiamo et al., 2020).\nFor fly song, DAS was trained to discriminate two major song modes, pulse and sine. However,\nDrosophila melanogaster males produce two distinct pulse types, termed Pslow and\nPfast (Clemens et al., 2018), and unsupervised classification robustly discriminates the two pulse\ntypes as well as the sine song in the DAS annotations (Figure 5A–C). Mouse USVs do not fall into\ndistinct types (Tabler et al., 2017; Goffinet et al., 2021; Sainburg et al., 2020). In this case, unsupervised clustering produces a low-dimensional representation that groups the syllables by the similarity of their spectrograms (Tabler et al., 2017; Coffey et al., 2019; Sangiamo et al., 2020,\nFigure 5D,E). For marmosets, unsupervised classification recovers the four manually defined call\ntypes (Figure 5F,G). However, most call types are split into multiple clusters, and the clusters for\ntrills and twitters tend to separate poorly (Figure 4—figure supplement 3G), which reflects the\nlarge variability of the marmoset vocalizations. This contrasts with the song of Zebra finches, for\nwhich the unsupervised method produces a one-to-one mapping between manually defined and\nunsupervised syllable types (Goffinet et al., 2021; Sainburg et al., 2020; Figure 5H,I). For the song\nof Bengalese finches, the unsupervised classification recovers the manual labeling (Goffinet et al.,\n2021; Sainburg et al., 2020; Figure 5J,K) and reveals manual annotation errors: For instance, the\nsong syllable that required >200 manual annotations to be annotated correctly by DAS is a mixture\nof three distinct syllable types (Figure 4—figure supplement 3C–F).\nOverall, unsupervised methods simplify annotation work: DAS can be trained using annotations\nthat do not discriminate between syllable types and the types can be determined post hoc. If distinct\ntypes have been established, DAS can be retrained to directly annotate these types using the labels\nproduced by the unsupervised method as training data.\nDiscussion\nWe here present Deep Audio Segmenter (DAS), a method for annotating acoustic signals. DAS\nannotates song in single- and multi-channel recordings from flies (Figure 1, Figure 1—figure supplement 3), mammals ( Figure 2, Figure 2—figure supplement 1), and birds (Figs Figure 3, Figure 3—figure supplement 2) accurately, robustly, and quickly (Figure 4A,B). DAS performs as well\nas or better than existing methods that were designed for specific types of vocalizations\n(Koumura and Okanoya, 2016; Cohen et al., 2020; Tachibana et al., 2020; Coffey et al., 2019,\nTable 2). DAS performs excellently for signals recorded on single and multiple channels (Figure 1,\nFigure 1—figure supplement 3), with different noise levels, and with diverse characteristics. This\nsuggests that DAS is a general method for accurately annotating signals from a wide range of\nrecording setups and species.\nUsing a user-friendly graphical interface, our method can be optimized for new species without\nrequiring expert knowledge and with little manual annotation work (Figure 4C–E). Network performance is robust to changes in the structural parameters of the network, like filter number and duration, or the network depth (Figure 4—figure supplement 5). Thus, the structural parameters do not\nneed to be finely tuned to obtain a performant network for a new species. We have trained networks\nusing a wide range of signal types (Table 4) and these networks constitute good starting points for\nadapting DAS to novel species. We provide additional advice for the design of novel networks in\nMethods. This makes the automatic annotation and analysis of large corpora of recordings from\ndiverse species widely accessible.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 11 of 25\nTools and resources Neuroscience\nWe show that the annotation burden can be further reduced using unsupervised classification of\nsyllable types, in particular for species with large or individual-specific repertoires (Figure 5,\nClemens et al., 2018; Tabler et al., 2017; Coffey et al., 2019; Goffinet et al., 2021;\nSainburg et al., 2020; Arthur et al., 2021). In the future, incorporating recent advances in the selfsupervised or semi-supervised training of neural networks will likely further reduce data requirements\n(Mathis et al., 2021; Raghu et al., 2019; Devlin et al., 2019; Chen and He, 2020). These\napproaches use unlabeled data to produce networks with a general and rich representation of sound\nfeatures that can then be fine-tuned for particular species or individuals using few annotated samples. DAS currently does not work well with recordings in which the signals produced by multiple\nanimals overlap. In the future, DAS will be extended with methods for multi-speaker speech recognition to robustly annotate vocalizations from animal groups.\nLastly, the high inference speed (Figure 4A,B) allows integration of DAS in closed-loop systems\nin which song is detected and stimulus playback or optogenetic manipulation is triggered with low\nlatency (Bath et al., 2014; Stowers et al., 2017). In combination with realtime pose tracking\n(Mathis et al., 2018; Pereira et al., 2019; Graving et al., 2019), DAS provides unique opportunities\nto tailor optogenetic manipulations to specific behavioral contexts, for instance to dissect the neural\ncircuits underlying acoustic communication in interacting animals (Coen et al., 2014; Fortune et al.,\n2011; Okobi et al., 2019).\nA\nSine\nPslow\nPfast\nB\nC\n4 ms\nJ\nK\nD\nE\nH\nI\n0.5\n8.0kHz\n0.1 s\n-70\n-10\ndB\nek\ntwitter tsik\ntrill\nF\nG\nek\ntwitter\ntsik\ntrill\nFigure 5. DAS can be combined with unsupervised methods for song classification. (A) Low-dimensional representation obtained using the UMAP\n(McInnes and Healy, 2018) method of all pulse and sine song waveforms from Drosophila melanogaster annotated by DAS in a test data set. Data\npoints correspond to individual waveforms and were clustered into three distinct types (colors) using the density-based method HDBSCAN\n(McInnes et al., 2017). (B, C) All waveforms (B) and cluster centroids (C) from A colored by the cluster assignment. Waveforms cluster into one sine\n(blue) and two pulse types with symmetrical (red, Pslow) and asymmetrical (orange, Pfast) shapes. (D, E) Low-dimensional representation of the\nspectrograms of mouse USVs (D) and mean spectrogram for each cluster in D (E). Individual syllables (points) form a continuous space without distinct\nclusters. Song parameters vary continuously within this space, and syllables can be grouped by the similarity of their spectral contours using k-means\nclustering. (F, G) Low-dimensional representation of the spectrograms of the calls from marmosets (F) and mean spectrogram for each cluster in F (G).\nCalls separate into distinct types and density-based clustering (colors) produces a classification of syllables that recovers the manual annotations\n(Figure 4—figure supplement 3G, homogeneity score 0.88, completeness score 0.57, v-score 0.69). Most types split into multiple clusters, reflecting\nthe variability of the call types in marmosets. Colored bars on top of each spectrogram in G correspond to the colors for the individual clusters in F.\nThe dashed line shows the boundary separating trills and twitters. (H, I) Low-dimensional representation of the spectrograms of the syllables from one\nZebra finch male, mean spectrogram for each cluster in H (I, top), and example of each clustered syllable within the motif (I, bottom). Density-based\nclustering (colors) recovers the six syllable types forming the male’s motif. Colored bars on top of each spectrogram in I correspond to the colors for\nthe individual clusters in H. (J, K) Low-dimensional representation of the spectrograms of the syllables from four Bengalese finch males (J) and mean\nspectrogram for each cluster in J (K). Syllables separate into distinct types and density-based clustering (colors) produces a classification of syllables\nthat closely matches the manual annotations (homogeneity score 0.96, completeness score 0.89, v-score 0.92). X-axes of the average spectrograms for\neach cluster do not correspond to linear time, since the spectrograms of individual syllables were temporally log-rescaled and padded prior to\nclustering. This was done to reduce the impact of differences in duration between syllables.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 12 of 25\nTools and resources Neuroscience\nMaterials and methods\nInstructions for installing and using DAS can be found at https://janclemenslab.org/das. Code for\nthe das python module is available at https://github.com/janclemenslab/das, code for the unsupervised methods is at https://github.com/janclemenslab/das_unsupervised. All fitted models (with\nexample data and code) can be found at https://github.com/janclemenslab/das-menagerie.\nWe also provide instructions for training DAS using google colab, which provides a GPU-accelerated python environment. Colab removes the need to install GPU libraries: Annotations can be\nmade locally in the GUI without a GPU and training and prediction are done on GPU-accelerated\nnodes in the cloud. See this notebook for details: http://janclemenslab.org/das/tutorials/colab.html.\nData sources\nAll data used for testing DAS were published previously. Sources for the original data sets, for the\ndata and annotations used for training and testing, and for the fitted models are listed in Table 5.\nSingle-channel recordings of Drosophila melanogaster (strain OregonR) males courting females were\ntaken from Stern, 2014. The multi-channel data from Drosophila melanogaster (strain NM91) males\ncourting females were recorded in a chamber tiled with nine microphones (Coen et al., 2014) and\nwas previously published in Clemens et al., 2018. Annotations for fly song were seeded with FlySongSegmenter (Arthur et al., 2013; Coen et al., 2014) and then manually corrected. Recordings\nof mouse USVs were previously published in Ivanenko et al., 2020. The USVs were manually labeled\nusing the DAS graphical interface. Marmoset recordings were taken from the data published with\nLandman et al., 2020. Since we required more precise delineation of the syllable boundaries than\nwas provided in the published annotations, we manually fixed annotations for a subset of the data\nthat then was used for training and testing. The network was trained and tested on a subset of four\nvocalization types (eks/trills/tsiks/twitters, N=603/828/115/868). The remaining vocalization types\nwere excluded since they had 60 or fewer instances in our subset. To test DAS on bird songs, we\nused a publicly available, hand-labeled collection of song from four male Bengalese finches\nTable 5. Sources of all data used for testing DAS.\n‘Data’ refers to the data used for DAS and to annotations that were either created from scratch or modified from the original annotations (deposited under https://data.goettingen-research-online.de/dataverse/das). ‘Original data’ refers to the recordings and annotations deposited by the authors of the original publication. ‘Model’ points to a directory with the model files as well as a small test data\nset and demo code for running the model (deposited under https://github.com/janclemenslab/das-menagerie).\nSpecies Reference Data and model repositories\nFly single channel Stern, 2014 data: https://doi.org/10.25625/TP4ODR\noriginal data: https://www.janelia.org/lab/stern-lab/tools-reagents-data\nmodel: https://github.com/janclemenslab/das-menagerie/dmel_single\nFly multi channel Clemens et al., 2018 data: https://doi.org/10.25625/8KAKHJ\nmodel: https://github.com/janclemenslab/das-menagerie/dmel_multi\nMouse Ivanenko et al., 2020 data: https://doi.org/10.25625/VVSKCH\noriginal data: https://data.donders.ru.nl/collections/di/dcn/DSC_620840_0003_891\nmodel: https://github.com/janclemenslab/das-menagerie/mouse\nMarmoset Landman et al., 2020 data: https://doi.org/10.25625/DYG3KV\noriginal data: https://osf.io/q4bm3/\nmodel: https://github.com/janclemenslab/das-menagerie/marmoset\nBengalese finch Nicholson et al., 2017 data: https://doi.org/10.25625/ENKMJS\noriginal data: https://doi.org/10.6084/m9.figshare.4805749.v6\nmodel: https://github.com/janclemenslab/das-menagerie/bengalese_finch\nZebra finch Goffinet et al., 2021 data: https://doi.org/10.25625/ZXJJJY\noriginal data: https://research.repository.duke.edu/concern/datasets/9k41zf38g\nmodel: https://github.com/janclemenslab/das-menagerie/zebra_finch\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 13 of 25\nTools and resources Neuroscience\n(Nicholson et al., 2017) and recordings of female-directed song from a male Zebra finch from\nGoffinet et al., 2021. For training and testing the Zebra finch network, we manually labeled 473 syllables of six types (320 s of recordings).\nDAS network\nDAS is implemented in Keras (Chollet, 2015) and Tensorflow (Abadi et al., 2016). At its core, DAS\nconsists of a stack of temporal convolutional blocks, which transform an input sequence of audio\ndata into an output sequence of labels.\nInputs\nDAS takes as input raw, single or multi-channel audio. Pre-processing of the audio using a wavelet\nor short-time Fourier transform (STFT) is optional and integrated into the network. DAS processes\naudio in overlapping chunks (Figure 1—figure supplement 1A–D). The chunking accelerates annotations since multiple samples are annotated in a single computational step. Edge effects are\navoided by processing overlapping chunks and by discarding a number of samples at the chunk\nboundaries. The overlap depends on the number of layers and the duration of filters in the network.\nSTFT frontend\nThe trainable STFT frontend is an optional step and was implemented using kapre (Choi et al.,\n2017). Each frequency channel in the output of the frontend is the result of two, one-dimensional\nstrided convolutions which are initialized with the real and the imaginary part of discrete Fourier\ntransform kernels:\nxði;fÞ ¼XT1\nt ¼0\nxði  sþ t Þ½cosð2pf t =TÞ isinð2pf t =TÞ\nyði;fÞ ¼ log10ð\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi\n<xði;fÞ\n2 þ =xði;fÞ\n2\nq\nÞ\nwhere f is the frequency, s is the stride, and T is the filter duration. The stride results in downsampling of the input by a factor s.\nThe STFT kernels are optimized with all other parameters of the network during training. The\nSTFT frontend was used for mammal and bird signals, but not for fly song. In the mammal and bird\nnetworks, we used 33 STFT filter pairs with a duration T ¼ 64 samples and a stride s ¼ 16 samples.\nFor mouse and bird song, the STFT frontend sped up training and inference, and had a small positive impact on performance. For fly song, the STFT frontend tended to reduce performance and was\nomitted.\nTemporal convolutional blocks\nTemporal convolutional network (TCN) blocks are central to DAS and produce a task-optimized hierarchical representation of sound features at high temporal resolution (Bai et al., 2018). Each TCN\nblock consists of a stack of so-called residual blocks (Figure 1—figure supplement 1E, He et al.,\n2016):\nA dilated convolutional layer filters the input with a number of kernels of a given duration:\nyiðtÞ ¼ P\nt ;g\nkiðt ; gÞ  xðt  at ; gÞ, where kiðt ; gÞ is the i th kernel, xðt; gÞ is the input on channel g at\ntime t, yiðtÞ the output, and a the gap or skip size (Yu and Koltun, 2016). In old-fashioned convolution a ¼ 1. Increasing a allows the kernel to span a larger range of inputs with the same number of\nparameters and without a loss of output resolution. The number of parameters is further reduced for\nnetworks processing multi-channel audio, by using separable dilated convolutions in the first two\nTCN blocks (Mamalet and Garcia, 2012). In separable convolutions, the full two-dimensional kðt ; gÞ\nconvolution over times and channels is decomposed into two one-dimensional convolutions. First, a\ntemporal convolution, k\nt\nðt ; 1Þ, is applied to each channel and then N channel convolutions, k\ng\nð1; gÞ,\ncombine information across channels. Instead of t  g parameters, the separable convolution only\nrequires t þ N  g parameters. Note that each temporal convolution is applied to each channel,\nleading to a sharing of filter parameters across channels. This makes explicit the intuition that some\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 14 of 25\nTools and resources Neuroscience\noperations should be applied to all channels equally. We also tested an alternative implementation,\nin which individual channels were first processed separately by a single-channel TCN, the outputs of\nthe TCN blocks for each channel were concatenated, and then fed into a stack of standard TCNs\nwith full two-dimensional convolutions. While this architecture slightly increased performance it was\nalso much slower and we therefore chose the architecture with separable convolutions. Architecture\nchoice ultimately depends on speed and performance requirements of the annotation task.\nA rectifying linear unit transmits only the positive inputs from the dilated convolutional layer by\nsetting all negative inputs to 0: yi ¼ maxð0; yiÞ.\nA normalization layer rescales the inputs to have a maximum absolute value close to 1:\nyi=ðmaxðjyi\njÞ þ 105\nÞ.\nThe output of the residual block, zðtÞ, is then routed to two targets: First, it is added to the input:\noðtÞ ¼ xðtÞ þ zðtÞ and fed into subsequent layers. Second, via so-called skip connections, the outputs\nof all residual blocks are linearly combined to produce the network’s final output (van den Oord\net al., 2016).\nA single TCN block is composed of a stack of five residual blocks. Within a stack, the skip size a\ndoubles - from one in the first to 2\n5 ¼ 16 in the final residual block of a stack. This exponential\nincrease in the span of the filter t  a allows the TCN block to produce a hierarchical representation\nof its inputs, from relatively low-level features on short timescales in early stacks to more derived features on longer timescales in late stacks. Finally, a full network consists of a stack of 2 to 4 TCN\nblocks, which extract ever more derived features (Figure 1—figure supplement 1A–D).\nOutput\nThe network returns a set of confidence scores—one for each song type (and for ’no song’)—for\neach sample from a linear combination of the output of each residual block in the network, by using\na single dense layer and a softmax activation function. Re-using information from all blocks via socalled skip connections ensures that downstream layers can discard information from upstream\nlayers and facilitates the generation of specialized higher order presentations. If the input recording\ngot downsampled by a STFT frontend, a final upsampling layer restores the confidence scores to the\noriginal audio rate by repeating values. The parameters of all used networks are listed in Table 4.\nChoice of structural network parameters\nDAS performance is relatively robust to the choice of structural network parameters like filter duration and number, or network depth (Figure 4—figure supplement 5). The networks tested here are\ngood starting points for adapting DAS to your own data (Table 4). In our experience, a network with\n32 filters, filter duration 32 samples, 3 TCN blocks, and a chunk duration of 2048 samples will produce good results for most signals. A STFT downsampling layer with 32 frequency bands and 16x\ndownsampling should be included for most signals except when the signals have a pulsatile character. These parameters have been set as defaults when creating a new DAS network. Given that DAS\ntrains quickly (Figure 4E), network structure can be optimized by training DAS networks over a grid\nof structural parameters, for instance to find the simplest network (in terms of the number of filters\nand TCN blocks) that saturates performance but has the shortest latency. We here provide additional guidelines for choosing a network’s key structural parameters:\nThe chunk duration corresponds to the length of audio the network processes in one step and\nconstitutes an upper bound for the context available to the network. Choose chunks sufficiently long\nso that the network has access to key features of your signal. For instance, for fly song, we ensured\nthat a single chunk encompasses several pulses in a train, so the network can learn to detect song\npulses based on their regular occurrence in trains. Longer chunks relative to this timescale can\nreduce short false positive detections, for instance for fly sine song and for bird song. Given that\nincreasing chunk duration does not increase the number of parameters for training, we recommend\nusing long chunks unless low latency is of essence (see below).\nDownsampling/STFT weakly affects performance but strongly accelerates convergence during\ntraining. This is because (A) the initialization with STFT filters is a good prior that reduces the number\nof epochs it takes to learn the optimal filters, and (B) the downsampling reduces the data bandwidth\nand thereby the time it takes to finish one training epoch. The overall increase in performance from\nadding the STFT layer is low because convolutional layers in the rest of the network can easily\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 15 of 25\nTools and resources Neuroscience\nreplicate the computations of the STFT layer. For short pulsatile signals or signals with low sampling\nrates, STFT and downsampling should be avoided since they can decrease performance due to the\nloss of temporal resolution.\nThe number of TCN blocks controls the network’s depth. A deeper network can extract more\nhigh-level features, though we found that even for the spectro-temporally complex song of Bengalese finches, deeper networks only weakly improved performance (Figure 4—figure supplement 5).\nMulti-channel audio can be processed with multi-channel filters via full convolutions or with\nshared channel-wise filters via time-channel separable convolutions. This can be set on a per-TCNblock basis. We recommend to use separable convolutions in the first 1–2 layers, since basic feature\nextraction is typically the same for each channel. Later layers can then have full multi-channel filters\nto allow more complex combination of information across channels.\nReal-time performance can be optimized by reducing networks complexity and chunk duration\n(Figure 4—figure supplement 2). We recommend starting with the default parameters suggested\nabove and then benchmarking latency. If required, latency can then be further reduced by reducing\nchunk duration, the number and duration of filters, and the number of TCN blocks.\nTraining\nNetworks were trained using the categorical cross-entropy loss and the Adam optimizer\n(Kingma and Ba, 2015) with a batch size of 32. Prediction targets were generated from fully annotated recordings and one-hot-encoded: Segments were coded as binary vectors, with yiðtÞ ¼ 1 if a\nsegment of type i occurred at time t, and yiðtÞ ¼ 0 otherwise. To encode uncertainty in the timing of\nfly song pulses, the pulses were represented as Gaussian bumps with a standard deviation of\n1.6 ms. A ’no song’ type was set to ynosongðtÞ ¼ 1\nP\ni\nyiðtÞ. That way, y corresponds to the probability of finding any of the annotated song types or no song. For bird song, short gaps (6.25 ms, 200\nsamples at 32 kHz) were introduced between adjacent syllables to aid the detection of syllable onand offsets after inference. That way, syllable on- and offsets could be unequivocally detected as\nchanges from ‘no song’ to any of the syllables. This reduced the amount of false positive on- and offsets from switches in the inferred label within a syllable.\nTypically, multiple fully annotated recordings were combined in a data set. Each recording was\nsplit 80:10:10 into a training, validation, and test set. The validation and test data were randomly\ntaken from the first, the middle or the last 10% of each recording. Given the uneven temporal distribution of call types in the marmoset recordings, we split the data 60:20:20 to ensure that each call\ntype was well represented in each split. For all networks, training was set to stop after 400 epochs\nor earlier if the validation loss was not reduced for at least 20 epochs. Training typically stopped\nwithin 40–80 epochs depending on the dataset. The test set was only used after training, for evaluating the model performance.\nGeneration of annotations from the network output\nThe confidence scores produced by the model correspond to the sample-wise probability for each\nsong type. To produce an annotation label for each sample, the confidence scores were further\nprocessed to extract event times and syllable segments. In the resulting annotations, song types are\nmutually exclusive, that is, each sample is labeled as containing a single song type even if song types\noverlap.\nEvent times for event-like song types like fly pulse song were determined based on local maxima\nin the confidence score, by setting a threshold value between 0 and 1 and a minimal distance\nbetween subsequent peaks (using peakutils, Negri and Vestri, 2017). For the pulse song of flies,\nwe set a minimal distance of 10 ms and a threshold of 0.7 for single channel data (Figure 1) and 0.5\nfor multi-channel data (Figure 1—figure supplement 3).\nFor segment-like song types like fly sine song or the syllables of mouse, marmoset, and bird\nsong, we first transformed the sample-wise probability into a sequence of labels using argmaxi\nyði; tÞ.\nThe resulting annotation of segments was then smoothed by filling short gaps (flies 20 ms, mice 10\nms, marmosets and birds 5 ms) and removing very short detections (flies 20 ms, mice 5 ms, marmosets and birds 30 ms). These values were chosen based on the statistics of song found in the training\ndata. Syllable on- and offsets were detected as changes from no-song to song and song to no-song,\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 16 of 25\nTools and resources Neuroscience\nrespectively. For bird and marmoset vocalizations, syllable labels were determined based on a\nmajority vote, by calculating the mode of the sample-wise labels for each detected syllable.\nEvaluation\nDAS was evaluated on segments of recordings that were not used during training.\nEvents\nFor events—fly pulse song, or the on- and offsets of segments—we matched each true event with its\nnearest neighbor in the list of true events and counted as true positives only events within a specified distance from a true event. For the pulse song of flies as well as for the onsets and offsets of\nmouse, marmoset, and bird syllables, this distance was set to 10 ms. Results were robust to the specific choice of the distance threshold (Figure 1—figure supplement 2A). For the onsets and offsets\nof fly sine song and of the marmoset vocalizations, we set this distance to 40 ms, since these signals\ntended to fade in and out, making the delineation of exact boundaries difficult. False positive events\nwere counted if the distance from a detected event to the nearest true event exceeded the distance\nthreshold or if another detected event was closer to each true event within the distance threshold. If\nseveral detected pulses shared the same nearest true pulses, only the nearest of those was taken as\na true positive, while the remaining detections were matched with other true pulses within the distance threshold or counted as false positives.\nFalse negatives were counted as all true events without nearby detected events. For pulse,\npseudo true negative events were estimated as the number of tolerance distances (2x tolerance distance) fitting into the recording, minus the number of pulses. These true negatives for pulse do not\ninfluence precision, recall, and F1-scores and are only used to fill the confusion matrices in\nFigure 1D,I and Figure 1—figure supplement 3C,H. Pulse and sine song were evaluated only up to\nthe time of copulation.\nMatching segment labels\nFor songs with only one syllable type, we compared the predicted and true labels for each sample\nto compute the confusion matrix (Figure 1—figure supplement 1F,G). In the case of multiple syllable types, the mode of the true and predicted labels for the samples of each detected syllable were\ncompared. A true positive was counted if the mode of the true labels was the same for the samples\ncovered by the detected syllable. Using the true syllables as reference produces similar results (Figure 2—figure supplement 1E,F and Figure 3—figure supplement 1D,E).\nPerformance scores\nFrom the false negative (FN), false positive (FP), and true positive (TP) counts we extracted several\nscores: Precision (P)—the fraction of true positive out of all detections TP/(FP+TP)—and recall (R)—\nthe fraction of true positives out of all positives TP/(TP+FN). The F1 score combines precision and\nrecall via their geometric mean: 2  P  R=ðP þ RÞ. For datasets with many different syllable types,\nwe also used as a summary measure of performance the accuracy—the fraction of correctly labelled\nsyllables: (TP+TN)/(TP+TN+FP+FN). For comparison with other studies, we additionally provide the\nerror rate for the song of Bengalese finches, which is based on the Levenshtein edit distance and\ncorresponds to the minimal number of inserts, deletions, and substitutions required to transform the\nsequence of true syllable labels into the sequence of predicted syllable labels normalized by the\nlength of the true sequence (Koumura and Okanoya, 2016; Cohen et al., 2020).\nTemporal precision\nThe temporal precision for events (pulses, syllable onsets and offsets) was calculated as the median\nabsolute distance between all matched events.\nAnnotation errors for Bengalese finches\nThe network for annotating bird song was trained on all syllable types. We removed from the test\ndata one syllable type with only a single instance in the test set (which was correctly classified),\nbecause the performance could not be assessed reliably based on a single instance. We also\nexcluded as annotation error a syllable type that contained syllables of more than six distinct types.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 17 of 25\nTools and resources Neuroscience\nEstimation of signal-to-noise ratio from audio recordings\nTo assess the robustness of annotation performance to noise, we assessed the recall of DAS for\nepochs with different signal-to-noise ratios (SNRs) for the fly and the mouse networks. Because of\nfundamental differences in the nature of the signals, SNR values were computed with different methods and are therefore not directly comparable across species.\nPulse\nPulse waveforms were 20 ms long and centered on the peak of the pulse energy. The root-mean\nsquare (RMS) amplitudes of the waveform margins (first and last 5 ms) and center (7.5–12.5 ms) were\ntaken as noise and signal, respectively. RMS is defined as\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi P\ni\nxðiÞ\n2\nq\n. For multi-channel recordings,\nthe pulse waveform from the channel with the highest center RMS was chosen to calculate the SNR.\nSine\nSignal was given by the RMS amplitudes of the recording during sine song. Noise is the RMS amplitude in the 200 ms before and after each sine song, with a 10 ms buffer. For instance, if a sine song\nended at 1000 ms, the recording between 1010 and 1210 ms was taken as noise. From the 200 ms\nof noise, we excluded samples that were labeled as sine or pulse and included intervals between\npulses. For multi-channel recordings, the SNR was calculated for the channel with the largest signal\namplitude.\nMouse\nWe assumed an additive noise model: s\n2\ntotal ¼ s\n2\nsignal þ s\n2\nnoise is the squared signal averaged over a\nwindow of 1 ms. Since noise variance changed little relative to the signal variance in our recordings,\nwe can assume constant noise over time to calculate the signal strength: s\n2\nsignal ¼ s\n2\ntotal\nP\nt s\n2\nnoise.\nThe sample-wise SNR is then given by SNRðtÞ ¼ ssignalðtÞ\n2\n=\nP\nt s\n2\nnoise.\nSpeed benchmarks\nInference speed was assessed using throughput and latency. Throughput is the number of samples\nannotated per second and latency is the time it takes to annotate a single chunk. Throughput and\nlatency depend on the chunk duration—the duration of a recording snippet processed by the network at once—and on the batch size—the number of chunks processed during one call. Larger\nbatches maximize throughput by more effectively exploiting parallel computation in modern CPUs\nand GPUs and reducing overheads from data transfer to the GPU. This comes at the cost of higher\nlatency, since results are available only after all chunks in a batch have been processed. Using small\nbatch sizes and short chunks therefore reduces latency, since results are available earlier, but this\ncomes at the cost of reduced throughput because of overhead from data transfer or under-utilized\nparallel compute resources. To assess throughput and latency, run times of model.predict were\nassessed for batch sizes ranging from 1 to 1024 (log spaced) with 10 repetitions for each batch size\nafter an initial warmup run (Figure 4—figure supplement 1A–L). Results shown in the main text are\nfrom a batch size corresponding to 1 s of recording for throughput (Figure 4A) and a batch size of 1\nfor latency (Figure 4B, see also Figure 4—figure supplement 1). For fly song, latency was optimized\nby reducing the chunk size to 25.6 ms (Figure 4—figure supplement 2). Benchmarks were run on\nWindows 10, Tensorflow 2.1, with the network either running on a CPU (Intel i7-7770, 3.6 GHz) or on\na GPU (GTX1050 Ti 4 GB RAM).\nWe also benchmarked the throughput of existing methods for comparison with DAS (Table 2).\nSince neither of the methods considered are designed to be used in ways in which latency can be\nfairly compared to that of DAS, we did not assess latency. The throughput values include all preprocessing steps (like calculation of a spectrogram) and comparisons to DAS were done using the\nsame hardware (CPU for FSS and USVSEG, GPU for TweetyNet and Oikarinen et al., 2019). The\nthroughput of FSS (Arthur et al., 2013; Coen et al., 2014) was tested using 400 s of single-channel\nand 9-channel recordings in Matlab2019a. USVSEG Tachibana et al., 2020 was tested on a 72 s\nrecording in Matlab2019a. TweetyNet (Cohen et al., 2020) was tested using a set of 4 recordings\n(total duration 35 s). Throughput for TweetyNet was given by the combined runtimes of the preprocessing steps (calculating of spectrograms from raw audio and saving them as temporary files)\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 18 of 25\nTools and resources Neuroscience\nand the inference steps (running the network on a GPU). For the previously published network for\nannotating marmoset calls (Oikarinen et al., 2019), we relied on published values for estimating\nthroughput: A processing time of 8 min for a 60 min recording corresponds to a throughput of 7.5\ns/s.\nData economy\nFor estimating the number of manual annotations required to obtain accurate annotations, we\ntrained the networks using different fractions of the full training and validation sets (for instance,\n0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0). Performance of all networks trained on the different subsets\nwas evaluated on the full test sets. The number of manual annotations in each subset was determined after training from the training and validation sets. The number of annotations required to\nexceed 90% of the F1 score of a model trained on the full data sets was calculated based on a lowess fit (Cleveland, 1979) to the data points (Figure 4A,B).\nUnsupervised classification\nSegmented signals were clustered using unsupervised methods described previously in\nClemens et al., 2018, Sainburg et al., 2020, and Sangiamo et al., 2020. First, signals were preprocessed: For fly song, pulse and sine waveforms of duration 15 ms were extracted from the\nrecording, aligned to their peak energy, normalized to unit norm, and adjusted for sign (see\nClemens et al., 2018 for details). For mouse, marmoset, and bird vocalizations, we adapted the procedures described in Sainburg et al., 2020: Noise was reduced in the bird song recordings using\nthe noisereduce package (https://github.com/timsainb/noisereduce). For mouse and marmoset\nvocalizations, noise reduction tended to blur the spectral contours and was omitted. Then, syllable\nspectrograms were extracted from mel spectrograms of the recordings. The noise floor of the spectrogram at each frequency was estimated as the median spectrogram over time and each spectral\nband was then divided by the frequency-specific noise floor value. Finally, the spectrogram values\nwere log-transformed and thresholded at zero for mice and two for marmosets and birds after visual\ninspection of the spectrograms to further remove background noise. To reduce differences in the\nduration of different syllables, all syllables were first log resized in time (scaling factor 8) and then\npadded with zeros to the duration of the longest syllable in the data set. Lastly, the frequency axis\nof the spectrograms for mouse syllables were aligned to the peak frequency, to make clustering\nrobust to jitter in the frequency of the thin spectral contours (Sangiamo et al., 2020). The peak frequency of each mouse syllable was calculated from its time-averaged spectrogram, and only the 40\nspectrogram frequencies around the peak frequency were retained.\nThe dimensionality of the pre-processed waveforms (fly) or spectrograms (mouse, marmoset,\nbirds) was then reduced to two using the UMAP method (McInnes and Healy, 2018) (mindistX= 0.5, 0.1 for marmosets to improve separation of clusters). Finally, signals were grouped using\nunsupervised clustering. For the fly, marmoset, and bird signals, the UMAP distribution revealed distinct groups of syllables and we used a density-based method to cluster the syllables\n(Campello et al., 2013, min_samplesX= 10, min_cluster_sizeX= 20). For mouse USVs, no clusters were visible in the UMAP distribution and density-based clustering failed to identify distinct\ngroups of syllables. Syllables were therefore split into 40 groups using k-means clustering.\nOpen source software used\n. avgn https://github.com/timsainb/avgn_paper Sainburg et al., 2020\n. hdbscan McInnes et al., 2017\n. ipython Perez and Granger, 2007\n. jupyter Kluyver et al., 2016\n. kapre Choi et al., 2017\n. keras Chollet, 2015\n. keras-tcn https://github.com/philipperemy/keras-tcn\n. librosa McFee et al., 2015\n. matplotlib Hunter, 2007\n. noisereduce https://github.com/timsainb/noisereduce\n. numpy Harris et al., 2020\n. pandas McKinney, 2010\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 19 of 25\nTools and resources Neuroscience\n. peakutils Negri and Vestri, 2017\n. scikit-learn Pedregosa et al., 2011\n. scipy Virtanen et al., 2020\n. seaborn Waskom et al., 2017\n. snakemake Ko¨ster and Rahmann, 2018\n. tensorflow Abadi et al., 2016\n. UMAP McInnes and Healy, 2018\n. zarr Miles et al., 2020\n. xarray Hoyer and Hamman, 2017\nAcknowledgements\nWe thank Kurt Hammerschmidt for providing mouse data prior to publication. We thank Mala Murthy, David Stern, and all members of the Clemens lab for feedback on the manuscript.\nThis work was supported by the DFG through grants 329518246 (Emmy Noether) and 430158535\n(SPP2205) and by the European Research Council (ERC) under the European Union’s Horizon 2020\nresearch and innovation programme (Starting Grant agreement No. 851210 NeuSoSen).\nAdditional information\nFunding\nFunder Grant reference number Author\nDeutsche Forschungsgemeinschaft\n329518246 Jan Clemens\nDeutsche Forschungsgemeinschaft\n430158535 Jan Clemens\nEuropean Research Council 851210 Jan Clemens\nThe funders had no role in study design, data collection and interpretation, or the\ndecision to submit the work for publication.\nAuthor contributions\nElsa Steinfath, Data curation, Validation, Writing - review and editing; Adrian Palacios-Mun˜ oz, Julian\nR Rottscha¨fer, Deniz Yuezak, Data curation, Writing - review and editing; Jan Clemens, Conceptualization, Software, Funding acquisition, Visualization, Methodology, Writing - original draft, Project\nadministration\nAuthor ORCIDs\nElsa Steinfath https://orcid.org/0000-0002-8455-9092\nAdrian Palacios-Mun˜ oz https://orcid.org/0000-0002-9335-7767\nJulian R Rottscha¨fer https://orcid.org/0000-0003-3741-8358\nJan Clemens https://orcid.org/0000-0003-4200-8097\nDecision letter and Author response\nDecision letter https://doi.org/10.7554/eLife.68837.sa1\nAuthor response https://doi.org/10.7554/eLife.68837.sa2\nAdditional files\nSupplementary files\n. Transparent reporting form\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 20 of 25\nTools and resources Neuroscience\nData availability\nAny code and data used during this study is deposited at https://data.goettingen-research-online.\nde/dataverse/das and https://github.com/janclemenslab/das (copy archived at https://archive.softwareheritage.org/swh:1:rev:0cab8a136523bcfd18e419a2e5f516fce9aa4abf). All fitted models are\ndeposited at https://github.com/janclemenslab/das-menagerie (copy archived at https://archive.softwareheritage.org/swh:1:rev:c41f87f8fd77ca122ca6f2dcc4676717526aaf24).\nThe following dataset was generated:\nAuthor(s) Year Dataset title Dataset URL\nDatabase and\nIdentifier\nSteinfath E,\nPalacios-Mun˜ oz A,\nRottscha¨fer JR,\nYuezak D, Clemens\nJ\n2021 Data and models for Steinfath et al.\n2021\nhttps://data.goettingenresearch-online.de/dataverse/das\nGoettingen, das\nThe following previously published datasets were used:\nAuthor(s) Year Dataset title Dataset URL\nDatabase and\nIdentifier\nNicholson D,\nQueen JE, Sober JS\n2017 Bengalese finch song repository http://dx.doi.org/10.\n6084/m9.figshare.\n4805749.v5\nfigshare, 10.6084/m9.\nfigshare.4805749.v5\nIvanenko A,\nWatkins P, Gerven\nMAJ,\nHammerschmidt K,\nEnglitz B\n2020 Data from: Classifying sex and\nstrain from mouse ultrasonic\nvocalizations using deep learning\nhttps://data.donders.ru.\nnl/collections/di/dcn/\nDSC_620840_0003_891?0\nDonders Repository,\ndi.dcn.DSC_620\n840_0003_891\nLandman R 2017 Data from: Close range vocal\ninteraction through trill calls in the\ncommon marmoset (Callithrix\njacchus)\nhttps://osf.io/q4bm3/ Open Science\nFramework, 10.17605/\nOSF.IO/PSWQD\nStern D 2014 Data from: Reported Drosophila\ncourtship song rhythms are artifacts\nof data analysis.\nhttp://research.janelia.\norg/sternlab/rawData.tar\nJanelia, sternlab/\nrawData.tar\nGoffinet J, Brudner\nS, Mooney R,\nPearson J\n2021 Data from: Low-dimensional\nlearned feature spaces quantify\nindividual and group differences in\nvocal repertoires\nhttps://doi.org/10.7924/\nr4gq6zn8w\nDuke Digital\nRepository, 10.7924/\nr4gq6zn8w\nClemens J, Coen P,\nRoemschied FA,\nPereira TD,\nMazumder D,\nAldarondo DE,\nPacheco DA,\nMurthy M\n2018 Data from: Discovery of a New\nSong Mode in Drosophila Reveals\nHidden Structure in the Sensory\nand Neural Drivers of Behavior.\nhttps://doi.org/10.25625/\n8KAKHJ\nGoettingen Research\nOnline, 10.25625/\n8KAKHJ\nReferences\nAbadi M, Barham P, Chen J, Chen Z, Davis A, Dean J, Devin M, Ghemawat S, Irving G, Isard M, Kudlur M,\nLevenberg J, Monga R, Moore S, Murray DG, Steiner B, Tucker P, Vasudevan V, Warden P, Wicke M, et al.\n2016. Tensorflow: A System for Large-Scale Machine Learning OSDI’16 . https://www.usenix.org/system/files/\nconference/osdi16/osdi16-abadi.pdf\nArthur BJ, Sunayama-Morita T, Coen P, Murthy M, Stern DL. 2013. Multi-channel acoustic recording and\nautomated analysis of Drosophila courtship songs. BMC biology 11:11. DOI: https://doi.org/10.1186/1741-\n7007-11-11, PMID: 23369160\nArthur BJ, Ding Y, Sosale M, Khalif F, Kim E, Waddell P, Turaga SC, Stern DL. 2021. Songexplorer: a deep\nlearning workflow for discovery and segmentation of animal acoustic communication signals. bioRxiv.\nDOI: https://doi.org/10.1101/2021.03.26.437280\nBai S, Kolter JZ, Koltun V. 2018. An empirical evaluation of generic convolutional and recurrent networks for\nsequence modeling. arXiv . https://arxiv.org/abs/1803.01271.\nBaker CA, Clemens J, Murthy M. 2019. Acoustic Pattern Recognition and Courtship Songs: Insights from Insects.\nAnnual review of neuroscience 42:129–147. DOI: https://doi.org/10.1146/annurev-neuro-080317-061839,\nPMID: 30786225\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 21 of 25\nTools and resources Neuroscience\nBath DE, Stowers JR, Ho¨ rmann D, Poehlmann A, Dickson BJ, Straw AD. 2014. FlyMAD: rapid thermogenetic\ncontrol of neuronal activity in freely walking Drosophila. Nature Methods 11:756–762. DOI: https://doi.org/10.\n1038/nmeth.2973, PMID: 24859752\nBehr O, von Helversen O. 2004. Bat serenades—complex courtship songs of the sac-winged bat (Saccopteryx\nbilineata). Behavioral Ecology and Sociobiology 56:106–115. DOI: https://doi.org/10.1007/s00265-004-0768-7\nBenichov JI, Vallentin D. 2020. Inhibition within a premotor circuit controls the timing of vocal turn-taking in\nzebra finches. Nature Communications 11:1–10. DOI: https://doi.org/10.1038/s41467-019-13938-0, PMID: 31\n924758\nBennet-Clark HC. 1998. Size and scale effects as constraints in insect sound communication. Philosophical\nTransactions of the Royal Society of London. Series B: Biological Sciences 353:407–419. DOI: https://doi.org/\n10.1098/rstb.1998.0219\nCalhoun AJ, Pillow JW, Murthy M. 2019. Unsupervised identification of the internal states that shape natural\nbehavior. Nature neuroscience 22:1–10. DOI: https://doi.org/10.1038/s41593-019-0533-x, PMID: 31768056\nCampello R, Moulavi D, Sander J. 2013. Density-Based Clustering Based on Hierarchical Density Estimates. In:\nMoulavi D (Ed). Advances in Knowledge Discovery and Data Mining. Heidelberg, Germany: Springer. p. 160–\n172. DOI: https://doi.org/10.1007/978-3-030-75768-7\nCa¨ sar C, Zuberbu¨ hler K, Young RJ, Byrne RW. 2013. Titi monkey call sequences vary with predator location and\ntype. Biology letters 9:20130535. DOI: https://doi.org/10.1098/rsbl.2013.0535, PMID: 24004492\nCator LJ, Arthur BJ, Harrington LC, Hoy RR. 2009. Harmonic convergence in the love songs of the dengue vector\nmosquito. Science 323:1166541. DOI: https://doi.org/10.1126/science.1166541, PMID: 19131593\nChaverri G, Gillam EH, Kunz TH. 2013. A call-and-response system facilitates group cohesion among disc-winged\nbats. Behavioral Ecology 24:481–487. DOI: https://doi.org/10.1093/beheco/ars188\nChen X, He K. 2020. Exploring simple siamese representation learning. arXiv. https://arxiv.org/abs/2011.10566.\nChoi K, Joo D, Kim J. 2017. Kapre: on-gpu audio preprocessing layers for a quick implementation of deep neural\nnetwork models with keras. arXiv . https://arxiv.org/abs/1706.05781.\nChollet F. 2015. Keras. https://keras.io.\nClay Z, Smith CL, Blumstein DT. 2012. Food-associated vocalizations in mammals and birds: what do these calls\nreally mean? Animal Behaviour 83:323–330. DOI: https://doi.org/10.1016/j.anbehav.2011.12.008\nClemens J, Coen P, Roemschied FA, Pereira TD, Mazumder D, Aldarondo DE, Pacheco DA, Murthy M. 2018.\nDiscovery of a New Song Mode in Drosophila Reveals Hidden Structure in the Sensory and Neural Drivers of\nBehavior. Current biology : CB 28:2400–2412. DOI: https://doi.org/10.1016/j.cub.2018.06.011, PMID: 3005730\n9\nClemens J, Hennig RM. 2013. Computational principles underlying the recognition of acoustic signals in insects.\nJournal of computational neuroscience 35:75–85. DOI: https://doi.org/10.1007/s10827-013-0441-0,\nPMID: 23417450\nCleveland WS. 1979. Robust locally weighted regression and smoothing scatterplots. Journal of the American\nStatistical Association 74:829–836. DOI: https://doi.org/10.1080/01621459.1979.10481038\nCoen P, Clemens J, Weinstein AJ, Pacheco DA, Deng Y, Murthy M. 2014. Dynamic sensory cues shape song\nstructure in Drosophila. Nature 507:233–237. DOI: https://doi.org/10.1038/nature13131, PMID: 24598544\nCoen P, Xie M, Clemens J, Murthy M. 2016. Sensorimotor Transformations Underlying Variability in Song\nIntensity during Drosophila Courtship. Neuron 89:629–644. DOI: https://doi.org/10.1016/j.neuron.2015.12.035,\nPMID: 26844835\nCoffey KR, Marx RG, Neumaier JF. 2019. DeepSqueak: a deep learning-based system for detection and analysis\nof ultrasonic vocalizations. Neuropsychopharmacology : official publication of the American College of\nNeuropsychopharmacology 44:1–10. DOI: https://doi.org/10.1038/s41386-018-0303-6, PMID: 30610191\nCohen Y, Nicholson D, Sanchioni A, Mallaber EK, Skidanova V, Gardner TJ. 2020. TweetyNet: a neural network\nthat enables high-throughput, automated annotation of birdsong. bioRxiv. DOI: https://doi.org/10.1101/2020.\n08.28.272088\nDeutsch D, Clemens J, Thiberge SY, Guan G, Murthy M. 2019. Shared Song Detector Neurons in Drosophila\nMale and Female Brains Drive Sex-Specific Behaviors. Current biology : CB 29:3200–3215. DOI: https://doi.\norg/10.1016/j.cub.2019.08.008, PMID: 31564492\nDevlin J, Chang M-W, Lee K, Toutanova K. 2019. Bert: pre-training of deep bidirectional transformers for\nlanguage understanding. arXiv. https://arxiv.org/abs/1810.04805.\nDing Y, Berrocal A, Morita T, Longden KD, Stern DL. 2016. Natural courtship song variation caused by an intronic\nretroelement in an ion channel gene. Nature 536:329–332. DOI: https://doi.org/10.1038/nature19093,\nPMID: 27509856\nDing Y, Lillvis JL, Cande J, Berman GJ, Arthur BJ, Long X, Xu M, Dickson BJ, Stern DL. 2019. Neural evolution of\nContext-Dependent fly song. Current Biology 29:1089–1099. DOI: https://doi.org/10.1016/j.cub.2019.02.019,\nPMID: 30880014\nFitch WT, Neubauer J, Herzel H. 2002. Calls out of chaos: the adaptive significance of nonlinear phenomena in\nmammalian vocal production. Animal Behaviour 63:407–418. DOI: https://doi.org/10.1006/anbe.2001.1912\nFortune ES, Rodrı´guez C, Li D, Ball GF, Coleman MJ. 2011. Neural mechanisms for the coordination of duet\nsinging in wrens. Science 334:666–670. DOI: https://doi.org/10.1126/science.1209867, PMID: 22053048\nGerhardt CH, Huber F. 2002. Acoustic Communication in Insects and Anurans. Illinois, United States: University\nof Chicago Press. DOI: https://doi.org/10.1093/icb/42.5.1080\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 22 of 25\nTools and resources Neuroscience\nGoffinet J, Brudner S, Mooney R, Pearson J. 2021. Low-dimensional learned feature spaces quantify individual\nand group differences in vocal repertoires. eLife 10:e67855. DOI: https://doi.org/10.7554/eLife.67855,\nPMID: 33988503\nGraves A, Jaitly N. 2014. Towards End-To-End speech recognition with recurrent neural networks. International\nConference on Machine Learning 1764–1772. http://proceedings.mlr.press/v32/graves14.pdf.\nGraving JM, Chae D, Naik H, Li L, Koger B, Costelloe BR, Couzin ID. 2019. DeepPoseKit, a software toolkit for\nfast and robust animal pose estimation using deep learning. eLife 8:18. DOI: https://doi.org/10.7554/eLife.\n47994, PMID: 31570119\nGuirguis K, Schorn C, Guntoro A, Abdulatif S, Yang B. 2021. Seld-Tcn: sound event localization & detection via\ntemporal convolutional networks. 2020 28th European Signal Processing Conference (EUSIPCO) 16–20.\nDOI: https://doi.org/10.23919/Eusipco47968.2020.9287716\nHaack B, Markl H, Ehret G. 1983. Sound communication between parents and offspring. In: Willott J. F (Ed). The\nAuditory Psychobiology of the Mouse. Springfield, Illinois: CC Thomas. p. 57–97. DOI: https://doi.org/10.\n18725/OPARU-1174\nHarris CR, Millman KJ, van der Walt SJ, Gommers R, Virtanen P, Cournapeau D, Wieser E, Taylor J, Berg S, Smith\nNJ, Kern R, Picus M, Hoyer S, van Kerkwijk MH, Brett M, Haldane A, del Rı´o JF, Wiebe M, Peterson P, Ge´ rardMarchant P, et al. 2020. Array programming with NumPy. Nature 585:357–362. DOI: https://doi.org/10.1038/\ns41586-020-2649-2\nHe K, Zhang X, Ren S, Sun J. 2016. Deep residual learning for image recognition. 2016 IEEE Conference on\nComputer Vision and Pattern Recognition (CVPR). DOI: https://doi.org/10.1109/CVPR.2016.90\nHoly TE, Guo Z. 2005. Ultrasonic songs of male mice. PLOS Biology 3:e386. DOI: https://doi.org/10.1371/\njournal.pbio.0030386, PMID: 16248680\nHoyer S, Hamman JJ. 2017. Xarray: n-d labeled arrays and datasets in python. Journal of Open Research\nSoftware 5:148. DOI: https://doi.org/10.5334/jors.148\nHunter JD. 2007. Matplotlib: a 2D graphics environment. Computing in Science & Engineering 9:90–95.\nDOI: https://doi.org/10.1109/MCSE.2007.55\nIvanenko A, Watkins P, van Gerven MAJ, Hammerschmidt K, Englitz B. 2020. Classifying sex and strain from\nmouse ultrasonic vocalizations using deep learning. PLOS Computational Biology 16:e1007918. DOI: https://\ndoi.org/10.1371/journal.pcbi.1007918, PMID: 32569292\nJanik VM, Slater PJB. 1998. Context-specific use suggests that bottlenose dolphin signature whistles are\ncohesion calls. Animal behaviour 56:829–838. DOI: https://doi.org/10.1006/anbe.1998.0881, PMID: 9790693\nKingma DP, Ba J. 2015. Adam: a method for stochastic optimization. Conference Paper at ICLR 2015. https://\narxiv.org/pdf/1412.6980.pdf.\nKluyver T, Ragan-Kelley B, Pe´ rez F, Granger B, Bussonnier M, Frederic J, Kelley K, Hamrick J, Grout J, Corlay S,\nIvanov P, Avila D, Abdalla S, Willing C, development team J. 2016. Jupyter notebooks - a publishing format for\nreproducible computational workflows. In: Loizides F, Scmidt B (Eds). Positioning and Power in Academic\nPublishing: Players, Agents and Agendas. Netherlands: IOS Press. p. 87–90.\nKollmorgen S, Hahnloser RHR, Mante V. 2020. Nearest neighbours reveal fast and slow components of motor\nlearning. Nature 577:526–530. DOI: https://doi.org/10.1038/s41586-019-1892-x\nKo¨ ster J, Rahmann S. 2018. Snakemake-a scalable bioinformatics workflow engine. Bioinformatics 34:3600.\nDOI: https://doi.org/10.1093/bioinformatics/bty350, PMID: 29788404\nKoumura T, Okanoya K. 2016. Automatic Recognition of Element Classes and Boundaries in the Birdsong with\nVariable Sequences. PLOS ONE 11:e0159188. DOI: https://doi.org/10.1371/journal.pone.0159188,\nPMID: 27442240\nKrizhevsky A, Sutskever I, Hinton GE. 2012. ImageNet classification with deep convolutional neural networks.\nAdvances in Neural Information Processing Systems 25 (NIPS 2012). https://papers.nips.cc/paper/2012/hash/\nc399862d3b9d6b76c8436e924a68c45b-Abstract.html.\nLandman R, Sharma J, Hyman JB, Fanucci-Kiss A, Meisner O, Parmar S, Feng G, Desimone R. 2020. Close-range\nvocal interaction in the common marmoset (Callithrix jacchus). PLOS ONE 15:e0227392. DOI: https://doi.org/\n10.1371/journal.pone.0227392, PMID: 32298305\nLipkind D, Marcus GF, Bemis DK, Sasahara K, Jacoby N, Takahasi M, Suzuki K, Feher O, Ravbar P, Okanoya K,\nTchernichovski O. 2013. Stepwise acquisition of vocal combinatorial capacity in songbirds and human infants.\nNature 498:104–108. DOI: https://doi.org/10.1038/nature12173, PMID: 23719373\nLong MA, Fee MS. 2008. Using temperature to analyse temporal dynamics in the songbird motor pathway.\nNature 456:189–194. DOI: https://doi.org/10.1038/nature07448, PMID: 19005546\nMamalet F, Garcia C. 2012. Simplifying ConvNets for Fast Learning. In: Garcia C (Ed). Artificial Neural Networks\nand Machine Learning – ICANN 2012. Heidelberg: Springer. p. 58–65. DOI: https://doi.org/10.1007/978-3-642-\n33266-1_8\nMathis A, Mamidanna P, Cury KM, Abe T, Murthy VN, Mathis MW, Bethge M. 2018. DeepLabCut: markerless\npose estimation of user-defined body parts with deep learning. Nature Neuroscience 21:1281–1289.\nDOI: https://doi.org/10.1038/s41593-018-0209-y, PMID: 30127430\nMathis A, Biasi T, Schneider S, Yu¨ ksekgo¨ nu¨ l M, Rogers B, Bethge M, Mathis M. 2021. Pretraining boosts Out-ofDomain robustness for pose estimation. 2021 IEEE Winter Conference on Applications of Computer Vision\n(WACV). DOI: https://doi.org/10.1109/WACV48630.2021.00190\nMcFee B, Raffel C, Liang D, Ellis DP, McVicar M, Battenberg E, Nieto O. 2015. Librosa: audio and music signal\nanalysis in python. Proceedings of the 14th Python in Science Conference. https://conference.scipy.org/\nproceedings/scipy2015/pdfs/brian_mcfee.pdf.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 23 of 25\nTools and resources Neuroscience\nMcInnes L, Healy J, Astels S. 2017. Hdbscan: hierarchical density based clustering. The Journal of Open Source\nSoftware 2:205. DOI: https://doi.org/10.21105/joss.00205\nMcInnes L, Healy J. 2018. Umap: uniform manifold approximation and projection for dimension reduction. arXiv.\nhttps://arxiv.org/abs/1802.03426.\nMcKinney W. 2010. Data structures for statistical computing in python. Proc. of the 9th Python in Science Conf.\n(SCIPY 2010). https://conference.scipy.org/proceedings/scipy2010/pdfs/mckinney.pdf.\nMiles A, Kirkham J, Durant M, Bourbeau J, Onalan T, Hamman J, Patel Z, shikharsg R, Schut V, de Andrade ES,\nAbernathey R, Noyes C, Tran T, Saalfeld S, Swaney J, Moore J, Jevnik J, Kelleher J, Funke J, Sakkis G, et al.\n2020. Zarr-Developers/zarr-Python, Zenodo, v2.4.0 https://github.com/zarr-developers/zarr-python..\nMorley EL, Jonsson T, Robert D. 2018. Auditory sensitivity, spatial dynamics, and amplitude of courtship song in\nDrosophila melanogaster. The Journal of the Acoustical Society of America 144:734–739. DOI: https://doi.org/\n10.1121/1.5049791, PMID: 30180716\nNegri LH, Vestri C. 2017. Lucashn/peakutils, Zenodo, v1.1.0 https://github.com/lucashn/peakutils..\nNeunuebel JP, Taylor AL, Arthur BJ, Egnor SE. 2015. Female mice ultrasonically interact with males during\ncourtship displays. eLife 4:e06203. DOI: https://doi.org/10.7554/eLife.06203, PMID: 26020291\nNicholson D, Queen JE, Sober, S J. 2017. Bengalese finch song repository. figshare. DOI: https://doi.org/10.6084/\nm9.figshare.4805749.v5\nOikarinen T, Srinivasan K, Meisner O, Hyman JB, Parmar S, Fanucci-Kiss A, Desimone R, Landman R, Feng G.\n2019. Deep convolutional network for animal sound classification and source attribution using dual audio\nrecordings. The Journal of the Acoustical Society of America 145:654–662. DOI: https://doi.org/10.1121/1.\n5087827, PMID: 30823820\nOkobi DE, Banerjee A, Matheson AMM, Phelps SM, Long MA. 2019. Motor cortical control of vocal interaction in\nneotropical singing mice. Science 363:983–988. DOI: https://doi.org/10.1126/science.aau9480, PMID: 3081\n9963\nPedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, Weiss R,\nDubourg V, Vanderplas J, Passos A, Cournapeau D, Brucher M, Perrot M, Duchesnay E´\n. 2011. Scikit-learn:\nmachine learning in python. Journal of Machine Learning Research 12:2825–2830.\nPereira TD, Aldarondo DE, Willmore L, Kislin M, Wang SS, Murthy M, Shaevitz JW. 2019. Fast animal pose\nestimation using deep neural networks. Nature methods 16:1–125. DOI: https://doi.org/10.1038/s41592-018-\n0234-5, PMID: 30573820\nPerez F, Granger BE. 2007. IPython: a system for interactive scientific computing. Computing in Science &\nEngineering 9:21–29. DOI: https://doi.org/10.1109/MCSE.2007.53\nRaghu M, Zhang C, Kleinberg J, Bengio S. 2019. Transfusion: understanding transfer learning for medical\nimaging. NeurIPS. https://paperswithcode.com/paper/transfusion-understanding-transfer-learning.\nSainburg T, Thielk M, Gentner TQ. 2020. Finding, visualizing, and quantifying latent structure across diverse\nanimal vocal repertoires. PLOS Computational Biology 16:e1008228. DOI: https://doi.org/10.1371/journal.pcbi.\n1008228, PMID: 33057332\nSangiamo DT, Warren MR, Neunuebel JP. 2020. Ultrasonic signals associated with different types of social\nbehavior of mice. Nature neuroscience 23:1–12. DOI: https://doi.org/10.1038/s41593-020-0584-z, PMID: 32066\n980\nSrivastava KH, Holmes CM, Vellema M, Pack AR, Elemans CP, Nemenman I, Sober SJ. 2017. Motor control by\nprecisely timed spike patterns. PNAS 114:1171–1176. DOI: https://doi.org/10.1073/pnas.1611734114, PMID: 2\n8100491\nStern DL. 2014. Reported Drosophila courtship song rhythms are artifacts of data analysis. BMC Biology 12:38.\nDOI: https://doi.org/10.1186/1741-7007-12-38, PMID: 24965095\nStern DL, Clemens J, Coen P, Calhoun AJ, Hogenesch JB, Arthur BJ, Murthy M. 2017. Experimental and\nstatistical reevaluation provides no evidence for Drosophila courtship song rhythms. PNAS 114:9978–9983.\nDOI: https://doi.org/10.1073/pnas.1707471114, PMID: 28851830\nStowers JR, Hofbauer M, Bastien R, Griessner J, Higgins P, Farooqui S, Fischer RM, Nowikovsky K, Haubensak\nW, Couzin ID, Tessmar-Raible K, Straw AD. 2017. Virtual reality for freely moving animals. Nature methods 14:\n995–1002. DOI: https://doi.org/10.1038/nmeth.4399, PMID: 28825703\nTabler JM, Rigney MM, Berman GJ, Gopalakrishnan S, Heude E, Al-Lami HA, Yannakoudakis BZ, Fitch RD, Carter\nC, Vokes S, Liu KJ, Tajbakhsh S, Egnor SR, Wallingford JB. 2017. Cilia-mediated hedgehog signaling controls\nform and function in the mammalian larynx. eLife 6:e19153. DOI: https://doi.org/10.7554/eLife.19153, PMID: 2\n8177282\nTachibana RO, Kanno K, Okabe S, Kobayasi KI, Okanoya K. 2020. USVSEG: A robust method for segmentation of\nultrasonic vocalizations in rodents. PLOS ONE 15:e0228907. DOI: https://doi.org/10.1371/journal.pone.\n0228907, PMID: 32040540\nTschida K, Mooney R. 2012. The role of auditory feedback in vocal learning and maintenance. Current opinion in\nneurobiology 22:320–327. DOI: https://doi.org/10.1016/j.conb.2011.11.006, PMID: 22137567\nvan den Oord A, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, Kalchbrenner N, Senior A, Kavukcuoglu\nK. 2016. Wavenet: a generative model for raw audio. arXiv. https://arxiv.org/abs/1609.03499.\nVan Segbroeck M, Knoll AT, Levitt P, Narayanan S. 2017. MUPET-Mouse Ultrasonic Profile ExTraction: A Signal\nProcessing Tool for Rapid and Unsupervised Analysis of Ultrasonic Vocalizations. Neuron 94:465–485.\nDOI: https://doi.org/10.1016/j.neuron.2017.04.005, PMID: 28472651\nVirtanen P, Gommers R, Oliphant TE, Haberland M, Reddy T, Cournapeau D, Burovski E, Peterson P, Weckesser\nW, Bright J, van der Walt SJ, Brett M, Wilson J, Millman KJ, Mayorov N, Nelson ARJ, Jones E, Kern R, Larson E,\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 24 of 25\nTools and resources Neuroscience\nCarey CJ, et al. 2020. SciPy 1.0: fundamental algorithms for scientific computing in Python. Nature methods\n17:261–272. DOI: https://doi.org/10.1038/s41592-019-0686-2, PMID: 32015543\nWarren MR, Clein RS, Spurrier MS, Roth ED, Neunuebel JP. 2020. Ultrashort-range, high-frequency\ncommunication by female mice shapes social interactions. Scientific Reports 10:1–14. DOI: https://doi.org/10.\n1038/s41598-020-59418-0\nWaskom M, Botvinnik O, O’Kane D, Hobson P, Lukauskas S, Gemperline DC, Augspurger T, Halchenko Y, Cole\nJB, Warmenhoven J, de Ruiter J, Pye C, Hoyer S, Vanderplas J, Villalba S, Kunter G, Quintero E, Bachant P,\nMartin M, Meyer K, et al. 2017. Mwaskom/seaborn, Zenodo, v0.8.1. https://github.com/mwaskom/seaborn\nWeiss M, Hultsch H, Adam I, Scharff C, Kipper S. 2014. The use of network analysis to study complex animal\ncommunication systems: a study on nightingale song. Proceedings of the Royal Society B: Biological Sciences\n281:20140460. DOI: https://doi.org/10.1098/rspb.2014.0460\nYu F, Koltun V. 2016. Multi-scale context aggregation by dilated convolutions. arXiv. https://arxiv.org/abs/1511.\n07122.\nSteinfath et al. eLife 2021;10:e68837. DOI: https://doi.org/10.7554/eLife.68837 25 of 25\nTools and resources Neuroscience", "affiliations": [{"country": "Germany", "discipline": "Neuroscience", "university": "European Neuroscience Institute"}, {"country": "Germany", "discipline": "Neuroscience", "university": "University of Göttingen"}], "species_categories": ["Insect", "Terrestrial Mammal", "Other", "Bird"], "specialized_species": ["Drosophila melanogaster", "Mus musculus", "Callithrix jacchus", "Padda oryzivora", "Taeniopygia guttata"], "computational_stages": ["Data Collection", "Pre-processing", "Meaning Identification"], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.887465", "updated_at": "2026-01-13T16:11:25.348191", "committed_at": "2026-01-13T14:11:04.186346"}
{"id": "12ebc1f3-6a84-4d9c-87d5-28051444e4c3", "title": "ANIMAL-SPOT enables animal-independent signal detection and classification using deep learning", "authors": ["Bergler, Christian", "Smeele, Simeon Q", "Tyndel, Stephen A", "Barnhill, Alexander", "Ortiz, Sara T", "Kalan, Ammie K", "Cheng, Rachael Xi", "Brinkl{\\o}v, Signe", "Osiecka, Anna N", "Tougaard, Jakob", "others"], "year": "2022", "journal": "Scientific Reports", "abstract": "", "doi": "", "analysis_notes": "1\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports\nANIMAL‑SPOT enables\nanimal‑independent signal\ndetection and classification using\ndeep learning\nChristian Bergler1*, Simeon Q. Smeele2,3,4, StephenA.Tyndel2,5, Alexander Barnhill1\n,\nSaraT. Ortiz6\n, Ammie K. Kalan7\n, Rachael Xi Cheng8\n, Signe Brinkløv9\n, Anna N. Osiecka10,\nJakobTougaard11, Freja Jakobsen12, MagnusWahlberg12, Elmar Nöth1\n, Andreas Maier1 &\nBarbara C. Klump2*\nBioacoustic research spans a wide range of biological questions and applications, relying on\nidentification of target species or smaller acoustic units, such as distinct call types. However, manually\nidentifying the signal of interest is time-intensive, error-prone, and becomes unfeasible with large\ndata volumes. Therefore, machine-driven algorithms are increasingly applied to various bioacoustic\nsignal identification challenges. Nevertheless, biologists still have major difficulties trying to transfer\nexisting animal- and/or scenario-related machine learning approaches to their specific animal datasets\nand scientific questions. This study presents an animal-independent, open-source deep learning\nframework, along with a detailed user guide. Three signal identification tasks, commonly encountered\nin bioacoustics research, were investigated: (1) target signal vs. background noise detection, (2)\nspecies classification, and (3) call type categorization. ANIMAL-SPOT successfully segmented humanannotated target signals in data volumes representing 10 distinct animal species and 1 additional\ngenus, resulting in a mean test accuracy of 97.9%, together with an average area under the ROC\ncurve (AUC) of 95.9%, when predicting on unseen recordings. Moreover, an average segmentation\naccuracy and F1-score of 95.4% was achieved on the publicly available BirdVox-Full-Night data corpus.\nIn addition, multi-class species and call type classification resulted in 96.6% and 92.7% accuracy on\nunseen test data, as well as 95.2% and 88.4% regarding previous animal-specific machine-based\ndetection excerpts. Furthermore, an Unweighted Average Recall (UAR) of 89.3% outperformed the\nmulti-species classification baseline system of the ComParE 2021 Primate Sub-Challenge. Besides\nanimal independence, ANIMAL-SPOT does not rely on expert knowledge or special computing\nresources, thereby making deep-learning-based bioacoustic signal identification accessible to a broad\naudience.\nIn order to gain deeper insights and a better understanding about animal communication, it is imperative to\nidentify vocalization prototypes, derive linguistic patterns, and correlate acoustic paradigms with corresponding\nbehavioral observations. Therefore, it is mandatory to perform in-depth data analysis of large-scale bioacoustic\nOPEN\n1\nPattern Recognition Lab, Department of Computer Science, Friedrich-Alexander-Universität Erlangen-Nürnberg,\n91058 Erlangen, Germany. 2\nCognitive and Cultural Ecology Lab, Max Planck Institute of Animal Behavior,\n78315 Radolfzell, Germany. 3\nDepartment of Human Behavior, Ecology and Culture, Max Planck Institute\nfor Evolutionary Anthropology, 04103 Leipzig, Germany. 4\nBiology Department, University of Konstanz,\n78464 Constance, Germany. 5\nDepartment of Natural Resources and Environmental Sciences, University of Illinois\nUrbana-Champaign, Champaign, IL, United States. 6\nMax Planck Institute for Biological Intelligence, in Foundation,\nSeewiesen Eberhard-Gwinner-Strasse, 82319 Starnberg, Germany. 7\nDepartment of Anthropology, University of\nVictoria, Victoria, BC V8P 5C2, Canada. 8\nLeibniz Institute for Zoo and Wildlife Research, Alfred‑Kowalke‑Straße\n17, 10315 Berlin, Germany. 9\nDepartment of Bioscience, Wildlife Ecology, Aarhus University, 8410 Rønde,\nDenmark. 10Department of Vertebrate Ecology and Zoology, Faculty of Biology, University of Gdańsk,\n80‑308 Gdańsk, Poland. 11Department of Bioscience, Marine Mammal Research, Aarhus University, 4000 Roskilde,\nDenmark. 12Department of Biology, University of Southern Denmark, 5230 Odense, Denmark. *email:\nchristian.bergler@fau.de; bklump@ab.mpg.de\n2\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\ndata archives in order to draw statistically significant and representative hypotheses regarding the vocal repertoire of a particular species. Passive Acoustic Monitoring (PAM) concepts1–3\n are widely used to acquire massive\nbioacoustic data collections4–7\n, without affecting the natural animal habitats8\n and thus significantly increase the\nprobability to observe all natural communicative patterns, following the observer’s paradox principle9\n. Furthermore, PAM-based approaches strongly benefit from decreasing costs for recording equipment and data\nstorage10–13, combined with recent technological advances14–20. However, time- and human-resource restrictions prohibit a profound and comprehensive manual data analysis. Consequently, machine (deep) learning\napproaches are increasingly applied in bioacoustic research21,22 and have shown to be a productive avenue to\nidentify target animal species (e.g., marine mammals23–26, birds27,28, bats29, mosquitos30), smaller acoustic units\nsuch as call types (e.g., bird call types27,31) and group-level differences within target animal species (e.g., killer\nwhale pods32). Despite a growing deployment of various machine (deep) learning techniques in the field of bioacoustics, essential research tasks such as target species identification and call type classification still prove to\nbe extremely difficult and challenging.\nMachine (deep) learning approaches are often designed for a particular animal species and lack data-related\nmodel adaption and hyperparameter fine-tuning options. In addition, the software and/or source code is often\nnot publicly available, combined with missing or insufficient user guidelines which describe required data preparation, network training setup, and model evaluation. It thereby often precludes not just a general transfer to\nanimal- and user-specific research questions, but mainly prevents non-computer science operators to train their\nown use-case and animal-specific models, which in turn significantly hampers progress in research on animal\ncommunication. In this study, we introduce ANIMAL-SPOT, an open-source machine learning framework that\nenables biologists to independently train and evaluate animal-specific deep learning-based classification models\nin order to address fundamental biological research questions, including target/noise detection and/or species/\ncall type identification.\nThree typical scenarios present themselves when attempting to identify the vocalizations of a target species\nor individual: (1) The target signal appears without confounding factors such as other similar vocalizations\nand the task is to determine the target signal with respect to background noise, (2) the target signal appears in\nconjunction with other, dissimilar, species-specific vocalizations and the signal of interest must be distinguished\nbetween other bioacoustic signals and background noise, and (3) the target signal appears with other signals,\nsome of which share similar properties to the target vocalizations and the model must differentiate between\nsimilar signals, dissimilar signals, as well as background noise. The approach described here allows a researcher\nto address all of these tasks, with slight differences in data structure as well as usage of the trained models.\nA detailed user guide33, provided in conjunction with this work which describes the data setup as well as\nmodel configuration, allows users to create and apply models with no prior deep learning knowledge. The core\ndeep learning workflow took inspiration from ORCA-SPOT34, a ResNet-1835-based Convolutional Neural Network (CNN), originally designed for segmenting killer whale (Orcinus orca) vocalizations from environmental\nbackground noise. ANIMAL-SPOT has been adapted and extended to become an animal-independent deep\nlearning framework, evaluating bioacoustic target versus environmental noise detection for 10 species-specific\ndata volumes and 1 additional genus-based dataset, next to the publicly available BirdVox-Full-Night36 repository. In addition, multi-species classification has been performed in two different scenarios: (1) as a downstream\nprocess, using previously machine-detected and extracted genus-specific target signals, and (2) as a stand-alone\nprocedure, analyzing the Computational Paralinguistics Challenge Primate (ComParE-PRS)37,38 multi-species\ndata volume. Moreover, multi-class call type classification has been exemplarily conducted for a single species,\nusing the same downstream approach. The ANIMAL-SPOT workflow is generalizable, enabling unparalleled\nflexibility in processing task- and animal-specific bioacoustic data corpora. Figure 1 visualizes all animal speciesspecific spectrograms (10 different species, 1 additional genus), representing a single vocalization event.\nIn summary, ANIMAL-SPOT provides a publicly-available animal-independent bioacoustic machine learning\nenvironment, which allows scientists, regardless of their technical backgrounds, to train and evaluate speciesspecific deep neural networks, supported by detailed user guidelines, in order to answer fundamental biological\nresearch questions (target/sound detection, species classification, and call type recognition). To the best of the\nauthors’ knowledge, this is the first study presenting an animal-independent and publicly-available deep learning framework, evaluated across many bioacoustic signal identification scenarios. As input data, we use many\nannotated datasets from a broad range of animal species and provide evaluation results using these as well as\npublicly available species detection and classification challenge data corpora.\nMaterials and methods\nBioacoustic signal identification and classification scenarios. Signal identification can be performed at different levels: (1) taxonomic group (e.g., all birds), (2) species (e.g., monk parakeet), or (3) call type\n(e.g., contact call). The level highly influences data preparation and classification complexity. Raising taxonomic\nspecialization simultaneously leads to an increase of the labeled data granularity being required for an adequate\nnetwork training. Furthermore, classification intricacy grows with the level of taxonomic detail. The network\nhas to learn and derive features, being robust against all potential types of environmental noise as well as other\nanimal sounds, except the signals of interest, including within-species variation. The level of taxonomy also\naffects the amount of chosen network output classes—binary detection (e.g., delphinidae vs. noise) or multi-class\nclassification (killer whale vs. white-sided dolphin vs. bottlenose dolphin vs. noise)—which in turn impacts classification complexity. An adequate identification scenario is therefore determined by the biological use-case and\ntaxonomic depth, in combination with the available data material, recorded via active/passive acoustic monitoring. Regarding the animal corpora, two initial data material situations are possible: (1) dataset only contains\nbackground noise and target signals, or (2) dataset includes background noise, target signals, and other vocaliza-\n3\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\ntions that often resemble the target signal. Consequently, the following classification procedures are conceivable:\n(1) binary target/noise detection—isolating environmental noise from the taxonomic-dependent animal signals\naccording to the above mentioned data scenarios, or (2) multi-class species/call type recognition—classifying\nbetween multiple target species or call types, combined with the illustrated potential data situations. To ensure\na robust, animal-independent identification procedure, a binary target/noise detection at the desired taxonomic\nlevel (e.g., animal genus) has to be conducted first, to remove noise and other irrelevant animal vocalizations\nin advance. Taxonomic depth leads to an increasing spectral closeness between signals being represented in the\nnoise class, which results in less distinctive network features separating both classes. Depending on the initial\nmodel performance for the chosen taxonomic rank, target/noise data distribution might be restructured with\nrespect to a higher, more generic taxonomic level (e.g. genus to order-level). Based on the respective detection\nresult, subsequent multi-class classification can be conducted with respect to more specific taxonomic ranks,\nsuch as animal species (e.g., Blue-winged vs. Golden-winged warbler) or different call types (e.g., monk parakeet\nalarm, contact, and other calls), ending up in a multi-stage classification procedure. ANIMAL-SPOT is also\ncapable of performing recognition with respect to different species-specific regional differences (dialects) as well\nas individual identification. Sufficient representative data for dialects of interest or individual-specific vocalizations, in the same way as for the other multi-class classification problems described here, is the only precluding\nfactor. Filtering away noise and other animal vocalizations via the two-step approach enables focus on analysis\nof regional differences (dialects) and acoustic identification of individuals. Instructions on model configuration\nand necessary data structure will be further detailed in the user guide33 with examples.\nAnimal species and recording setup. In order to show and prove animal independence, 10 different\nspecies and 1 additional genus within the chordate phylum were chosen. The overall goal was to test model\nrobustness for as many different habitat types (urban parks, marine reserve, arctic landice), frequency ranges\n(30 Hz for Atlantic cod to 100,000 Hz for Pygmy pipistrelle), vocalization durations (echolocation sweeps in ms\nto long roars of multiple seconds), signal-to-noise ratios (urban parks versus noise isolated laboratory), noise\ncharacteristics (underwater noise, human narrations, other species), as well as recording setups (passive acoustic\nmonitoring—e.g., Harbour seals—versus focal follows—e.g., Blue-/Golden-winged warblers). A detailed summary regarding all animal-specific recording and data collection setups, utilized within this study, is given in\nSupplementary Table S1.\nBioacoustic data material. No animals were approached for this study specifically but rather all data used\nwere collected by distinct research teams under their own ethics guidelines. In case of binary detection, each\nspecies/genus target and noise was manually annotated. The target class contained only vocalizations produced\nby the target species/genus (see Table 1). In cases where further sub-classification was envisioned (species level\nFigure 1.  Animal-specific data (10 different species, 1 additional genus) utilized to investigate the ANIMALSPOT framework (created via Inkscape39, Version 0.92.3).\n4\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nfor the two warblers—Table 2, call type level regarding monk parakeets—Table 3), these were labeled as well,\nbut all assigned to the target class. The noise class included all other sound segments, such as environmental/\nbackground noise, human narrations, and other animal sounds. While both the number of annotated segments\nand the class distribution differed for each species, the ratio between vocalization and noise ranges from ≈20%\nup to ≈57% for all listed data archives. To perform embedded noise augmentation, additional noise segments\nwere provided for some of the species (see Table 1). ANIMAL-SPOT was trained and evaluated in three different experiments: (1) detection between target and noise to separate noise from valuable animal signals, and (2)\nmulti-class species classification, and (3) multi-class call type identification. Besides the annotated detection data\nTable 1.  Animal-specific data corpora and distribution. *Additional noise augmentation training samples:\n[1.1] cockatiel—180 (2.87 min.), [1.2] monk parakeet—105 (1.08 min.), [1.3] Blue-/Golden-winged\nwarbler—500 (10.03 min.), [1.4] Harbour seal—2,531 (32.74 min.), [1.5] killer whale—6715 (258.27 min.),\n[1.6] Pygmy pipistrelle—543 (1.80 min.), [1.7] chimpanzee—1446 (40.34 min.). 1Samples (smp[#]), 2\nsample\nduration in minutes (smp[min.]), 3\nsample percentage (smp[%]), 4\nsummed target/noise duration of the three\nunseen test recordings (\u001fr[min.]). Significant values are in bold.\nDataset\nLabel type\nTarget label Noise label \u001f labels\nsmp[#]1 smp[min.]2 smp[%]3 \u001fr[min.]4 smp[#]1 smp[min.]2 smp[%]3 \u001fr[min.]4 smp[#]1 smp[min.]2 smp[%]3 \u001fr[min.]4\nCockatiel* 1271 12.41 40.9 2.46 1840 41.68 59.1 179.10 3111 54.09 100.0 181.56\nSulphur-crested\ncockatoo 1495 15.26 41.1 3.37 2145 34.99 58.9 46.81 3640 50.25 100.0 50.18\nPeach-fronted\nconure 1174 12.35 55.2 0.22 952 8.88 44.8 4.53 2126 21.23 100.0 4.75\nMonk parakeet* 3133 17.20 46.4 0.63 3612 75.25 53.6 12.63 6745 92.45 100.0 13.26\nBlue-/goldenwinged warbler* 1616 48.99 32.0 5.43 3431 95.10 68.0 14.57 5047 144.09 100.0 20.00\nChinstrap\npenguin 906 4.86 20.8 0.82 3454 15.40 79.2 3.26 4360 20.26 100.0 4.08\nAtlantic cod 382 3.14 30.6 0.19 867 6.00 69.4 20.82 1249 9.14 100.0 21.01\nHarbour seal* 2900 55.18 56.4 7.79 2245 58.67 43.6 22.21 5145 113.85 100.0 30.00\nKiller whale34* 17,104 649.45 27.8 20.64 44,323 2076.36 72.2 121.49 61,427 2725.81 100.0 142.13\nPygmy pipistrelle* 1570 0.18 31.0 0.10 3490 4.94 69.0 1.11 5060 5.12 100.0 1.21\nChimpanzee* 7079 231.17 57.2 2.89 5305 174.44 42.8 87.11 12,384 405.61 100.0 90.00\nBirdVox-FullNight36 35,402 295.02 50.0 − 35,402 295.02 50.0 − 70,804 588 100.0 −\nTable 2.  Blue-/golden-winged warbler data distribution. Significant values are in bold.\nLabel type\nDistribution\nSamples Min. %-samples\nBlue-winged warbler 707 21.16 22.4\nGolden-winged warbler 909 27.83 28.8\nOther bird 542 13.39 17.2\nNoise 1000 26.10 31.6\n\u001f 3158 88.48 100.0\nTable 3.  Monk parakeet call type data and distribution. Significant values are in bold.\nLabel type\nDistribution\nSamples Min. %-samples\nAlarm call 798 5.61 24.5\nContact call 689 3.61 21.2\nOther call 764 3.06 23.5\nNoise 1000 25.65 30.8\n\u001f 3251 37.93 100.0\n5\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\ncorpora, reported in Table 1, three additional unseen recordings were provided for the 10 different species and\n1 extra genus, with low, medium, and high appearance of target vocalizations. These were additionally used to\nvalidate model performance. In order to prove detection accuracy even further, an additional publicly-available\ndataset was utilized—the BirdVox-Full-Night data archive—presented by Lostanlen et al.36 for the evaluation\nof approaches designed to detect avian flight calls (see Table 1, last row). The original dataset consists of 9.8 h\nof audio, recorded by six sensors placed in the area around Ithaca, New York, which were manually annotated\nresulting in 35,402 500 ms-long flight calls of nocturnally migrating birds of about 25 species of passerines.\nTo balance the dataset an equal number of 500-ms-long noise samples were added to the dataset, resulting in\n70,804 files (see Table 1, last row). Regarding the BirdVox-Full-Night archive, there were no additional unseen\nrecordings, compared to the remaining data repositories listed in Table 1. Multi-class species classification was\nconducted between Blue-winged and Golden-winged warbler (see Table  2). In addition the Computational\nParalinguistics Challenge Primate (ComParE-PRS)37,38 dataset was used to distinguish between four different\nprimate species (see Table 4). The dataset includes over 10,000 annotated vocalizations from Chimpanzees (Pan\ntroglodytes), Mandrills (Mandrillus sphinx), Red-capped mangabeys (Cercocebus torquatus), and a mixed group\nof Guenons (Cercopithecus spp.). Additionally, exactly the same number of noise samples as vocalizations were\nextracted to make up the noise class38. Multi-class call type classification was computed for three main call type\nclasses of monk parakeet vocalizations including alarm, contact, and other calls, listed in Table 3. Across all\nmulti-class scenarios, the existing target class repertoire was extended by an additional noise category to simulate real-world scenarios, as well as cover and handle potential false alarms caused within the first detection stage\n(see Supplementary Figs. S5 and S6).\nDeep learning concepts and network architectures. Convolutional Neural Networks (CNNs) were\nutilized in order to identify animal vocalizations of interest. A CNN is an end-to-end deep learning architecture\nbased on the principles of pattern recognition including a feature learning and classification component being\nable to efficiently process the complexity of 2-dimensional input data (e.g., images, spectrograms)34,40,41. Convolutional layers are responsible for feature learning, while the classification part is done by the fully connected\nlayers40. Convolutional layers embed and represent the following important concepts34,40: (1) local receptive\nfields, (2) shared weights, and (3) subsampling (pooling). Due to the fact that convolutional and pooling layers only compute linear operations, CNNs integrate activation layers (e.g., Rectified Linear Unit34,42) as well as\nnormalization layers (e.g., batch normalization34,43) to handle the non-linearity within the data and to ensure a\nmore stabilized and regularized training procedure34. Several repetitive sequentially ordered sequences of convolutional, pooling, normalization, and activation layers lead to extracted and learned features which are used as\ninput for the fully-connected layer projecting the features on the respective output classes34. The core concept of\nthe presented deep learning framework is based on a so-called Residual Network (ResNet)35. A ResNet is a network architecture, which is built up from different concatenated residual layers35. A residual layer is constructed\nfrom an arrangement of building blocks which in turn consist of weight (e.g., convolutional, fully-connected),\nnormalization (e.g. batch-norm43), and activation layers (e.g., ReLU42), as well as residual-/skip-connections.\nDue to this residual-/skip-connection technique it is possible to learn a residual mapping F(x) = H(x) − x\ninstead of a direct underlying mapping H(x) for a given input x35, enabling to counteract the accuracy degradation problem (accuracy decrease after saturation region, by further increasing network depth, compared to shallower versions of the network35) and training deeper nets. Different numbers and structures of building blocks\nresult in various ResNet architectures. Well known and established ResNet models are ResNet18, ResNet34,\nResNet50, ResNet101, and ResNet15235. For more detailed insights about residual learning/networks see He\net al.35.\nANIMAL–SPOT. The deep learning framework consists of a ResNet18-based CNN, derived from ORCASPOT34, our previous killer whale deep detection model, which has been adapted and extended to handle all\nkinds of vocalizing animals. The initial max-pooling layer within the traditional ResNet18 architecture has been\nremoved to avoid losing too much resolution at the early stage of the training process34. Depending on the size\nof the temporal domain T of the input spectrogram, defined by the chosen training sequence length and corresponding FFT-settings, a 512-large global-averaged pooled feature vector, derived from the 512 × F × T feature\nmaps of the last residual layer (see Fig. 2), is generated and mapped to a subsequent fully-connected layer34. In\nTable 4.  The INTERSPEECH 2021 Computational Paralinguistics Challenge Primate (ComParE-PRS)37,38\ndata archive and distribution. Significant values are in bold.\nLabel type\nDistribution\nSamples Min. %-samples\nChimpanzee 6652 59.76 32.0\nMandrills 2623 13.14 12.7\nRed-capped mangabeys 627 5.31 3.0\nGuenons 476 1.69 2.3\nNoise 10,378 172.97 50.0\n\u001f 20,756 252.87 100.0\n6\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\norder to solve the final n-class classification problem the 512 hidden units of the fully-connected layer are processed onto an output layer consisting of n output nodes depending on the classification task (e.g., two classes\nfor target/noise detection, or multiple classes for species/call type classification). ANIMAL-SPOT is capable of\nhandling any number of output classes, and consequently dealing with multi-class classification scenarios as\nwell. Moreover, ANIMAL-SPOT integrates a refactored version of the entire data parsing and pre-processing\npipeline of ORCA-SPOT34, next to additional normalization techniques, in order to handle and fulfill all needed\nprerequisites required for dealing with various animal data sources (see Fig. 1 and Tables 1, 2, 3, 4), in combination with varying classification scenarios. Although advances in neural network structures have been made in\nrecent years, the focus of ANIMAL-SPOT is not a specific type of architecture (e.g., ResNet18, etc.). Instead, the\naim of ANIMAL-SPOT is to provide an open-source, animal-independent, and expandable machine learning\nframework, together with a robust and efficient data preprocessing pipeline. We add support by profound user\nguidelines to address the broadest possible audience. In addition, the capacity of the model used here is comparatively small, which facilitate researchers who may not have the opportunity to access powerful hardware,\nto train and evaluate their own animal- and task-specific models. Within the ANIMAL-SPOT framework it is\npossible to integrate any kind of architectural model designs, allowing the deployment of other novel and userpreferred deep neural network concepts.\nData preprocessing. Independent of the classification scenario all species and their corresponding data\nrepositories (see Tables 1, 2, and 3), followed the same generic data preprocessing pipeline. The core functions\nare applicable for all animals, however each species requires an animal-specific parameter set (see Supplementary Table S2) in order to guarantee valid data preparation and representation of the corresponding signal characteristics (e.g., typical vocalization duration, frequency range, sampling rate, Fast-Fourier-Transform (FFT)\nparameters, etc.). The entire preprocessing pipeline of ANIMAL-SPOT consists of the following steps: (1) conversion to mono and re-sampling, (2) Short-Time-Fourier-Transform (STFT) to convert the time signal into\na F  ×  T-large power-spectrogram using an animal-characteristic FFT window-length and step-size, where F\ncharacterizes the frequency domain and T describes the time domain, (3) integrated and concurrent signal augmentation with respect to the previous derived F × T-large power-spectrogram applying uniformly distributed\nrandom scalings including intensity, pitch, and time augmentation within given intervals (see Supplementary\nTable S2), where the default interval might slightly vary from species to species, (4) linear frequency compression (nearest neighbor, 256 frequency bins) representing a frequency range between fmin and fmax, while ignoring other frequency regions, chosen according to the typical spectral vocalization areas of the corresponding\nanimals, resulting in a 256 × T compressed power spectrogram, (5) noise augmentation by adding a pitch-/\ntime-augmented and frequency-compressed noise spectrogram utilizing a uniformly distributed randomly chosen signal-to-noise ratio (SNR), (6) power-spectrogram conversion to decibel (dB) scale, (7) 0/1-min/max- or\n0/1-dB-normalization, either using the spectral minimum and maximum, or applying a minimum and reference\ndecibel level, dependent on the respective target species, to normalize the spectral envelope, and (8) random\nsub-sampling or zero-padding of the spectrogram according to the chosen sequence length, leading to a final\n256 × T augmented and normalized spectral clip being used as network input. Figure 3 visualizes example network input spectrograms for each species, preprocessed according to the illustrated pipeline.\nNetwork training and evaluation. Due to ANIMAL-SPOT’s ResNet18-based feature extraction and\ncompression path (see Fig. 2), each input spectrogram is compressed by a factor of 16 during encoding, both\nin time T and in frequency F domain. The remaining F × T features for each of the 512 channels are mapped\nto the corresponding fully connected layer, conducting global average pooling, followed by a projection to the\nnumber of parametrizable output nodes/classes. During training, random data augmentation and sub-sampling/\npadding, can be enabled. However, to compare validation and test set results across various models, random\ndata augmentation and sub-sampling/padding was disabled. Validation and test samples were centered and\neither zero-padded or sub-sampled, in case the original length did not match the chosen sequence length34.\nANIMAL-SPOT was implemented in PyTorch17 using a cross entropy loss in combination with a batch-size of\n8 for all animals, together with an Adam optimizer applying an initial learning of 10−5, β1 = 0.5, and β2 = 0.999.\nAdditionally, ANIMAL-SPOT integrates a learning rate decay of 1/2 after 4 epochs without any improvement\non the validation set. The training was stopped after an animal-specific number of epochs (see Supplementary\nFigure 2.  ANIMAL-SPOT Network Architecture (created via Inkscape39, Version 0.92.3).\n7\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nTable S2) if no improvement was achieved on the validation set (early stopping). The accuracy was chosen as an\nappropriate network validation criterion. ANIMAL-SPOT integrates an intelligent data split mechanism, capable of automatically identifying all class labels, assuming that data preparation was performed in the prescribed\nformat33, and ensures that samples of a particular recording are only present in one of the splits. By default, the\ndata split is 70% for training, 15% validation, and 15% test. However, it may differ depending on the original data\ndistribution in combination with the above mentioned recording restriction (see Supplementary Tables S4–S6).\nRegarding the two challenge datasets—BirdVox-Full-Night36 and ComParE-PRS37,38—the original predefined\ndata splits have been applied for reasons of comparison. Network training and evaluation was computed utilizing mid-range graphics processing units (GPUs) (e.g., Nvidia GTX 1080), as well as standard central processing\nunits (CPUs), showing the broad applicability of the training setup. Supplementary Table S2 reports all animalspecific network-hyperparameters.\nANIMAL-SPOT’s network performance was evaluated via the following experimental constellations: (1)\nanimal- and scenario-specific model evaluation for target/noise detection (see Supplementary Table S3) and\nmulti-class classification (see Supplementary Tables S4, S5, S6), reporting various performance metrics regarding training, validation, and unseen test set, (2) evaluation of animal-specific target/noise detection networks\non three fully-annotated unseen test recordings, performing a sliding window approach in combination with\na given window-length ǫ and step-size κ to frame-wise segment between target and noise, and (3) inspection\nand verification of the multi-class classification models for warblers and monk parakeets based on the machinesegmented and extracted signal parts of step 2, generated by the corresponding segmentation models.\nThe first evaluation scenario visualizes the following training, validation, and test metrics: accuracy (ACC),\ntrue-positive-rate (TPR), false-positive-rate (FPR), precision (PREC), F1-score (F1), and area under the ROC\ncurve (AUC). In case of the ComParE-PRS37,38 primate species recognition challenge, only the unweighted average recall (UAR) was reported due to comparability reasons.\nThe second evaluation procedure classifies audio sections for each of the three unseen, animal-specific test\nrecordings, depending on the defined window-length ǫ and step-size κ, affecting the signal overlap, as a whole.\nMachine-predicted audio chunks are compared frame-by-frame with the ground truth34. Each predicted frame/\nsegment of the unseen recordings, together with the respective frame-wise network confidence (probability),\nallow to present the ROC-curve44 and its respective AUC34. In addition, frames showing a larger value than a\nmodel confidence δ, are transformed into an annotation with its corresponding start and end time. Therefore,\nsuccessive frames of the same label (noise = 0 or target = 1) are concatenated and extracted as one annotation\nexcerpt34. Frame-wise smoothing was used to mark classified noise segments as target frames if the neighboring\nsignal chunks are exclusively labeled as target signals34. Neighboring frames are frames which include preceding or subsequent signal content of the current sound segment because of the respective overlap34. ANIMALSPOT-S refers to the smoothed version, whereas ANIMAL-SPOT corresponds to the non-smoothed variant\n(see Supplementary Figs. S2–S12). Additionally, the predicted, smoothed, and extracted network detections\nwith an exemplary model confidence of δ ≥ 50% and δ ≥ 90%, were used to calculate and report time-wise\nprecision (PREC) versus corresponding recall (TPR), in order to show intersection accuracy between machineand human-annotated labels. To calculate time-based precision and recall all ground truth annotations, which\nare not further apart than a merging factor ξ = ǫ\n2 (half of the prediction window in seconds), were combined to\none annotation, since such cases lead to sliding windows ǫ, while at least half of the window contains animal\nvocalizations. In case of time-wise precision calculation an additional overlapping factor \u001f = ǫ\n2 was introduced,\nFigure 3.  ANIMAL-SPOT preprocessed 256 × 128-large network input spectrograms (256 frequency bins, 128\ntime frames) utilizing animal-specific network-hyperparameters listed in Supplementary Table S2 (created via\nInkscape39, Version 0.92.3).\n8\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nextending the ground truth annotation start and end accordingly (start − \u001f, end + \u001f), covering overlapping\npredictions at the annotation borders.\nThe third and last evaluation scenario reports results on multi-class classification by presenting the following\nevaluation criteria on training, validation, and test data: (1) accuracy, (2) confusion matrix, and (3) UAR (only for\nthe ComParE-PRS37,38 dataset). Additionally, the model was evaluated on the corresponding machine-annotated\nwarbler and monk parakeet results, utilizing the same sliding window approach. However, during prediction of\nthe multiple classes, a noise identification was only considered as correct if the network confidence was higher\nthan > 85%, due to the assumption that the previous detection process has a low false positive rate. If the network’s\nconfidence regarding noise was lower than this boundary, but still the highest probability, it was ignored and the\nsecond largest confidence value was chosen as correct prediction. The chosen window length, in combination\nwith the input file duration, ends up in two potential cases: (1) window length is larger than the input file duration, leading to an updated window equal to the pre-segmented audio clip, and (2) window size is shorter than\nthe input file size, leading to a sliding, frame-wise classification approach determined by window- and step-size,\nwhile only considering full windows in order to avoid potential misclassification. If multiple sequentially-ordered\nframe-wise classifications per pre-segmented file exist, probabilities of each frame and predicted class are summed\nup cumulatively. Finally, the class providing the largest probability mass was selected. All detection and multiclass species/call type classification metrics are visualized and illustrated in Figs. 4, 5, 6, as well as Supplementary\nTable S7 and Supplementary Figs. S2–S12.\nANIMAL‑SPOT guide. The ANIMAL-SPOT Guide33 is a step-by-step and detailed user guide, publicly\navailable together with the source code33, which enables researchers to train and evaluate animal-specific deep\nneural networks on their own bioacoustic data corpora (see Supplementary Fig. S1). The guidelines involve:\n(1) operating-system independent installation, data preparation, and detailed documentation of the ANIMALSPOT source code33, (2) instructions and guidance in order to set up, train, and evaluate animal- and scenariospecific architectures, as well as (3) use-case dependent prediction of unseen data material utilizing stand-alone\nnoise/target detection models, species/call type classification networks, or a combined version of detection and\nsubsequent classification (see Supplementary Fig. S1). The ANIMAL-SPOT guide provides a detailed description with respect to the following three scenarios: (1) single-stage detection between animal vocalizations of\ninterest and noise, based on unseen data, (2) single-stage classification of animal species and/or specific call\ntypes directly on unseen raw audio material, and (3) a combined version of step 1 and 2 by firstly pre-segmenting\nunseen audio recordings, followed by subsequent classification (animal species, call types, etc.), while taking\nonly the respective pre-segmented target vocalizations as input.\nExperiments\nAnimal‑species target/noise segmentation. In a first experiment animal-species segmentation was\nperformed for all animal-specific (see Fig. 1) data volumes listed in Table 1. Data partitioning was conducted\nfor each animal-specific data archive (see Supplementary Table S3), whereas the training set comprises ≈70%,\nvalidation and test set each ≈15% of the total labeled data corpora listed in Table 1. Using the respective data\ndistributions in combination with the animal-specific network-hyper-parameters presented in Supplementary Table S2, different ANIMAL-SPOT architectures were trained and evaluated according to the previously\ndescribed network training and evaluation procedure. An exception is the BirdVox-Full-Night36 challenge dataset (see Table 1, last row), which used the same data distribution, training, and evaluation procedure as described\nin Lostanlen et al.36, in order to allow a meaningful comparison with the original results. Consequently, a leaveone-out testing procedure whereby one unit of the given six was utilized for testing and the other five were used\nfor training and validation. This results in exactly the same data split as reported, but also means that there exist\nno additional and unseen data available for further evaluation, as it was the case for all other data corpora listed\nFigure 4.  Overall summary across all 11 animal-specific segmentation models (10 different species, 1\nadditional genus), visualizing performance metrics with respect to the animal-specific, unseen, human-labeled\ntest data (1.1), ROC-curves and AUC-Range (1.2), as well as threshold-dependent precision/recall values (1.3),\nboth based on the animal-related unseen recording tapes (see also species-specific results in Supplementary\nFigs. S2–S12 and Supplementary Table S7) (created via Inkscape39, Version 0.92.3).\n9\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nTable 1. For reasons of comparison and the sake of completeness, parts of the already published results on killer\nwhales (see ORCA-SPOT34) are reported and visualized as well.\nMulti‑class species and call type classification. As baseline for the second experiment, results of the\nfirst target/noise (binary) animal-species segmentation were utilized, next to a pure stand-alone multi-species\nFigure 5.  Multi-class warbler species identification results, visualizing spectrogram examples of Blue-/Goldenwinged warblers (1.1,1.2), multi-class training/validation accuracy (1.3), confusion matrix regarding the\nunseen human-labeled test data (1.4), as well as confusion matrix concerning previous machine-based warbler\ndetection (1.5) (created via Inkscape39, Version 0.92.3).\nFigure 6.  Multi-class call type classification results, visualizing spectrogram examples of alarm, contact, and\nother call types (1.1–1.3), multi-class training/validation accuracy (1.4), confusion matrix regarding the unseen\nhuman-labeled test data (1.5), as well as confusion matrix concerning previous machine-based monk parakeet\ndetection (1.6) (created via Inkscape39, Version 0.92.3).\n10\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nclassification scenario without pre-segmentation. To demonstrate, prove and verify performance of the proposed\nmulti-step classification procedure, three of the 12 animal species (see Fig.  1) were utilized—Golden-/Bluewinged warblers (genus) and monk parakeets.\nIn case of the warblers a subsequent multi-class classification model, trained on the data and distribution listed\nin Supplementary Table S4, was used to further separate the genus-specific and previously machine-segmented\ndata pool into Golden-winged, Blue-winged warblers, other birds, and noise. To counteract possible false alarms\nfrom the segmentation phase, two classes—other birds and noise—were introduced besides the corresponding\nsignals of interest.\nThe proposed multi-stage approach was further evaluated training a multi-class classification network to differentiate between various monk parakeet call types, using the data and distribution in Supplementary Table S5,\nincluding contact, alarm, and other calls, as well as noise, in order to handle previous segmentation errors.\nIn case of the golden- and blue-winged warblers, a total of 210 machine-annotated audio segments were\nextracted utilizing a network confidence of ≥ 90%. Under identical conditions 103 monk parakeet machine\nsegmentations were predicted and extracted. Example spectrograms for golden-/blue-winged warbler vocalizations, as well as for the various monk parakeet call types, are visualized in Figs. 5 and 6.\nIn order to assess the efficacy of the multi-stage approach, instead of a single-stage multi-class approach, a\nmulti-class model was exemplarily trained to perform detection and classification of Golden-winged warbler,\nBlue-winged warbler, and noise (pure background noise, other birds) in one step, using exactly the same three\nunseen, manually labeled recordings for evaluation as during the detection phase within the multi-stage procedure (see Table 1). The three audio files contain either: (1) only Golden-winged warblers, (2) only Blue-winged\nwarblers, (3) a combination of both warbler types. The model used the same data distribution for Golden-/\nBlue-winged warbler as stated in Supplementary Table S4, together with the warbler noise distribution listed in\nSupplementary Table S3.\nNevertheless, in order to also show and demonstrate the possibility of directly training a multi-species classification network without previous segmentation, the ComParE-PRS dataset (see Table 4) was used to distinguish\nbetween 4 different primate species as well as background noise, trained on the given data distribution listed in\nSupplementary Table S6.\nResults\nAnimal‑species target/noise segmentation. ANIMAL-SPOT successfully segmented all 10 target species, as well as the additional genus, leading to an overall mean test set accuracy of 97.9% (range: 94.5–99.8%).\nAdditionally, an average area under the ROC curve (AUC) of 95.9% (range: 91.7–99.1%) across all 33 unseen\nanimal-specific recordings (3 tapes per detection scenario) was achieved (see Supplementary Table S7. Besides\nnetwork generalization on the unseen tapes, a detailed performance overview with respect to model training,\nvalidation, and testing is reported and visualized in Supplementary Figs.  S2–S12. In addition, all detection\nresults are summarized and available in Supplementary Table S7. Moreover, Fig. 4 summarizes detection results\nin a compressed version, averaged across all 11 animal-specific segmentation models (10 different species, 1\nadditional genus), visualizing: (1) network performance metrics based on the animal-specific human-annotated\ntraining, validation, and testing repositories (see Supplementary Table S3, Fig. 4—1.1), (2) model results across\nall 11 averaged Receiver-Operating-Characteristics44 (ROC) curves by visualizing 2 out of 11 curves, indicating\nthe minimum and maximum AUC, spanning the average AUC-range where all other remaining ROC-curves\nare located (Fig. 4—1.2), and (3) network output across all 11 averaged and threshold-dependent precision/\nrecall scores (Fig. 4—1.3). Apart from the segmentation results of all 11 animal-specific segmentation models\n(10 different species, 1 additional genus), ANIMAL-SPOT also successfully processed the BirdVox-Full-Night36\ndataset. In comparison to the results given by Lostanlen et  al.36, with the best performance coming from a\nCNN with noise augmentation, which resulted in an average accuracy of 94.9% and an average F1-Score of\n62.7%, ANIMAL-SPOT achieved a slightly better average accuracy of 95.4% and a significantly better F1-Score\nof 95.4%. These results were achieved by training 10 models for each unit and taking the average of the results\nwhen removing the best and worst two performing models, resulting in an average over six models for each unit.\nMulti‑class species and call type classification. Multi-class species classification was applied to the\nprevious warbler target/noise detection results (see Supplementary Fig.  S6), in order to further separate the\nmachine-segmented warbler species vocalizations, exemplarily visualized in Fig. 5—1.1,1.2, into Blue-winged\nand Golden-winged warbler, resulting in a multi-class (4-classes) species identification scenario. Therefore,\nANIMAL-SPOT, trained in a multi-class species classification scenario using the data listed in Supplementary\nTable S4, achieved an overall accuracy of 96.6% for the human-labeled unseen test set, as well as 95.2% with\nrespect to the total number of 210 previously machine-detected audio segments (see Supplementary Fig. S6).\nMoreover, training and validation accuracy is shown besides two confusion matrices (4 classes), visualizing the\naforementioned results achieved on the respective unseen human-labeled and machine-segmented test corpora\n(see Fig. 5—1.3–1.5, Supplementary Fig. S6).\nCompared to the results of the proposed two-stage approach, which includes target/noise detection and downstream multi-class identification, the single-stage method, which performs both, detection and classification, in a\nmulti-class model at once, performed significantly worse. Across all three unseen warbler recordings the Golden-/\nBlue-winged warbler detection model (threshold δ≥ 0.9) identified a total of 210 potential vocalizations of interest, resulting in a time-based precision of 95.3% (see Supplementary Fig. S6). All 210 of the segmented samples\nwere then used for downstream multi-class classification. In comparison, the 3-class single-stage approach\ndetected 233 warbler events, with 200 true predictions resulting in a sample-based precision of 85.8%, whereas\njust 77.3% (180 out of 233 vocal events) were detected and classified as the correct warbler species. In the case \n11\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nof the two-stage approach multi-species classification achieved an accuracy of 95.2% (see Fig. 5). This indicates\nthat a two-step approach, where the network can focus more on the distinguishing features of the individual bird\nspecies without also having to filter out as much noise, is preferable to a single-step approach.\nBesides all the results regarding warbler-species classification, ANIMAL-SPOT was also successfully deployed\nto identify various primate species using the Computational Paralinguistics Challenge Primate (ComParEPRS)37,38 data archive. The initial challenge investigation utilizes five different approaches for feature extraction\nand classification of primate vocalizations, namely openSMILE45, openXBOW46, DeepSpectrum47, AuDeep48,\nand End2You49 in conjunction with either an SVM (openSMILE, openXBOW, DeepSpectrum, AuDeep) or a\nrecurrent neural network (RNN) (End2You) for the final classification. The initial baseline for the challenge,\ncalculated by majority voting using the best configuration for each approach, reported the best unweighted\naverage recall (UAR) of 87.5%37,38. In comparison, ANIMAL-SPOT outperformed the baseline achieving a UAR\nof 89.3%. Multi-class call type classification was applied to the previous monk parakeet target/noise detection\nresults (see Supplementary Fig. S5), similarly to the warblers, however, with the aim to classify between different\ncall types visualized in Fig. 6—1.1–1.3, leading to a multi-class (4 classes) monk parakeet call type classification\nscenario. For this purpose, ANIMAL-SPOT was trained on the data listed in Supplementary Table S5. The final\nmodel achieved an overall test set accuracy of 92.7%, compared to 88.4% on the previous machine-based detection results (see Fig. 6—1.4–1.6, Supplementary Fig. S5).\nDiscussion and future outlook\nIn total, 10 different species and 1 extra genus (see Figs. 1, 4, Supplementary Figs. S2–S12), as well as the publiclyavailable BirdVox-Full-Night36 dataset, were analyzed in a binary detection scenario in order to prove ANIMALSPOT’s ability to generalize across a wide variety of sound-types and to assess the feasibility of the proposed\nmulti-stage detection/classification pipeline (see Figs. 5 and 6). As the results on the unseen recordings prove,\npromising time-wise and threshold-dependent recall/precision values were achieved, indicating an accurate\nintersection between ANIMAL-SPOT’s predictions and the actual ground truth (see Fig. 4—1.3, Supplementary\nTable S7 and Supplementary Figs. S2–S12). In addition, ROC-curves and corresponding AUC values show a\nsignificant reduction of the species-dependent and original noise-heavy data material (see Fig. 4—1.2). Thus,\nthreshold-dependent recall and false-positive-rate combinations can be derived according to the respective usecase, which in turn considerably speeds up and improves downstream data analysis. Furthermore, the combined\nstrong results seen in both unseen test set as well as unseen real-world recordings, suggest no indication of model\noverfitting and prove network generalization across all different animal species.\nThe improvements with respect to the publicly available BirdVox-Full-Night36 dataset are also very promising, as the detection accuracy was improved by 0.6%, which indicates an error reduction of about 12%, besides\na significant improvement of 32.7% regarding the F1-Score.\nANIMAL-SPOT integrates a large repertoire of distinct parameterization options for setting up data preprocessing and network training (see Supplementary Table S2). Thus, ANIMAL-SPOT performs equally across\nwide ranges of temporal contexts (e.g average vocalization duration of Pygmy pipistrelles compared to killer\nwhales), frequency ranges (e.g low-range Atlantic cod and Harbour seal vocalizations, mid-range bird sounds,\nand ultrasound bat signals), as well as spectral patterns (e.g., pulse-like structure of the Harbour seal or warbler\nsignals and harmonic properties of the killer whale, Atlantic cod, and chimpanzee vocalizations). It is even possible to learn and distinguish between spectral call structures which are very similar to noise, seen in ANIMALSPOT’s exemplary ability to distinguish Sulphur-crested cockatoo, Harbour seal, monk parakeet, and chimpanzee\nvocalizations from very similar background noise. In case of binary target/noise detection, ANIMAL-SPOT is\nespecially useful in recording situations where the noise characteristics are an order of magnitude larger than\nthe amount of valuable animal vocalizations.\nANIMAL-SPOT’s parameterization capacity also enables flexible adaptations regarding model architecture,\ndata preprocessing, and network training/evaluation, allowing researchers to address and answer various specific\nbioacoustic research questions. Furthermore, the binary-class target/noise detection process enables researchers\nto separate target species that show poor results in the single-stage binary target/noise detection scenario. This\ncan occur especially when the target species spectrally resemble other vocalizing species that are also found in\nthe unseen recordings. In such situations the primary focus is on a generic distinction between target vocalizations and superfluous noise, making subtle spectral differences of other species difficult to model, because of\ngeneralization properties across both classes leading to increasing mis-classifications. This phenomenon was\nobserved in case of Blue-winged and Golden-winged warblers, after both were individually trained and analyzed\non species level, which demonstrated significant performance variations. However, using a two-step identification scenario consisting of target/noise detection at genus level (see Supplementary Fig. S6), and subsequent\nmulti-class species classification, ANIMAL-SPOT achieved an overall test set accuracy of 96.6% on unseen test\ndata, which had been labeled by a human expert, and an accuracy of 95.2% on the target detections identified\nby ANIMAL-SPOT in the target/noise detection scenario (see Fig. 5).\nIn addition, the same two-step approach was successfully applied to distinguish and classify between different\nmonk parakeet call types, resulting in 92.7% test set accuracy for human-annotated samples, and 88.4% with\nrespect to the machine-performed detection results (see Supplementary Fig. S5, see Fig. 6). These combined\nresults demonstrate the wide range of biological scenarios which can be covered by ANIMAL-SPOT in combination with user- and animal-specific data material. In both multi-class classification scenarios—warbler species\nand monk parakeet call types—ANIMAL-SPOT extracts and classifies centered signal sections of the unseen\nnetwork test set samples according to the training sequence length (see Supplementary Table S2, see Figs. 5—1.4\nand 6—1.5). However, the pre-segmented audio chunks, different in length, were classified by utilizing a sliding\nwindow approach, together with the corresponding settings (see Figs. 5—1.5 and 6—1.6). At each frame the \n12\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nmaximum probability of all classes was chosen. The class showing the highest probability mass across the entire\nsignal was selected as the final network hypothesis. In both experiments, each of the confusion matrices show\ncomprehensible and similar results, being an auspicious indicator for model generalization across various data\n(see Figs. 5—1.4,1.5 and 6—1.5,1.6). Furthermore, sequence length and step-size are very important parameters\nto guarantee robust predictions. In terms of species and/or call type classification the step-size should be an\norder of magnitude smaller than the sequence length, in order to guarantee sufficient overlap and not to miss\nimportant spectral features during the prediction phase.\nANIMAL-SPOT demonstrated also great results in terms of single-stage multi-species primate classification, by outperforming the ComParE baseline system. The final result of 89.3% also exceeds the UAR of 88.3%\npresented by challenge competitor Illium et al.50, who applied a vision transformer to the classification problem.\nMüller et al.51 report the same UAR of 89.3% while applying a Deep Recurrent Neural Network. The remaining\ncompetitors who performed better than ANIMAL-SPOT utilized either ensembling of multiple classifiers, as in\nthe case of Egas-López et al.52, who achieved a UAR of 89.8%, or data augmentation techniques such as SpecAugment or MixUp and training tricks such as exponential moving average of the model weights, as presented by\nThomas Pellegrini53, who achieved a UAR of 92.5% on the test set. ANIMAL-SPOT is therefore placed squarely\nin the middle of the top challenge performers despite using only a single, relatively simple classifier and basic\naugmentation techniques.\nIn order to robustly train and report promising results, data volume, distribution, and variation is crucial.\nMoreover, the data corpus must be representative with respect to unseen real-world data. If these criteria are not\nfulfilled, models often lead to significantly worse results, despite promising training, validation, and test metrics.\nIn order to enlarge data variation, especially for small animal corpora, various embedded spectral augmentations\nwere computed (see Supplementary Table S2). However, such augmentation variants and corresponding values\nmust be determined independently for each animal species and can therefore not be generalized. In particular,\nnoise augmentation must be applied carefully, because of differing Signal-to-Noise-Ratio (SNR) between the\noriginal sounds and utilized noise data, particularly in case of animal vocalizations being very similar to noise\ndata (e.g., Sulphur-crested cockatoo, distant chimpanzee pant-hoot versus bird vocalizations in the same frequency range). Therefore, it is essential to ensure that noise samples, chosen for augmentation, are representative\nand independent from training, validation, and test noise excerpts. Despite promising scenario- and animalspecific results on the unseen test data, audio recordings, machine-driven pre-detections, and challenge datasets\n(see Figs. 4, 5, 6, Supplementary Figs. S2–S12, and Supplementary Table S7), the performance may still vary to\na certain extent, due to the following reasons: (1) non-representative data and/or insufficient training data, (2)\nrecording artifacts introducing spectral outliers which are difficult to interpret by the network, (3) other animal\nvocalizations or noise characteristics showing a similar spectral envelope as the target sounds, (4) strong deviation\nof the signal intensities compared to the chosen reference and minimum dB-values of the 0/1-dB-normalization\nduring training (see Supplementary Table S2), (5) overlapping animal signals and human narrations, (6) vocalization types of a given species which have significant spectral and temporal differences between each other, and\n(7) window-length ǫ and step-size κ used during prediction phase. Figure 7 visualizes different examples of such\nanimal- and task-specific misclassifications, caused by the previously illustrated error sources, which significantly\ninfluence network prediction results.\nFigure 7.  Spectrogram examples visualizing potential error sources leading to performance drops of ANIMALSPOT (created via Inkscape39, Version 0.92.3).\n13\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nFurthermore, during multi-class classification, special attention needs to be paid towards correct machinebased detection outputs indicating one of the following scenarios: (1) multiple vocalizations of the same and/\nor different species/call types within a single segment, (2) truncated signals, either at the beginning or end of\na segment, and (3) overlapping vocalizations. Examples of the above mentioned and remaining challenges are\nvisualized in Fig. 8.\nIn addition, data collection should be conducted via a consistent recording setup. Including data material\noriginating from varying recording environments and/or setups will result in spurious outputs unless sufficient\nexamples of this variation is represented in the training and validation datasets.\nANIMAL-SPOT’s performance and network training stabilization strongly correlates with the chosen hyperparameter setup, respective data structure and distribution, as well as model initialization. In order to identify\nthe best fitting training setup for a certain species and classification procedure, a parametric search within the\ntarget-specific value range (with regards to e.g., signal frequency range, average sound duration, type of vocalization) should be performed. Additionally suitable prediction settings—window length ǫ and step-size κ—as well as\nnetwork parameters (see Supplementary Table S2) are very important. Window length ǫ has to be approximately\nin the same dimension as the network training length. To ensure adequate prediction settings, ANIMAL-SPOT\nshould be evaluated on a small portion of unseen manually labeled recordings, before processing large unseen\ndata archives. Moreover, network initialization, as well as random augmentations during training, may impact\nnetwork performance, especially in case of small training corpora, affecting final model performance despite\nsimilar training, validation, and test set metrics.\nResearchers face various acoustic detection scenarios, namely simple target/noise segmentation, identification\nof target signals among other distinct animal-specific vocalizations, and the recognition of target vocalizations\namong other similar animal-related vocalizations. All these scenarios can be addressed by the ANIMAL-SPOT\nframework and its underlying methods. For the simple case of identifying a target signal among nondescript\nbackground noise a simple one-step procedure can be applied as well as utilization of the framework-supplied\nnoise augmentation to account for differences in signal-to-noise ratios in varying real-world conditions. Similarly,\nin the case where the target signal is dissimilar to the to other known vocalizations, a one-step model application\nprocedure can be applied, and the classification is altered from a binary target-noise scenario to a multi-class\nproblem which includes vocalizations from other known species present in the recordings. Finally, when dealing\nwith the scenario in which the target vocalization exhibits similar characteristics such as to make them difficult\nto discern from each other, a multi-step approach can be taken, as was shown when attempting to accurately\ndistinguish between Blue and Golden-winged warblers (see Fig. 5) or different monk parakeet call types (see\nFig. 6). The same applies to the recognition of species-specific dialects and single individuals. The first task is\nto eliminate to the fullest extent the background noise (pure noise, other dissimilar animal vocalizations) from\nthe classification problem. After background noise is removed from the data, it appears that the model is more\ncapable of distinguishing between similar acoustic features through the focus on other spectral characteristics\nand features. Note that, due to the relatively small model sizes used here, a two-step approach could also be\napplied to the case where vocalizations are dissimilar without incurring a significant penalty with respect to\ncomputation time.\nBesides the animal-independent target/noise and multi-step/class identification results (see Figs. 4, 5, and 6),\nthis study also puts special emphasis on the proposed ANIMAL-SPOT guide33 (see Supplementary Fig. S1), which\nenables researchers to setup their own user-specific deep learning framework, without the need of prior machinelearning knowledge. The ANIMAL-SPOT guide33 describes the entire software framework from beginning to\nend, including OS-specific installation manuals regarding all necessary software components, data preparation\nand processing guidelines, as well as detailed descriptions on how to setup, train, and run the final network\nprediction/evaluation on unseen data (see Supplementary Fig. S1).\nThe entire deep learning framework, as well as user- and animal-specific setup, can be verified and evaluated\nthrough the additionally provided example data archive on monk parakeets54 , which is publicly available33, next\nto all the source code and user-friendly instruction manual. This guide enables the bioacoustic community to\nindependently train/evaluate task- and animal-specific deep models in order to gain deeper insights into animal\ncommunication and understanding.\nFigure 8.  Machine-segmented spectrograms for Blue-/Golden-winged warblers and monk parakeets,\nvisualizing various challenging scenarios for a potential subsequent multi-class classification (created via\nInkscape39, Version 0.92.3).\n14\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\nMany different fields of potential future follow-up work arise, such as (1) animal-specific representation55\nand/or transfer learning, utilizing larger labeled/unlabeled bioacoustic data corpora and/or other data archives\n(e.g., ImageNet56), (2) investigation regarding various deep network architectures (e.g., CNN-LSTM25, ResNeXt57,\nInception/Inception-ResNet58, or Transformer-based approaches59), and (3) animal-independent signal enhancement/denoising60, acting as additional data preprocessing option. To the best of the authors knowledge, ANIMAL-SPOT is the first open-source33 machine learning approach, capable of handling various bioacoustic signal\nidentification scenarios (binary target/noise detection, multi-class species/call type classification), verified on a\nwide portfolio of animal vocalizations from different animal taxa and challenge datasets. In combination with a\ndetailed user guide, ANIMAL-SPOT allows the broader bioacoustic research community to develop their own\ntask-specific deep neural networks, on virtually any animal species.\nData availibility\nThe acoustic data archives supporting the findings of this study are available from the respective data owners\nupon reasonable request. Contact details can be obtained from the corresponding author. Upon acceptance,\nthe code for ANIMAL-SPOT, besides the entire ANIMAL-SPOT guidelines, all together with an example data\ncorpus54, will be made publicly available at https://github.com/ChristianBergler.\nReceived: 12 September 2022; Accepted: 14 December 2022\nReferences\n1. Sugai, L. S. M., Silva, T. S. F., Ribeiro, J., José, Wagner & Llusia, D. Terrestrial passive acoustic monitoring: Review and perspectives.\nBioScience 69, 15–25. https://doi.org/10.1093/biosci/biy147 (2018).\n2. Symes, L. B. et al. Analytical approaches for evaluating passive acoustic monitoring data: A case study of avian vocalizations. Ecol.\nEvol. 12, e8797. https://doi.org/10.1002/ece3.8797 (2022).\n3. Van Hoeck, R. V. et al. Passive acoustic monitoring complements traditional methods for assessing marine habitat enhancement\noutcomes. Ecosphere 12, e03840. https://doi.org/10.1002/ecs2.3840 (2021).\n4. Ness, S. The Orchive : A system for semi-automatic annotation and analysis of a large collection of bioacoustic recordings. Ph.D.\nthesis, Department of Computer Science, University of Victoria, 3800 Finnerty Road, Victoria, British Columbia, Canada, V8P\n5C2 (2013).\n5. Allen, A. N. et al. A convolutional neural network for automated detection of humpback whale song in a diverse, long-term passive\nacoustic dataset. Front. Mar. Sci. https://doi.org/10.3389/fmars.2021.607321 (2021).\n6. Pérez Granados, C. & Schuchmann, K.-L. Passive acoustic monitoring of chaco chachalaca (Ortalis canicollis) over a year: Vocal\nactivity pattern and monitoring recommendations. Trop. Conserv. Sci. https://doi.org/10.1177/19400829211058295 (2021).\n7. Davis, G. et al. Long-term passive acoustic recordings track the changing distribution of North Atlantic right whales (Eubalaena\nglacialis) from 2004 to 2014. Sci. Rep. https://doi.org/10.1038/s41598-017-13359-3 (2017).\n8. Melo, I., Llusia, D., Bastos, R. P. & Signorelli, L. Active or passive acoustic monitoring? Assessing methods to track anuran communities in tropical savanna wetlands. Ecol. Indic. 132, 108305. https://doi.org/10.1016/j.ecolind.2021.108305 (2021).\n9. Håkansson, G. & Westander, J. Communication in Humans and Other Animals (John Benjamins Publishing Company, 2013).\n10. Hill, A. et al. AudioMoth: Evaluation of a smart open acoustic device for monitoring biodiversity and the environment. Methods\nEcol. Evol. https://doi.org/10.1111/2041-210X.12955 (2017).\n11. Wall, C. et al. The next wave of passive acoustic data management: How centralized access can enhance science. J. Acoust. Soc. Am.\n150, A79–A79. https://doi.org/10.1121/10.0007688 (2021).\n12. Browning, E., Gibb, R., Glover-Kapfer, P. & Jones, K. E. Passive acoustic monitoring in ecology and conservation, https://doi.org/\n10.13140/RG.2.2.18158.46409 (2017).\n13. Gibb, R., Browning, E., Glover-Kapfer, P. & Jones, K. E. Emerging opportunities and challenges for passive acoustics in ecological\nassessment and monitoring. Methods Ecol. Evol. 10, 169–185. https://doi.org/10.1111/2041-210X.13101 (2019).\n14. Hilbert, M. & López, P. The world’s technological capacity to store, communicate, and compute information. Science 332, 60–65\n(2011).\n15. Sood, D., Kour, H. & Kumar, S. Survey of computing technologies: Distributed, utility, cluster, grid and cloud computing. JNCET\n6 (2016).\n16. Géron, A. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to bBuild Intelligent Systems 2nd edn. (O’Reilly Media, 2019).\n17. Paszke, A. et al. Automatic differentiation in PyTorch. In NIPS 2017 Workshop (2017).\n18. Mittal, S. & Vaishay, S. A survey of techniques for optimizing deep learning on GPUs. J. Syst. Archit. 99, 101635. https://doi.org/\n10.1016/j.sysarc.2019.101635 (2019).\n19. Wu, Z., Sun, J., Zhang, Y., Wei, Z. & Chanussot, J. Recent developments in parallel and distributed computing for remotely sensed\nbig data processing. Proc. IEEE 109, 1282–1305. https://doi.org/10.1109/JPROC.2021.3087029 (2021).\n20. Howard, J. & Gugger, S. Fastai: A layered API for deep learning. Information 11, 108. https://doi.org/10.3390/info11020108 (2020).\n21. Stowell, D. Computational bioacoustics with deep learning: A review and roadmap. PeerJ 10, e13152 (2022).\n22. Bianco, M. J. et al. Machine learning in acoustics: Theory and applications. J. Acoust. Soc. Am. 146, 3590–3628. https://doi.org/10.\n1121/1.5133944 (2019).\n23. Shiu, Y. et al. Deep neural networks for automated detection of marine mammal species. Sci. Rep. 10, 607. https://doi.org/10.1038/\ns41598-020-57549-y (2020).\n24. Bermant, P., Bronstein, M., Wood, R., Gero, S. & Gruber, D. Deep machine learning techniques for the detection and classification\nof sperm whale bioacoustics. Sci. Rep. 9, 1–10. https://doi.org/10.1038/s41598-019-48909-4 (2019).\n25. Madhusudhana, S. et al. Temporal context improves automatic recognition of call sequences in soundscape data. J. Acoust. Soc.\nAm. 148, 2442. https://doi.org/10.1121/1.5146737 (2020).\n26. Thomas, M., Martin, B., Kowarski, K., Gaudet, B. & Matwin, S. Marine mammal species classification using convolutional neural\nnetworks and a novel acoustic representation. In Joint European Conference on Machine Learning and Knowledge Discovery in\nDatabases, 290–305 (Springer, 2019).\n27. Priyadarshani, N., Marsland, S. & Castro, I. Automated birdsong recognition in complex acoustic environments: A review. J. Avian\nBiol. 49, jav01447. https://doi.org/10.1111/jav.01447 (2018).\n28. Stowell, D., Wood, M., Pamuła, H., Stylianou, Y. & Glotin, H. Automatic acoustic detection of birds through deep learning: The\nfirst bird audio detection challenge. Methods Ecol. Evol. 10, 368–380 (2018).\n29. Mac Aodha, O. et al. Bat detective-deep learning tools for bat acoustic signal detection. PLoS Comput. Biol. 14, 1–19. https://doi.\norg/10.1371/journal.pcbi.1005995 (2018).\n15\nVol.:(0123456789)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\n30. Khalighifar, A. et al. Application of deep learning to community-science-based mosquito monitoring and detection of novel species. J. Med. Entomol. 59, 355–362. https://doi.org/10.1093/jme/tjab161 (2021).\n31. Bravo Sanchez, F. J., Hossain, M. R., English, N. B. & Moore, S. T. Bioacoustic classification of avian calls from raw sound waveforms\nwith an open-source deep learning architecture. Sci. Rep. 11, 1–12 (2021).\n32. Zhang, L., Wang, D., Bao, C., Wang, Y. & Xu, K. Large-scale whale-call classification by transfer learning on multi-scale waveforms\nand time-frequency features. Appl. Sci. 9, 1020. https://doi.org/10.3390/app9051020 (2019).\n33. Bergler, C. Github-Repository. https://github.com/ChristianBergler.\n34. Bergler, C. et al. Orca-spot: An automatic killer whale sound detection toolkit using deep learning. Sci. Rep. 9, 1–17. https://doi.\norg/10.1038/s41598-019-47335-w (2019).\n35. He, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision\nand Pattern Recognition (CVPR), 770–778 (2016).\n36. Lostanlen, V., Salamon, J., Farnsworth, A., Kelling, S. & Bello, J. P. Birdvox-full-night: A dataset and benchmark for avian flight\ncall detection. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 266–270, https://doi.\norg/10.1109/ICASSP.2018.8461410 (2018).\n37. Schuller, B. W. et al. The INTERSPEECH 2021 computational paralinguistics challenge: COVID-19 cough, COVID-19 speech,\nescalation & primates. In Interspeech 2021, https://doi.org/10.21437/interspeech.2021-19 (ISCA, 2021).\n38. Zwerts, J. A. et al. Introducing a Central African primate vocalisation dataset for automated species classification. In Proc. Interspeech 2021, 466–470, https://doi.org/10.21437/Interspeech.2021-154 (2021).\n39. Inkscape Project. Inkscape. https://inkscape.org (March 2018), Version 0.92.3.\n40. LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. Gradient-based learning applied to document recognition. Proc. IEEE 86, 2278–2324\n(1998).\n41. Maier, A., Syben, C., Lasser, T. & Riess, C. A gentle introduction to deep learning in medical image processing. Zeitschrift für\nMedizinische Physik 29, 86–101 (2019).\n42. Nair, V. & Hinton, G. E. Rectified linear units improve restricted Boltzmann machines. In Proceedings of the 27th International\nConference on International Conference on Machine Learning, 807–814 (2010).\n43. Ioffe, S. & Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proceedings\nof the 32nd International Conference on International Conference on Machine Learning, vol. 37, 448–456 (2015).\n44. Fawcett, T. Roc graphs: Notes and practical considerations for researchers. Mach. Learn. 31, 1–38 (2004).\n45. Eyben, F., Wöllmer, M. & Schuller, B. Opensmile: the munich versatile and fast open-source audio feature extractor. In Proceedings\nof the 18th ACM international conference on Multimedia (2010).\n46. Schmitt, M. & Schuller, B. Openxbow: Introducing the passau open-source crossmodal bag-of-words toolkit. J. Mach. Learn. Res.\n18, 3370–3374 (2017).\n47. Zhao, Z. et al. Deep spectrum feature representations for speech emotion recognition. In Proceedings of the Joint Workshop of the\n4th Workshop on Affective Social Multimedia Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia\nData, ASMMC-MMAC’18, 27–33, https://doi.org/10.1145/3267935.3267948 (Association for Computing Machinery, New York,\nNY, USA, 2018).\n48. Freitag, M., Amiriparian, S., Pugachevskiy, S., Cummins, N. & Schuller, B. Audeep: Unsupervised learning of representations from\naudio with deep recurrent neural networks. J. Mach. Learn. Res. 18, 6340–6344 (2017).\n49. Tzirakis, P. End2you: Multimodal profiling by end-to-end learning and applications. In Proceedings of the 1st International on\nMultimodal Sentiment Analysis in Real-Life Media Challenge and Workshop, MuSe’20, 9, https://doi.org/10.1145/3423327.34235\n13 (Association for Computing Machinery, 2020).\n50. Illium, S., Müller, R., Sedlmeier, A. & Popien, C.-L. Visual Transformers for Primates Classification and Covid Detection. In Proc.\nInterspeech 2021, 451–455, https://doi.org/10.21437/Interspeech.2021-273 (2021).\n51. Müller, R., Illium, S. & Linnhoff-Popien, C. A Deep and Recurrent Architecture for Primate Vocalization Classification. In Proc.\nInterspeech 2021, 461–465, https://doi.org/10.21437/Interspeech.2021-1274 (2021).\n52. Egas-López, J. V., Vetráb, M., Tóth, L. & Gosztolya, G. Identifying conflict escalation and primates by using ensemble X-vectors\nand Fisher vector features. In Proc. Interspeech 2021, 476–480, https://doi.org/10.21437/Interspeech.2021-1173 (2021).\n53. Pellegrini, T. Deep-learning-based central African primate species classification with MixUp and SpecAugment. In Proc. Interspeech\n2021, 456–460, https://doi.org/10.21437/Interspeech.2021-1911 (2021).\n54. Smeele, S. Q., Tyndel, S. A., Aplin, L. M. & McElreath, M. B. Multi-level analysis of monk parakeet vocalisations shows emergent\ndialects between cities in the European invasive range. bioRxiv https://doi.org/10.1101/2022.10.12.511863 (2022).\n55. Bergler, C. et al. Deep representation learning for orca call type classification. In Text, Speech, and Dialogue, 22nd International\nConference, TSD 2019, Ljubljana, Slovenia, September 11–13, 2019, Proceedings, vol. 11697 LNAI, 274–286, https://doi.org/10.\n1007/978-3-030-27947-9_23 (Springer Verlag, 2019).\n56. Deng, J. et al. Imagenet: A large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern\nRecognition, 248–255 (IEEE, 2009).\n57. Xie, S., Girshick, R., Dollár, P., Tu, Z. & He, K. Aggregated residual transformations for deep neural networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 5987–5995, https://doi.org/10.1109/CVPR.2017.634 (2017).\n58. Szegedy, C., Ioffe, S., Vanhoucke, V. & Alemi, A. Inception-v4, inception-resnet and the impact of residual connections on learning.\nAAAI Conference on Artificial Intelligence (2016).\n59. Wang, Y. et al. Transformer-based acoustic modeling for hybrid speech recognition. In ICASSP 2020-2020 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP), 6874–6878 (IEEE, 2020).\n60. Bergler, C. et al. ORCA-CLEAN: A Deep Denoising Toolkit for Killer Whale Communication. In Proc. Interspeech 2020, 1136–1140,\nhttps://doi.org/10.21437/Interspeech.2020-1316 (2020).\n61. ORCALAB. Orcalab—a whale research station on Hanson Island. http://orcalab.org (2022).\n62. Ness, S. Orchive. http://orchive.cs.uvic.ca/ (2020).\nAcknowledgements\nWe are grateful for support with—data collection of cockatiel data: Lucy Aplin and Gustavo Alarcón-Nieto; data\ncollection and annotations of killer whale data (orcalab.org61,62): Helena Symonds, Paul Spong, and Steven Ness4\n(formely UVIC); logistical support: Lucy Aplin (cockatiels, Sulphur-crested cockatoos, monk parakeets); John\nMartin, Anastasia Dalziell, and Justin Welbergen (Sulphur-crested cockatoos); Tim Wilder, Susan Vos and Fort\nMcCoy Natural Resource Branch and Range Control (Blue- and Golden-winged warblers); access to field sites:\nWisconsin and Illinois Department of Natural Resources (Blue- and Golden-winged warblers): The Bikuben\nFoundation and Mols Bjerge National Park (Pygmy pipistrelles); co-hosting the Heidelberg Academy of Sciences\nworkshop: Jens Koblitz and Nora Carlson; design of the ANIMAL-SPOT network architecture image (part of\nFig. 2): Michael Weber. We thank Joeri Zwerts for granting access to the ComParE-PRS primates dataset. All\nauthors complied with the legislation in the respective countries were fieldwork was conducted. Ethical approval \n16\nVol:.(1234567890)\nScientific Reports | (2022) 12:21966 | https://doi.org/10.1038/s41598-022-26429-y\nwww.nature.com/scientificreports/\n(where necessary) was obtained as follows: Data from cockatiels was collected by Lucy Aplin and Gustavo\nAlarcón-Nieto under ethical permission from the Regierungspräsidium Freiburg. Az. 35-9185.81/G-18/009; data\nfrom Sulphur-crested cockatoos was collected by Barbara Klump and John Martin under ethical permission from\nthe Ethics Council of the Max Planck Society (application no. 2018_12; permit given to Lucy Aplin); data from\nBlue- and Golden-winged warblers was collected by Stephen Tyndel under ethical permission from the University\nof Illinois at Urbana-Champaign’s IACUC committee (protocol #16022); data from chimpanzees was collected\nby Ammie Kalan under ethical permission from the Ministère de la Recherche Scientifique, the Ministère de\nl’Environnement et des Eaux et Forêts, and the Office Ivorien des Parcs et Reserves in Côte d’Ivoire (Ref: 11/\nMINEF/OIPR/DT/CAT). Research was conducted with funding from: German Research Council (DFG; grant\nMA-4898/18-1 to CB); Paul G. Allen Frontier’s Group (CB); Max Planck Society (AKK; Mary Brooke McElreath\nfunded SQS); Max Planck Society Independent Group Leader Fellowship to Lucy Aplin (funded SQS, SAT, BCK);\nInternational Max Planck Research School (IMPRS) for Organismal Biology (SQS, SAT, STO); German Academic Exchange Service (DAAD PhD scholarship to SAT); United States Department of Defense, Environmental\nSecurity Technology Certification Program (ESTCP grant #RC 201615 to Jinelle Sperry, Michael Ward and Brett\nDegregorio, U.S. Army Corps of Engineers, funded SAT); Animal Minds Project e.V. (STO); Carlsberg Foundation Semper Ardens grant to Peter Teglberg Madsen (funded SB); Danish Environmental Protection Agency\n(ANO, JT); Dansk Akustisk Selskab (FJ); University of Southern Denmark (Research grant to FJ); Office of Naval\nResearch (MW); SDU Lighthouse Project (MW); Heidelberg Academy of Sciences (workshop grant to BCK).\nAuthor contributions\nC.B., B.C.K., S.Q.S., S.A.T., and E.N. conceived of, initiated and led the project; data was collected by B.C.K.,\nS.Q.S., S.A.T., A.K.K., S.B., S.T.O., F.J., J.T., M.W., A.N.O.; data was prepared (labeling, extraction and formatting) by: C.B., B.C.K., S.Q.S., S.A.T., A.N.O., F.J., A.K.K., R.X.C., S.T.O., S.B.; the ANIMAL-SPOT software was\ndeveloped by C.B.; data preparation procedures for all animal species were verified by C.B., A.B., S.Q.S., S.A.T.,\nB.C.K.; verification of the experiments were performed by C.B., A.B., S.Q.S., S.A.T.; the manuscript was written by: C.B., B.C.K., S.Q.S., S.A.T., and A.B.; with support and feedback from A.M. and E.N., and edited by all\nauthors. E.N., B.C.K. and A.M. supervised the project; B.C.K. secured funding for the workshop during which\nthis project was conceived.\nFunding\nOpen Access funding enabled and organized by Projekt DEAL.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at https://doi.org/\n10.1038/s41598-022-26429-y.\nCorrespondence and requests for materials should be addressed to C.B. or B.C.K.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and\ninstitutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International\nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or\nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the\nCreative Commons licence, and indicate if changes were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the\nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not\npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from\nthe copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n© The Author(s) 2022", "affiliations": [{"country": "Germany", "discipline": "Computer Science", "university": "University of Erlangen-Nuremberg"}, {"country": "Germany", "discipline": "Ecology", "university": "Max Planck Institute"}, {"country": "Germany", "discipline": "Biology", "university": "University of Konstanz"}, {"country": "United States", "discipline": "Environmental Science", "university": "University of Illinois Urbana-Champaign"}, {"country": "Germany", "discipline": "Biology", "university": "Max Planck Institute"}, {"country": "Canada", "discipline": "Anthropology ", "university": "University of Victoria"}, {"country": "Germany", "discipline": "Zoology", "university": "Leibniz Institute for Zoo and Wildlife Research"}, {"country": "Denmark", "discipline": "Biology", "university": "Aarhus University"}, {"country": "Poland", "discipline": "Ecology", "university": "University of Gdańsk"}, {"country": "Denmark", "discipline": "Biology", "university": "University of Southern Denmark"}], "species_categories": ["Bird", "Other", "Marine Mammal", "Fish", "Terrestrial Mammal"], "specialized_species": ["Cockatiel", "Sulphur-crested cockatoo", "Peach-fronted conure", "Monk parakeet", "Blue-/golden-winged warbler", "Chinstrap penguin", "Atlantic cod", "Harbour seal", "Killer whale", "Pygmy pipistrelle", "Chimpanzee"], "computational_stages": ["Data Collection", "Pre-processing", "Meaning Identification"], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Discreteness and Syntax", "Semanticity"], "status": "saved", "created_at": "2026-01-13T12:49:59.887461", "updated_at": "2026-01-13T16:11:33.745221", "committed_at": "2026-01-13T14:15:30.983063"}
{"id": "46eb33b7-4d47-447c-92d6-24eaa132a51b", "title": "Golden‐marmot Alarm Calls. II. Asymmetrical Production and Perception of Situationally Specific Vocalizations?", "authors": ["Blumstein,  Daniel T."], "year": "1995", "journal": "Ethology", "abstract": "", "doi": "10.1111/j.1439-0310.1995.tb00341.x", "analysis_notes": "Ethology 101, 25—32 (1995)\n© 1995 Blackwell Wissenschafts-Verlag, Berlin\nISSN 0179-1613\n\nAnimal Behavior Program, Section of Evolution and Ecology, University of California, Davis\n\nGolden-marmot Alarm Calls. II. Asymmetrical Production and Perception of Situationally Specific Vocalizations?\n\nDANIEL T. BLUMSTEIN\n\nBLUMSTEIN, D. T. 1995: Golden marmot alarm calls. II. Assymetrical production and perception of situationally specific vocalizations. Ethology 101, 25—32.\n\nAbstract\n\nMany species produce alarm calls that vary according to situation. An implicit assumption for these species is that production and perception of situationally specific alarm calls is symmetrical: perceivers respond to variation produced by signalers. The companion paper to this one (BLUMSTEIN 1995) showed that golden marmots (Marmota caudata aurea) produce variable alarm calls that vary in proportion to the degree of risk the caller perceives. Calls produced in higher-risk situations have fewer notes than calls produced in lower-risk situations. In this study, to determine the salience of the number of notes per call in eliciting different responses in conspecific perceivers, I played back three-note alarm calls, eight-note alarm calls, and the non-alarm vocalization of a local bird to adult golden marmots. Although marmots responded differently to bird calls and alarm calls, vigilance responses to the different alarm calls were similar. Several explanations may account for the apparent insensitivity to alarm-call variation: golden marmots may require additional contextual cues to properly interpret alarm calls, perceptual abilities do not parallel production abilities, or calls may serve a generalized alerting function.\n\nD. T. BLUMSTEIN, Department of Systematics and Ecology, University of Kansas, Lawrence, KS 66045, USA.\n\nIntroduction\n\nAn implicit assumption for species which produce situationally specific alarm calls is that production and perception of variable alarm calls is symmetrical: perceivers respond differently according to signal type (OWINGS 1994). Golden marmots (Marmota caudata aurea) produce situationally specific alarm calls. The results of my companion study (BLUMSTEIN 1995) suggest that the number of notes per call is inversely related to the degree of risk a calling marmot experiences when it calls. If call variation communicates the degree of risk or type of predator, then marmots who hear alarm calls should, in some way, respond differently to\n\nU.S. Copyright Clearance Center Code Statement: 0179-1613/95/1011-0025$11.00/0\n\n26 DANIEL T. BLUMSTEIN\n\n[Graphic: Figure 1: Representative spectrograms of the two marmot alarm calls and the bird call played back to marmots. Top: Three-note alarm call. Middle: Eight-note alarm call. Bottom: Black redstart. The X-axis is Time (s) from 0 to 2.0. The Y-axis is Frequency (kHz) from 0 to 6.]\n\nvariants (SMITH 1977; HARRIS et al. 1983; CHENEY & SEYFARTH 1990; MACEDONIA & EVANS 1993). I conducted playback experiments to determine whether marmots had overtly different responses to higher risk (three-note) and lower risk (eight-note) alarm calls.\n\nMethods\n\nHigh-quality human-elicited marmot calls recorded from different individuals were used for this experiment (recording details in BLUMSTEIN (1995)). Calls were sampled at 44 kHz using an AudioMedia AD-DA board then filtered (1000—5000 kHz three-pole Butterworth bandpass filter) using Signalyze software (KELLER 1992) to remove environmental noise. Longer calls were shortened to three or eight notes using AudioMedia, and playback tapes were made using AudioMedia software (DIGIDESIGN 1990).\n\nA total of 10 three-note and 11 8-note examples (Fig. 1), exhibiting 'natural' variation in other acoustic parameters (bandwidth, minimum and maximum frequencies, duration, inter-note intervals), were used for the experiments. By using multiple examples of alarm calls, I was able to test the hypothesis that marmots respond to different types of alarm calls and not to different examples of alarm calls (MCGREGOR et al. 1992).\n\nMarmots did not produce other loud vocalizations (e.g. food or territorial calls) that could be used as a suitable control sound. Instead, I used a single 1.21-s song of a common alpine bird (black redstart: Phoenicurus ochruros) as a control stimulus (Fig. 1). A redstart song was selected because, while it is not an alarm call, it is pulsed like marmot alarm calls. The control sound was used to test the hypothesis that marmots respond to alarm calls and not just to the experimental setup, and/or to a sudden pulsed sound.\n\nMarmot Alarm Calls. II 27\n\nEach experimental marmot heard all three stimuli: a three-note call, an eight-note call, and the redstart song. Between marmots, playback order was systematically varied. To avoid possible habituation to played-back alarm calls, I attempted to limit playbacks in a given day to the number that a marmot might normally hear (X̄ = 2.67 playbacks per playback day, range 1—8 c.f.; marmots naturally hear 6—22 natural 'bouts' of alarm calls per day; BLUMSTEIN 1995).\n\nBefore marmots emerged from their burrows in the morning, the speakers and cables were set up and left in place throughout the morning (and occasionally afternoon) experimental period. Stone boxes to camouflage the speaker (between one and several per marmot group) were constructed at least 1 wk prior to experiments and were left throughout the season. I sat with the video camera (with an attached telephoto lens) and tape deck in one of four hides between 180 and 460 m from the speaker. Different stone boxes were used in playbacks conducted on subsequent days.\n\nSeveral additional criteria, to ensure maximal responsiveness, had to be met prior to a playback. Firstly, no natural alarm calls could have occurred in the past 30 min. Secondly, if a previous playback had been conducted, I waited at least 7 min before playing back another sound. Thirdly, since behavior, and potentially location, can influence responsiveness to a played-back alarm call (BLUMSTEIN 1994), I attempted to control for behavior by conducting playbacks only to marmots that were sitting and looking or standing and looking from their main burrows (X̄ distance to main burrow = 0.36 m, range 0—4 m).\n\nExamples of calls were played back on a Sony WM-D6C tape deck. The audio signal was split leaving the Sony headphone jack, sending the exemplar directly to a video camera (Sony SP-7, video 8) and also through an unbalanced-to-balanced line-conversion box (Countryman Type-85 Direct Box), across 365—455 m of balanced microphone cable, into a line amplifier (Sure FP11) that also converted the signal back to an unbalanced one, and finally to a Sony SRS-77G powered speaker with a relatively flat frequency response.\n\nSince playback volume may influence responsiveness (BLUMSTEIN 1994), line levels on the tape deck, line amplifier, and powered speaker were adjusted until the sound-pressure level, 0.1 m in front of the speaker, was about 100—104 dB (measured using a Realistic model 33—2050 sound-level meter). In fact, the average playback volume was 104.8 dB (range: 97—112 dB), and the speakers were 13.4 m from the marmots (range: 5.4—25.5 m).\n\nThe playback situation mimicked the situation of a distant marmot calling. Depending on the exact location of the speaker, the hypothetical 'caller' could have been from the same or an adjacent social group. Marmots routinely responded to alarm calls produced throughout the meadow.\n\nSingle-frame analysis of the video (temporal resolution = 0.033 s) permitted marmots' responses to playbacks to be measured. From the videotape, variables hypothesized to reflect responsiveness on different temporal scales were measured to search for differential responsiveness. Immediate responses were quantified by measuring: 1. The delay in responding to the played-back stimulus, defined as the time between the beginning of the playback and the beginning of the first look; and 2. The duration of the first look following the playback. Short-term responses were quantified by recording the number and duration of each bout of looking in the first 17 s. This time was chosen because the average time between alarm calls was 17 s (BLUMSTEIN 1995). Longer-term responses were quantified by recording the number and duration of each bout of looking in the first 59 s following the playback. While any differential responsiveness to alarm-call variants would have been telling, I anticipated the number of looks and the time spent looking to be positively associated with the degree of risk 'encoded' in the call. Moreover, I anticipated shorter response times to alarm calls than to bird song.\n\nFriedman non-parametric ANOVAs (with no interaction effects) were used to test for differences in the responsiveness to these acoustic stimuli while controlling for individual variation. Pairwise post-hoc multiple comparisons were calculated using equation 7.5a from SIEGEL & CASTELLAN (1988).\n\nResults\n\nMarmots responded differently to alarm calls than to the bird song, but did not respond differently to three-note and eight-note alarm calls (Fig. 2). Between 24 May and 16 Aug. 1993, I played back the three different acoustic stimuli to 15 adult marmots (nine males/six females) in six different social groups. Overall, the\n\n28 DANIEL T. BLUMSTEIN\n\n[Graphic: Figure 2: Responsiveness (±SE to played back acoustic stimuli in terms of: a. Response time following the played back stimulus; b. Duration of the first look following the played back stimulus; c. The number of looks in the first 17 s following the playback; d. The number of looks in the first 59 s; e. The average duration of each look during the first 17 s; and f. The average duration of each look during the first 59 s. Significance tested with Friedman's nonparametric ANOVA, blocked by individual. Solid lines above graphs illustrate non-significantly different pairwise comparisons (p > 0.05). Response delays of marmots to the bird song and the three-note alarm call were not significantly different.]\n\naverage time between playbacks was 1.91 d; individual marmots averaged 3.6 d between playbacks of different acoustic stimuli.\n\nResponse delays to different acoustic stimuli differed significantly (p = 0.031). Multiple pairwise comparisons revealed that marmots had indistinguishable response delays to alarm calls but took longer to respond to bird song than to eight-note alarm calls.\n\nThe duration of the first look following playbacks also differed among treatments (p = 0.017). Multiple comparisons suggested that marmots only differentiated three-note alarm calls from bird song. However, the comparison of eight-note alarm calls to bird song was close to the significantly different multiple-comparison criteria. The duration of the first look was indistinguishable between three-note and eight-note alarm calls. A longer first look in response to bird song than to alarm calls was expected since bird song was not supposed to be alarming: alarmed marmots appeared 'agitated' and looked around frequently. Marmots 'responding' to bird song tended to 'casually' look around and did not appear agitated.\n\nMarmot Alarm Calls. II 29\n\nNone of the short-term or long-term measurements of responsiveness differed significantly between treatments.\n\nDiscussion\nWhy Perceivers May Not Respond to Call Variation\n\nGiven the apparently robust relationship between the number of notes per call and the degree of risk the caller experiences when calling (BLUMSTEIN 1995), it is somewhat surprising that marmots did not respond differently to the played-back three-note and eight-note alarm calls. That marmots responded differently to alarm calls and the bird song suggests that marmots were not simply responding to sound coming from the speaker, nor to the pulsed playback. There are several non-mutually exclusive explanations of why marmots appeared not to differentiate alarm-call types.\n\nFirstly, measurements of vigilance may not be sensitive enough to detect slight, but perceptually meaningful, evidence of stimulus discrimination (HAUSER 1994). Yet, other investigators have found vigilance patterns to be sensitive measurements of response differences to acoustic stimuli (LEGER & OWINGS 1978; OWINGS & LEGER 1980; HARRIS et al. 1983; HAUSER 1986; CHENEY & SEYFARTH 1990; EVANS et al. 1993). Different measurements of responsiveness such as tail-pilo-erection onset time (COSS 1995), specific cardiac responses (EVANS & GAIONI 1990), or other autonomic nervous-system responses (BROOKS 1983), might have revealed significantly different responses to variants.\n\nSecondly, alarm calls alone may not have provided sufficient context for perceivers to properly interpret the meaning of the calls (SMITH 1977; LEGER 1993). Some species are able to recognize individuals by their vocalizations (GREEN & MARLER 1979; CONNER 1985; CHENEY & SEYFARTH 1990). Golden marmots live in sufficiently stable social groups for perceivers to have the opportunity to learn the special characteristics of their neighbors' calls and to include that knowledge in their assessment of a call's meaning: adding marmot identity increased the total explained variation in the number of notes per call; BLUMSTEIN (1995). Additionally, volume-related potential cues may have aided marmots' interpretation of an alarm call. Since these contextual cues were, by design, absent in this experiment, marmots might normally—with appropriate contextual cues—be able to differentiate alarm-call variants. Nevertheless, if these cues are required to respond differently, then the number of notes per call alone cannot communicate variation in predation risk. If so, the opportunity for asymmetrical production and perception seems plausible.\n\nThirdly, previous studies that found an ability for species to perceive temporal differences in calls have been conducted on species that have the ability to produce structurally different calls (LEGER & OWINGS 1978; HARRIS et al. 1983; STONE & TROST 1991; studies of Eurasian marmots by NIKOL'SKII & NESTEROVA 1988, 1989, 1990 (loc. cit. NIKOL'SKII et al. 1994) are apparent exceptions). However, some species, such as golden marmots, produce only temporally different calls. If the ability to produce structurally distinct call types was correlated with the\n\n30 DANIEL T. BLUMSTEIN\n\nability to differentiate call types, then species producing only temporally variable calls would be less able to differentiate alarm-call variants. This potential evolutionary constraint must be studied by investigating production and perception in the entire genus. Specifically, to determine whether perceptual abilities are correlated with production abilities, the order of trait evolution must be studied (BROOKS & MCLENNAN 1991).\n\nFourthly, it is probable that marmots use simple rules-of-thumb to assess predation risk (BOUSKILA & BLUMSTEIN 1992). An example of an assessment rule might be where perceivers treat any alarm call as representing an equivalent threat. If so, different calls would elicit identical responses. Assessing calls similarly might be a reasonably inexpensive strategy because: 1. The immediate response to an alarm call is looking and presumably assessing the situation; and 2. Alarm calls are not common. It is worth noting that calls may have been perceived differently but have had equivalent meanings to the marmots (see discussion of 'just meaningful difference' in NELSON & MARLER (1990)).\n\nFinally, the first alarm call might serve a generalized alerting function (BALPH & BALPH 1966). Perceivers might use changes in the number of notes in subsequent calls to assess the relative risk of predation (sensu BELETSKY et al. 1986). Given that a substantial amount of variation in the number of notes per call may be explained by knowing the caller's identity, a perceiver might pay less attention to the absolute number of notes per call in the first call than to how the number of notes from the same caller changes over time. If the change in the number of notes in subsequent calls is used to assess predation risk, degree of risk is not communicated immediately. While calls may be repeated to track risk, an alternative explanation of repeated calls is that they are used to maintain vigilance (SCHLEIDT 1973; OWINGS & VIRGINIA 1978; HARRIS et al. 1983; OWINGS & HENNESSY 1984; LOUGHRY & MCDONOUGH 1988). Yet, if risk is communicated over a larger time scale, then the inter-call interval would be a variable requiring additional study (see NIKOL'SKII et al. 1994).\n\nConclusions\n\nThis study underscores the importance of conducting playback experiments to study the meaning of alarm calls (GREEN & MARLER 1979). Many studies have looked for correlations between alarm call variation and stimulus variation. Such studies can be used to define what potential information is made available to perceivers. Relatively few investigators have played back alarm call variants to a species to determine whether variants are able to elicit different responses (but see: LEGER & OWINGS 1978; LEGER et al. 1979; SCHWAGMEYER & BROWN 1981; HARRIS et al. 1983; BROWN 1985; CHENEY & SEYFARTH 1990; MACEDONIA 1990; STONE & TROST 1991; NIKOL'SKII & NESTEROVA 1988, 1989, 1990 cited in NIKOL'SKII et al. 1994; BLUMSTEIN & ARNOLD 1995). Studies that only correlate call types with situation may erroneously assume that perceivers respond to call variation. Playback experiments must be conducted to determine whether subjects respond to different call types (MACEDONIA & EVANS 1993). It is theoretically possible that subjects do not respond differently to call variants. Com-\n\nMarmot Alarm Calls. II 31\n\nmunication can be understood only by studying the behavior of both the signaler and the receiver (SMITH 1977).\n\nAcknowledgements\n\nI thank the government of Pakistan and the Khunjerab Village Organization for permission to work in Khunjerab, and for their hospitality while in Pakistan. I also thank Walter ARNOLD, Don OWINGS, Susan PERLOFF, Brad SHAFFER, W. John SMITH, and, especially, Judy STAMPS for comments on previous versions of this paper.\n\nFunding was generously provided by The National Geographic Society, the Fulbright-Hayes programme, the University of California-Davis (Graduate Fellowships, Graduate Research Awards, Jastro-Shields Research Scholarships), The American Institute of Pakistan Studies, the NSF Training Grant in Animal Behavior to UC Davis, the World Wide Fund for Nature-Pakistan, the World Pheasant Association-Pakistan, the US National Park Service — International Division, Sigma Xi, The Explorers Club, The American Society of Mammalogists, and the Max-Planck-Gesellschaft (through Wolfgang WICKLER). Commercial support was provided by Bushnell — a division of Bausch and Lomb, Deckers Corporation (Teva), Delta Airlines, Hi-Tec Sports, Sterigenics, and The North Face.\n\nLiterature Cited\n\nBALPH, D. M. & BALPH, D. F. 1966: Sound communication of Uinta ground squirrels. J. Mammal. 47, 440—450.\nBELETSKY, L. D., HIGGINS, B. J. & ORIANS, G. H. 1986: Communication by changing signals: call switching in red-winged blackbirds. Behav. Ecol. Sociobiol. 18, 221—229.\nBLUMSTEIN, D. T. 1994: Predation hazard assessment and management in golden marmots (Marmota caudata aurea). PhD Diss., Univ. of California, Davis.\n—— 1995: Golden marmot alarm calls: I. The production of situationally-specific vocalizations. Ethology 100, 113—125.\n—— & ARNOLD, W. 1995: Situational-specificity in alpine marmot alarm communication. Ethology 100, 1—13.\nBOUSKILA, A. & BLUMSTEIN, D. T. 1992: Rules of thumb for predation hazard assessment: predictions from a dynamic model. Am. Nat. 139, 161—176.\nBROOKS, C. M. 1983: Newer concepts of the autonomic system’s role derived from reductionist and behavioral studies of various animal species. J. Auton. Nerv. Syst. 7, 199—212.\nBROOKS, D. R. & MCLENNAN, D. A. 1991: Phylogeny, Ecology, and Behavior. Univ. of Chicago Press, Chicago.\nBROWN, E. D. 1985: Functional interrelationships among the mobbing and alarm caws of common crows (Corvus brachyrhynchos). Z. Tierpsychol. 67, 17—33.\nCHENEY, D. L. & SEYFARTH, R. M. 1990: How Monkeys See the World. Univ. of Chicago Press, Chicago.\nCONNER, D. A. 1985: The function of the pika short call in individual recognition. Z. Tierpsychol. 67, 131—143.\nCOSS, R. G. 1995: Evolutionary persistence of behavior: restraints on geographic variation and phenotypic plasticity. In: Geographic Variation of Behavior: an Evolutionary Perspective (FOSTER, S. A. & ENDLER J. A., eds). Oxford Univ. Press, Oxford, in press.\nDIGIDESIGN 1990: AudioMedia User’s Guide. Digidesign Inc., Menlo Park.\nEVANS, C. S. & GAIONI, S. J. 1990: Conspecific calls evoke characteristic cardiac responses in mallard ducklings. Anim. Behav. 39, 785—796.\n——, EVANS, L. & MARLER, P. 1993: On the meaning of alarm calls: functional reference in an avian vocal system. Anim. Behav. 46, 23—38.\nGREEN, S. & MARLER, P. 1979: The analysis of animal communication. In: Handbook of Behavioral Neurobiology, Vol. 3. Social Behavior and Communication (MARLER, P. & VANDENBERGH, J. G., eds). Plenum Press, New York. pp. 73—158.\nHARRIS, M. A., MURIE, J. O. & DUNCAN, J. A. 1983: Responses of Columbian ground squirrels to playback of recorded calls. Z. Tierpsychol. 63, 318—330.\nHAUSER, M. D. 1986: Male responsiveness to infant distress calls in free-ranging vervet monkeys. Behav. Ecol. Sociobiol. 19, 65—71.\n\n32 DANIEL T. BLUMSTEIN\n\n—— 1994: How monkeys feel about how they see the world. Language Commun. 14, 31—36.\nKELLER, E. 1992: Signalyze, Vers. 2. InfoSignal Inc., Lausanne.\nLEGER, D. W. 1993: Contextual sources of information and responses to animal communication signals. Psych. Bull. 113, 295—304.\n—— & OWINGS, D. H. 1978: Responses to alarm calls by California ground squirrels: effects of call structure and maternal status. Behav. Ecol. Sociobiol. 3, 177—186.\n——, —— & BOAL, L. M. 1979: Contextual information and differential responses to alarm whistles in California ground squirrels. Z. Tierpsychol. 49, 142—155.\nLOUGHRY, W. J. & MCDONOUGH, C. M. 1988: Calling and vigilance in California ground squirrels: a test of the tonic communication hypothesis. Anim. Behav. 36, 1533—1540.\nMACEDONIA, J. M. 1990: What is communicated in the antipredator calls of lemurs: evidence from playback experiments with ringtailed and ruffed lemurs. Ethology 86, 177—190.\n—— & EVANS, C. S. 1993: Variation among mammalian alarm call systems and the problem of meaning in animal signals. Ethology 93, 177—197.\nMCGREGOR, P. K., et al. 1992: Design of playback experiments: the Thornbridge Hall NATO ARW consensus. In: Playback and Studies of Animal Communication: Problems and Prospects (MCGREGOR, P. K., ed.). Plenum Press, New York. pp. 1—9.\nNELSON, D. A. & MARLER, P. M. 1990: The perception of birdsong and an ecological concept of signal space. In: Comparative Perception (BERKLEY, M. & STEBBINS, W., eds). Wiley & Sons, New York. pp. 443—478.\nNIKOL'SKII, A. A., NESTEROVA, N. L. & SUCHANOVA, M. V. 1994: Situational variations of spectral structure in Marmota bobac Müll. alarm signal. In: Actual Problems of Marmots Investigation (RUMYANTSEV, V. Y., ed.). ABF Publ. House, Moscow. pp. 127—148.\nOWINGS, D. H. 1994: How monkeys feel about the world: a review of how monkeys see the world. Language Commun. 14, 15—30.\n—— & HENNESSY, D. F. 1984: The importance of variation in sciurid visual and vocal communication. In: The Biology of Ground-dwelling Squirrels (MURIE, J. O., & MICHENER, G. R., eds). Univ. of Nebraska Press, Lincoln. pp. 169—200.\n—— & LEGER, D. W. 1980: Chatter vocalizations of California ground squirrels: predator- and social-role specificity. Z. Tierpsychol. 54, 163—184.\n—— & VIRGINIA, R. A. 1978: Alarm calls of California ground squirrels (Spermophilus beecheyi). Z. Tierpsychol. 46, 58—70.\nSCHLEIDT, W. M. 1973: Tonic communication: continual effects of discrete signs in animal communication systems. J. Theor. Biol. 42, 359—386.\nSCHWAGMEYER, P. & BROWN, C. H. 1981: Conspecific reaction to playback of thirteen-lined ground squirrel vocalizations. Z. Tierpsychol. 52, 25—32.\nSIEGEL, S. & CASTELLAN, N. J., Jr. 1988: Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill, New York.\nSMITH, W. J. 1977: The Behavior of Communicating. Harvard Univ. Press, Cambridge.\nSTONE, E. & TROST, C. H. 1991: Predators, risks and context for mobbing and alarm calls in black-billed magpies. Anim. Behav. 41, 633—638.\n\nReceived: September 13, 1994\nAccepted: January 13, 1995 (W. Wickler)", "affiliations": [{"country": "United States", "discipline": "Ecology", "university": "University of California, Los Angeles"}], "species_categories": ["Terrestrial Mammal"], "specialized_species": ["Golden marmots"], "computational_stages": ["Data Collection", "Pre-processing"], "linguistic_features": ["Semanticity"], "status": "saved", "created_at": "2026-01-13T12:49:59.882708", "updated_at": "2026-01-13T16:13:28.653524", "committed_at": "2026-01-13T15:34:26.168135"}
{"id": "d6b27f68-509f-4685-a02a-39080d43c1af", "title": "Finding a parent in a king penguin colony: the acoustic system of individual recognition", "authors": ["JOUVENTIN,  PIERRE", "AUBIN,  THIERRY", "LENGAGNE,  THIERRY"], "year": "1999", "journal": "Animal Behaviour", "abstract": "", "doi": "10.1006/anbe.1999.1086", "analysis_notes": "ANIMAL BEHAVIOUR, 1999, 57, 1175–1183\nArticle No. anbe.1999.1086, available online at http://www.idealibrary.com on\nFinding a parent in a king penguin colony: the acoustic system of\nindividual recognition\nPIERRE JOUVENTIN*, THIERRY AUBIN† & THIERRY LENGAGNE*†\n*CEBC–CNRS UPR 4701, Station de Chize ́, France\n†NAM–CNRS URA 1491, Universite ́ Paris-Sud\n(Received 4 September 1997; initial acceptance 3 December 1997;\nfinal acceptance 13 January 1999; MS. number: 5646R)\nTo be fed, a king penguin, Aptenodytes patagonicus, chick must identify the call of its parents, in\nthe continuous background noise of the colony. To study this recognition process, we played back to the\nchicks parental calls with acoustic parameters modified in the temporal and frequency domains. The\nparental call is composed of syllables (complex sounds with harmonic series) separated by pronounced\namplitude declines. Our experiments with modified signals indicate that the chick’s frequency analysis of\nthe call is not tuned towards precise peak energy values, the signal being recognized even when the carrier\nfrequency was shifted 100 Hz down or 75 Hz up. To recognize the adult, chicks used frequency rather\nthan amplitude modulation, in particular the frequency modulation shape of the syllable. This structure\nis repeated through the different syllables of the call giving a distinct vocal signature. Our experiments\nalso show that the receiver needs to perceive only a small part of the signal: the first half of the syllable\n(0.23 s) and the first three harmonics were sufficient to elicit recognition. The small amount of\ninformation necessary to understand the message, the high redundancy in the time and frequency\ndomains and the almost infinite possibilities of coding provided by the frequency modulation signature\npermit the chick to recognize the adult, without the help of a nest site. For these reasons, the code used\nin the call of the king penguin can be regarded as a functional code, increasing the possibility of\nindividual recognition in an acoustically constraining environment.\n 1999 The Association for the Study of Animal Behaviour\nIn birds, many vocal exchanges, particularly between\nmates and between parents and young, occur at short\nrange, over distances of a few metres at most (Falls 1982).\nAt these short distances, the signal is only weakly modified during propagation, by, for example, the ground\neffect, atmospheric absorption or geometric attenuation\n(Wiley & Richards 1978; Dabelsteen 1984; Dabelsteen\net al. 1993). Nevertheless, even at short range, communication between individuals may sometimes be difficult,\nfor example in noisy environments, such as dense\ncolonies of birds. In these colonies, a continuous background noise is generated by sounds used for communication and by other sounds such as wind, waves, beak\nclapping and wing flapping. The level of ambient noise is\nhigh (more than 70 dB: Robisson 1991; Mathevon 1996)\nand consequently the value of the signal-to-noise ratio is\nlow. In addition, the numerous vocalizations generate\njamming in both frequency and temporal domains. Thus,\nit is difficult for individuals in the colony to extract\ninformation from the background noise.\nSeabird colonies are particularly crowded and noisy.\nBreeding on land and feeding at sea, mates are separated\nfor days or weeks during the breeding season, but are\nfaithful to each other and to their offspring (see Jouventin\n1982 for penguins). The ability to recognize mates,\nparents or chicks is particularly important in seabird\ncolonies, where nest sites are densely packed, increasing\nthe possibility of confusion (Hutchison et al. 1968). To\nfind the egg(s) or chick(s), nesting birds also use landmarks, so to isolate vocal recognition in this study, we\nused a non-nesting species, the king penguin, Aptenodytes\npatagonicus.\nKing penguins breed on flat areas in homogeneous and\ndense monospecific colonies numbering thousands of\nbirds (1.6 breeders/m2 ; Guinet et al. 1995). There are no\nnest sites: each bird carries its egg and then its small chick\non its feet. At the end of the breeding cycle, as in our\nstudy, each individual is identified by its chick only by\nvocal cues (the ‘long call’ in the behavioural repertoire\ndescribed by Stonehouse 1960) and a few landmarks\n(Derenne et al. 1979 for the king penguin; Jouventin\nCorrespondence and present address: P. Jouventin, CEFE–CNRS UPR\n9056, 1919 Route de Mende, F-34213 Montpellier Cedex 5, France\n(email: jouventin@cefe.cnrs-mop.fr). T. Aubin is at NAM–CNRS URA\n1491, Universite ́ Paris-Sud, F-91400 Orsay, France.\n0003–3472/99/061175+09 $30.00/0  1999 The Association for the Study of Animal Behaviour11751982 for the penguin family). Observations of banded\nbirds and playback experiments show that only the mate\nresponds to its partner coming back. Similarly, chicks\nrespond only to their parents (or their calls played back).\nFor the chick, recognition of the parental call is important\nfor survival as parents usually only feed a chick they have\nidentified by its call (Jouventin 1982). Nevertheless, some\nadoptions do occur (Stonehouse 1960) by failed breeders\n(Jouventin & Mauget 1996).\nThat birds can recognize one another by voice alone\nhas been demonstrated repeatedly. In numerous studies\n(for reviews see Falls 1982; Dhondt & Lambrechts 1992),\nthe structure of the signal has been analysed, to\ndetermine which parameters encode acoustic identity\nand allow recognition between individuals. An ideal\nsignal for individual recognition would be highly\nstereotyped within each individual but would differ\nnoticeably between individuals. A method of quantifying\nthis is to define a ratio of acoustic parameters such\nas Cvb/Cvi, where Cvb is the coefficient of variation between individuals and Cvi the coefficient of\nvariation within individuals (Hutchison et al. 1968; for\na review see Scherrer 1984). The Cvb/Cvi ratio and\ncoefficients of correlation have been calculated for the\nking penguin call (Jouventin 1982; Robisson 1992;\nLengagne et al. 1997): the between-individual variation\nwas less stereotyped and on average three times greater\nthan the within-individual variation for time parameters\nand four times greater for frequency parameters. Thus,\nindividuals encode their call by making it highly\nstereotyped.\nKnowing that it is possible to distinguish the signals of\nindividuals statistically does not, however, tell us how\nbirds manage do it. Playback experiments are needed to\ninvestigate this. Our previous observations (Jouventin\n1982) and experiments (Aubin & Jouventin 1998) show\nthat king penguin chicks are able to decode a precise\nacoustic signal despite extreme jamming and high-level\nbackground noise generated by the colony (called the\n‘cocktail-party effect’ in humans by Cherry 1966), suggesting that a variety of fine details are fitted into the\ncode. How can penguins appreciate subtle qualities of\nsounds in such a noisy and jamming environment? How\ncan acoustic individuality be encoded when faced by such\nstrong acoustical constraints?\nDetection of signals in noise is a complex issue.\nThe most detailed knowledge of the mechanisms\ninvolved comes from psychoacoustic experiments\nperformed in controlled laboratory environments (Klump\n1996). Few field studies have studied experimentally\nhow signals of animals are detected amidst background\nnoise in the natural environment. The capacity of\nthe king penguin chick to recognize the parental\ncall requires peculiar strategies of coding/decoding.\nOur aim in this study was to determine to which\nacoustic parameters the chick is tuned in order to\nextract the information from the background noise. For\nthis purpose, we broadcast different parental calls modified in the frequency and temporal domains, to\nchicks waiting in the colony for their parents to return\nfrom the sea.\nMETHODS\nSubjects and Location\nWe studied king penguins at Ile Possession, Crozet\narchipelago (46)25*S, 51)45*E) from early December 1995\nto mid-January 1996. The study was conducted at Baie du\nMarin, in a large colony containing about 40 000 pairs\nof adults and 1500 chicks. The chicks we tested were\nbetween 10 and 12 months old. At this stage of its life, the\nchick is pushed away by new breeders from where the egg\nwas laid but is entirely dependent on its parents for food.\nTo identify them, we banded tested chicks on a flipper\nwith a temporary plastic band.\nRecording Procedure\nTo record parental calls of king penguins (the ‘long\ncall’ of Stonehouse 1960) we used an omnidirectional\nSennheiser MD211 microphone (frequency response\n150–18 000 Hz&1 dB) mounted on a 2.5-m perch and\nconnected to a Sony TCD10 Pro II digital audiotape\nrecorder (sampling frequency: 44.6 kHz, frequency\nresponse flat within the range 20–20 000 Hz&1 dB). The\ndistance between the beak of the recorded bird and the\nmicrophone was approximately 1 m.\nSound Synthesis and Analysis\nSignals were digitized with a 16-bit Oros Au21 acquisition card (with a 120-dB/octave antialiasing filter) at a\nsampling frequency of 16 kHz and stored on the hard disk\nof a PC computer. They were then examined and modified with the Syntana analytical package (Aubin 1994).\nSound pressure level measurements (SPL in dB) were\nmeasured with a Brue ̈l & Kjaer Sound Level Meter type\n2235 (linear scale, slow setting) equipped with a 1-inch\ncondenser microphone type 4176.\nPlayback Procedure\nFor playback experiments we used a 4200 Uher taperecorder (tape speed 19 cm/s) connected to a 50-W Audix\nPH3 self-powered loudspeaker (frequency response 100–\n5600 Hz&2 dB). Signals were played at a natural sound\npressure level (Robisson 1993a), of approximately 95 dB,\nmeasured 1 m from the loudspeaker.\nWe conducted tests between 1000 and 1700 hours,\nduring clear and dry weather, with a wind speed of less\nthan 4 m/s. The chick was generally resting in the feeding\narea, preening itself. The distance between the loudspeaker and the bird was ca. 7 m, this corresponding to a\nnatural calling distance of an adult (Robisson 1993b). At\nfirst, chicks were tested with the natural call of one of\ntheir parents. A few chicks (1/20) that did not respond\nbecause they had just been fed were tested the next day.\nOnly chicks whose intensity of response was ranked 4 (see\ncriteria of responses below) were kept for further tests\nwith modified signals. Thus, the population of chicks\ntested was homogeneous in motivation to detect the\n1176 ANIMAL BEHAVIOUR, 57, 6parental call. All these chicks reacted without ambiguity.\nTo minimize habituation, we tested chicks with the\nexperimental signals 2 or 3 days after testing them with a\nnatural call, while their parents were absent. We broadcast two identical experimental signals, separated by an\ninterval of 5 s, to a chick in a feeding area with a normal\ndensity of birds; then 15 min later, we broadcast another\nseries of two identical signals. The 15-min period between\nbroadcasts allowed the chick to recover its natural\nactivity. To prevent habituation, a maximum of three\nseries of signals a day was broadcast to any one chick.\nEach chick was tested with all the different types of\nsignal. The order of presentation of the signals was\nrandomized for the different chicks tested. In the same\nway, the order of presentation of experimental signals\nfrom day to day was not the same for each chick. Hence,\nthe observed responses for the whole group of chicks\ntested were neither a result of cumulative excitation nor\ndependent on playback order. To avoid a possible masking effect not studied here (see Aubin & Jouventin 1998),\nexperimental signals were broadcast only during relative\nperiods of silence, that is, when birds in the vicinity of the\ntested chick remained silent.\nCriteria of Responses\nIn natural conditions, when the parents are absent, the\nchick remains silent, lying quietly. The adult, returning\nfrom the sea to feed its chick, makes its way to the area of\nthe colony where the chick is usually located (rendezvous\nsite) and calls at regular intervals. The chick in the flock\nholds up its head, calls in reply and moves towards the\nparent, often running (Stonehouse 1960; Jouventin\n1982). The other chicks in the vicinity, resting or preening themselves, never react to the extraneous calls and\ntheir behaviour does not change.\nTo evaluate the intensity of response of tested chicks to\nplayback signals, we used a five-point scale, as follows: 0\n(none): no reaction; 1 (weak): head turning, agitation; 2\n(medium): head turning and calls after the second broadcast; 3 (strong): head turning, calls after the first broadcast; and 4 (very strong): head turning, calls after the first\nbroadcast, approaches in the direction of the loudspeaker\nand stops in the vicinity (less than 3 m). This behavioural\nscale is similar to those used in previous studies on the\nking penguin (see Derenne et al. 1979; Jouventin et al.\n1979; Robisson 1990).\nStatistical Analysis\nStatistics and interpretations of results were based on\nthe analysis of the distribution of the observed values\nwithin the five response classes. To compare paired\nsamples in more than two categories, we used the marginal homogeneity test (Agresti 1990) together with exact\ntwo-sided P values. When the same marginal distribution\nwas used through several comparisons, we used the\nBonferroni-corrected P values to assess the final significance of the test. Computations of exact two-sided P\nvalues were carried out with StatXact software (Cytel\n1995). We used a significance level of P≤0.05.\nExperimental Signals\nWe tested 17 experimental signals. These consisted of\nnatural calls modified in the frequency and temporal\ndomains.\nThe original signal\nThis signal was the natural parental call specific to\nthe chick being tested. So, for each chick tested there\nwas an original signal corresponding to the call of one\nof the parents (male or female) and a series of experimental signals. Figures 1 and 2 show an example of a\nnatural parental call. The call corresponds to a series\nof sound components, termed syllables by Jouventin\n(1982), separated by strong amplitude declines which\ncoincide with falls in frequency. The call duration\nvaried from 3 to 6 s (X&SD=4.45&1.16 s, N=66), the\nfirst syllable generally being the longest. The spectral\ncomposition of syllables corresponds to harmonic\nseries. Most of the energy is concentrated between\n500 and 2500 Hz, with a maximum level corresponding\nmost often to the harmonic (twice the fundamental\nfrequency, Fo).\nSignals with a modified harmonic structure\nWe modified the parental calls in two ways.\n(1) The parental call was filtered by low-pass or highpass digital filters (Fig. 1) by applying optimal filtering\nwith a fast Fourier transform (FFT; Press et al. 1988;\nMbu-Nyamsi et al. 1994). The window size of the FFT was\n4096 Hz (precision in frequency: ƒF=4 Hz). Four signals\nwere constructed (Fig. 1): with the fundamental frequency alone; with the fundamental (Fo) and the first\nharmonic (2Fo ); with the lower part of the spectrum\n(Fo +2Fo +3Fo ); and with the upper part of the spectrum\n(between 2000 and 8000 Hz).\n(2) The parental call was shifted up or down in frequency. This was done by picking a data record through a\nsquare window, applying short-term overlapping (50%)\nFFT, followed by a linear shift (+ or \") of each spectrum\nand by a short-term inverse fast Fourier transform\n(FFT\"1 ; Randall & Tech 1987). The window size was\n4096 Hz (ƒF=4 Hz). The linear shifts of the spectra were\n+100, +75, +50, \"50, \"75 and \"100 Hz. These values\nwere chosen on the basis of the natural distribution of\nfundamental frequency values. Except for these modifications of the pitch of the carrier frequency, temporal\nand amplitude parameters of the parental call were\nunchanged.\nSignals with a modified temporal pattern\nWe modified both frequency and amplitude modulations (FM and AM) and the syllable duration of natural\ncalls.\n(1) For FM and AM modifications, two signals were\nconstructed. (a) A natural AM was applied to a carrier\nfrequency without FM (Fig. 2). The carrier frequency was\na harmonic series and the value of the fundamental\ncorresponded to the mean value of the fundamental\nfrequency of the parental call. We applied to this carrier\n1177JOUVENTIN ET AL.: KING PENGUIN CALL RECOGNITIONfrequency the natural AM (the envelope) that was\nextracted from the call of the parent, using the Hilbert\ntransform calculation (Seggie 1987; Bre ́mond & Aubin\n1992; Mbu-Nyamsi et al. 1994). In these conditions,\nbecause of the application of the envelope, the temporal\nsuccession of syllables of the parental call was maintained. The only difference between this call and the\nnatural call was the lack of FM. (b) The AM of the parental\ncall was removed without modification of the natural FM\nand the natural carrier frequency. To do this, we used\nanalytical signal analysis (Mbu-Nyamsi et al. 1994). The\nresult was a signal with a normal FM and duration, but\nwithout any AM.\n(2) To modify syllable duration, we truncated the syllable. To prevent spectral artefacts arising from an abrupt\ngap in amplitude, an envelope was applied (by multiplication) to the data set in the time domain so as to smooth\nall the edges. As previously, the Hilbert transform calculation was used to build the envelope. Previous studies\n(Derenne et al. 1979; Jouventin 1982) have shown that\nthe broadcast of a part of the parental call is sufficient to\nelicit the chick’s response. In the present study, we\nFigure 1. Sound spectrograms of a king penguin parental call and of the four experimental signals corresponding to the same call modified\nin the frequency domain.\n1178 ANIMAL BEHAVIOUR, 57, 6broadcast signals where only the first or a part of the first\nsyllable of the parental call was present. We constructed\nfive signals: with the first syllable (Sy1); with a syllable\nbelonging to the middle of the call (Sym); with the\nfirst half of the first syllable (H1Sy1); with the second\nhalf of the first syllable (H2Sy1); and with the first quarter\nof the first syllable (Q1Sy1). The mean duration&SD\nof the syllables of the calls tested was 0.462&0.011 s\n(N=17).\nRESULTS\nTo simplify the results, we grouped response classes 0 and\n1 together as negative responses, and classes 2, 3 and 4 as\npositive responses. Effectively, it was only for classes 2, 3\nand 4 that recognition appeared clearly, with a call in\nreply to the signal broadcast. In contrast, for class 1\nresponses, chicks only looked towards the loudspeaker,\nnot particularly because they recognized the parental call\nbut more probably because they were surprised by an\nunusual (nonspecific?) signal. As a general rule, the chicks\ndid not recognize the manipulated signals as well as\nthey did the original parental call (Agresti’s marginal\nhomogeneity test: P<0.05).\nHarmonic Structure\nTable 1 shows the results. There was no significant\ndifference between responses to Fo and to Fo +2Fo. For\nboth signals a majority of positive responses was\nobserved. In contrast, there was a significant difference\nbetween the low-pass and the high-pass signals, the latter\neliciting a majority of negative responses.\nThere were significant differences between some\nfrequency-shifted signals, but they elicited a majority of\npositive responses (Table 1) except for the +100-Hz\nsignal, which differed significantly from all other signals\n(marginal homogeneity tests: +100 Hz versus: +75 Hz:\nS=25; +50 Hz: S=29; \"50 Hz: S=29; \"75 Hz: S=28;\n\"100 Hz: S=18; P<0.001 in all cases except \"100 Hz\nwhere P=0.005).\nTemporal Pattern\nTable 2 shows the results. Signals with a natural AM\nand without FM did not trigger a response. In every case\n(except one instance of head turning), chicks remained\nstationary, resting or preening themselves, as before the\nbroadcast. In contrast, signals with a natural FM and\nwithout AM triggered recognition. These signals differed\nsignificantly.\nThe broadcast of one syllable was sufficient to elicit\nrecognition (majority of positive responses). Recognition\nwas not linked to a particular syllable since it was\nobserved for both the first syllable and one from the\nmiddle of the call (no significant difference between Sy1\nand Sym). The majority of chicks recognized just the first\nhalf of the first syllable (mean duration&SD=0.231&\n0.005 s, N=17; no significant difference between Sy1 and\nH1Sy1). Recognition did not occur when only the first\nquarter or the second half of the first syllable was broadcast (significant difference between Sy1 on the one hand\nand Q1Sy1 and H2Sy1 on the other).\nDISCUSSION\nWhich Parameters Encode Acoustic Identity?\nThat the chicks did not recognize the manipulated\nsignals as well as they did the original signal, that is, the\n6 Parental call (CS)\n0\n1 s\nWith AM: without FM\nFrequency (kHz)\n6\n0\nWith FM: without AM\n6\n0\nFigure 2. Sound spectrograms of the parental call shown in Fig. 1\nand of the two experimental signals corresponding to the same call\nbut with either the amplitude modulation (AM) or the frequency\nmodulation (FM) removed.\n1179JOUVENTIN ET AL.: KING PENGUIN CALL RECOGNITIONparental call, is not surprising. The majority of birds use a\ncomplex of differentially weighted parameters, rather\nthan any simple feature, to recognize their signals. This\nhas been shown for songs (Weary 1990) and for calls\n(Gaioni & Evans 1986; Dooling et al. 1987). The king\npenguin is similar in this respect. Thus, the lack of some\nparameters even weakly important for individual recognition in our manipulated calls would explain the\ndifferent level of response to the manipulated signal.\nOur experiments on harmonic structure show that\nchicks pay attention to the low part of the spectrum of\ntheir parents’ call, not to the higher part. Only the\nlow-pass calls were recognized by the chicks. Even a signal\nwith only the Fo and 2Fo retained was still recognized.\nNevertheless, a parental call with only the fundamental\nfrequency kept was not recognized. A pure tone, such as a\nsignal with the fundamental alone, is therefore not sufficient and the addition of the first harmonic is necessary\nto trigger a response. Thus we conclude that chicks pay\nattention to the width of the spectrum of their parental\ncalls (two frequencies at least are necessary), the important part being the lower frequencies. They may use low\nfrequencies because high frequencies cannot be transmitted far in the atmosphere without strong attenuation\n(Wiley & Richards 1978) and the background noise is so\nloud that a call cannot be heard more than 16–18 m away\n(Jouventin 1982; Aubin & Jouventin 1998). Moreover,\nhigh frequencies cannot be propagated through penguin\nbodies (Robisson 1991).\nOur results also show that chicks are sensible to the\neffects of shifting frequency: significant differences were\nobtained with changes of as little as 25 Hz (for example\nbetween +75- and +50-Hz signals and +100- and +75-Hz\nsignals). Nevertheless, signals shifted 100 Hz down or\n75 Hz up still elicited a majority of positive responses\n(ranked 2–4 in intensity).\nOur experiments showed that AM alone was not\nsufficient to elicit recognition, even though such a\nTable 1. Responses of king penguin chicks to parental calls with modified frequency parameters\nExperiments\nResponses\nN\nMarginal\nhomogeneity\ntests\n0 1 2 3 4 S P\nFiltration\nFo 5 3 2 5 1 16 }Fo +2Fo 2 0 1 6 3 12 24 0.351\nLow pass 0 0 0 8 8 16 }High pass 5 5 3 1 2 16 62 0.0004\nLinear shift (Hz)\n+100 8 3 1 4 0 16 }+75 0 2 2 7 5 16 } 25 0.0002\n+50 0 0 0 6 10 16 } 26 0.016\n−50 0 0 0 4 12 16 } 8 1.000\n−75 1 1 1 6 7 16 } 28 0.013\n−100 3 1 4 7 1 16 56 0.039\nFor the linear shift series, P values are Bonferroni corrected.\nTable 2. Responses of king penguin chicks to parental calls with modified temporal parameters\nExperiments\nResponses\nN\nMarginal\nhomogeneity\ntests\n0 1 2 3 4 S P\nModulation\nWithout FM 15 1 0 0 0 16 }Without AM 0 0 0 7 10 17 16 <0.001\nSyllable duration\n1st syllable (Sy1) 1 2 1 11 2 17\n} } } }Middle syllable (Sym) 1 1 2 4 2 12 29 3.375\n1st half of 1st syllable (H1Sy1) 4 1 1 8 1 15 19 0.750\n2nd half of 1st syllable (H2Sy1) 10 1 1 0 0 12 41 0.004\n1st quarter of 1st syllable (Q1Sy1) 12 1 1 0 0 14 53 <0.001\nFor the syllable duration series, P values are Bonferroni corrected.\n1180 ANIMAL BEHAVIOUR, 57, 6signal respects the harmonic structure and the temporal\nsuccession of syllables of the parental call. In contrast, a\nsignal in which the parental AM was suppressed was\nrecognized without ambiguity by all the chicks tested.\nThese experiments prove that FM is a key feature for the\nrecognition of the parental call, whereas AM is not used\nfor individual recognition. The information content of\nthe FM is concentrated at the level of the syllable since\nrecognition occurred when only one syllable of the\nparental call was broadcast (signals Sy1 and Sym), whatever the syllable (the first or a syllable in the middle of the\ncall). In fact, it seems that the first half of the syllable was\nsufficient for recognition. In contrast, the second part of\nthe syllable was not recognized by the chicks. With regard\nto the FM structure of a syllable of a parental call, it\nappears that the basic shape is always the same: an\nincrease followed by a decrease in frequency. For all the\nparental calls that we have analysed, the inflexion point\nbetween the increase and decrease in frequency was\nalways contained in the first half of the syllable. It seems\nthat this inflexion point is necessary to elicit recognition.\nWhen the inflexion point was lacking, as with the first\nquarter or the second half of the syllable (signals Q1Sy1\nand H2Sy1), the signal was not recognized. The shape of\nthe increasing and then decreasing frequency of the first\nhalf of the syllable should correspond to the vocal signature of the call. These results with chicks parallel previous\nfindings with adult king penguin calls. Derenne et al.\n(1979) and Robisson (1992) performed field playback\nexperiments in which they tested the ability of adults to\nrecognize their mates. They played back reversed calls or\nsignals whose pitch and duration of syllables had been\nmore or less modified and in all cases individual recognition failed. In these experiments, the FM signature of the\nsyllable was modified. As for recognition between mates,\nthe recognition of the parent by the chick seems to be\nlinked to the FM shape of the syllable, which is repeated\nas a vocal signature on the different syllables of the call.\nAdaptation to the Noisy Environment of the\nColony\nProblems of animal communication in noise can be\nanalysed in engineering terms (Okanoya & Dooling\n1991). Two methods used in communication engineering\nare used to study sensory filtering in animals from the\nreceiver’s point of view: the frequency-based filter model\nand the matched filter model (Hopkins 1983). In a\nfrequency-based filter the output signal corresponds to\nthe correlation between the spectrum of the input signal\nand the gain of the filter. Such examples of correlations\nbetween the acoustic signal and behavioural and auditory\nthresholds are numerous in birds (Konishi 1970; Dooling\net al. 1971; Dooling & Saunders 1975; Okanoya &\nDooling 1988). In the matched filter model, the output of\nthe filter corresponds to the cross-correlation between the\nreceived and expected signals (an internal template). The\nexistence of this model is suggested by some studies (for\nexample Gaioni & Evans’s 1986 study of the distress call\nof mallard ducklings, Anas platyrhynchos). It is likely that\nking penguin chicks use matched filtering to detect the\nparental call embedded in the masking noise of the\ncolony. Effectively, signals with reversed syllables or without FM or without the inflexion point (in the FM structure) did not elicit recognition. On the other hand,\nsignals strongly shifted up or down in frequency did elicit\npositive responses, and this fails to support the notion\nthat chicks were using frequency-based filters. Crosscorrelation detection by matching filtering is known to\nbe the most sensitive method for detecting a signal in\nnoise (Lee 1960). The use of this method of detection\nshould explain why chicks are able to extract the parental\ncall even when call intensity is well below that of the\nnoise of simultaneous calls produced by other adults in\nthe colony (Aubin & Jouventin 1998). In humans, this\nprocess of acoustic recognition against a background\nnoise has been called the cocktail-party effect (Cherry\n1966) and several authors have suggested its occurrence\nin animals (Busnel 1977; Wiley & Richards 1982).\nAnother important point concerns the redundancy of\nthe information. The parental call corresponds to a succession of syllables with a broad frequency band. Our\nexperiments showed that the receiver needs only a small\npart of the information to recognize the call: chicks\nidentified the parental call with only the first two harmonics, with one syllable and even with the first half of a\nsyllable, a time period less than 6% of the total signal\nduration (230 ms for a signal of 4–5 s mean duration).\nThus the king penguin call is highly redundant in time\nand frequency. Why such a high redundancy? The background noise of the colony is almost continuous and\nwindows of silence are scarce and unpredictable, for\nexample during a 4-min recording made in a feeding area\n(unpublished data), only 15% of the time corresponded\nto relatively quiet periods and the mean duration of these\nperiods of silence was 0.6 s. The adult cannot predict\nwhen and for how long it can be heard without jamming.\nTo enhance the chance of feeding its chick, the adult\nrepeats the same information many times and, therefore,\nhas the opportunity to find a window of silence. In terms\nof harmonic structure, some parts of the spectrum are\nmore or less modifed, depending on the conditions of\npropagation of the signal, for example, distance, the\nscreening effect of penguin bodies. In this case, if important parameters, such as the frequency modulation, are\ndistributed over many harmonics, these redundant elements of information are more likely to be transmitted\nwithout destruction. According to the theory of information (Schannon & Weaver 1949), such high redundancy\nimproves the probability of receiving a message in a noisy\nchannel.\nLastly, the parental call of the king penguin comprises\nthree to seven syllables (Jouventin 1982), each syllable\nbeing separated by deep declines in amplitude which\nappear as silences. These sharp amplitude variations,\ncorresponding to a succession of syllables, are easily\ndistinguished from continuous noises such as wind or sea\nwaves. They also have the advantage of increased locatability (Wiley & Richards 1982) which in turn helps the\nreceiver to detect the signal in the background noise. This\nis important for king penguins, which do not have a nest\nsite. All the chicks responded with a score of 4 to the\n1181JOUVENTIN ET AL.: KING PENGUIN CALL RECOGNITIONnatural parental call and with a score of 2–4 for modified\nsignals such as low pass, without AM or one-syllable\nsignals. These results do not necessarily imply that these\nmodified signals are recognized less; instead they could be\nmore difficult to locate (class 4 response corresponding to\nan approach oriented towards the loudspeaker).\nWith an FM signature highly redundant in time and\nfrequency, the code of the king penguin call can thus be\nregarded as a functional code increasing the possibility of\nindividual recognition in an acoustically constraining\nenvironment.\nBiological Significance of the Code\nParent–offspring recognition by acoustic signals has\nbeen amply documented for birds, and particularly for\nbirds with nests (Falls 1982; Beecher 1989). Often, discussions have emphasized the parents’ need to recognize\noffspring but have neglected pressures for young to recognize parents (Beecher et al. 1985), especially in species\nwithout a nest site, such as king penguins. Derenne et al.\n(1979) showed that parents were able to recognize the call\nof their young and we have now shown that chicks also\nrecognize the FM signature of the parental call. This\nrecognition process supposes that three conditions are\nfulfilled.\n(1) The chick must learn the parental call. As a result,\nthe call of the parent forms a template (Slater 1989) that,\naccording to the matched filter model described above,\nthe chick correlates (compares) with each received call. In\nnumerous birds, parent–young recognition is effective\nwhen young become mobile (Falls 1982; Williams 1982;\nBo ̈hner 1990), for example the Adelie penguin, Pygoscelis\nadeliae (Jouventin & Roux 1979). The young king penguin has the opportunity to memorize the call of its\nparent during its first 5 weeks when it remains on the\nparents’ feet, and maybe before, during hatching. Each\ntime a parent returns from foraging to meet its mate, it\ngives a call for mutual identification, and this call, heard\nby the chick, is identical to the one the chick later uses to\nidentify its parent (Jouventin 1982).\n(2) The FM signature must offer a sufficient number of\nvariations to ensure recognition of each individual and\navoid confusion with others. Beecher (1982, 1989) developed a quantitative method for measuring the information capacity needed in a signature system to identify\neach member of a population with a small probability of\nconfusion. In our case, it was difficult to calculate the\ntheoretical number of possible features of FM signatures.\nEffectively, an FM signature allows an almost infinite\nnumber of combinations between temporal and frequency parameters, far more than that necessary under\nnatural conditions to ensure individual recognition in the\ncolony. In addition, there could be fewer FM signatures\nthan adults in the colony since chicks meet their parents\non a rendezvous site, so limiting the probability of\nconfusion.\n(3) The FM signature of the parents must be sufficiently\nstable during the year. The chick must learn at least one\nFM signature contained in the call of each parent and\nmust be able to distinguish these parental signatures from\nothers. This is a complex learning process. A parental\nsignature system that continually changed would be very\nconfusing for the chick. Previous findings indicate that\nking penguins do not change their calls: the temporal and\nfrequency features of the calls remain remarkably constant during the year (Jouventin 1982) and even from\nyear to year (unpublished data). Nevertheless, in some\nspecies of seabirds, the calls vary continuously. Learning\nof parental calls by chicks appears to be a countinuing\nprocess in the laughing gull, Larus atricilla (Beer 1979), for\nexample; this species has nest sites, however, so landmarks limit the possibility of confusion and facilitate\nindividual recognition.\nThe evolution of coding and decoding sounds may be\ndetermined by phylogeny or ecology. The penguin family\nuses the largest range of breeding sites known for colonial\nbreeding species: (1) burrows as in the little penguin,\nEudyptula minor; (2) nests made with stones, grasses or\nbranches as in the majority of penguins (and birds); (3)\nwithout a nest but on a site during the brooding phase as\nin the king penguin; and (4) without a nest and without\na site such as the emperor penguin, Aptenodytes forsteri,\nmoving with its egg on its feet. Since the two non-nesting\nspecies need only vocal cues to identify themselves\namong several hundred breeders (Jouventin 1982), they\nconstitute good models for individual recognition. In\nfuture studies, we intend to compare the acoustic mechanisms of identification of the nesting and non-nesting\nspecies to determine if coding-decoding processes are\nrelated to the breeding constraints of these four groups of\nbirds.\nAcknowledgments\nThe study was supported in the field by the Institut\nFranc ̧ais pour la Recherche et la Technologie Polaires\n(I.F.R.T.P.) and in the laboratory by the Centre National\nde la Recherche Scientifique (C.N.R.S.). We are grateful to\nJean Claude Bre ́mond, Marcel Lambrechts, Jacques Lauga,\nStephen Hall and an anonymous referee for comments\nand Antoine Catard for help in the field. Mary-Anne Lea\nimproved the English.\nReferences\nAgresti, A. 1990. Categorical Data Analysis. New York: J. Wiley.\nAubin, T. 1994. Syntana: a software for the synthesis and analysis of\nanimal sounds. Bioacoustics, 6, 80–81.\nAubin, T. & Jouventin, P. 1998. Cocktail-party effect in king\npenguin colonies. Proceedings of the Royal Society of London, Series\nB, 265, 1665–1673.\nBeecher, M. D. 1982. Signature systems and kin recognition.\nAmerican Zoologist, 22, 477–490.\nBeecher, M. D. 1989. Signalling systems for individual recognition:\nan information theory approach. Animal Behaviour, 38, 248–261.\nBeecher, M. D., Stoddard, P. K. & Loesche, P. 1985. Recognition\nof parent’s voices by young cliff swallows. Auk, 102, 600–605.\nBeer, C. G. 1979. Vocal communication between laughing gull\nparents and chicks. Behaviour, 70, 118–146.\nBo ̈hner, J. 1990. Early acquisition of song in the zebra finch,\nTaeniopygia guttata. Animal Behaviour, 39, 369–374.\n1182 ANIMAL BEHAVIOUR, 57, 6Bre ́mond, J. C. & Aubin, T. 1992. The role of amplitude modulation\nin distress-call recognition by the black-headed gull (Larus argentatus). Ethology, Ecology and Evolution, 4, 187–191.\nBusnel, R. G. 1977. Acoustic communication. In: How Animals\nCommunicate (Ed. by T. A. Sebeok), pp. 233–251. Bloomington:\nIndiana University Press.\nCherry, C. 1966. On Human Communication. 2nd edn. Cambridge,\nMassachusetts: MIT Press.\nCytel 1995. StatXact 3 User’s Manual. Cambridge: Cytel Software\nCorporation.\nDabelsteen, T. 1984. An analysis of the full song of the blackbird\nTurdus merula with respect to message coding and adaptations for\nacoustic communication. Ornis Scandinavica (Journal of Avian\nBiology), 15, 227–239.\nDabelsteen, T., Larsen, O. N. & Pedersen, S. B. 1993. Habitatinduced degradation of sound signals: quantifying the effects of\ncommunication sounds and bird location on blur ratio, excess\nattenuation, and signal-to-noise ratio in blackbird song. Journal of\nthe Acoustic Society of America, 93, 2206–2220.\nDerenne, P., Jouventin, P. & Mougin, J. L. 1979. Le chant du\nmanchot royal (Aptenodytes patagonicus) et sa signification e ́volutive. Le Gerfaut, 69, 211–224.\nDhondt, A. A. & Lambrechts, M. M. 1992. Individual recognition in\nbirds. Trends in Ecology and Evolution, 7, 178–179.\nDooling, R. J. & Saunders, J. C. 1975. Hearing in the parakeet\n(Melopsittacus undulatus), absolute thresholds, critical ratios, frequency difference limens, and vocalizations. Jounal of Comparative\nPsychology, 88, 1–20.\nDooling, R. J., Mulligan, J. M. & Miller, J. D. 1971. Auditory\nsensitivity and song spectrum of the common canary\n(Serinus canarius). Journal of the Acoustic Society of America, 50,\n700–709.\nDooling, R. J., Brown, D. D., Park, T. J., Okanoya, K. & Soli, S. D.\n1987. Perceptual organization of acoustic stimuli by budgerigars\n(Melopsittacus undulatus): 1. Pure tones. Journal of Comparative\nPsychology, 101, 367–381.\nFalls, J. B. 1982. Individual recognition by sound in birds. In: Acoustic\nCommunication in Birds, Vol. 2 (Ed. by D. E. Kroodsma & E. H.\nMiller), pp. 237–278. New York: Academic Press.\nGaioni, S. J. & Evans, C. S. 1986. Perception of distress calls in\nmallard ducklings (Anas platyrhynchos). Behaviour, 99, 250–274.\nGuinet, C., Jouventin, P. & Malacamp, J. 1995. Satellite remote\nsensing in monitoring change of seabirds. Use of spot image in\nking penguin population increase at Ile aux cochons, Crozet\nArchipelago. Polar Biology, 15, 511–515.\nHopkins, C. P. 1983. Sensory mechanisms in communication. In:\nAnimal Behaviour 2, Communication (Ed. by T. R. Halliday & P. J. B.\nSlater), pp. 123–154. Oxford: Blackwell Scientific.\nHutchison, R. E., Stevenson, J. G. & Thorpe, W. 1968. The basis for\nindividual recognition by voice in the Sandwich tern (Sterna\nsandvicensis). Behaviour, 32, 150–157.\nJouventin, P. 1982. Visual and Vocal Signals in Penguins, their\nEvolution and Adaptive Characters. Berlin: Verlag Paul Parey.\nJouventin, P. & Mauget, R. 1996. The endocrine basis of the\nreproductive cycle in the king penguin (Aptenodytes patagonicus).\nJournal of Zoology, 238, 665–678.\nJouventin, P. & Roux, P. 1979. Le chant du Manchot Ade ́lie. Roˆle\ndans la reconnaissance individuelle et comparaison avec le chant\nd’un oiseau non-territorial, le Manchot empereur. L’Oiseau et\nR.F.O., 49, 31–37.\nJouventin, P., Guillotin, M. & Cornet, A. 1979. Le chant du\nmanchot empereur et sa signification adaptative. Behaviour, 70,\n231–250.\nKlump, G. M. 1996. Bird communication in the noisy world. In:\nEcology and Evolution of Acoustic Communication in Birds (Ed. by\nD. E. Kroodsma & E. H. Miller), pp. 321–338. Ithaca: Cornell\nUniversity Press.\nKonishi, M. 1970. Comparative neurophysiological studies of hearing and vocalizations in songbirds. Zeitschrift fu ̈r Vergleichende\nPhysiologie, 66, 257–272.\nLee, Y. M. 1960. Statistical Theory of Communication. New York: J.\nWiley.\nLengagne, T., Lauga, J. & Jouventin, P. 1997. A method of\nindependent time and frequency decomposition of bioacoustic\nsignals: inter-individual recognition in four species of penguins.\nComptes Rendus de l’ Acade ́mie des Sciences, 320, 885–891.\nMathevon, N. 1996. What parameters can be used for individual\nacoustic recognition by the greater flamingo? Comptes Rendus de\nl’ Acade ́mie des Sciences, 319, 29–32.\nMbu-Nyamsi, R. G., Aubin, T. & Bre ́mond, J. C. 1994. On the\nextraction of some time dependent parameters of an acoustic\nsignal by means of the analytic signal concept. Its application to\nanimal sound study. Bioacoustics, 5, 187–203.\nOkanoya, K. & Dooling, R. J. 1988. Hearing in the swamp sparrow,\nMelospiza georgiana, and the song sparrow, Melospiza melodia.\nAnimal Behaviour, 36, 726–732.\nOkanoya, K. & Dooling, R. J. 1991. Detection of species-specific\ncalls in noise by zebra finches Poephila guttata and budgerigars\nMelopsittacus undulatus: time or frequency domain? Bioacoustics,\n3, 163–172.\nPress, W. H., Flannery, B. P., Teukolsky, S. A. & Vetterling, W. T.\n1988. Numerical Recipes in C. The Art of Scientific Computing. New\nYork: Cambridge University Press.\nRandall, R. B. & Tech, B. 1987. Frequency Analysis. Naerum: Bru ̈el &\nKjaer.\nRobisson, P. 1990. The importance of the temporal pattern of\nsyllables and the syllable structure of display calls for individual\nrecognition in the genus Aptenodytes. Behavioural Processes, 22,\n157–163.\nRobisson, P. 1991. Broadcast distance of the mutual display call in\nthe emperor penguin. Behaviour, 119, 302–316.\nRobisson, P. 1992. Roles of pitch and duration in the discrimination\nof the mate’s call in the king penguin Aptenodytes patagonicus.\nBioacoustics, 4, 25–36.\nRobisson, P. 1993a. Adaptation du transfert de l’information\nindividuelle au milieu colonial chez les manchots. Revue\nd’Ecologie—Terre et Vie, 48, 133–141.\nRobisson, P. 1993b. La reconnaissance individuelle chez deux\nespe`ces jumelles. Le manchot empereur Aptenodytes forsteri, et le\nmanchot royal Aptenodytes patagonicus. PhD thesis, University of\nRennes.\nSchannon, C. E. & Weaver, W. 1949. The Mathematical Theory of\nCommunication. Urbana: University of Illinois.\nScherrer, B. 1984. Biostatistique. Que ́bec: Gae ̈tan Morin.\nSeggie, D. 1987. The application of analytic signal analysis in speech\nprocessing. Processing Institute of Acoustics, 8, 82–85.\nSlater, P. J. B. 1989. Bird song learning: causes and consequences.\nEthology, Ecology and Evolution, 1, 19–46.\nStonehouse, B. 1960. The king penguin Aptenodytes patagonicus of\nSouth Georgia. 1. Breeding behaviour and development. Falkand\nIsland Dependencies Survey Scientific Reports, 23, 1–81.\nWeary, D. M. 1990. Categorization of song notes in great tits: which\nacoustic features are used and why? Animal Behaviour, 39, 450–\n457.\nWiley, R. H. & Richards, D. B. 1978. Physical constraints on acoustic\ncommunication in the atmosphere: implication for the evolution\nof animal vocalizations. Behavioral Ecology and Sociobiology, 3,\n69–94.\nWiley, R. H. & Richards, D. G. 1982. Adaptations for acoustic\ncommunication in birds: transmission and signal detection. In:\nAcoustic Communication in Birds, Vol. I (Ed. by D. E. Kroodsma &\nE. H. Miller), pp. 131–181. New York: Academic Press.\nWilliams, H. 1982. Models for song learning in the zebra finch:\nfathers or others? Animal Behaviour, 39, 745–757.\n1183JOUVENTIN ET AL.: KING PENGUIN CALL RECOGNITION", "affiliations": [{"country": "France", "discipline": "Biology", "university": "Centre National de la Recherche Scientifique"}, {"university": "", "country": "", "discipline": ""}], "species_categories": ["Bird"], "specialized_species": ["king penguin"], "computational_stages": ["Data Collection", "Pre-processing", "Meaning Identification"], "linguistic_features": ["Semanticity", "Vocal Auditory Channel and Turn-taking", "Discreteness and Syntax", "Reference and Displacement"], "status": "saved", "created_at": "2026-01-13T12:49:59.882712", "updated_at": "2026-01-13T16:13:39.281338", "committed_at": "2026-01-13T15:35:47.216002"}
{"id": "0da2ddaf-1d4e-4273-8d71-5e576e2afd50", "title": "Call matching in the quacking frog ( Crinia georgiana )", "authors": ["Gerhardt,  H. C.", "Roberts,  J. D.", "Bee,  M. A.", "Schwartz,  J. J."], "year": "2000", "journal": "Behavioral Ecology and Sociobiology", "abstract": "", "doi": "10.1007/s002650000226", "analysis_notes": "Abstract Males of the quacking frog Crinia georgiana\nproduce calls consisting of 1–11 notes. Playback experiments using synthetic calls showed that males tend to\nmatch the number of notes in 2-note and 4-note stimuli;\nhowever, males tended to produce more than 1 note in\nresponse to a 1-note stimulus and fewer than 8 notes in\nresponse to an 8-note stimulus. Successive playbacks of\ntwo, 4-note calls from separate speakers indicate that\nmales are likely to match the combined number of notes\nin the calls of two neighbors, even if they are not equidistant from the focal male. The results are compared\nwith the few other studies of matching in anurans, and\ninterpreted in terms of hypotheses developed to explain\nmatching in songbirds. One attractive and testable hypothesis for call matching in C. georgiana is that males\nare attempting to produce calls that are at least as attractive to females as those of rivals, without wasting energy.\nKey words Call matching · Male competition · Frogs ·\nCrinia georgiana\nIntroduction\nCompetition among males for mates takes many forms\n(Andersson 1994). Males may fight over receptive females or for territories containing resources needed by\nfemales or serving to improve detection of a male’s signals. Endurance rivalry is another important form of\ncompetition, where males attempt to out-signal one another or to maximize their participation in signaling aggregations that form in places where females arrive for\nmating. In numerous species, mating success is positively correlated with the rate or duration of signaling and\nwith attendance at display areas (Andersson 1994).\nDisplays are often energetically demanding, and in\nspecies with long breeding seasons, signaling males often lose a significant proportion of their body mass. Signaling males may also incur increased risks of detection\nby predators, parasites, or both (e.g., Given 1988; Grafe\n1996a; Murphy 1994; Zuk et al. 1998). Because of these\ncosts, we might expect to find mechanisms that allow\nmales to adjust their signaling effort according to that of\ntheir nearby rivals rather than always signaling at the\nmaximum sustainable rate.\nMost studies of male-male interactions between vocalizing frogs have focused on the signaling used to\nacquire and defend territories (Wells 1988) or on the\ntiming of the signals of neighbors, which is usually\nsome form of call alternation (Grafe 1996b; Klump and\nGerhardt 1992; Schwartz 1993). As in some acoustic insects, pairs of males rapidly alternate calls, and their signals rarely overlap; however, because of female preferences, males may compete to produce leading rather than\nlagging signals (Greenfield 1994). Call matching, another form of vocal interaction which is probably competitive, has been described in a few species of frogs. In\nthese species, the number and complexity of calls that\nare produced by a male are approximately matched by its\nneighbor. In the Neotropical treefrog, Hyla microcephala, males match secondary, click-like notes that are produced after long introductory notes (Schwartz 1986). In\na Sri Lankan species, Philautus leucorhinus, neighboring\nmales match the number of notes in calls during exchanges of multi-note aggressive calls (Arak 1983). Call\nmatching by number and song type also has been well\ndescribed in birds (e.g., Catchpole and Slater 1995;\nKrebs et al. 1981; see Discussion).\nIn this paper, we discuss experimental studies of call\nmatching in an Australian frog, Crinia georgiana (Myobatrachidae), a species with a complex mating system\nCommunicated by A. Mathis\nH.C. Gerhardt (✉) · M.A. Bee · J.J. Schwartz\nDivision of Biological Sciences, 105 Tucker Hall,\nUniversity of Missouri, Columbia, MO 65211-7400, USA\ne-mail: gerhardtc@missouri.edu\nTel.: +1-573-8827219\nJ.D. Roberts\nDepartment of Zoology, University of Western Australia,\nNedlands, WA 9607, Australia\nBehav Ecol Sociobiol (2000) 48:243–251 © Springer-Verlag 2000\nORIGINAL ARTICLE\nH. Carl Gerhardt · J. Dale Roberts · Mark A. Bee\nJoshua J. Schwartz\nCall matching in the quacking frog (Crinia georgiana)\nReceived: 14 February 2000 / Received in revised form: 11 April 2000 / Accepted: 3 May 2000\nthat includes frequent polyandrous matings resulting\nfrom other males joining conventionally amplexed pairs\n(Byrne and Roberts 1999; Roberts et al. 1999). Males of\nthis species produce advertisement calls that consist of 1\nto 11 pulsed notes (Figs. 1, 2). A previous laboratory\nstudy showed that males tended to alternate calls with an\nartificial acoustic stimulus and increased then reduced\nthe number of notes in their calls as the rate of stimulus\npresentation increased (Ayre et al. 1984). These authors\ninterpreted these results as a tactic to reduce the likelihood of call overlap. The acoustic stimuli they used did\nnot, however, simulate the natural calls of this species,\nnor were the responses of males interpreted as call\nmatching. In this paper, using more realistic stimuli and\nfield playbacks, we show that call matching is well developed in C. georgiana and that males might match the\ncombined number of notes produced by two neighbors.\nWe argue that call matching functions to adjust a male’s\nenergetic output to equal that of his rivals in order to\nconserve energetic reserves while still effectively competing for females.\nMethods\nField assessments of advertisement calls, male attributes,\nand calling behavior\nWe recorded the advertisement calls of 116 males on magnetic\ntape using Sony WMD6C (Walkman), TCD5PRO, or TCD5ProII\ncassette tape recorders and Beyer M88, M100, or Sennheiser\nME88 microphones. This total included many of the males that we\ntested in playback experiments. We measured the air and water\ntemperature at the calling site, body mass, and snout-vent length\n(SVL). We also measured the call amplitude [sound pressure level\n(SPL) in decibels re 20 µPa; C-weighted and peak or fast root\nmean square settings (RMS)] at distances of 30 cm in front of a\nsubset (n=30) of males using a Brüel and Kjœr type 2231 sound\nlevel meter with a type 4155 microphone. These data were used to\nassess correlations between body size, call amplitude, and attributes of the calls such as dominant frequency and median and\nmaximum numbers of notes per call and to set intensity levels during call playbacks. The number of males used in these correlations\nis sometimes less than the sample sizes stated here because we\nfailed to measure all attributes for all males.\nWe used a computer-based system to record the number of\nnotes per call produced by groups of up to eight males (n=67; see\nSchwartz 1993 for details). Up to eight directional microphones\n(Audio-technica ATR-55) were connected to a battery-powered interface board that sent its output to an IBM 733 Thinkpad via the\nparallel port. The output for each of eight parallel channels of the\nboard underwent a retriggerable voltage transition, of preset duration, in response to above-threshold input from a microphone. The\nduration of the output pulse from the board (7.5 ms) and the sampling rate of the computer (100 Hz) were set so the temporal resolution of the system was more than sufficient to discern individual\nnotes in the calls of C. georgiana. Data were filed to disk every\n10 min. We used custom software (J.J. Schwartz, unpublished) to\nconvert the raw binary data files into ASCII files listing the start\nand end times of the calls of each male as well as a note count\nwithin each call. These files were subsequently analyzed using\nSAS (Cary, N.C., version 6.12). The distances between males\n(n=66), their mass and SVL (n=61), and temperature at each calling site were measured after the recordings were completed.\nAcoustic stimuli\nAcoustic stimuli consisted of synthetic signals that were created\nby a custom-designed program written by J. Schwartz. The digital\nfiles consisted of 8-bit data with an output sampling rate of\n20 kHz. The acoustic properties of these signals were chosen to\nmatch estimated mean values of the following properties of samples of natural calls recorded at two temperatures (11 and 14°C):\npulse rate, note duration, note rise-fall times and shapes, and carri244\nFig. 1 Oscillograms of a 4-note advertisement call and a representative 4-note synthetic call\nFig. 2 Histograms showing frequency of occurrence of calls with\ndifferent note numbers. Values are median note numbers (A) and\nmaximum note numbers (B) recorded from individual males\n(n=67) during 10-min recording sessions\ner frequency. The synthetic calls did not incorporate the relatively\nsmall changes in pulse rate that occur within notes, nor the slight,\nwithin-note frequency modulation. The oscillograms of Fig. 1\ncompare a recorded 4-note advertisement call with a 4-note synthetic call. Calls were played back from an IBM 733 Thinkpad\n(interfacing hardware and software from Siliconsoft) through an\nAiwa Mini Compo Stereo Integrated Amplifier 16 and Sonics\nMini 7 speakers. In 1997, we also used a Hewlett-Packard 350D\nAttenuator Set to vary relative output levels from two speakers. In\nstandard playbacks, amplifier and attenuator settings were adjusted to achieve SPLs of approximately 80–85 dB at a distance of\n50 cm in front of the speaker. The intensity of the advertisement\ncalls of six males at 50 cm ranged from 82 to 88 dB SPL (fast\nRMS).\nGeneral playback procedures\nPersistently calling males were located, and any other calling\nmales within about 2 m of the target male were removed. We measured air and water temperatures near the male and chose the set\nof synthetic calls that best matched field temperatures (±1.5°C).\nOne or two speakers were positioned about 50 cm from the male.\nSpeaker orientation in single-speaker tests was in a frontal zone\nfrom between about 90° left to 90° right of the frog; the angle varied depending on vegetation and frog movements. The speakers in\ntwo-speaker tests were positioned, to the extent possible, at 90°\nleft and 90° right relative to the frog. Playbacks commenced after\nthe frog had produced several spontaneous calls, and its responses\nas well as our acoustic stimuli were recorded. After completion of\na playback, we captured the frog, weighed and measured it as described above. The microphone of the sound level meter was then\nplaced at the frog’s original position, and the actual SPL of the\nsynthetic signal was measured at that point. The SPL of the stimulus varied between 80–85 dB.\nExperiment 1:\ncall matching in response to playbacks from a single speaker\nIn September 1996, we tested 19 males using a repeated-measures\nexperimental design. A stimulus call contained 1, 2, 4, or 8 notes.\nA complete test consisted of broadcasts of two repetitions of each\nof these stimuli in each of five consecutive random sequences for\na total of 40 stimulus presentations. The order of the sequences\nwas determined randomly for each new subject. Calls within sequences were separated by call periods of 8–10 s, and consecutive\nsequences were separated by 15–30 s. The two intervals between\nplaybacks of calls used here and in experiment 2 (see below) were\nboth within the range of variation for call period: about 8 to >60 s\n(mean=27.7 s). Due to technical difficulties with the playback\nsystem during one test, one male included in our dataset heard 12\n1-note, 11 2-note, 9 4-note, and 8 8-note stimuli.\nFrom the recordings of each test, we determined the proportion\nof times a male responded to each of the four stimuli, and we determined the number of notes in the first call produced during the\ninterval between two consecutive stimuli. Using the oscilloscope\nmode of a Kay DSP Sona-Graph Model 5500, we measured (to the\nnearest millisecond) the latency of the first note produced by a\nmale in response to a synthetic call from (1) the beginning of the\nfirst note of each stimulus (latency A) and (2) the end of the last\nnote in each stimulus (latency B). One subject did not respond to\nany of the 1-note stimuli and was excluded from the analyses of\nresponse latency and note number.\nExperiment 2:\ncall matching in response to playbacks from two separate speakers\nIn August 1997, we tested eight males in a second within-subjects\nexperiment to determine whether males match only the notes in\nthe calls of their closest neighbor or whether they might produce\nmulti-note calls that matched the sum of the call notes of two\nneighbors. We also varied the relative SPL of the playbacks from\nthe two speakers to simulate two neighbors at different distances\nfrom the target male. This procedure was designed to determine if\nthe number of notes produced by a male was influenced only by\nthe calls of very close neighbors or whether males might be influenced by the calls of a nearby neighbor and a relatively distant\none. We presented males with a 4-note call from a single speaker\nas a control stimulus. As test stimuli, we presented four 8-note\ncalls in which the first 4 notes and the last 4 notes were broadcast\nfrom different speakers separated by 180°. To simulate neighbors\nat variable distances, we attenuated the second 4 notes by 0, 6, 12,\nor 20 dB. During a test, we broadcast each of the five stimuli (the\nfour 8-note calls and the control) between 2 and 28 times in a randomly determined order. Seven of eight males heard each stimulus\nat least six times. We counted the number of notes in each response call.\nStatistical analysis\nWe calculated the mean number of notes in responses to each\nstimulus for each subject in experiments 1 and 2, and the mean\nlatencies to respond (A and B, defined above) in experiment 1.\nThe data on the number of notes in each response in experiment\n1 met the assumptions of parametric statistics so we used repeated-measures analysis of variance (ANOVA). Relationships between response variables and both body size and temperature were\nexamined with Pearson’s product-moment correlations, and we\napplied a sequential Bonferroni correction to adjust the experimentwide α-level (Rice 1989). We used the modification of the\nFreeman and Tukey (1950) arcsine square root transformation\nsuggested by Zar (1984) to transform the proportion of times\nmales responded to each stimulus in experiment 1. The transformed proportions for responses to the 8-note stimulus still departed from normality because most males responded to every presentation of this stimulus. These data were also analyzed using repeated-measures ANOVA, however, because parametric statistics\nare widely regarded as robust to violations of the assumption of\nnormality (e.g., Lindman 1974). Because omnibus repeatedmeasures tests can violate the additional assumptions of compound symmetry and sphericity, we applied the Greenhouse and\nGeiser (1959) method to adjust the degrees of freedom for each\ntest. We report P-values for these adjusted degrees of freedom, but\nreport the unadjusted degrees of freedom for each F-test. We also\ncomputed linear contrasts and used Scheffé’s multiple-comparisons test to compare responses to each stimulus.\nWe analyzed response latency using Friedman’s two-way\nANOVA by ranks instead of the parametric repeated-measures test\nfor two reasons. First, variances were not homogeneous: responses\nto the 1-note stimulus were considerably more variable than other\nresponses. Second, the variance in latency B was positively correlated with mean values across treatment groups. We compared responses to each stimulus using the all-pairs multiple comparison\nsuggested by Hollander and Wolfe (1973).\nBecause our sample size for the two-speaker playbacks was\nsmall (n=8), we were not confident in our tests of the assumptions\nof parametric statistics. Therefore, we used Friedman’s ANOVA\nand the simultaneous inference test comparing treatments to a control described by Hollander and Wolfe (1973), which we used to\ncompare responses to each of the 8-note stimuli to the 4-note control.\nIn all analyses, we adopt the conventional significance level of\nP=0.05 for rejecting null hypotheses. Because of the small sample\nsize, failure to reject the null hypothesis in some tests (noted below) is probably attributable to low statistical power rather than to\nthe lack of an effect.\n245\nResults\nAnalysis of call structure in natural choruses\nFigure 2 shows the median and maximum numbers of\nnotes per call produced by 67 males over 10-min periods\nin natural choruses. A comparison of the two measures\nreflects our impression of calling behavior in this species. When males were not interacting with a nearby\nneighbor, they tended to produce mostly 1- and 2-note\ncalls; however, during relatively brief interactions with\nneighbors, multi-note calls were commonly produced.\nThere were weak trends for larger males to produce fewer notes per call. From our dataset of 10-min recording\nsessions, we computed correlations between body mass\nand median and maximum note number (r=–0.12,\nP=0.38, n=61 and r=–0.28, P=0.027, n=61, respectively;\nthe latter correlation is not significant after a sequential\nBonferroni correction). The distance to the nearest\nneighbor did not appear to influence either median or\nmaximum note number (r=0.04, P=0.75, n=66 and\nr=0.10, P=0.41, n=66, respectively).\nA summary of correlations between temperature,\nbody mass, body size, dominant frequency of the first\nnote of the advertisement call, and SPL is shown in\nTable 1. Dominant frequency was strongly and negatively correlated with body mass and SVL, whereas SPL was\npositively correlated with body mass and size.\nExperiment 1\nRepeated-measures ANOVA revealed significant differences in the proportion of times males responded to each\nstimulus (F3,54=39.04, P<0.0001). Males responded to\nproportionally more presentations of a stimulus as the\nnumber of notes in the stimulus increased (Fig. 3A). This\ntrend is reflected by a significant linear contrast across\nstimuli (linear contrast: F1,18=68.67, P<0.0001). Pairwise\nmultiple comparisons revealed that males responded\nequally as often to the 1- and 2-note stimuli (Scheffé:\nP=0.56). Males responded more often to the 4-note stimulus than to the 1-note stimulus (Scheffé: P<0.0001) and\nthe 2-note stimulus (Scheffé: P<0.0001). Responses occurred more often to the 8-note stimulus than to the\n4-note stimulus (Scheffé: P<0.01), the 2-note stimulus\n(Scheffé: P<0.0001), and the 1-note stimulus (Scheffé:\nP<0.0001). There was also a strong negative correlation\nbetween body size and the proportion of times a male responded for the 13 males for which SVL measurements\nwere available: 1-note stimulus (r=–0.66, P=0.015,\nn=13); 2-note stimulus (r=–0.64, P=0.019, n=13); 4-note\nstimulus (r=–0.49, P=0.087, n=13); 8-note stimulus\n(r=–0.62, P=0.024, n=13). None of these correlations\nwas significant after a sequential Bonferroni correction,\nprobably reflecting low statistical power due to small\n246\nTable 1 Pearson product-moment correlations between body size\n(snout-vent length, SVL), body mass, temperature, the dominant\nfrequency of the first call note (averaged over 1–16 calls), and\nsound pressure level (SPL; measured as peak SPL at 30 cm in\nfront of the calling male). Sample sizes and P-values are provided\nfor each correlation\nTemperature SVL Mass Dominat\nfrequency\nSVL r=0.05\nn=116\nP=0.59\nMass r=0.04 r=0.93\nn=116 n=116\nP=0.64 P<0.001\nDominant r=0.11 r=–0.77 r=–0.74\nfrequency n=113 n=103 n=103\nP=0.24 P<0.001 P<0.001\nSPL r=0.65 r=0.59 r=0.61 r=–0.18\nn=30 n=28 n=28 n=15\nP<0.001 P<0.001 P<0.001 P=0.53\nFig. 3A–B Responses to the 1-, 2-, 4-, and 8-note stimuli in experiment 1. Different letters indicate significant differences using\nScheffé’s all-pairs multiple comparisons following a significant\nrepeated-measures ANOVA (*P<0.05 for test of departure from\nperfect matching). A Mean (±SE) proportion of times males responded to each stimulus. B Mean (±SE) number of notes in response to each stimulus. C Mean (±SE) deviations from perfect\nmatching calculated as the difference between the number of notes\nin a male’s response and the number of notes in the stimulus\nsample sizes. Temperature was not correlated with the\nproportion of times a male responded to any stimulus.\nAs the number of notes in the stimulus increased,\nmales increased the number of notes in their responses\n(Fig. 3B). There were significant differences in the mean\nnumber of call notes among responses to the four stimuli\n(ANOVA: F3,51=71.54, P<0.0001). The number of notes\nin response calls increased linearly as the number of\nstimulus notes increased (linear contrast: F1,17=122.21,\nP<0.0001). Responses to the 1- and 2-note stimuli did\nnot differ significantly (Scheffé: P<0.93). However, responses to both the 4- and 8-note stimuli consisted of\nsignificantly more notes than responses to the 1- and 2-\nnote stimuli (Scheffé: Ps<0.0001), and males produced\nsignificantly more call notes in responses to the 8-note\nstimulus than to the 4-note stimulus (Scheffé:\nP<0.0001). There were no significant relationships between either SVL or temperature and the number of\nnotes in responses to each stimulus.\nSome males were quite good at precisely matching\nthe number of notes in each stimulus (Fig. 4). In general,\nhowever, males did not match the number of notes in\neach stimulus perfectly. To examine the departure from\nperfect matching, we calculated deviation scores by subtracting the expected number of notes in response to\neach stimulus (1, 2, 4, or 8) from the mean number of\nnotes in each male’s responses to that stimulus (Fig. 3C).\nThere were significant differences among deviation\nscores in response to the four stimuli (ANOVA:\nF3,51=36.02, P<0.0001). Contrast analysis revealed a decreasing linear trend in deviation scores as the number of\nstimulus notes increased (linear contrast: F1,17=62.31,\nP<0.0001). In their responses to the 2- and 4-note stimuli, males tended to produce 2- and 4-note calls, respectively. The number of notes in responses to these two\nstimuli did not significantly depart from what would be\nexpected if males were perfectly matching the number of\nnotes in the stimulus (independent t-test: 2-note stimulus, t34=–0.20, P=0.85; 4-note stimulus, t34=–1.34,\nP=0.19). In response to the 1-note stimulus, however,\ndeviation scores were positive and males produced calls\nwith significantly more notes than expected for perfect\nmatching (independent t-test: t34=2.47, P=0.02). In contrast, deviation scores for responses to the 8-note stimulus were negative and males produced calls with significantly fewer than 8 notes (independent t-test: t34=–5.56,\nP<0.0001).\nLatencies to respond to a particular stimulus were in\npart determined by the number of notes in the stimulus\n(Fig. 5). There were significant differences among\nthe median latencies to respond to the four stimuli\nfor latency A, measured from the beginning of the stimulus (Friedman’s test: χ2=42.47, df=3, P<0.0001), and\n247\nFig. 4 Oscillograms showing an example of male responses to the\nsynthetic 1-, 2-, 4-, and 8-note stimuli in experiment 1\nFig. 5A–B Box plots representing the median (line), interquartile\nrange (box), and range (whiskers) of latencies to the 1-, 2-, 4-, and\n8-note stimuli in experiment 1. Different letters indicate significant differences using Dunn’s all-pairs multiple comparisons following a significant Friedman’s test. A Latency A measured from\nthe beginning of the first note of the stimulus. B Latency B measured from the end of the last note of the stimulus\nfor latency B, measured from the end of the stimulus\n(Friedman’s test: χ2=11.53, df=3, P<0.0092). For latency A, the median latency to respond to the 8-note stimulus was significantly longer than latencies to the 1-note\n(P<0.05), 2-note (P<0.05), and 4-note (P<0.05) stimuli,\nwhich did not significantly differ (Fig. 5A). In contrast,\nfor latency B, latencies tended to become shorter as the\nnumber of notes in the stimulus increased (Fig. 5B).\nPairwise multiple comparisons revealed that latencies to\nthe 1- and 2-note stimuli were not significantly different, and latencies to the 4- and 8-note stimuli also did\nnot differ. All remaining pairwise comparisons were significant (Ps<0.05). There were correlations between\nSVL and response latency to the 4-note stimulus (latency A: r=0.62, P=0.024, n=13; latency B: r=0.60,\nP=0.029, n=13), but these relationships were not significant after a sequential Bonferroni correction. Response\nlatencies were not related to temperature.\nExperiment 2\nIn this experiment, we predicted that if males attempt to\nsum the call notes of more than one neighbor, then the\nnumber of notes in responses to the 8-note stimuli, 4\nnotes of which were emitted by two separate speakers,\nshould be significantly greater than the number produced\nin responses to the 4-note control stimulus broadcast\nfrom a single speaker. There were significant differences\nin the number of notes in responses to the 4-note call and\nthe 8-note calls with different degrees of attenuation\n(Friedman’s test: χ2=24.35, df=4, P<0.0001; Fig. 6).\nCompared to the 4-note control, males produced calls\nwith significantly more notes when the second 4 notes of\nthe 8-note stimulus were not attenuated (i.e., 0 dB;\nP<0.05) and when they were attenuated by –6 dB\n(P<0.05). Males also gave calls with more notes in response to the 8-note stimulus in which the second 4\nnotes were attenuated by –12 dB, but the differences\nwere marginally non-significant (0.06<P<0.07). Males\ndid not produce significantly more notes in response to a\n20-dB attenuation (0.25<P<0.29). Although males produced calls with significantly more notes in responses to\nsome 8-note stimuli compared to responses to the 4-note\nstimulus, they tended to produce fewer notes in responses to attenuated 8-note stimuli compared to the unattenuated 8-note stimulus (see Fig. 6).\nDiscussion\nOur playback experiments demonstrate that C. georgiana\nmales frequently match the number of notes in synthetic\nadvertisement calls but matching is imperfect. Although\nmales tended to match stimuli that had 2 or 4 notes, they\nregularly produced more than 1 note in response to a\n1-note stimulus but produced less than 8 notes in response to an 8-note stimulus (Fig. 3).\nLatency to respond was also related to the number of\nnotes in the stimulus. Latency A (from the beginning of\nthe stimulus) was constant for 1-, 2- and 4-note stimuli\nbut was significantly longer for 8-note stimuli. Latency\nB declined with increasing note number in the stimulus\n(Fig. 5B). These data are consistent with a simple model\nof calling behavior. Frogs have a fixed latency to call\nmeasured from the start of a stimulus call. However, if\nthe stimulus call is longer than average (e.g., longer than\nthe modal maximum note numbers of 6 and 7; Fig. 2B),\nthen calling is inhibited. If frogs called at a fixed delay\nafter the end of a stimulus, e.g., as seen in call alternation patterns in Pseudacris (=Hyla) crucifer (Rosen and\nLemon 1974), then latency B would be constant, and latency A, an increasing function of stimulus duration.\nMales usually called in small groups and tended to\ncluster their calls in the time period immediately after\nthe first male’s calls, an impression that was enhanced\nby the fact that inter-call intervals were long relative to\nthe call duration of multi-note calls. Experiment 2 was\ndesigned to explore response patterns to calls of neighboring frogs. As long as the amplitude of the second\nstimulus was not more than about 10–12 dB less than\nthat of the first stimulus, males tended to produce more\nnotes in their responses than they did to a 4-note control\ncall (Fig. 6).\nExperiment 2 was potentially unrealistic in three\nways: (1) the target male always heard the louder calls\nsimulating the closer neighbor first in those tests in\nwhich calls from one speaker were attenuated; (2) the\nnotes from both sound sources had the same carrier frequency and temporal properties, and (3) the delay between the last note of the first stimulus and the first note\nof the second stimulus was the same as that between the\nnotes in all multi-note stimuli (at a given temperature)\nand therefore shorter than expected (cf. delay periods;\nFig. 5). These three aspects of the design need to be\naddressed in future studies. Perhaps males are less likely\nto match the total number of notes if the less intense\n248\nFig. 6 Box plots as in Fig. 5 representing the number of call notes\nin responses to a 4-note stimulus and four 8-note stimuli in which\nthe second 4 notes were attenuated by 0, 6, 12, or 20 dB. P-values\nare for a post hoc comparison of each 8-note stimulus to the 4-\nnote control following a significant Friedman’s test\ncalls of a distant neighbor are heard first. Pilot experiments indicate that males still matched the total number\nof notes, even if the stimuli produced by the two speakers had different carrier frequencies (H. Gerhardt, D.\nRoberts, M. Bee, unpublished data), but more data are\nclearly needed. Additionally, preliminary experiments\nindicate that if the time interval between two consecutive\n2- or 4-note stimuli is increased by a factor of four or\nmore (>1.5 s), then males often begin to respond to the\nfirst stimulus before the second stimulus occurs. Males\nseemingly ignore the second stimulus and usually match\nthe number of notes in the first stimulus; thus, the second\nstimulus neither inhibits them nor elicits additional notes\n(H.C. Gerhardt, J.D. Roberts, M.A. Bee, unpublished data). Additional analyses of the calls of neighbors monitored in the field, and more realistic playback designs\nmay further unravel the complexity of male-male interactions.\nComparisons with call matching in other species\nTiming relationships\nC. georgiana males almost always wait until the end of a\nneighbor’s calls before calling. Similar calling interactions, in which one male’s signals follow the completion\nof a neighboring male’s calls, have also been described\nfor Hyperolius tuberilinguis (Pallett and Passmore 1988)\nand Rana nicobariensis (Jehle and Arak 1998). The relatively long intervals between relatively short advertisement calls in C. georgiana give the impression of distinct leader-follower relationships. We are currently analyzing multi-channel recordings of C. georgiana choruses to determine whether consistent leader-follower relationships between interacting neighbors occur in this\nspecies.\nIn contrast to the species just discussed, P. leucorhinus males show a distinctive alternation of multinote calls which, although they seldom overlap, are repeated at intervals comparable to, or just slightly longer\nthan the call duration. Inspection of an oscillogram of\nthe calls of a pair of interacting frogs indicates that leader and follower roles change during the exchange of calls\n(see Fig. 3 in Arak 1983). H. microcephala and Hyla\nphlebodes males differ from those of P. leucorhinus by\nthe precise interdigitation of secondary click notes when\ntheir multi-note advertisement calls overlap those of\nneighboring males (Schwartz 1993; Schwartz and Wells\n1984, 1985). H. phlebobes males may interdigitate 15 or\nmore secondary notes during their interactions between\nmales, which seem to add notes on a one-by-one basis\ndepending on the addition of notes by rivals. However,\nno formal analysis of matching is available for this species.\nPrecision of matching\nIn comparison to C. georgiana, P. leucorhinus, and Hyla\nmicrocephala, call matching is very crude in H. tuberilinguis. Males increased the production of 2-note and\n(less often) 3-note calls when confronted with 2-, 3-, or\n4-note stimuli, but did not regularly match the number\nof notes in the stimulus. Males are capable of producing\nas many as 6 notes but rarely do so except in peak periods of breeding activity (Pallett and Passmore 1988).\nR. nicrobariensis males appear to be more precise than\nHyperolius, but nearly always produced the same or fewer notes per call than the number in the playback stimulus (Jehle and Arak 1998). Poor matching at high note\nnumbers might result from an energetic or size constraint. In C. georgiana, the energy required for repeated\nmuscle contractions, or the volume of gas in the lungs\nneeded to generate 8-note or longer calls might not be\ngenerally available, as reflected in modal maximum note\nnumbers of 6–7 notes in natural choruses (Fig. 2B).\nPresumed call type of matched signals\nC. georgiana and H. tuberilinguis males are almost certainly matching advertisement calls. We have never\nheard C. georgiana produce distinct aggressive calls (D.\nRoberts, personal observation), but H. tuberilinguis\nmales have an aggressive signal in their repertoire\n(Pallett and Passmore 1988). The situation in R. nicrobariensis is more complex. The longer, multi-note\ncalls that are produced during interactions between\nneighboring males or in response to playbacks at close\nrange contain elements that Jehle and Arak (1998) interpret as aggressive in function. The distinctive signals\nthat are matched in P. leucorhinus have only been heard\nduring vocal interactions between males. P. leucorhinus\nmales also produce a distinct advertisement call, which\nwas heard when females approached. In H. microcephala, click notes normally follow the introductory note,\nwhich is necessary and sufficient to attract females\n(Schwartz 1986). The number of these click notes, which\nmay be matched by neighbors, tend to increase during\ninteractions between males (Wells and Taigen 1989).\nAdaptive significance\nDrawing on the literature on song matching in birds,\nArak (1983) considered three hypotheses for call matching in P. leucorhinus. First, asymmetrical matching by a\npair of interacting males could indicate dominance, as in\nmarsh wrens (Kroodsma 1979). Arak rejected this hypothesis for P. leucorhinus because each male matched\nits rival. An analysis of natural interactions within\ngroups of males is needed to test this hypothesis in C.\ngeorgiana. Large males were somewhat less likely to respond to playbacks than small males, but we found no\npattern of size-dependent matching. Further research\n249\nshould examine the possibility that a male’s size relative\nto the perceived size of a rival, as indicated by its dominant frequency, could have an influence. Second, matching might be a mechanism to direct aggressive signals to\nparticular males, perhaps even grading the response by\nthe precision of matching (Bremond, in Armstrong 1973;\nKrebs et al. 1981). Arak (1983) considered this hypothesis to be the most likely explanation for call matching in\nP. leucorhinus. For C. georgiana, the results of our twospeaker playbacks cast doubt on this hypothesis because\nmales tended to match the combined number of notes\nplayed back from separate speakers even when the playback level of the notes from one speaker was substantially less intense than that from the other speaker. This\nmodel could be tested further by playing back notes with\ndifferent dominant frequencies from two speakers. If\nmales detect the differences in frequency, intensity, or location, then they would be expected to match only one of\nthe simulated rivals if call matching is used to direct an\naggressive message to a particular rival. This also might\nbe shown by different patterns of matching in natural\nchoruses where adjacent males differ radically in size.\nSmallest and largest males in choruses can vary between\n<1 g and >6 g (M. Smith, unpublished data).\nA third, non-mutually exclusive explanation for call\nmatching is that females can better detect or prefer calls\nwith multiple notes (Arak 1983): matching is then a\nmechanism for producing calls that are at least as attractive as those of neighbor(s) without wasting energy. This\nis an attractive hypothesis for call matching in C. georgiana that can be tested by determining how note number affects the relative attractiveness of signals to females and by estimating the energetic costs of producing\nmany multi-note calls. This hypothesis is not, however,\nsupported by the results of preliminary experiments with\nfemale choice tests in the laboratory. Given a choice of\n2- and 4-note synthetic calls, females showed no preference for 4-note calls (eight preferred 2 notes, six preferred 4 notes; M. Smith and D. Roberts, unpublished\ndata), but patterns of preference might differ in tests\nwhere the difference between alternative note numbers is\ngreater.\nFemales might also simply not prefer higher numbers\nof notes beyond some minimum number, as in H. tuberilinguis (Pallett and Passmore 1988). Females of Hyla\nversicolor also show a decline in preference strength\nbased on differences in call duration once the absolute\ndurations of alternatives equal and exceed mean values\n(Gerhardt et al., in press). Clearly, playback experiments\nwith females will be essential to understand the adaptive\nbases for call matching in C. georgiana and other species.\nAcknowledgements This research was supported by ARC Grant\nno. A19602654 to R.S. Seymour and J.D.R. H.C.G. was supported\nby a Distinguished Visiting Scholars Fellowship from the University of Western Australia and an NIMH Research Scientist Award,\nand M.A.B. was supported by an NSF Graduate Research Fellowship. Thanks to Oliver Berry and Phil Byrne for help in the field\nor with analyses of call structure and to Mike Smith for data on\nSPL and frequency versus male body size. Frogs were collected\nand work was conducted under permits from the West Australian\nDepartment of Conservation and Land Management (CALM Licence no. SF 001913 and SF 002239) and the University of Western Australia, Animal Experimentation Ethics Committee (Approval no. 131/96/96 and 117/97). We also thank the CALM,\nMundaring, and Catchment Operations (Water Authority of Western Australia) for permission to work in the study area.\nReferences\nAndersson M (1994) Sexual selection. Princeton University Press,\nPrinceton, NJ\nArak A (1983) Vocal interactions, call matching and territoriality\nin a Sri Lankan treefrog, Philautus leucorhinus (Rhacophoridae). Anim Behav 31:292–302\nArmstrong EA (1973) A study of bird song, 2nd edn. Dover, New\nYork\nAyre DJ, Coster P, Bailey WN, Roberts JD (1984) Calling tactics\nin Crinia georgiana (Anura: Myobatrachidae): alternation and\nvariation in call duration. Aust J Zool 32:463–470\nByrne PG, Roberts JD (1999) Simultaneous mating with multiple\nmales reduces fertilization success in the myobatrachid frog\nCrinia georgiana. Proc R Soc Lond B 266:717–721\nCatchpole CK, Slater PJB (1995) Bird song. Cambridge University Press, Cambridge, UK\nFreeman MF, Tukey JW (1950) Transformations related to the angular and the square root. Ann Math Stat 21:607–611\nGerhardt HC, Tanner SD, Corrigan CM, Walton HC. Female\npreference functions based on call duration in the gray treefrog\n(Hyla versicolor). Behav Ecol, in press\nGiven MF (1988) Growth rate and the cost of calling activity in\nmale carpenter frogs, Rana virgatipes. Behav Ecol Sociobiol\n22:153–160\nGrafe TU (1996a) The function of call alternation in the African\nreed frog (Hyperolius marmoratus): precise call timing prevents auditory masking. Behav Ecol Sociobiol 38:149–158\nGrafe TU (1996b) Energetics of vocalization in the African reed\nfrog (Hyperolius marmoratus). Comp Biochem Physiol 114:\n235–243\nGreenfield MD (1994) Cooperation and conflict in the evolution\nof signal interactions. Annu Rev Ecol Syst 24:97–126\nGreenhouse SW, Geiser S (1959) On methods in the analysis of\nprofile data. Psychometrika 24:95–112\nHollander M, Wolfe DA (1973) Nonparametric statistical methods. Wiley, New York\nJehle R, Arak A (1998) Graded call variation in the Asian cricket\nfrog Rana nicrobariensis. Bioacoustics 9:35–48\nKlump GM, Gerhardt HC (1992) Mechanisms and function of\ncall-timing in male-male interactions in frogs. In: McGregor\nPK (ed) Playback and studies of animal communication. Plenum, New York, pp 153–174\nKrebs JR, Ashcroft R, Orsdol K van (1981) Song matching in the\ngreat tit Parus major L. Anim Behav 29:918–923\nKroodsma DE (1979) Vocal duetting among male marsh wrens:\nevidence for ritualized expression of dominance/subordination. Auk 96:506–515\nLindman HR (1974) Analysis of variance in complex experimental designs. Freeman, San Francisco\nMurphy CG (1994) Determinants of chorus tenure in barking treefrogs (Hyla gratiosa). Behav Ecol Sociobiol 34:285–294\nPallett JR, Passmore NI (1988) The significance of multi-note advertisement calls in a reed frog, Hyperolius tuberilinguis. Bioacoustics 1:13–23\nRice WR (1989) Analyzing tables of statistical tests. Evolution\n43:223–225\nRoberts JD, Standish RJ, Byrne PG, Doughty P (1999) Synchronous polyandry and multiple paternity in the frog Crinia\ngeorgiana (Anura: Myobatrachidae). Anim Behav 57:721–\n726\n250\nRosen M, Lemon RE (1974) The vocal behavior of spring peepers,\nHyla crucifer. Copeia 1974:940–950\nSchwartz JJ (1986) Male calling behavior and female choice in a\nNeotropical frog. Ethology 73:116–127\nSchwartz JJ (1993) Male calling behavior, female discrimination\nand acoustic interference in the Neotropical treefrog Hyla microcephala under realistic acoustic conditions. Behav Ecol Sociobiol 32:401–414\nSchwartz JJ, Wells KD (1984) Vocal behavior of the Neotropical\ntreefrog Hyla phlebodes. Herpetologica 40:452–463\nSchwartz JJ, Wells KD (1985) Intra- and interspecific vocal behavior of the Neotropical treefrog Hyla microcephala. Copeia\n1985:27–38\nWells KD (1988) The effects of social interactions on anuran vocal behavior. In: Fritszch B, Wilczynski W, Ryan MJ, Hetherington T, Walkowiak W (eds) The evolution of the amphibian\nauditory system. Wiley, New York, pp 433–454\nWells KD, Taigen TL (1989) Calling energetics of a Neotropical\ntreefrog, Hyla microcephala. Behav Ecol Sociobiol 25:\n13–22\nZar JH (1984) Biostatistical analysis, 2nd edn. Prentice-Hall,\nEnglewood Cliffs, NJ\nZuk M, Rotenberry JT, Simmons LW (1998) Calling songs of field\ncrickets (Teleogryllus oceanicus) with and without phonotactic\nparasitoid infection. Evolution 52:166–171\n251", "affiliations": [{"country": "United States", "discipline": "Biology", "university": "University of Missouri, Columbia"}, {"country": "Australia", "discipline": "Zoology", "university": "University of Western Australia"}], "species_categories": ["Amphibian"], "specialized_species": ["quacking frog"], "computational_stages": ["Data Collection"], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Semanticity", "Discreteness and Syntax"], "status": "saved", "created_at": "2026-01-13T12:49:59.882717", "updated_at": "2026-01-13T16:13:43.936756", "committed_at": "2026-01-13T15:36:50.693029"}
{"id": "c2a9fab9-7641-4fb7-8392-244429221aa1", "title": "Coding in the song of the wren: importance of rhythmicity,  syntax and element structure", "authors": ["Holland,  Jo", "Dabelsteen,  Torben", "Paris,  Angela López"], "year": "2000", "journal": "Animal Behaviour", "abstract": "", "doi": "10.1006/anbe.2000.1529", "analysis_notes": "ANIMAL BEHAVIOUR, 2000, 60, 463–470\ndoi:10.1006/anbe.2000.1529, available online at http://www.idealibrary.com on\nCoding in the song of the wren: importance of rhythmicity,\nsyntax and element structure\nJO HOLLAND, TORBEN DABELSTEEN & ANGELA LOu PEZ PARIS\nDepartment of Animal Behaviour and Centre for Sound Communication, Zoological Institute,\nUniversity of Copenhagen\n(Received 24 November 1999; initial acceptance 12 January 2000;\nfinal acceptance 16 May 2000; MS. number: 6415)\nCommunication between territorial songbirds usually involves a transfer of encoded information over\nlong distances. We would expect coding and decoding strategies to be adaptive given the constraints\nimposed by the habitat. We used playback to examine some song parameters important for information\ntransfer in the wren, Troglodytes troglodytes. Six stimuli were tested with various modifications to song\nrhythmicity, song composition, element structure, syntax and overall song spectra. Song features\nencoding information essential for eliciting a territorial response seemed to be embedded in the fine\nstructure of song elements, that is, their variations in frequency and amplitude over time. To function,\nthis strategy must be flexible enough to accommodate the deleterious effects of habitat-induced\ndegradation. All stimuli composed of original song elements elicited responses regardless of their\nother alterations. Rhythmicity seemed not to be essential for eliciting territorial behaviour. However,\nalterations in song rhythmicity, syntax and spectra affected territorial responses, suggesting that these\nnonessential song parameters do contribute to the options for discrimination.\n 2000 The Association for the Study of Animal Behaviour\nCommunication involves a transfer of information using\nspecially evolved signaller and receiver adaptations. The\nsignals used contain messages that may be derived from\nthe signalling behaviour itself (e.g. timing and location)\nor be coded by signal parameters (e.g. Dabelsteen &\nPedersen 1992; see reviews by Becker 1982; Falls 1992).\nHowever, sounds attenuate as they propagate and\nbecome distorted by the habitat (e.g. Michelsen 1978;\nWiley & Richards 1978, 1982). When songbirds communicate, their songs become unavoidably degraded to\nvarying extents depending on a number of factors: the\ndistance to the receiver; the respective orientation of\nthe receiver; the elevation of both the sender and the\nreceiver; the habitat and atmospheric conditions along\nthe transmission pathway; and the characteristics of the\nsounds propagated (e.g. Lemon et al. 1981; Larsen &\nDabelsteen 1990; Dabelsteen et al. 1993; Mathevon et al.\n1996; Naguib 1996; Holland et al. 1998; Mathevon 1998).\nThe often formidable task facing the receiving bird is\nto detect an incoming signal from a background of\npotentially interfering noise and to extract encoded\ninformation despite the song degradation. Moreover,\nwe would expect these challenges to increase with\nlonger transmission pathways since the signal-to-noise\nratio decreases and the degradation increases with\ndistance.\nSince long-range communication has evolved under\nthese constraints, signal alterations occurring during\ntransmission are thought to have influenced the evolution of various coding and decoding strategies. A\nnumber of studies support the idea that these strategies\nare generally based on sound features that resist degradation, thus ensuring effective transfer of information\nover relevant distances (e.g. Bre ́mond 1978; Bre ́mond &\nKreutzer 1986; Robisson 1987; Dabelsteen & Pedersen\n1985, 1988, 1992, 1993; Bre ́mond & Aubin 1990;\nRobisson et al. 1993). Information encoding speciesspecific identity is implicit for communication; it therefore follows that the transfer of this information should\nbe exceptionally robust. This is, however, a difficult\nmatter to test as processes of species recognition can only\nreally be inferred by testing discriminative abilities.\nWe used playback experiments to identify song\nparameters eliciting territorial responses in the wren,\nTroglodytes troglodytes, and we discuss these in relation to\ntheir robustness when degraded during transmission.\nWren song typically consists of a series of rapidly\nmodulated elements with a centre frequency of about\n6 kHz, features that should be particularly susceptible to\ndegradation (Wiley & Richards 1982; Mathevon et al.\n1996). In addition, wrens favour the lower levels of forest\nCorrespondence: J. Holland, Department of Animal Behaviour,\nZoological Institute, University of Copenhagen, Tagensvej 16,\nDK-2200 Copenhagen N, Denmark. (email: jholland@zi.ku.dk).\n0003–3472/00/100463+08 $35.00/0  2000 The Association for the Study of Animal Behaviour463habitats (average perch height whilst singing is 3 m,\nunpublished data) which are acoustically complex and\nwhere the degradation caused by reverberations is particularly severe (e.g. Richards & Wiley 1980). As well as its\nseemingly maladaptive song given the transmission conditions, we had another reason for choosing the wren as\nour study species. The rapid presentation of short noiselike sounds (average element durations <50 ms), often in\ntrill sequences, seems very important to our identification\nof wren song. This seems to contrast with our identification of other species living in a similar habitat, such as\nblackbirds, Turdus merula, and blackcaps, Sylvia atricapilla,\nwhere structural variations such as frequency modulations over longer elements seem to aid our identification more. We wondered whether wrens weight these\nkinds of temporal features when communicating as\nheavily as we do and if so to what consequence given the\ntransmission constraints.\nSongs consist of elements and interelement pauses. We\nwanted to test whether the rhythm resulting from the\nalternation of these two was enough to elicit a response.\nOne effect of degradation is a distortion of the structure\nof the elements. At a base level the received element\ncould be viewed as a burst of noise that, together with\nperiods of silence, constitutes a rhythm. We aimed to test\nthe relative importance of rhythmicity by comparing\nresponses to a number of stimuli, in which aspects of\nnatural rhythmicity and/or song composition were\naltered. Whilst some of these song features have previously been investigated with manipulated songs and\nplayback (notably by Bre ́mond and colleagues in the\nwren, e.g. Bre ́mond 1968), we used modern technology to\nvary single parameters without introducing confounding\nalterations to the song and we focused on song features\nthat relate to within-song rhythmicity.\nMETHODS\nTest Sounds\nWe used three songs throughout the experiment. These\ncame from three individuals spontaneously singing from\nclose (<5 m) and exposed perches in different areas of the\nstudy site more than 3 years previously. The recordings\nwere made with a Sennheiser MKH 816 T directional\nmicrophone and a Sony TCD D10 PRO DAT recorder.\nThey were subsequently taken into a computer through\nthe analogue input, digitized (sampling frequency\n20 kHz) and then bandpass filtered (2.7–8.5 kHz). These\nsongs constituted the base from which the different test\nstimuli were derived. Each stimulus thus had three versions derived from the three original songs (versions A, B\nand C). The stimulus types are shown in Fig. 1 and\ndetailed below.\nControl stimulus\nWe cut out the elements and pauses of the original\nsongs, then pasted them together in their original order\nand amplified them to a uniform peak value across the\nthree versions (Fig. 1a).\nBroadband noise stimulus\nThis stimulus conserved only song rhythmicity and\ncontained neither frequency information, carrier or\nmodulation, nor amplitude variation. A response to this\nwould have indicated that important cues are carried by\nthe song rhythmicity alone, without the addition of any\ninformation encoded by element structure (frequency\nand temporal) and/or syntax. Computer-generated white\nnoise was bandpass filtered in the same way as the base\nsongs. This long broadband noise signal was then cut into\nnoise blocks with the same durations as the song elements. The broadband noise blocks were then assembled\nin the same order as the corresponding elements in the\noriginal song. The natural pauses were inserted. As there\nwas no variation in amplitude across the elements, it\nwould have been inappropriate to equate peak values\nwith those of the control stimulus; therefore, we amplified the signal until the root mean square value was\nequivalent to that of the control song (Fig. 1b).\nFiltered noise stimulus\nThis stimulus was a slight elaboration on the broadband noise stimuli, as crude frequency and amplitude\n2\n8\nTime (s)\n(f)\nFrequency (kHz)\n1\n6\n4\n3 4 5 6\n8\n(e)\n6\n4\n8\n(d)\n6\n4\n8\n(c)\n6\n4\n8\n(b)\n6\n4\n8\n(a)\n6\n4\nFigure 1. Sonagrams of the six stimuli, shown here for version 1. (a)\nControl stimulus, (b) broadband noise stimulus, (c) filtered noise\nstimulus, (d) random order stimulus, (e) only trills stimulus and (f)\nlow-pass filter stimulus. Two other versions of stimuli were derived\nfrom two other songs. Sonagrams were created on PC with AVISOFT\nsoftware (sampling frequency: 22 050 Hz, 16 bit; bandwidth:\n161 Hz; time resolution: 5.8 ms).\n464 ANIMAL BEHAVIOUR, 60, 4modulations were added throughout the ‘song’ (between\nbut not within ‘elements’). As with the broadband noise\nstimuli, we cut artificial noise into noise blocks with\ndurations matching the song elements. Each noise block\nwas then digitally filtered following the frequency parameters of each original song element. The filtered noise\nblocks were assembled in the same order as the corresponding elements in the original songs. This filtering\nprocess introduced a variation in amplitude between the\nelements (cf. broadband noise stimulus). The natural\npauses were inserted. We amplified each signal to give the\nuniform peak value of the control signal (Fig. 1c).\nRandom order stimulus\nThis stimulus also tested the value of song rhythmicity;\nhowever, in this case we replaced the noise blocks with\nactual song elements, thus adding any information\ncarried by element frequency and amplitude modulations. Elements and pauses were presented in a random\norder, which precluded the transfer of any information by\nsyntax while maintaining the spectral qualities of the\nwhole song. The elements and pauses of the original\nsongs were cut out, then pasted together following two\ntables of random numbers: one for the element series and\none for the pause series. Each song version used different\nrandom numbers and each was amplified to give the\nuniform peak value (Fig. 1d).\nOnly trills stimulus\nThis stimulus increased the order of song elements and\npauses to some extent, whilst changing the spectrum of\nthe whole song. It consisted entirely of trill sections and\nomitted the often high-frequency intermittent elements.\nA trill was defined as a song element or small group of\nelements, repeated consecutively more than twice. The\nthree song versions A, B and C contained seven, three and\nfive trill sections, respectively. The elements and pauses\nof the original songs were cut out, then pasted together in\ntheir original order. All nontrill elements (and pauses)\nwere removed and the trills extended into the vacant\nregions by repeating parts of the adjacent trill section.\nWe amplified the signal to give the uniform peak value\n(Fig. 1e).\nLow-pass filter stimulus\nThis final stimulus was a filtered control song without\nthe high frequencies. As the attenuation conferred upon\nthe song under transmission is frequency dependent, a\ncommon feature of received songs is strongly attenuated\nor even missing high-frequency elements. This stimulus\ntested whether a change in the song spectrum and a slight\nchange in rhythmicity from the absolute loss of some\nelements and pitch change of others influences the signal\nvalue of the song in any way. We cut out the elements\nand pauses of the original songs, then pasted them\ntogether in their original order. We determined a lowpass cutoff by finding the trough in the power spectrum\nthat seemed to separate the high-frequency elements\nfrom the other elements: 6.32 kHz (versions A and B);\n6 kHz (version C). The low-pass filters were applied and\nthe signals were amplified to the uniform peak value\n(Fig. 1f).\nAll the signal manipulations and D/A conversions\nwere carried out on a PC equipped with a Signal Data DSP\nSPB2 signal processing board, using the program SIGPRO\nversion 1.3 (Pedersen 1998). The filtering used a digital\nlinear phase FIR-filter of order 63 (for details see Kaiser\n1974). A transition function with a window size of 1.6 ms\nwas used for cutting the signals, which ensured a smooth\ntransition when pasting signal parts together. The test\nstimuli were converted to analogue and recorded on to a\nHHB PDR1000 PORTADAT. The test sequences consisted\nof 12 repeats of the stimulus over a 2-min period which is\nequivalent to a natural high song rate.\nExperimental Design and Playback Routine\nWe did the experiment between 0800 and 1600 hours\nin April and early May 1999, at Strødam Biological Field\nStation and in the adjacent Gribskov forest, Denmark.\nDuring the experimental period, the weather was consistently mild with low winds. Wren territories were approximately mapped before and during the experimental\nperiod from sightings and song post locations. Each\nindividual was used only once, neighbours received different playback stimuli and different song versions and\nwe ensured that the spacing between males used on the\nsame day was large enough to minimize the chance of\ninterference by eavesdropping (Dabelsteen et al. 1997).\nWe presented all six stimuli and three versions as evenly\nas possible over each experimental day under the above\nrestrictions to counterbalance any effects of day, time and\nversion.\nAs we were testing whether the wrens responded to\nthe stimuli and then how the responses differed, we\nwanted to avoid altering the birds’ motivation before\nthey experienced the stimuli. Therefore, we did not use\nplayback to attract the subject; rather, our experimental\nroutine involved waiting at the territory until we either\nsaw or heard the wren singing. If we heard it, we also\nwaited until the end of the singing bout. Once these\ncriteria were met, we played the test sequence from a\nspeaker (3 m high) well within the territory boundaries\nfor 2 min and observed for a further 2 min. When there\nwas no response or only a weak distant response this was\nfollowed by playback of the control stimulus for 30 s. If\nthe bird failed to respond to the test and the control we\nabandoned the trial and later repeated it with a different\nindividual. This design allowed us to include trials with\nno response whilst controlling for the subjects’ presence\nin the territory throughout. Upon completion, each\ntreatment was represented by 10 successful trials (N=60).\nThe test stimuli were broadcast from a HHB PDR1000\nPORTADAT through a Vifa D26 NC-05-06 neodymium\ntweeter assembled with a 1.2-kHz (f\u00013 dB ) high-pass filter\n(Larsen & Dabelsteen 1997). The signals were amplified\nwith a Denon DCA-600 power amplifier and adjusted to a\nnatural level (Holland 2000) where a broadcast wren song\ngave a maximum intensity of 67 dB (A) from 10 m in\n465HOLLAND ET AL.: SIGNAL VALUE IN WREN SONGfront of the speaker (as measured with a Bru ̈el and Kjær,\nType 2236 Precision integrating sound level meter).\nResponse Measures\nWe noted the movements of the wrens relative to the\nlocation of the speaker, their perch heights and any\nposturing throughout both the playback period and the\nfollowing 2 min. To investigate any differences in the\nsinging responses we recorded the whole trial with a\nSennheiser MKH 816 T directional microphone and a\nSony TCD D10 PRO DAT recorder. From these data, we\nextracted the following response measures for both the\nplayback period and the observation period after playback: (1) minimum distance to the speaker, (2) time spent\nwithin 5 m of the speaker, and (3) maximum perch\nheight as measures of approach; (4) number of songs sung\nand (5) percentage of time spent singing as measures of\nsong output; and (6) (analysed separately) the occurrence\nof posturing behaviour which indicates a high level of\nexcitation. These variables were chosen in the light of\nprevious playback experiments with wrens, where discriminable differences in their responses to playback\nstimuli have been found with such measures (Mathevon\n& Aubin 1997; Holland 2000).\nWhen the wrens were silent and concealed, we\ncould not enter data for any of their locations, although\nstrong and immediate responses to the control playback\nassured us that they were within the territory. In these\ncases the trial was classed as one with ‘no response’.\nWhen there was any recordable location or singing the\ntrial was classed as one with ‘response’. These two highly\nconservative measures are used later in the analysis.\nStatistical Analysis\nThere were two stages to the statistical analysis. The\nfirst concerned the distribution of those trials with ‘no\nresponse’ over the treatments and the second concerned\nthe differences between treatments when there was a\nresponse. Rather than pooling the data collected during\nplayback and during the observation period, we kept\nthem as separate variables since there could be qualitative\ndifferences, in some of the measures, between treatments.\nFor example, a small minimum distance to the speaker\nduring playback, followed by a longer minimum distance\nduring the observation period, would indicate a retreat\nrather than a continuing search for a silent intruder. The\ntwo periods were not analysed separately, as both would\ncontain measures that were not independent from those\nin the other period. Instead of analysing separately 10\nnonindependent measures of response (variables 1–5 during and after playback), which were correlated with each\nother to some extent (range of rS values 0.002–0.87, with\n59% being correlated significantly), we used a principal\ncomponent analysis to derive a single composite score of\nresponse for each trial (McGregor 1992). The scores of the\nfirst principal component were then used in further\nanalysis. The posturing data were analysed separately. All\ntests were two tailed.\nRESULTS\nThe majority of the trials where the treatment stimulus\nwas created from artificial noise did not elicit any\nresponse (broadband noise: no response in all 10 trials;\nfiltered noise: response in 3/10 trials), whereas those\ntreatment stimuli derived from manipulated wren song\nnearly always elicited a response (in 39/40 trials;\n\u00012\n1 =39.37, P<0.001, Yates’ correction applied). This result\nclearly suggests that the noise-derived stimuli did not\ncontain cues necessary for eliciting a territorial response,\nwhereas all four of the other treatments did despite their\nmanipulations.\nWe analysed the four treatments that did elicit\nresponses further to investigate qualitative differences\nbetween them. Figure 2 shows how the five measures of\nbehavioural response varied across the treatments, during\nthe playback treatment and during the 2 min of observation after playback. The control response was characterized by a relatively close approach to the speaker, a\nlong time spent near the speaker, a high maximum perch\nheight and a high song output. The other three stimuli\nall elicited territorial responses similar to that elicited by\nthe control stimulus, although these were slightly less\nintense; the speaker was not approached as closely, the\nwrens tended to leave the vicinity of the speaker after a\nshorter period, perch height was slightly lower and the\nsong output was lower. These differences were maintained throughout the observation period to varying\nextents (Fig. 2b).\nThe first principal component derived from these 10\nvariables explained 46% of the variation and the second\nprincipal component explained a further 22%. Response\nmeasures for which low values indicated a strong\nresponse (minimum distance to speaker) loaded negatively on the first principal component, whereas those\nresponse measures where high values indicated a strong\nresponse (time within 5 m of speaker, perch height,\nnumber of songs, percentage time spent singing) loaded\npositively. Collectively this meant that high values of the\nfirst principal component indicated a strong response.\nThere was no significant effect of trial day on the first PC\n(linear regression: F1,38 =0.25, P=0.62). Experiments with\nother species have recorded changes in responsiveness\nwith time of day (e.g. Dabelsteen 1984; Shy & Morton\n1986); however, we found no such relationship despite\nrunning trials over a relatively long period of the day\n(linear regression: F1,38 =0.26, P=0.61). We used a twoway ANOVA to test for effects of both treatment and\nsong version. Responses varied significantly between\ntreatments (F3,28 =3.58, P=0.03), with the difference\nlying between the control and the other treatments (95%\nleast significant difference, multiple range test; Fig. 3).\nResponses also varied between versions (F2,28 =3.73,\nP=0.04), the difference being between version A and the\nother two versions. There was no significant interaction\nbetween these two main factors (F6,28 =1.25, P=0.31). The\nsecond principal component did not vary significantly\nbetween either treatments or version.\nThe effect of song version on the responses seemed\npredominantly due to differences in singing behaviour,\n466 ANIMAL BEHAVIOUR, 60, 4which were weighted heavily on the first principal component. During playback, song length was significantly\nshorter after version A than versions B and C (one-way\nANOVA: F2,37 =5.57, P<0.01) and fewer songs were sung\n(F2,37 =5.2, P=0.01). These differences between song\nversions did not persist after playback (song length:\nF2,37 =2.2, P=0.12; number of songs: F2,37 =1.12, P=0.34).\nWe analysed the occurrence of posturing behaviour\nseparately. The wrens postured in every experiment using\nthe control stimulus (10/10 trials). This was a significantly higher rate of posturing than that elicited by the\nmanipulated signals (posturing in 13/30 trials; Fisher’s\nexact test: P=0.0013).\nDISCUSSION\nThe stimuli derived from noise signals (broadband noise\nand filtered noise) rarely elicited a response. Filtering\nthe noise blocks to mirror the bandpass parameters of the\nrespective elements was not enough to evoke any significant response in wrens. We conclude that neither of these\nstimuli contained parameters that released any territorial\nbehaviour. The song’s rhythm alone did not code\nsufficient cues for this purpose. Given the reverberative\nhabitat favoured by the wren and the distances over\nwhich this signal must function, it is not surprising\nto find that essential information is coded by song\nparameters other than rhythm. Reverberations elongate\nelements, which has the effect of filling the interelement\n‘pauses’ with sound energy (for examples of sonagrams\nsee Richards & Wiley 1980; McGregor et al. 1983;\nMathevon & Aubin 1997). This effect is particularly\napparent in songs with rapid amplitude modulations, as\nis the case with wren song (Holland et al. 1998, 1999).\nThis result mirrors that of Bre ́mond (1986) who found\nthat an imitation of song rhythm derived from a constant\nfrequency tone did not elicit a response. A compressed\nwren song from which all interelement pauses had been\nremoved still evoked a territorial response (J.-C. Bre ́mond,\nunpublished data), which again supports the assertion\nthat the natural element/pause rhythm alone does not\naffect territorial behaviour.\nIt seems that features of the actual element series are\nnecessary to evoke a territorial response. These features\ncould be properties of the series (or part of it; e.g. length\n2\nPercentage of\ntime spent\nsinging\nDistance (m), time (s), number or percentage × 10–1\n(a)\n0 4 6 8 10 12 14\nMinimum\ndistance to\nspeaker (m)\nNumber of\nsongs sung\nMaximum\nperch height\n(m)\nTime (s) spent\nwithin 5 m\nof the speaker\nControl\nRandom\nOnly trills\nLow-pass filter\n2\n(b)\n0 4 6 8 10 12 14\nFigure 2. The means±SE of the response measures (a) during playback and (b) during the 2 min after playback. Means were calculated across\n10 successful trials for each of the four treatments.\n–2 Control\n–1.5\nTreatment\nPrincipal component score\n–1\n–0.5\n0\n0.5\n1\n1.5\n2\n2.5\nRandom Only trills Low-pass\nfilter\nFigure 3. The means±SE of the first principal component scores for\nresponse for each of the treatments. The loadings of the principal\ncomponent are such that a strong response is indicated by a large\npositive value and a weak response by a large negative value.\n467HOLLAND ET AL.: SIGNAL VALUE IN WREN SONGof song, spectral characteristics, overall modulation\nfrequency and/or amplitude, syntax) or properties of\nindividual elements (e.g. durations, frequency and/or\namplitude modulations; for a review see Becker 1982).\nIndividual element characteristics were conserved in all\nthe stimuli that elicited responses, implying that they are\ncritical for evoking a territorial response. However, the\nfine structure of wren song elements is altered during\ntransmission in both the frequency and temporal\ndomains. Given this, it seems unlikely that the exact\nintegrity of all or specific elements would be necessary for\nthis coding. Indeed, if this were the case, wrens would not\nrespond to any degraded versions of their conspecifics’\nsongs. A coding strategy depending on element structure\nmust tolerate a substantial degree of degradation to\nfunction over long distances through a dense habitat\n(Mathevon et al. 1996; Holland et al. 1998).\nA territorial response was given by wrens after playback\nof manipulated songs consisting of degraded (by 50-m\npropagations) elements and undegraded pauses (Fig. 4;\nHolland 2000). In many ways these signals resemble the\nfiltered noise stimulus tested here, both visually and\nacoustically. However, since this stimulus rarely elicited a\nresponse, it seems that the degraded elements contain\nadditional information to the noise-derived filtered noise\nstimulus. The filtered noise stimuli were easily recognizable to us and others working in our department as wren\nsongs. This implies that, at least in some ways, the\nprocesses leading to our identification of wren song are\ndifferent to those of the wren. It is possible the broadband\nnoise and filtered noise stimuli did not contain those cues\nessential for species recognition in the wren, although\nthis experiment tested only the elicitation of a territorial\nresponse. In contrast the random, only trills and lowpass filter stimuli all evoked responses implying that they\nwere recognizable and contained cues eliciting territorial\ndefence. This was despite their manipulations: changes\nin the rhythmicity caused by complete changes of syntax\nand tempo (random stimuli); changes in syntax and\noverall element variety both of which increased\nmonotony (only trills stimuli); and changes that introduced depletions (low-pass filter stimuli). Moreover, none\nof them evoked a response as intense as that of the\ncontrol stimulus. This implies that, although rhythmicity\nis not essential, in the sense that territorial behaviour\nis not elicited if it is altered, it is a very characteristic\nfeature of the song, which contributes to the options for\ndiscrimination.\nTerritorial responses are based on the acquisition of\ninformation through a decoding strategy that is robust\nto changes in song syntax, spectrum, monotony and\ndeletions. In the case of the latter three, this could be\nconsidered an adaptation for effective information transfer given that degradation causes frequency-dependent\nattenuation and that incorporating redundancy into\nthe signal ensures reception despite irregular amplitude\nfluctuations along transmission pathways and the chance\nof masking. Our results imply that syntax is not an\nessential song parameter for coding this type of information. Syntax is one song feature that can be controlled\nby the singer and is fairly resistant to alterations during\ntransmission. However, randomizing element and pause\norder still evoked a response in wrens, but was completely\nunrecognizable to us and our colleagues. That the\nresponse was significantly less intense than a normal\nterritorial response suggests that some information is\nencoded by syntax and that this was missing. These\nresults are consistent with those found by Kreutzer &\nBre ́mond (1986) with the advantage that we controlled\nfor song length. The only trills stimulus added some order\nto the song and the response tended to increase from that\nevoked by the random stimulus, although remained significantly less intense than to the control (Fig. 3). The\nresponse to the low-pass filter stimulus was also significantly less intense than to the control suggesting that\nthe high-frequency elements have information value.\nFrequency-dependent attenuation is likely to provide\nranging cues in degraded songs (e.g. Naguib 1995). We\nimitated a song degraded by only this process and\nobserved a less intense territorial response. Moreover, this\nis somewhat consistent with the response expected had\nthe stimulus been ranged outside the territory; a reduced\napproach with much effort put into singing (Fig. 2). This\nis particularly interesting given that the stimulus contained no other features of degradation in the remaining\nsong, for example overall attenuation or reverberations.\nThis result is comparable to the responses of Carolina\nwrens, Thryothorus ludovicianus, to the playback of songs\nmodified in a similar fashion (Naguib 1995).\nVersion A of the stimuli tended to elicit a less intense\nterritorial response than the other two versions (the\nvariations in responses did not differ between versions).\nThis seems to be predominantly due to differences in\nsinging behaviour, which were weighted heavily by the\nfirst principal component. The original songs were of\nvarying lengths (6 s (A), 4.2 s (B) and 4.5 s (C)), a variation\nthat was conserved in the stimuli versions. These were\nplayed at the same rate with one song starting every 10 s;\nconsequently more song was played back for version A.\nSince many studies have found a relationship between\nthe amount of playback and the intensity of response, the\nvariation observed here was somewhat counterintuitive.\nThe differences in response intensity between versions\ncould suggest that the original songs and their presentation contained differing information, which rendered\nthem more or less likely to elicit strong territorial\nresponses. However, these differences were apparent only\nduring the playback period and we would expect response\ndifferences caused by a more aggressive interaction to\n5\nTime (s)\nFrequency\n(kHz)\n1 2 3 4 6\n4\n6\n8\nFigure 4. Sonagram of a manipulated wren song where elements\nfrom a degraded song were pasted with pauses from an undegraded\nsong. This song elicited a response from territorial males (Holland\n2000), whereas a visually and acoustically similar version (Fig. 1c)\ndid not. Sonagram was created on PC with AVISOFT software\n(settings as in Fig. 1).\n468 ANIMAL BEHAVIOUR, 60, 4continue after the playback stops. An alternative explanation seems more likely. A consequence of the playback\nroutine was that the intersong pauses were markedly\nshorter during playback of version A stimuli than for\nversions B and C. Wrens attempting to avoid overlapping\nby alternating their songs with the playback had less\ntime available during version A. During playback, song\nlength was shorter after version A than versions B and C\nand fewer songs were sung. These differences between\nversions did not persist after playback, which could suggest that they were a consequence of the playback routine\nrather than varying messages within the songs. Noninteractive playback disturbs the singing pattern in wrens\n(Bre ́mond & Aubin 1992) which can presumably become\nless variable once playback stops. Our results seem in\nkeeping with this explanation. As the three versions were\npresented evenly across treatments, this effect does not\nconfound the main results.\nIn conclusion, the rhythmicity of wren song is not\nan essential parameter for eliciting a territorial response.\nOur results imply that transfer of the necessary information for such a response is somehow dependent on the\npresence of the actual song elements. This, and previous\nstudies, have manipulated other song parameters without\nappearing to alter the probability of a territorial response.\nSupporting this surmise is a previous study where\nelement morphology was modified, along with syntax,\nand the response was lost (Kreutzer & Bre ́mond 1986).\nThe habitat-induced degradation accumulated during\nlong-range communication in wrens is great: some\nelements become too weak to detect and all elements\nbecome distorted (Holland et al. 1998). Any information\ntransfer depending on element structure (frequency and\ntemporal) must tolerate these changes to some extent to\nallow the signal to function at long distance through\ndense habitat. The high broadcast intensity, variability\nin element morphology and the repeated elements in\nwren song increase the chances of efficient transfer of\ninformation encoded by element structure.\nOur various alterations to the song rhythmicity, syntax\nand spectra still elicited a territorial response, although\nless intense than responses to control songs. It seems that\nwhilst these features are not essential, they are still\ncharacteristic and add to the options for discrimination.\nThis composite decoding strategy could, in itself, be\nadaptive when communicating through an environment\nwhere elements become severely degraded.\nAcknowledgments\nThis study was funded by the Centre for Sound\nCommunication, which is financed by the Danish\nNational Research Foundation. We thank Thorsten\nBalsby, Peter McGregor, Tom Peake, Marc Naguib and\nan anonymous referee for their helpful comments and\nadvice on the manuscript.\nReferences\nBecker, P. H. 1982. The coding of species-specific characteristics in\nbird sounds. In: Acoustic Communication in Birds, Vol. 1 (Ed. by\nD. E. Kroodsma & E. H. Miller), pp. 213–252. New York: Academic\nPress.\nBre ́mond, J.-C. 1968. Valeur spe ́cifique de la syntaxe dans le signal\nde de ́fense territoriale du troglodyte (Troglodytes troglodytes).\nBehaviour, 30, 66–75.\nBre ́mond, J.-C. 1978. Acoustic competition between the song of the\nwren (Troglodytes troglodytes) and the songs of other species.\nBehaviour, 65, 89–98.\nBre ́mond, J.-C. 1986. Role of the carrier frequency in the territorial\nsongs of oscines. Ethology, 73, 128–135.\nBre ́mond, J.-C. & Aubin, T. 1990. Responses to distress calls by\nblack-headed gulls, Larus ridibundus: the role of non-degraded\nfeatures. Animal Behaviour, 39, 503–511.\nBre ́mond, J.-C. & Aubin, T. 1992. Cadence d’e ́mission du chant\nterritorial du troglodyte (Troglodytes troglodytes). Comptes Rendus\nde l’Aucademie des Sciences Paris, 314, 37–42.\nBre ́mond, J.-C. & Kreutzer, M. 1986. Comment le chant du\ntroglodyte (Troglodytes troglodytes) e ́merge du bruit. Behaviour,\n98, 361–370.\nDabelsteen, T. 1984. Variation in the response of freeliving\nblackbirds Turdus merula to playback of song. Zeitschrift fu ̈r\nTierpsychologie, 65, 215–227.\nDabelsteen, T. & Pedersen, S. B. 1985. A method for computerized\nmodification of certain natural animal sounds for communication\nstudy purposes. Biological Cybernetics, 52, 399–404.\nDabelsteen, T. & Pedersen, S. B. 1988. Do female blackbirds,\nTurdus merula, decode song in the same way as males? Animal\nBehaviour, 36, 1858–1860.\nDabelsteen, T. & Pedersen, S. B. 1992. Song features essential\nfor species discrimination and behaviour assessment by male\nblackbirds (Turdus merula). Behaviour, 121, 259–287.\nDabelsteen, T. & Pedersen, S. B. 1993. Song-based species\ndiscrimination and behaviour assessment by female blackbirds,\nTurdus merula. Animal Behaviour, 45, 759–771.\nDabelsteen, T., Larsen, O. N. & Pedersen, S. B. 1993. Habitatinduced degradation of sound signals: quantifying the effects of\ncommunication sounds and bird location on blur ratio, excess\nattenuation and signal-to-noise ratio. Journal of the Acoustical\nSociety of America, 93, 2206–2220.\nDabelsteen, T., McGregor, P. K., Holland, J., Tobias, J. A. &\nPedersen, S. B. 1997. The signal function of overlapping singing\nin male robins. Animal Behaviour, 53, 249–256.\nFalls, J. B. 1992. Playback: a historical perspective. In: Playback and\nStudies of Animal Communication (Ed. by P. K. McGregor),\npp. 11–33. New York: Plenum.\nHolland, J. 2000. Song communication and degradation in the\nwren. Ph.D. thesis, University of Copenhagen.\nHolland, J., Dabelsteen, T., Pedersen, S. B. & Larsen, O. N. 1998.\nDegradation of wren Troglodytes troglodytes song: implications for\ninformation transfer and ranging. Journal of the Acoustical Society\nof America, 103, 2154–2166.\nHolland, J., Dabelsteen, T., Paris, A. L. & Pedersen, S. B. 1999.\nEnergetic tails: potential cues for ranging? In: Advances in\nEthology 34 (Ed. by S. Sridhara), page 136. Berlin: Blackwell\nScience.\nKaiser, J. F. 1974. Nonrecursive digital filter design using the Io-sinh\nwindow function. In: Proceedings of the 1974 International\nSymposium on Circuits and Systems (Ed. by S. R. Parker), pp. 20–23.\nNew York: IEEE.\nKreutzer, M. & Bre ́mond, J.-C. 1986. Les effets additifs de la\nsyntaxe et de la forme des syllabes lors de la reconnaissance\nspe ́cifique chez le troglodyte (Troglodytes troglodytes). Canadian\nJournal of Zoology, 64, 1241–1244.\nLarsen, O. N. & Dabelsteen, T. 1990. Directionality of blackbird\nvocalization. Implications for vocal communication and its further\nstudy. Ornis Scandinavica, 21, 37–45.\n469HOLLAND ET AL.: SIGNAL VALUE IN WREN SONGLarsen, O. N. & Dabelsteen, T. 1997. The 1’’ Vifa Neodymium\nTweeter: a versatile speaker for playback experiments. Bioacoustics,\n8, 323–326.\nLemon, R. E., Struger, M., Lechowicz, M. J. & Norman, R. F. 1981.\nSong features and singing heights of American warblers: maximization or optimization of distance? Journal of the Acoustical\nSociety of America, 69, 1169–1176.\nMcGregor, P. K. 1992. Quantifying responses to playback: one,\nmany, or composite multivariate measures? In: Playback Studies of\nAnimal Communication (Ed. by P. K. McGregor), pp. 79–95. New\nYork: Plenum.\nMcGregor, P. K., Krebs, J. R. & Ratcliffe, L. M. 1983. The reaction\nof great tits (Parus major) to playback of degraded and undegraded songs: the effect of familiarity with the stimulus song\ntype. Auk, 100, 898–906.\nMathevon, N. 1998. Degraded temporal sound features as a\nfunction of distance and potential as cues for ranging in birds.\nBioacoustics, 9, 17–33.\nMathevon, N. & Aubin, T. 1997. Reaction to conspecific degraded\nsong by the wren Troglodytes troglodytes: territorial response and\nchoice of song post. Behavioural Processes, 39, 77–84.\nMathevon, N., Aubin, T. & Dabelsteen, T. 1996. Song degradation\nduring propagation: importance of song post for the wren\nTroglodytes troglodytes. Ethology, 102, 397–412.\nMichelsen, A. 1978. Sound reception in different environments. In:\nSensory Ecology (Ed. by M. A. Ali), pp. 345–373. New York: Plenum.\nNaguib, M. 1995. Auditory distance assessment of singing conspecifics in Carolina wrens: the role of reverberation and frequencydependent attenuation. Animal Behaviour, 50, 1297–1307.\nNaguib, M. 1996. Ranging by song in Carolina wrens Thryothorus\nludovicianus: effects of environmental acoustics and strength of\nsong degradation. Behaviour, 133, 541–559.\nPedersen, S. B. 1998. Preliminary Operation Manual for Signal\nProcessor SIGPRO, Version 1.3. Copenhagen: Centre for Sound\nCommunication.\nRichards, D. G. & Wiley, R. H. 1980. Reverberations and amplitude fluctuations in the propagation of sound in a forest:\nimplications for animal communication. American Naturalist, 115,\n381–399.\nRobisson, P. T. 1987. L’adaptation des re`gles de de ́codage des\nsignaux acoustiques des oiseaux au canal de transmission.\nEtude applique ́e aux cris de detresse du vanneau huppe ́ Vanellus\nvanellus. Comptes Rendus de l’Aucademie des Sciences Paris, 304,\n275–278.\nRobisson, P. T., Aubin, T. & Bre ́mond, J.-C. 1993. Individuality in\nthe voice of the emperor penguin, Aptenodytes forsteri: adaption\nto a noisy environment. Ethology, 94, 279–290.\nShy, E. & Morton, E. S. 1986. The role of distance, familiarity, and\ntime of day in Carolina wrens responses to conspecific songs.\nBehavioral Ecology and Sociobiology, 19, 393–400.\nWiley, R. H. & Richards, D. G. 1978. Physical constraints on\nacoustic communication and the atmosphere: implications for\nthe evolution of animal vocalizations. Behavioral Ecology and\nSociobiology, 3, 69–94.\nWiley, R. H. & Richards, D. G. 1982. Adaptations for acoustic\ncommunication in birds: transmission and signal detection. In:\nAcoustic Communication in Birds, Vol. 1 (Ed. by D. E. Kroodsma &\nE. H. Miller), pp. 131–181. New York: Academic Press.\n470 ANIMAL BEHAVIOUR, 60, 4", "affiliations": [{"country": "Denmark", "discipline": "Zoology", "university": "University of Copenhagen"}, {"university": "", "country": "", "discipline": ""}], "species_categories": ["Bird"], "specialized_species": ["wren"], "computational_stages": [], "linguistic_features": ["Discreteness and Syntax", "Semanticity"], "status": "saved", "created_at": "2026-01-13T12:49:59.882724", "updated_at": "2026-01-13T16:13:47.941809", "committed_at": "2026-01-13T15:38:16.709310"}
{"id": "8552ddb3-f41e-4739-9e65-15614dbc8fdc", "title": "Using Shannon Entropy on Measuring the Individual Variability in the Rufous-bellied Thrush Turdus rufiventris Vocal Communication", "authors": ["DA SILVA,  MARIA LUISA", "PIQUEIRA,  JOSÉ ROBERTO C.", "VIELLIARD,  JACQUES M.E."], "year": "2000", "journal": "Journal of Theoretical Biology", "abstract": "", "doi": "10.1006/jtbi.2000.2155", "analysis_notes": "?Author to whom correspondence should be addressed.\nE-mail: piqueira@lac.usp.br\nJ. theor. Biol. (2000) 207, 57}64\ndoi:10.1006/jtbi.2000.2155, available online at http://www.idealibrary.com on\nUsing Shannon Entropy on Measuring the Individual Variability in the\nRufous-bellied Thrush Turdus ruf iventris Vocal Communication\nMARIA LUISA DA S ILVA*, J OSED ROBERTO C. P IQUEIRA-?, AND JACQUES M. E. V IELLIARDA\n*Departamento de Psicologia Experimental, Nu& cleo de NeurocieLncias e Comportamento, ;niversidade de\nSaJo Paulo, SaJo Paulo, SP, Brasil, -Departamento de Engenharia EletroLnica,  ̧aborato& rio de Automac7aJo\ne Controle, Escola Polite& cnica, ;niversidade de SaJo Paulo, Av. Prof.  ̧uciano Gualberto, ¹ravessa 3,\nno 380, 05508-900 SaJo Paulo, SP, Brasil and A;nicamp, Departamento de Zoologia, CP 6109,\n13083-970 Campinas, SP, Brasil\n(Received on 21 March 2000, Accepted in revised form on 20 July 2000)\nWe applied the information theory concepts to notes repertoire characteristics combined with\ntemporal parameters of the Rufous-bellied thrush ¹urdus ru,ventris song, using this particular\ncase to test a new method of analysing quantitatively complex animal communication systems.\nLike most ¹urdus thrushes, Rufous-bellied thrushes are remarkable for their long, varied and\nmelodious songs. For the analysis of the species repertoire, we used recordings of 44 individuals from 24 localities covering its full geographical range. We measured the repertoire size,\nnote duration and rhythm (frequency of note utterance), and combined these parameters with\nthe Shannon entropy values calculated for each individual. Although individuals maintain\nspecies-speci\"c recognition capacity, we \"nd a large variation between their song parameters\nand show that the information theory can be useful to analyse large and varied animal vocal\nrepertoires. We are introducing two new parameters, temporal average entropy (Et) and\nutterance frequency average entropy (Ef), for measuring such communication systems.\n( 2000 Academic Press\nIntroduction\nThere are many books on the use of information\ntheory applied to communication (Shannon\n& Weaver, 1949; Khinchin, 1957; Culmann et al.,\n1967; Guiassu & Theodorescu, 1968) and papers\nand book chapters trying to apply that theory to\nbiological problems (Blumenfeld, 1981; Kugler\n& Turvey, 1987; Weber et al., 1988; Piqueira,\n1994; McCowan et al., 1999). In this context, we\nare studying the song of birds and its variability\nby identifying the frequency of occurrence of the\nsound units, that we call notes. Those relative\nfrequencies are assumed to be probabilities, and\nthus an individual information value can be\nassigned to each note. The mean value of the\nsong information for each individual is de\"ned as\ninformational entropy (E). The maximum entropy (Em) would be obtained if all the notes had\nthe same probability.\nMost ¹urdus thrushes are remarkable for their\nlong, varied and melodious songs. The speciesspeci\"c song of the Rufous-bellied thrush ¹urdus\nru,ventris is composed of whistles and trills of\nmedium pitch (frequency range between 1 and\n4 kHz). The phrases are uttered in long sequences\nof regularly spaced notes (Silva, 1997).\nWe looked at the individual localities to eventually \"nd peculiar population characteristics.\n0022}5193/00/210057#08 $35.00/0 ( 2000 Academic PressSick (1993) reports a di!erent ¹urdus ru,ventris\nsong in Rio de Janeiro city describing it as\n&&simple and monotonous, (2) constituting a degraded form of song, a sort of dialect (2)''.\nHowever, later data of song analyses (Silva, 1997)\ndo not demonstrate song populational di!erences, in either repertoire size, notes structure or\nsequence.\nRufous-bellied thrush is a good species to\nstudy complex varied songs because it is abundant and widespread, allowing the study of many\nindividuals from di!erent localities. Like the\nmajority of Oscines that have songs with populational or even individual variations (Mundinger,\n1982; Marler, 1997; Kroodsma, 1982, 1996;\nCanady et al., 1984; Baker & Cunningham, 1985;\nTodt & Hultsch, 1996), thrushes show inter- and\nintra-individual variations. Those variations represent indirect evidences of a learning process\nduring song ontogenesis (Vielliard, 1987).\nIn order to normalize the entropy measures it\nis important to de\"ne new quantities that consider the temporal parameters of note emission in\nanalogy to the idea of necessary capacity of the\nchannel required for communication. So we have\nde\"ned the entropy average rate in two di!erent\nways: the rate considering the average duration\nof the notes or &&temporal average entropy'' (Et)\nand the rate considering the average frequency\nor rhythm of notes emission, the &&utterance\nfrequency average entropy'' (Ef).\nWe present the following measures for each\nindividual: entropy (E) based on relative frequency of notes occurrence, the mean value of\nduration of notes, the mean value of notes utterance frequency and two di!erent combinations of\nthese parameters, temporal average entropy (Et)\nand utterance frequency average entropy (Ef).\nThese analyses produced several sets of data,\npermitting to test the methodology developed\nand to propose, as a result, some biological\ninferences.\nOur goal is to de\"ne an easy way to calculate\nsingle index, that represents the variability of\ncomplex vocal communication signals.\nEntropy Calculations\nLet us consider some kind of alphabet, composed by N symbols and let us consider the\nprobability pi assigned to each symbol as a number calculated according to its relative frequency,\nobserved experimentally. Under those conditions, we can de\"ne individual information of\neach symbol Ii (Shannon & Weaver, 1949) as\nIi\"log2 (1/pi). (1)\nConsidering all the N symbols emitted, we can\nde\"ne the mean value of Ii and call it informational entropy (E):\nE\" N\n+\ni/1\npiIi. (2)\nIt is important to note that the individual information (Ii) is given in bits and the entropy (E)\nis given in bits per symbol.\nBecause the results obtained applying eqs (1)\nand (2) to our data were highly heterogeneous,\nand in order to compare individuals with di!erent repertoire size (number of note types), we\nintroduced two new equations for calculating\naverage entropy rates, as de\"ned in the following\nparameters.\nTemporal average entropy rate (Et) can be\nde\"ned as\nEt\"E\nq ]1000 (3)\nwith q being the mean value of duration of the\nnote in ms:\nq\" N\n+\ni/1\nqipi. (4)\nUtterance frequency (rhythm) average entropy\nrate (Ef) can be de\"ned as\nEf\"EU (5)\nwith U being the mean value of the number of\nnotes emitted per second in Hz:\nU\" N\n+\ni/1\nUipi. (6)\nEt and Ef units are bits per second (bps) in both\ncases.\n58 M. L. DA SILVATABLE 1\nSample localities and individual designation, presented from north to south\n(NE\"North-east, C=\"Central-west, SE\"south-east, S\"South)\nNo. locality Region Locality Individual\nI NE Crato, CE 2\nII NE Caruaru, PE 1\nIII SE Formosa do Rio Preto, BA 9\nIV NE Morro do ChapeHu, BA 3\nV NE Itabuna, BA 4, 5, 6, 7 and 10\nVI CW BrasmHlia, DF 19\nVII CW PoconeH, MT 16\nVIII SE Piracanjuba, GO 21\nIX SE Rio Miranda, MS 29\nX SE Santa Teresa, ES 40 and 41\nXI SE Rio de Janeiro, RJ 11\nXII SE Piracicaba, SP 17 and 18\nXIII SE Cunha, SP 35, 36, 37 and 38\nXIV SE Picinguaba, SP 20\nXV SE Caraguatatuba, SP 31, 42, 43 and 44\nXVI SE BoraceHia, SP 15\nXVII SE Sa8o Paulo, SP 8, 28, 30, 32, 33 and 34\nXVIII SE Sete Barras, SP 22\nXIX SE Ilha do Cardoso, SP 14\nXX S La Cornisa de Jujuy, Salta-ARG 23\nXXI S Palmas, PR 12 and 13\nXXII S Pelotas, RS 39\nXXIII S Reserva Costanera Sur, B. Aires, AR 27\nXXIV S Estancia El Destino, Magdalena, AR 24, 25 and 26\nMaterial and Methods\nIn all of our experiments we considered only\nsongs uttered in typical advertising conditions,\nwhich is the best match to our concept of the\n&&species-speci\"c recognition function of the\nacoustic communication signal'' or functional\nsong sensu Vielliard (1987). Then, we selected the\nbest available recordings in the Arquivo Sonoro\nNeotropical, 75 recordings of 44 individuals from\n24 di!erent localities, which correspond to the\nfull geographical distribution of ¹urdus ru,ven-\ntris. The individuals were identi\"ed by a number\nfrom 1 to 44, and the corresponding localities\nclassi\"ed into four major regions as shown in\nTable 1.\nThese recordings are of high \"delity and technical quality and were analysed on UNISCAN II\ndigital sonograph in the Laboratory of Bioacoustics at the University of Campinas (Unicamp),\nSa8o Paulo, Brazil.\nThe sonograms were used to de\"ne the song\nunits that we call notes. Each note was identi\"ed\nvisually, and named with an alphabet order\naccording to the sequence of its emission. The\nnotes were then classi\"ed into sound types, and\norganized in clusters according to their shape\nand kind of modulation, allowing us to recognize\nthe notes shared by di!erent individuals.\nFor each individual, we measured the duration\n(q) and rhythm (U) of each note, as shown in\nFig. 1. After obtaining the individual repertoire,\nwe calculated the frequency of occurrence of each\nof the note types making its repertoire. From\nthese data, we calculated E, Et and Ef for each\nindividual.\nResults\nThe individual repertoire size varied from 1 to\n36 note types (mean\"14, S.D.\"7.46; N\"44)\nand the entropy values varied from 0 to 4.55\n(mean\"3.19, S.D.\"0.9; N\"44). Figure 2 shows\nthe distribution of the mean values and the correlation between repertoire size and entropy.\nMost of the notes of our sample are gently\nmodulated pure sounds. We found 592 note types\nSHANNON ENTROPY AND ¹;RD;S SONG 59FIG. 1. Schematic representation of two di!erent sequencial notes A and B, indicating the duration of the note (q) and\nthe period of emission (1/U).\nFIG. 2. Entropy vs. repertoire size (E).\nFIG. 3. Temporal average entropy (Et) vs. repertoire size.\nFIG. 4. Utterance frequency average entropy (Ef) vs. repertoire size.\nin the whole sample, of which 24 (4.05%) were\nshared by di!erent individuals. Of the shared\nnotes, 12 (50%) were between males from the\nsame locality, and only one between neighbour\nmales (individuals 40 and 41 from Santa Teresa,\nEspmHrito Santo state).\nThe mean value of the duration of the notes\nvaried between the individuals analysed from 134\nto 356 ms (mean\"259, S.D.\"49; N\"44). We\ncalculated Et using eqn (3) and plotted these\nvalues in correlation with the repertoire size in\nFig. 3.\nThe rhythm was obtained in Hz or notes per\nsecond and the mean value varied individually\nbetween 1.62 and 3.13 Hz (mean\"2.44, S.D.\"\n0.36; N\"44). We calculated Ef using eqn (5) and\nthese values were plotted in correlation with repertoire size in Fig. 4.\nThe di!erent entropy mean values, with their\nstandard deviation and standard error where\nmore than one individual has been analysed, are\npresented according to the locality in Fig. 5 for E,\nFig. 6 for Et and Fig. 7 for Ef.\nThe localities were grouped into four major\nregions, North-east, Central-west, South-east\nand South, and the entropy (E) mean values, with\ntheir standard deviation, standard error and\nextralimital values plotted as in Fig. 8.\nDiscussion\nThese results corroborate our early descriptive\nstudy of the ¹urdus ru,ventris song (Silva, 1997)\nin its most prominent feature: its quite large and\nremarkable inter-individual variation. However,\nalthough our sample included some individuals\npresenting extreme repertoire size values, most of\nthem presented similar information quantity\nin their song. Individual 36, with its repertoire\n60 M. L. DA SILVAFIG. 5. Distribution of entropy (E) mean values, with\ntheir standard deviation and standard error where more\nthan one individual has been analysed, according to the\nlocality: ( ) mean#S.D. , mean!S.D.; ( ) mean#S.E.,\nmean!S.E.; ( ) mean.\nFIG. 6. Distribution of Et mean values, with their standard deviation and standard error where more than one\nindividual has been analysed, according to the locality:\n( ) mean#S.D., mean!S.D.; ( ) mean#S.E., mean!S.E.;\n( ) mean; ( ) outliers.\nFIG. 7. Distribution of Ef mean values, with their standard deviation and standard error where more than one\nindividual has been analysed, according to the locality:\n( ) mean#S.D., mean!S.D.; ( ) mean#S.E., mean!S.E.;\n( ) mean; ( ) outliers.\nFIG. 8. Distribution of the entropy mean values with\ntheir standard deviation, standard error and extralimital\nvalues according to the localities which were grouped in four\nmajor regions, north-east (NE), central-west (CW), southeast (SE) and south (S): ( ) mean#S.D., mean!S.D.; ( )\nmean#S.E., mean!S.E.; ( ) mean; ( ) extremes.\nreduced to a single note type, emits a song with\nno entropy, whereas individual 16 exhibits an\nextraordinarily large repertoire of 36 note types\nwhich would allow it to the highest entropy.\nNevertheless, individual 36 appeared to communicate e!ectively, and individual 16 had not\nused its full potential and presented an entropy\nvalue lower than individuals with smaller repertoires (equivalent to individual 44 with only 24\nnote types). The entropy has a relation with the\nrepertoire size, but that relation may be signi\"-\ncantly altered, particularly when the repertoire\nsize value is outside the core of the sample.\nThe temporal organization is de\"ned by the\nparameters with lesser variation in the song of\n¹urdus ru,ventris (Silva, 1997) and is possibly\na species-speci\"c character. The frequency of\nnote utterance represents the combination of\nSHANNON ENTROPY AND ¹;RD;S SONG 61note duration and silence interval, which means\nthe song rhythm; its variation in the sample is still\nsmaller than that of the note duration. The entropy values calculated in combination with\nthese parameters, Et taking into account the\nduration of the notes and Ef their rhythm, put\ninto evidence further individual variations between entropy and repertoire size. Besides the\ncon\"rmation of extreme individual values, these\ncorrelations discriminate more distinctively\nthose individuals forming the core of the sample,\nthan simple entropy had permitted. Interestingly, individuals depart di!erently from their\noriginal position (as de\"ned by repertoire size\nand entropy E) if we introduce one or another\ntemporal parameter. For instance, individual 18,\nwith 22 note types, presents an entropy in accord with its repertoire size (Fig. 2); in relation to Ef, its value continues near the regression\nline of the sample (Fig. 4), but not when the\ncorrelation is with Et (Fig. 3). Looking at other\nindividuals, we can \"nd the other kind of deviations.\nThe entropy values did not show any correlation with the localities of the sampled individuals,\nimpeding us to evidence any populational patterns. Even in the cases where we analysed\nseveral neighbouring birds, no similarities\nappeared, which would indicate the possibility\nof a local dialect. As the only learning process known in the ontogenesis of bird song\nis through vocal mimicry, it remains a mystery\nhow ¹urdus ru,ventris singers manage to learn\ntheir repertoire without sharing it with their\nneighbours.\nIf we are, for now, unable to say from where\n¹urdus ru,ventris singers learn their normally\nlarge repertoire of di!erent note types, we can say\nthat individual entropy values vary considerably\nfrom one locality to another (Figs 5}7). As with\nthe repertoire, the correlations of the localities\nwith the entropy show interesting variation depending on its calculation method: crude or in\ncombination with duration or rhythm of the signal (note type). A visual comparison of Figs 5}7\nwill show potentially instructive discrepancies.\nFor instance, the two individuals from Santa\nTeresa are very similar if we look at E and Et, but\nnot for Ef, whereas the two individuals from\nPiracicaba are similar for E and Ef but not for Et.\nDespite these strong variations between individuals and even between localities, an overall\nanalysis dividing the sample into four regions\nshows much less entropy variation in the South\nregion (Fig. 8). It is interesting to note that\nalthough the mean values are not signi\"cantly\ndi!erent between the four regions, the variation remains high in each, except for the\nSouth. A biological explanation we could suggest is that the southern population of ¹urdus\nru,ventris is made of relatively recent colonizers, derived from a reduced genetical or\ncultural pool, exhibiting therefore a lesser heterogeneity.\nThe large individual variability demonstrated\nby ¹urdus ru,ventris in its song needs to be\nmeasured not only by the number of di!erent\nnote types each singer may utter, but also by the\ninformational entropy it may emit. Because bird\nsong represents an acoustic signal of communication, using a sound channel for transmitting the\ninformation it carries, it becomes necessary to\nmeasure the #ow of that information. This is the\nreason what we are proposing here to introduce\nthe two average rates of entropy, both in linear\nproportion to temporal parameters: duration of\nthe units or notes for Et, rhythm of delivery of\nthese units for Ef.\nThe comparison of the repertoire size, which\ndetermine the maximum entropy that an individual singer has the potential to deliver, with the\nentropy of the song it e!ectively emits shows that\nindividuals depart di!erently from their maximum entropy, and that most of the individuals\nanalysed utter songs whose entropy remains near\nthe mean of the sample. Our data show that\nrepertoire size and overall entropy are not varying in the same proportion. A study of the rate of\ndeparture from the maximum entropy might\nreveal unsuspected patterns.\nBy introducing the temporal (Et) and utterance\nfrequency (Ef) average entropy rates, we discovered more individual discrepancies, which\nneed to be analysed in detail. It would be necessary to choose one entropy value, in order to\nestablish, together with the repertoire size, a kind\nof index of individual variation. Since it incorporates a more heuristic concept of the temporal\n#ow of information, Ef would be the best candidate. However, more comparisons are needed to\n62 M. L. DA SILVAunderstand the signi\"cance of the di!erences\nobserved here.\nConclusions\nBiological conclusions are still premature, but\nunexpected interesting suggestions can be made.\nVariability in the song of ¹urdus ru,ventris is\ncon\"rmed to be individual, not populational.\nHowever, that variability, as expressed by the\nindividual entropy, consisted of a strange pattern\nof variation: a high deviation from the mean\nover the geographical range, except in the south.\nSince the mean is not signi\"cantly di!erent\nbetween the southern individuals and the rest of\nthe sample, biological hypothesis must incorporate various theories to explain such a complex\nsituation.\nSick (1993) used his common sense to interpret\n¹urdus ru,ventris monotonous song from the\ncity of Rio de Janeiro as a dialect, but our single\nrecording is well within the rest of the sample.\nAlthough more data from that population might\nreveal some microgeographic patterns of variation, it is clear that empirical evaluations based\non aural impressions are misleading, especially\nwhen the song is complex and highly variable.\nIf we admit that the colonization of ¹urdus\nru,ventris comes from the north, the southern\npopulation could be more recent and should\nhave had less time to present variation of the\nentropy of its song. To have some idea on how\nthis could happen, we would need to know how\nyoung birds learn and disperse in natural conditions.\nThese results are preliminary but demonstrated that quantitative tools have a great potential to evaluate complex vocal communication\nsystems and to compare their informational\nstructure with biological evolutionary processes.\nWe will continue to study the ¹urdus ru,ventris\nsong database, trying to \"nd correlations\nbetween entropy and environmental factors.\nEven if, for the moment, our analysis is bringing more unexpected questions than answers, it is\nclear that the use of entropy values has a great\nimportance for the characterization and understanding of biological communication systems\nwith high natural complexity. In the case of\n¹urdus ru,ventris, we still need to develop and\nincorporate an index derived from the sequencing of the signal units. In that species, as in\nfew other birds, the song is not only variable\nthrough the individual diversity of signal units or\nnotes, but is said to be versatile for the order of\nutterance of these notes is also variable and even,\nin part, unpredictable.\nData are from M.L.S. thesis, \"nanced by Capes.\nCNPq supported the Laboratory of Bioacoustics at\nthe University of Campinas.\nREFERENCES\nBAKER, M. C. & C UNNINGHAM , M. A. (1985). The biology of\nbird-song dialects. Behav. Brain Sci. 8, 85}133.\nBLUMENFELD , L. A. (1981). Problems of Biological Physics.\nBerlin: Springer-Verlag.\nCANADY, R. A., K ROODSMA, D. E. & NOTTEBOHM , F.\n(1984). Population di!erences in complexity of a learned\nskill are correlated with the brain space involved. Proc.\nNatl. Acad. Sci. ;.S.A. 81, 6232}6234.\nCULMANN, G., DENIS -PAPIN, M. Y. & K AUFMANN, A.\n(1967). Elementos de Ca& lculo Informacional. Bilbao, Spain:\nUrmo.\nDA SILVA, M. L. (1997). Descriia8o do reperto& rio vocal do\nSabia& -laranjeira ¹urdus ru,ventris (Aves, Passeriformes,\nTurdinae). Unpublished M.Sc. Dissertation, Sa8o Paulo\nUniversity, Sa8o Paulo, Brazil.\nGUIASSU, S. & THEODORESCU , R. (1968).  ̧a ¹he& orie\nmathe& matique de l'Information. Paris, France: Dunod.\nKHINCHIN, A. I. (1957). Mathematical Foundations of In-\nformation ¹heory. New York, U.S.A.: Dover Publications\nInc.\nK ROODSMA, D. E. (1982). Song learning and its consequences. In: Acoustic Communication in Birds (Kroodsma,\nD. E. & Miller, E. H., eds), pp. 315}326. New York:\nAcademic Press.\nK ROODSMA, D. E. (1996). Ecology of Passerine song development. In: Ecology and Evolution of Acoustic Communica-\ntion in Birds (Kroodsma, D. E. & Miller, E. H., eds),\npp. 3}19. Ithaca: Cornell University Press.\nK UGLER, P. N. & TURVEY, M. T. (1987). Information,\nNatural  ̧aw, and the Self assembly of Rhythmic Move-\nment. Hillsdale, NJ: Lawrence Erbaun Associated Publishers.\nM ARLER, P. (1997). Three models of song learning: evidence\nfrom behavior. J. Neurobiol. 33, 501}516.\nMCCOWAN , B., HANSER, S. F. & DOYLE, L. R. (1999).\nQuantitative tools for comparing animal communication\nsystems: information theory applied to bottlenose dolphin\nwhistle repertoires. Anim. Behav. 57, 409}419.\nM UNDINGER, P. C. (1982). Microgeographic and macrogeographic variation in the acquired vocalizations of birds.\nIn: Acoustic Communication in Birds (Kroodsma, D. E. &\nMiller, E. H., eds), pp. 147}208. New York: Academic\nPress.\nP IQUEIRA, J. R. C. (1994). Structural and functional\ncomplexity: an informational approach. Proceedings of\nIEEE Conference on Systems, Man and Cybernetics,\npp. 1974}1978. TX, U.S.A.: San Antonio.\nSHANNON ENTROPY AND ¹;RD;S SONG 63S HANNON , C. & WEAVER, W. (1949). ¹he Mathematical\n¹heory of Communication. Chicago, U.S.A.: University of\nIllinois Press.\nSICK, H. (1993). Birds in Brazil, a Natural History. Princeton,\nNJ: Princeton University Press. (translated by William\nBelton.)\nT ODT , D. & HULTSCH , H. (1996). Acquisition and performance of song repertoires: ways of coping with diversity\nand versatility. In: Ecology and Evolution of Acoustic\nCommunication in Birds (Kroodsma, D. E. & Miller,\nE. H., eds), pp. 79}96. Ithaca: Cornell University\nPress.\nVIELLIARD, J. M. E. (1987). Uso da bioacuHstica na\nobservaia8o das aves. In: II Encontro Nac. Anilhad. Aves,\npp. 98}121. Rio de Janeiro.\nW EBER, B. H., D EPEW , D. J. & S MITH, J. D. (1988). Entropy,\nInformation and Evolution. Cambridge, MA, U.S.A.: MIT\nPress.\n64 M. L. DA SILVA", "affiliations": [{"country": "Brazil", "discipline": "Psychology", "university": "University of São Paulo"}, {"country": "Brazil", "discipline": "Electrical Engineering", "university": "University of São Paulo"}], "species_categories": ["Bird"], "specialized_species": ["Rufous-bellied Thrush"], "computational_stages": ["Data Collection", "Sequence Representation", "Meaning Identification"], "linguistic_features": ["Discreteness and Syntax", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882730", "updated_at": "2026-01-13T16:13:52.946142", "committed_at": "2026-01-13T15:58:06.640544"}
{"id": "b05b7676-8483-465d-8d72-2bbbe14c1266", "title": "Whistle Matching in Wild Bottlenose Dolphins (Tursiops truncatus)", "authors": ["Janik,  Vincent M."], "year": "2000", "journal": "Science", "abstract": "", "doi": "10.1126/science.289.5483.1355", "analysis_notes": "25. For further details, see Science Online at www.\nsciencemag.org/feature/data/1047997.shl.\n26. G. Kojouharoff et al., Clin. Exp. Immunol. 107, 353\n(1997).\n27. L. Steidler et al., data not shown.\n28. D. M. Rennick, M. M. Fort, N. J. Davidson, J. Leukocyte\nBiol. 61, 389 (1997).\n29. Mice were housed in ventilated cages in which incoming and outgoing air was filtered over a highefficiency particulate air filter. All manipulations\nwere performed inside a class II biosafety hood. This\n“clean” housing may account for the lower degree of\nintestinal inflammation in our mice than that previously reported in the literature.\n30. G. Corthier, C. Delorme, S. D. Ehrlich, P. Renault, Appl.\nEnviron. Microbiol. 64, 2721 (1998).\n31. M. Wysocka et al., Eur. J. Immunol. 25, 672 (1995).\n32. H. Groux et al., Nature 389, 737 (1997).\n33. L. Thompson-Snipes et al., J. Exp. Med. 173, 507\n(1991).\n34. We thank I. Bruggeman, H. Devlies, K. Pollinger, and K.\nVan Laer for technical assistance; J. Wells for pTREX1; T.\nVelu for mIL-10 cDNA; K. Madsen for 129Sv/Ev IL-102/2\nmice; G. Trinchieri for anti–IL-12–producing C17.8 hybridoma cells; J. Van Snick for MC/9 cells; M. Praet for\nautomated tissue processing; and C. Cuvelier, K. Madsen,\nand P. Vandenabeele for helpful discussion and critically\nreading the manuscript. L.S. is a fellow with the Vlaams\nInstituut voor de Bevordering van het Wetenschappelijktechnologisch Onderzoek in de Industrie. Supported by\ngrants 1.5567.98N and G005097 of the Fonds voor\nWetenschappelijk Onderzoek–Vlaanderen.\n16 December 1999; accepted 10 July 2000\nWhistle Matching in Wild\nBottlenose Dolphins\n(Tursiops truncatus)\nVincent M. Janik\nDolphin communication is suspected to be complex, on the basis of their call\nrepertoires, cognitive abilities, and ability to modify signals through vocal\nlearning. Because of the difficulties involved in observing and recording individual cetaceans, very little is known about how they use their calls. This report\nshows that wild, unrestrained bottlenose dolphins use their learned whistles in\nmatching interactions, in which an individual responds to a whistle of a conspecific by emitting the same whistle type. Vocal matching occurred over\ndistances of up to 580 meters and is indicative of animals addressing each other\nindividually.\nBottlenose dolphins show many cognitive\nand communicative skills that are rare among\nanimals. They are capable not only of generalizing rules, developing abstract concepts\nand syntactic understanding in an artificial\ncommunication system (1), but also of vocal\nlearning, i.e., the ability to modify the structure of a vocal signal as a result of experience\nwith those of other individuals (2). Although\nextensive studies in nonhuman primates have\nnot been able to present convincing evidence\nfor vocal learning, this prerequisite for the\nevolution of spoken language has been demonstrated with much less research effort in\nbottlenose dolphins (2). Dolphins are capable\nof imitating new sounds accurately at their\nfirst attempt, and they keep this ability\nthroughout their life (3). Vocal learning is\nalso an important factor in the ontogeny of an\nindividually distinctive signature whistle that\neach individual develops in the first few\nmonths of its life (4). Studies on captive\nindividuals have shown that signature whistles are primarily used if animals are out of\nsight of each other, and they are therefore\nthought to function in group cohesion and\nindividual recognition (5–7). However, because bottlenose dolphins are capable of vocal learning, individual signature whistles can\nbe found in the repertoire of more than one\nindividual in captive dolphins (6, 8).\nI investigated whether such shared whistles occur in matching whistle interactions\nbetween wild dolphins, a phenomenon indicative of their use in addressing specific individuals. Matching interactions were defined\nas an occurrence in which two whistles of the\nsame type produced by separate individuals\noccurred within 3 s of each other.\nThere is often a clear effect of observer\npresence on dolphin behavior when methods\nsuch as tagging or boat pursuits are applied\n(6, 9). I used a noninvasive passive acoustic\nlocalization technique (10) to locate calling\nbottlenose dolphins (11). This method uses\nthe differences in the time of arrival of the\nsame sound at different widely spaced hydrophones. Signals from different recording\nchannels were cross-correlated to determine\nthe difference in the time of arrival of a sound\nat the two corresponding hydrophones. The\ntime-of-arrival comparisons of three pairs of\nhydrophones then result in three hyperbolas\nof possible sound source locations. These\nhyperbolas intersect at the true location of the\nwhistling dolphin. This analysis was conducted with SIGNAL software (Engineering Design, Belmont, Massachusetts). Recordings\nwere conducted in the Kessock Channel of\nthe Moray Firth, Scotland. All data were\nacquired from the shore, so that no boats or\nhumans were present around the animals.\nVocal interactions between individuals\nwere identified by comparing the distance of\nthe source locations of two successive whistles (minus twice the maximum localization\nerror of 13 m) with the distance that a bottlenose dolphin could travel at its maximum\nreported swimming speed of 7.5 m/s (12) in\nthe interwhistle interval. If the distance between two whistle sources could not have\nbeen covered by one individual in the time\ninterval between those whistles, they must\nhave been produced by different individuals.\nFive naı ̈ve human observers were used to\nrate the similarity of each whistle interaction\nusing only the extracted contours (13) of the\nwhistles; this method is more reliable than\ncomputer-based methods that have been used\nin dolphin whistle studies (14). They were\nallowed to rate whistle similarity on a scale\nfrom 1 (5dissimilar) to 5 (5similar). The\nscores of the different observers were significantly similar (Kappa 5 0.34, z 5 16.9, P ,\n0.00001). Only whistle pairs that reached an\naverage score of more than 3.0 were considered to be matching interactions (15).\nIn a total recording time of 258 min and 43 s\nfrom seven different days in July and August\n1994 and 1995, a total of 1719 whistles was\nrecorded. These recordings were made with an\naverage of 10 animals present in the channel\n(quartiles: 7, 10, and 15). Independent counts\nconducted by a second observer from a higher\nobservation point using binoculars showed that\nthese counts were highly accurate. I could not\nidentify individuals in this study, but a photoidentification study showed that at least 14 different individuals were using this area on a\nregular basis and that occasionally groups of\nmore than 20 animals were present (16). Nine\nhundred ninety-one of the recorded whistles\nhad a sufficient signal-to-noise ratio on all hydrophones for their source location to be determined. In this sample, 176 whistle interactions\nwere found, of which 39 were classified as\nmatching interactions (Fig. 1). In both matching\nand nonmatching interactions, 80% of the interwhistle interval was less than 1 s. The mean\ndistance between matching individuals was\n179 m (standard error: 22.8 m); the maximum\nwas 579 m. Distances between animals in\nmatching interactions were significantly smaller than those of animals in nonmatching interactions (Kolmogorov-Smirnov Two-Sample\nTest, two-tailed, D 5 0.291, P , 0.025) (Fig.\n2). A randomization test (17) showed that this\nnumber of matching interactions was signifi-\nSchool of Biology, University of St. Andrews, Bute\nBuilding, Fife KY16 9TS, UK, and Lighthouse Field\nStation, Aberdeen University, Cromarty, Ross-shire\nIV11 8YJ, UK. Present address: Woods Hole Oceanographic Institution, Biology Department, Woods Hole,\nMA 02543, USA.\nR E P O R T S\nwww.sciencemag.org SCIENCE VOL 289 25 AUGUST 2000 1355cantly greater than expected if all animals were\ncalling independently of each other (999 runs;\nobserved proportion: 0.04; chance proportion:\n0.018; P 5 0.001) (15). The assumptions of this\ntest were that each of the 10 animals present\nhad at least one individually distinctive signature whistle type and that it could copy each of\nthe signature whistle types used by the other\nnine individuals. Thus, matching was judged to\noccur in a repertoire of 10 shared but learned\nwhistle types. These assumptions are based on\nthe findings from previous studies that each\nindividual bottlenose dolphin develops its own\ndistinctive signature whistle type (5) and that a\nbottlenose dolphin can copy new whistle types\nat the first attempt (3). Furthermore, it was\nassumed that each dolphin whistled at the same\nrate. These assumptions are conservative, as an\nincrease in whistle types or unequal whistling\nrates would make matching less likely to occur\nby chance. Furthermore, most matching interactions occurred when there were more than 10\nanimals in the channel, which also makes\nmatching less likely to occur by chance.\nThe number of all whistle interactions including nonmatching interactions was not significantly different from chance (999 runs; observed proportion: 0.18; chance proportion:\n0.18; NS). Most matching interactions only involved two animals, each producing just one\nwhistle. However, in three cases, the first animal produced another matching whistle after it\nhad been matched, and in one case, two matching interactions followed each other within 5 s.\nIn three cases, matching interactions involved\nthree individuals (Fig. 3). Matching whistle interactions were found on all seven days for\nwhich recordings were analyzed.\nWith the methods used here, animals\nswimming within 26 m of each other could\nnot be identified as different individuals.\nThus, it is possible that matching interactions\nare more common than shown here. Indeed,\n50 overlapping whistles from one location\ncould be found in the sample. However, because individual cetaceans have been reported to produce two whistles simultaneously\n(18), I excluded these cases from the analysis.\nWhistles in seven matching interactions of\nclearly separate individuals, however, also\noverlapped, a behavior that has been linked\nwith aggression in birds (19 –21).\nThese results show that bottlenose dolphins\nuse their learned whistles in matching interactions, most likely to address each other. The\ncharacter of such addressing might be either\naggressive or affiliative. However, matching\ncould also signal alliance membership to third\nFig. 1. Spectrograms of\nthree examples of nonmatching (A) and matching (B) whistle interactions. The whistling dolphins were 55, 74, and\n29 m apart (from top to\nbottom) in (A) and 158,\n204, and 379 m apart in\n(B). Average similarity\nscores were 2, 2.4, and 1.4\nin (A) and 4.2, 4.2, and\n3.4 in (B). Human judges\ninspected frequency contours (i.e., line representations of the frequency\nmodulation of the fundamental frequency; time\nresolution: 5 ms; frequency resolution: 200\nHz) rather than spectrograms on a more detailed\nscale than shown here.\nThe actual size of each\ncontour graph was 10 cm\nby 12 cm (25).\nFig. 2. Distributions of the distances between\ndolphins in matching (solid bars) and nonmatching (hatched bars) whistle interactions.\nFig. 3. A matching whistle interaction that involved three individuals.\n(A) Spectrogram of the\nproduced whistles. (B)\nPlot of the array geometry with the locations of\neach of the dolphins that\nproduced whistles D1,\nD2, and D3 in (A). Gray\nareas at the top and the\nbottom of the plot represent the shoreline. Circles, animals; triangles,\nhydrophones (25).\nR E P O R T S\n25 AUGUST 2000 VOL 289 SCIENCE www.sciencemag.org1356parties or be used to prevent deception of third\nparties by a whistle-copying dolphin. Although\nvocal matching is common in birds (22),\nbottlenose dolphins are the only nonhuman\nmammals in which matching interactions\nwith learned signal types have been found.\nThe occurrence of such matching or labeling has been hypothesized to have been an\nimportant step in the evolution of human\nlanguage (23, 24 ). The results presented\nhere show that reaching that step can be\nachieved in very different environments.\nReferences and Notes\n1. L. M. Herman, A. A. Pack, P. Morrel-Samuels, in Language and Communication: Comparative Perspectives, H. L. Roitblat, L. M. Herman, P. E. Nachtigall, Eds.\n(Erlbaum, Hillsdale, NJ, 1993), pp. 403– 442.\n2. V. M. Janik and P. J. B. Slater, Adv. Study Behav. 26, 59\n(1997).\n3. D. G. Richards, J. P. Wolz, L. M. Herman, J. Comp.\nPsychol. 98, 10 (1984).\n4. P. L. Tyack, Bioacoustics 8, 21 (1997).\n5. M. C. Caldwell, D. K. Caldwell, P. L. Tyack, in The\nBottlenose Dolphin, S. Leatherwood and R. R. Reeves,\nEds. (Academic Press, San Diego, CA, 1990), pp. 199 –\n234.\n6. V. M. Janik and P. J. B. Slater, Anim. Behav. 56, 829\n(1998).\n7. L. S. Sayigh, P. L. Tyack, R. S. Wells, M. D. Scott, Behav.\nEcol. Sociobiol. 26, 247 (1990).\n8. P. Tyack, Behav. Ecol. Sociobiol. 18, 251 (1986).\n9. V. M. Janik and P. M. Thompson, Mar. Mammal Sci.\n12, 597 (1996).\n10. V. M. Janik et al., Mar. Mammal Sci. 16, 437 (2000).\n11. Observations and recordings were made from an\nobservation booth 30 m above water level on the\nnorth shore of the channel. Recordings were made\nfrom three High Tech SSQ94 hydrophones that were\nlocated in a triangle with side lengths of 208, 513,\nand 560 m (Fig. 3B). One hydrophone was located on\nthe south shore and two on the north shore of the\nchannel. Each hydrophone was about 50 m from\nshore at a depth of 1 to 5 m according to the state of\ntide. Each hydrophone was fitted with a Micron TX101 VHF radio transmitter. At the recording station,\nsignals were received by Yaesu FRG-9600 receivers,\nand all signals were recorded on a Fostex 380S multitrack tape recorder. The frequency response of the\nwhole system was 50 to 18,000 Hz 6 3 dB.\n12. T. G. Lang and K. S. Norris, Science 151, 588 (1966).\n13. V. M. Janik, G. Dehnhardt, D. Todt, Behav. Ecol.\nSociobiol. 35, 243 (1994).\n14. V. M. Janik, Anim. Behav. 57, 133 (1999).\n15. The randomization test ceased to be significant at\nP , 0.05 if interactions had to have scores of 3.5 or\nhigher to be considered matching. However, even a\nsimilarity score of 1.1 indicates some similarity between two whistles. For an example of an interaction\nthat received a score of 3.4, see Fig. 1.\n16. B. Wilson et al., J. Appl. Ecol. 34, 1365 (1997).\n17. B. F. J. Manly, Randomization and Monte Carlo Methods in Biology (Chapman & Hall, London, 1991).\n18. M. C. Caldwell and D. K. Caldwell, Mammalia 33, 505\n(1969).\n19. T. Dabelsteen, P. K. McGregor, M. Shepherd, X. Whittaker, S. B. Pederson, J. Avian Biol. 27, 189 (1996).\n20. T. Dabelsteen, P. K. McGregor, J. Holland, J. A. Tobias,\nS. B. Pederson, Anim. Behav. 53, 249 (1997).\n21. D. Todt, Z. Tierpsychol. 57, 73 (1981).\n22. C. K. Catchpole and P. J. B. Slater, Bird Song: Biological\nThemes and Variations (Cambridge Univ. Press, Cambridge, 1995).\n23. H. S. Terrace, Am. Psychol. 40, 1011 (1985).\n24. W. K. Wilkins and J. Wakefield, Behav. Brain Sci. 18,\n161 (1995).\n25. Sound files are available at www.sciencemag.org/\nfeature/data/1050732.shl.\n26. Funded by a DAAD-Doktorandenstipendium aus Mitteln des zweiten Hochschulsonderprogramms. I thank\nP. Slater for help throughout this project; P. Thompson, B. Greigg, T. Lu ̈tkebohle, S. MacDonald, and S.\nvan Parijs for their help in the field; Ross and\nCromarty District Council, Ross and Cromarty Enterprise, Scottish Natural Heritage, and the European\nLife Program for providing equipment and access to\nthe Dolphin and Seal Interpretation Centre; Highland\nCouncil, Merkinch Community Council, and the Royal\nNational Lifeboat Institution for permission to place\nequipment in their facilities; P. Hammond, M. Ritchie,\nand P. Thompson for providing additional equipment;\nand G. Beckers, P. den Hartog, S. de Kort, A. Leitao,\nand M. Verzijden for scoring the spectrograms.\n24 March 2000; accepted 23 June 2000\nPAX8-PPARg1 Fusion in\nOncogene Human Thyroid\nCarcinoma\nTodd G. Kroll,1* Pasha Sarraf,\n2 Lorenza Pecciarini,1\nChang-Jie Chen,1 Elisabetta Mueller,2 Bruce M. Spiegelman,2\nJonathan A. Fletcher1,2,3 *\nChromosomal translocations that encode fusion oncoproteins have been observed consistently in leukemias/lymphomas and sarcomas but not in carcinomas, the most common human cancers. Here, we report that t(2;3)(q13;p25),\na translocation identified in a subset of human thyroid follicular carcinomas,\nresults in fusion of the DNA binding domains of the thyroid transcription factor\nPAX8 to domains A to F of the peroxisome proliferator–activated receptor\n(PPAR) g1. PAX8-PPARg1 mRNA and protein were detected in 5 of 8 thyroid\nfollicular carcinomas but not in 20 follicular adenomas, 10 papillary carcinomas,\nor 10 multinodular hyperplasias. PAX8-PPARg1 inhibited thiazolidinedioneinduced transactivation by PPARg1 in a dominant negative manner. The experiments demonstrate an oncogenic role for PPARg and suggest that PAX8PPARg1 may be useful in the diagnosis and treatment of thyroid carcinoma.\nChromosomal translocations encoding fusion\noncoproteins are common in leukemias/lymphomas and sarcomas (1) but have been identified in only a single adult human (thyroid\npapillary) carcinoma. Compared with fusion\noncoproteins in noncarcinomas, those in thyroid papillary carcinoma occur at relatively low\nfrequency and are derived from several distinct\ngene fusion events, the most common of which\nresult from subtle chromosomal inversions (2).\nMost cytogenetic abnormalities characterized in\ncarcinomas to date are deletions that remove\ngrowth-restraining tumor suppressor genes.\nThese findings imply (i) that most human carcinomas develop through translocation-independent events, or (ii) that most carcinoma\ntranslocations are subcytogenetic alterations\nthat are difficult to detect in complex carcinoma\nkaryotypes (3). Distinction between these alternatives is important because carcinomas constitute up to 90% of human cancers.\nWe have determined the genetic consequences of t(2;3)(q13;p25), a chromosomal\ntranslocation identified in human thyroid follicular carcinomas. Three consecutive thyroid follicular carcinomas (4) karyotyped in our laboratory exhibited t(2;3)(q13;p25), which has\nbeen reported previously in thyroid follicular\ntumors, including one with lung metastases (5).\nWe first mapped the 3p25 and 2q13 translocation breakpoints using interphase fluorescence\nin situ hybridization (FISH) (6). The 3p25\nbreakpoint region was narrowed to ;600 kb\nand was bordered by yeast artificial chromosomes (YACs) 753f 7 (telomeric) and 903e6\n(centromeric) (Fig. 1A). Hybridization with\nflanking YACs 753f 7 and 932f 3 confirmed\n3p25 rearrangements in tumor but not normal\ncells (Fig. 1B). The 2q13 breakpoint was localized within overlapping YACs 989f 12 and\n896a8 (Fig. 2A) to a region containing PAX8,\nwhich encodes a paired domain transcription\nfactor essential for thyroid development (7). A\nPAX8-containing bacterial artificial chromosome (BAC), 110L24, crossed the 2q13 breakpoint and cohybridized with 3p25 YAC 753f 7\n(Fig. 2B), consistent with involvement of PAX8\nand a 3p25 partner in the translocation.\nTo identify the 3p25 partner, we performed\nrapid amplification of cDNA ends (RACE) using 59 PAX8 primers (8). Sequence analysis of\nRACE products from t(2;3)-positive follicular\ncarcinomas (8) revealed in-frame fusion of\nPAX8 to the peroxisome proliferator–activated\nreceptor g (PPARg) gene (Fig. 3A). PPARg has\nbeen mapped to 3p25 (9), and a PPARg-containing BAC, 321f 13, crossed the 3p25 breakpoint and cohybridized with 2q13 YAC 989f12\n1Department of Pathology, Brigham and Women’s\nHospital, 75 Francis Street, Boston, MA 02115, USA,\nand Harvard Medical School, Boston, MA 02115, USA.\n2Dana-Farber Cancer Institute and Department of Cell\nBiology, Harvard Medical School, Boston, MA 02115,\nUSA. 3\nDepartments of Pathology and Pediatric Oncology, Children’s Hospital, Boston, MA 02115, USA.\n*To whom correspondence should be addressed. Email: tkroll@rics.bwh.harvard.edu; jfletcher@rics.bwh.\nharvard.edu\nR E P O R T S\nwww.sciencemag.org SCIENCE VOL 289 25 AUGUST 2000 1357", "affiliations": [{"country": "UK", "discipline": "Biology", "university": "University of St. Andrews"}], "species_categories": ["Marine Mammal"], "specialized_species": ["Bottlenose Dolphins"], "computational_stages": ["Data Collection", "Pre-processing", "Meaning Identification"], "linguistic_features": ["Vocal Auditory Channel and Turn-taking", "Discreteness and Syntax", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882734", "updated_at": "2026-01-13T16:23:46.734285", "committed_at": "2026-01-13T16:23:50.826373"}
{"id": "3e8fccbd-75cd-46bb-852c-51b19ba95862", "title": "Receivers respond differently to chick-a-dee calls varying in note composition in Carolina chickadees,  Poecile carolinensis", "authors": ["Freeberg,  Todd M", "Lucas,  Jeffrey R"], "year": "2002", "journal": "Animal Behaviour", "abstract": "", "doi": "10.1006/anbe.2001.1981", "analysis_notes": "ANIMAL BEHAVIOUR, 2002, 63, 837–845\ndoi:10.1006/anbe.2001.1981, available online at http://www.idealibrary.com on\nARTICLES\nReceivers respond differently to chick-a-dee calls varying in note\ncomposition in Carolina chickadees, Poecile carolinensis\nTODD M. FREEBERG & JEFFREY R. LUCAS\nDepartment of Audiology and Speech Sciences\nand\nDepartment of Biological Sciences, Purdue University\n(Received 17 May 2001; initial acceptance 19 September 2001;\nfinal acceptance 30 October 2001; MS. number: A9067)\nThe chick-a-dee call of the avian genus Poecile is a structurally complex vocal system because it possesses\na set of simple rules that governs how the notes of the call are ordered, and variable numbers of each of\nthe note types strung together can generate an extraordinary number of unique calls. Whereas it has been\nhypothesized that chick-a-dee calls with different notes may convey different information, no experimental evidence has been offered in support of the hypothesis. Previously published studies suggested\nthat flock members use chick-a-dee calls in the context of moving to or from a feeding site. Here, we\ntested Carolina chickadees’ responses to playbacks of chick-a-dee calls that differed in note composition.\nPlaybacks were conducted in the field in the context of a novel food source. Our pilot data had indicated\nthat chick-a-dee calls with relatively large numbers of ‘C’ notes were given by birds on their first contact\nwith a novel seed stand. In the present study, we found that chickadees flew in close to the playback\nspeaker and subsequently took seed from a seed stand more often during playbacks of chick-a-dee calls\ncontaining C notes than chick-a-dee calls not containing C notes or than control playbacks. Vocal\nresponses of chickadees to the playbacks also differed in relation to the particular vocal signal being\nplayed back. These results indicate that receivers respond differently to chick-a-dee calls containing\ndifferent compositions of note types and represent a first step to link variation in note composition and\nordering in these calls to possible meanings.\n 2002 The Association for the Study of Animal Behaviour. Published by Elsevier Science Ltd. All rights reserved.\nVocal communication is important to maintaining social\norganization in many vertebrate species. Vocalizations\nthat notify group members (i.e. receivers of the signal) of\ngroup movement, a located predator, or a found food\nsource may be of adaptive value. This is particularly true\nfor species in which a group’s members are at times out of\nvisual contact with one another while they move through\nthe physical environment. Certain vocal signals in several\navian and mammalian species have been shown to be\nassociated with the presence and type of predator or food\n(Seyfarth et al. 1980; Dittus 1984; Gyger et al. 1987;\nMacedonia & Evans 1993; Evans & Marler 1994; Evans\n1997; Evans & Evans 1999). In the majority of these cases,\nthe animals possess distinct vocal signals within their\nrepertoires that are context specific.\nIn many other species, individuals communicate with\nparticular systems of calls that vary in the presence\nand/or number of note types that make up the calls. In\nsome species in which a single call system shows a high\ndegree of acoustic variability, there is an underlying\nstructure, a simple syntax governing the order of the\nunits, to that call system (Marler 1977). The most complex example of syntax governing a vocal system is, of\ncourse, human language. The rules that govern syntax in\nhuman languages result in a system that is functionally\nopen-ended (it shows ‘productivity’, Hockett 1960). Vocal\nsystems that are virtually open-ended due to simple\nordering rules have been documented in a number of\navian and nonhuman primate species and may provide\nclues to the evolution of systems of complex signals and\nperhaps human language (Snowdon 1990, 1993; Evans &\nMarler 1995; Ujhelyi 1996, 1998).\nIn avian species of the genus Poecile, a single call type,\nthe chick-a-dee call, is highly variable but possesses ordering rules that govern the sequences of note types in the\nCorrespondence: T. M. Freeberg, Department of Biological Sciences,\nLilly Hall, Purdue University, West Lafayette, IN 47907, U.S.A.\n(email: freeberg@bilbo.bio.purdue.edu).\n0003–3472/02/$35.00/0  2002 The Association for the Study of Animal Behaviour. Published by Elsevier Science Ltd. All rights reserved.\n837call (Hailman 1989). The ordering rules are particularly\nwell described in the black-capped chickadee, Poecile atricapilla, where there tend to be four major note types (A, B,\nC and D) that may or may not be present in a given\nchick-a-dee call and that, if present, can occur once or\nseveral times (Hailman & Ficken 1986). These four note\ntypes obey a general Markovian ordering rule, with highfrequency A notes virtually always coming first and\nlower-frequency D notes, if they occur, virtually always\ncoming last in the call. B notes, if they occur, tend to\nfollow A notes and to precede D notes, and C notes, if\nthey occur, may occur alone or follow A notes or precede\nD notes. Because chick-a-dee calls are combinatorial,\nconforming to these basic ordering rules (while being\nhighly variable), Hailman and colleagues have argued\nthat the calls theoretically could convey a very large\namount of information (Hailman et al. 1985, 1987).\nWhereas chick-a-dee calls theoretically could convey a\nlarge amount of information, little experimental evidence\nto date has been offered to confirm or refute this (see also\nSnowdon 1993). Some observational data suggest possible\nvariation in meanings, however. Hurd (1996) found that\nseveral other species (but not chickadees) responded differentially to playbacks of the ‘mobbing’ chick-a-dee\ncall of black-capped chickadees relative to playbacks of\na different chick-a-dee call. Ficken (1981), in a study\nof black-capped chickadees, showed that individuals\nfrequently gave chick-a-dee calls upon finding food at\nfeeders. Although Ficken (1981) did not report the note\ncomposition of the chick-a-dee calls she documented, the\ndata suggested that the calls may have facilitated recruitment of flockmates to the feeder. Gaddis (1985), in a\nstudy of mountain chickadees, P. gambeli, found that the\nchick-a-dee calls given frequently when individuals\narrived in a foraging patch were different in note composition from chick-a-dee calls given when individuals left a\nforaging patch or when individuals were startled. Smith\n(1972) found that different note types within the chicka-dee call of Carolina chickadees were used in different\ncontexts related to flock movement, often when feeding\nstations were nearby. In the present study, we used\nplaybacks of Carolina chickadee chick-a-dee calls varying\nin note composition to test whether different variants\nof the calls resulted in different behavioural responses of\nreceivers.\nThe chick-a-dee call in Carolina chickadees is similar to\nthat described above for black-capped chickadees, and\nhas been discussed by Smith (1972) as being produced in\na variety of social contexts. The call is typically composed\nof relatively high-frequency A notes (‘high-see’, ‘hightee’, and related notes in Smith 1972; see also Hailman\n1989), occasionally followed by a single B note (variants\nof ‘high-tee’ note) or by one or more structurally complex\nC notes (‘chick’ notes), and concluded with lowerfrequency D notes (‘dee’ notes). There is great variation\nin the number and even presence of each note type in\nthe chick-a-dee calls of Carolina chickadees, although\nas is the case for black-capped chickadees (see Hailman\net al. 1987), the ordering of note types in chick-a-dee\ncalls virtually always follows an A–B–D or A–C–D pattern\n(Fig. 1).\nIn a pilot study, conducted in central Indiana, we\nanalysed a small number of chick-a-dee calls recorded\nfrom Carolina chickadees as they initially arrived at\nfeeding stations, and we found that a high proportion of\nthese calls contained C notes (either with or without D\nnotes following). Because C notes are less common than\nA and D notes in the chick-a-dee calls of this population\n(unpublished data), we hypothesized that these ‘C-rich’\nchick-a-dee variants may: (1) signal increased arousal on\nthe part of the producer in the context of a novel and\nnonthreatening environmental stimulus, or (2) be associated with the presence of food items in the environment.\nIn either case, we predicted that in playback studies,\nCarolina chickadee receivers that heard any chick-a-dee\ncall variant would respond by approaching and investigating the area of the playback speaker. However, we\npredicted that the receiver would take seed from a novel\nseed stand more often in response to ‘C-rich’ calls than\nwould birds hearing alternative chick-a-dee calls or other\nvocalizations.\nMETHODS\nRecordings\nIn the present study, we tested this hypothesis for C\nnotes in chick-a-dee calls using playbacks at several sites\ncontaining a novel seed stand. The playbacks included\nvariants of chick-a-dee calls with C notes (‘C-rich’ calls)\nand chick-a-dee calls without C notes (‘long-D’ calls). As a\ncontrol for playbacks of chick-a-dee calls, we included in\nthe playback design variants of the ‘gargle’ vocalization of\nCarolina chickadees. The gargle is distinct from the chicka-dee call, but has a similar frequency range and pattern\nof high-frequency notes at the onset followed by notes\ngenerally decreasing in frequency over the course of the\nvocalization (Ficken et al. 1978; collectively also called\n‘T-slinks’ and ‘click-rasps’ in Carolina chickadees, Smith\n1972). As a control for playing back vocal signals of\nCarolina chickadees, we also played back a heterospecific\nvocalization, the ‘quank’ call of the white-breasted nuthatch, Sitta carolinensis, a species that commonly occurs\nwith chickadees in multispecies flocks in central Indiana.\nAs a control for playing back avian vocal signals in\ngeneral, we also used a ‘blank’ playback, which was no\nplayback whatsoever.\nCarolina chickadee vocalizations used for playbacks\nincluded six chick-a-dee calls containing C notes (C-rich),\nsix chick-a-dee calls without C notes but with several D\nnotes (long-D) and six gargles, often used by this species\nin agonistic interactions (Smith 1972). We recorded each\nof these vocalizations in an indoor aviary to minimize\nnoise and reverberation and to standardize recording\nconditions across calls. During recording, we housed\nchickadees individually in separate 1-m 3 cages, but birds\ncould hear other chickadees housed in the same room\nand in adjoining rooms. Each vocalization was recorded\nfrom a chickadee with a Saul Mineroff directional electret\nmicrophone, placed within 1 m of the bird, on Maxell\nXLII tape using a Marantz PMD 222 portable cassette\nrecorder. We obtained the six C-rich and six long-D calls\n838 ANIMAL BEHAVIOUR, 63, 5from five adult male and one adult female Carolina\nchickadee (we determined sex by wing chord according to\nknown distributions from the population; Thirakhupt\n1985). We obtained the six gargles from three adult male\nchickadees; and the six heterospecific quank calls from\nfour nuthatches (one male and one female accounted for\nfour of the quanks; the other two were recorded from the\nfield within 1 m and with the same recording equipment,\nand the sex of the caller was not documented at the time\nof the recording). Sonagrams of the vocalizations used in\nthe playbacks are displayed in Fig. 1.\nAll of the vocalizations were obtained from birds from\nthe Ross Biological Reserve, or, in the case of two of the\nnuthatches, the Martell Forest Reserve, two forest tracks\nlocated approximately 20 km west of Purdue University’s\ncampus. This area is near the northern edge of the\nCarolina chickadee’s range and the southern edge of the\nblack-capped chickadee’s, with whom it shares some\nsimilarities in plumage, morphology and behaviour. We\nconfirmed species identity using differences in size (see\nMerritt 1981; Thirakhupt 1985) and characteristics of\nterritorial songs and chick-a-dee calls (Ficken et al. 1978);\nthe birds of the present study produced songs and chicka-dee calls characteristic of Carolina chickadees.\nPlaybacks\nAs a first attempt to test for differences in behavioural\nresponses of receivers hearing chick-a-dee calls of different note compositions, we chose to use unmanipulated\ncalls. The recorded calls used as playbacks were digitized\nusing the Cool Edit sound analysis program (version 96,\nusing a sampling rate of 22 050 at 16-bit resolution). We\nthen recorded the vocalizations onto endless loop tapes\n(TDK EC-3M) or onto nonloop tapes (Maxell UR60) with\na Marantz PMD 222 portable cassette recorder. The vocalizations were recorded onto the tapes at a rate of six\nvocalizations/min, at roughly one vocalization every 10 s.\n0.5\nTime (s)\n0.0\n0\n10\n5\n0.25\nQuank 6 (3m)Gargle 6 (7m)Long-D 6 (6f = abddddd)C-rich 6 (6f = accdd)\n1.50.0 0.5 1.0\nQuank 5 (2f)Gargle 5 (2m)Long-D 5 (5m = aadddd)C-rich 5 (5m = acccc)\nQuank 4 (4?)Gargle 4 (7m)Long-D 4 (4m = aaaddddddd)C-rich 4 (4m = accccddd)\nQuank 3 (3m)Gargle 3 (5m)Long-D 3 (5m = aaddddd)C-rich 3 (3m = acccccd)\nQuank 2 (2f)Gargle 2 (2m)Long-D 2 (2m = adddddd)C-rich 2 (2m = acccddd)\nQuank 1 (1?)Gargle 1 (5m)Long-D 1 (1m = aabdddddd)C-rich 1 (1m = accccccdd)\nFrequency (kHz)\nFigure 1. Sonagrams of the Carolina chickadee C-rich chick-a-dee calls, long-D chick-a-dee calls and gargles, and white-breasted nuthatch\n‘quank’ calls used as playbacks. The Y axis represents the same frequency range (0–10 000 Hz) in each figure. The X axis for each figure\nindicates time: C-rich, long-D and gargle sonagrams are all represented on a 1.5-s scale; nuthatch quank vocalizations are represented on a\n0.5-s scale. In parentheses above each call are the birds’ sex (m=male, f=female, ?=unknown) and ID numbers, and for the C-rich and long-D\ncalls, the note compositions of the calls. Sonagrams were generated with Cool Edit using the Blackman–Harris windowing function with a\nresolution of 128 bands.\n839FREEBERG & LUCAS: RESPONDING TO CHICK-A-DEE CALLSWe attempted to sample the variation in C-rich and\nlong-D chick-a-dee calls in choosing our playback sample,\nwhile balancing recording quality of the calls. We generated six sets of playback calls, with each set played back at\ntwo different sites (see below). In each set, we paired the\nC-rich and long-D calls by overall number of notes: in\neach pair, calls had to possess the same overall number of\nnotes to within a two-note difference. It should be noted,\nhowever, that controlling for number of notes in the calls\nresulted in the long-D calls being longer in duration than\nthe C-rich calls, as D notes are longer in duration than C\nnotes (Fig. 1). We tried to control for the possibility of\ndifferential dominance status of the birds from which we\nobtained the recordings by pairing C-rich and long-D\ncalls from the same bird within each playback set. Five of\nthe six playback sets contained C-rich and long-D calls\nrecorded from the same individual (Fig. 1).\nWe tested the playback types at 12 sites in the Ross\nBiological Reserve and Ross Hills County Park, West\nLafayette, Indiana (which is adjacent to the Ross Biological Reserve) from 18 March to 6 May 2000. These two\nforest tracts combined comprise approximately 90 ha of\nlargely mature Quercus–Carya forest (Von Culin & Lindsey\n1973) surrounded by farms, disturbed forests and the\nWabash River. To increase our chances of playing back\ncalls to different flocks and to ensure that each site was\nlargely independent, we established the 12 playback sites\nso that each site was separated from the next closest site\nby at least 250 m. In support of our contention that these\ndistances between playback sites resulted in reasonable\nindependence between sites, of 11 banded Carolina\nchickadees observed during the playbacks at six different\nsites, we observed 10 only at one site and the 11th at two\ndifferent sites (we observed only unbanded chickadees at\nthe other six sites).\nWe tested each playback type (C-rich, long-D, gargle,\nnuthatch and blank) once at each playback site, with at\nleast 4 days separating consecutive playbacks at the same\nsite. The total study was comprised of five rounds: one\nplayback at each site per round. We randomized presentation of playback types except for the fact that we\nbalanced the five playback types across rounds, such that\nonly two or three of each type occurred within a round.\nFor example, the first round contained two C-rich, three\nlong-D, two gargle, three nuthatch and two blank playbacks. Over the course of the study across the 12\nsites, each individual playback variant was used at two\ndifferent sites.\nWe conducted the playback trials between 0830 and\n1330 hours Eastern Standard Time. Before each playback,\nwe gathered 10 min of preplayback data on vocalizations\nheard at the playback site. We played back each call type\nwith a Marantz PMD 222 portable cassette recorder\nthrough a Saul Mineroff Electronics powered speaker.\nPlayback trials lasted 60 min and were broken into six\n10-min blocks. Each of these 10-min blocks was made up\nof 3 min of playback of the vocalization (or blank) being\ntested that morning, followed by 7 min of silence.\nApproximately 5 min before collecting preplayback data,\nwe placed a seed stand (post=2 m high, seed tray=10 cm\ndiameter) into the ground and placed a playback speaker\nwithin 1 m of the seed stand (we either hung the speaker\nfrom a tree or placed it on a 1.5-m-high stand). After the\n10-min preplayback observation period, we filled the seed\ntray with sunflower seeds, and began the 60-min playback period. The observers conducted the playbacks while\nseated and motionless from behind a tree or vegetation,\n10–12 m from the playback speaker. We collected the\nseed and removed the seed stand from the site after each\nplayback was finished.\nData Collection and Analyses\nWe collected data on the following:\n(1) Number of sites at which at least one Carolina\nchickadee approached to within 20 m of playback speaker\nand the number of different Carolina chickadees to arrive\nwithin 20 m of the playback speaker. We were able to\ndetermine the number of chickadees to approach unambiguously for some of the sites where most of the birds\nto approach the speaker were banded. At the sites where\nthe birds were unbanded, given that birds would sometimes approach the speaker and then leave for several\nminutes before again approaching the speaker, we chose\nto be conservative and only counted more than one\nchickadee when we saw two or more birds in the area\nsimultaneously.\n(2) Taking seed from the seed stand: a Carolina chickadee landed on the seed stand, took a seed, and ate it there\nor flew off with it to eat or cache it elsewhere.\n(3) First-approach vocal response: the first time a Carolina chickadee approached to within 10 m of the playback speaker during a playback, we documented the vocal\nbehaviour of that bird in the next 1-min period.\n(4) Total vocal production: during the entire 60-min\nplayback period (60 1-min bins of data), we documented\nevery chick-a-dee, gargle and fee-bee-fee-bay (the territorial song of the species, Smith 1972) we were able to\nhear, regardless of the distance from the playback site.\nIn our analyses of receivers approaching to within 20 m\nof the playback speaker and taking seed from the seed\nstand, our dependent variable was dichotomous (yes\nversus no; take versus no-take). To test whether birds\nresponded differently by playback type for these variables, we used the Cochran Q test, a nonparametric test\nfor categorical data for more than two related samples\n(see Siegel & Casetellan 1988). When we detected a\nsignificant effect of playback type on chickadees’\nresponses, we used the McNemar change test to determine whether there were differences between the C-rich\nplaybacks and the other playbacks (Siegel & Castellan\n1988). To test whether the number of birds to approach\nwithin 20 m was affected by playback type, we used the\nFriedman two-way analysis of variance (ANOVA) by\nranks. We used site as the repeated measure for these\ntests, as well as for the vocal response tests described\nbelow, under the assumption that the response to\nrepeated playbacks at each site should be more strongly\ncorrelated than playbacks at different sites. Note, however, that there is some pseudoreplication in this analysis,\nbecause we used each of the six unique sets of playbacks\nat two different sites.\n840 ANIMAL BEHAVIOUR, 63, 5To normalize residuals from the data for the firstapproach vocal responses in the ANCOVA models, we\nlog-transformed (log (n+1)) the number of chick-a-dees\nand fee-bee-fee-bays and double-log-transformed (log(log(n+1))) the number of gargles given in response to the\nplayback types. For the total vocal production data (all\nvocalizations recorded during the 60-min of playback\nobservation), we double-log-transformed the data to\nobtain normal distributions of residuals. These transformations were needed because the distribution of number\nof calls was highly skewed. We used repeated measures\nanalysis of covariance (ANCOVA) with first-order autoregressive covariance structure (Proc Mixed; SAS Institute\n1994) to test for differences in vocalization rates between\nsites. Finally, when significant results were detected for\nfixed effects of playback type with ANCOVAs using the\nmixed procedure in SAS, we performed multiple contrasts\ncomparing the C-rich playbacks to the other four playback types. In the Results section, we report only significant contrasts (at P≤0.05).\nRESULTS\nBirds Approaching the Playback Speaker\nThe probability that at least one Carolina chickadee\nreceiver approached within 20 m of the playback speaker\nvaried significantly with playback type (Fig. 2a; Cochran\nQ test: \u00012\n4 =12.97, two-tailed P<0.05). Contrasts of the\nresponses to C-rich playbacks compared with the other\nplaybacks indicated that birds approached to within 20 m\nat more sites to playbacks of C-rich calls than to playbacks\nof nuthatch quank calls (McNemar change test: \u00012\n1 =6.13,\ntwo-tailed P<0.05). None of the other contrasts was significantly different. The number of different individuals\nto approach within 20 m of the playback speaker was\nmarginally dependent upon the playback type, but was\nnot statistically significant (Fig. 2b: Friedman repeated\nmeasures ANOVA on ranks: \u00012\n4 =8.38, NS).\nWe detected no effect of playback type on the latency\nwith which Carolina chickadees approached to within\n20 m of the playback speaker (F4,13 =0.52, P=0.72), or to\nwithin 10 m of the playback speaker (F4,9 =0.40, P=0.80).\nWe also detected no effect of playback type on the\npreplayback rates of vocalizing. For rates of vocalizing\nover the 10-min interval before each playback, we could\nnot detect any effect of playback site on the total vocal\nproduction data (F4,44 =0.78, P=0.54). Thus, even though\nCarolina chickadees tended to be more active in general\nat some sites relative to others (see Discussion), any\npossible site differences did not appear to affect our\nplayback results.\nTaking Seed from the Seed Stand\nThe probability that chickadees took seed from the\nnovel seed stands varied with playback type (Fig. 2c;\nCochran Q test: \u00012\n4 =18.53, two-tailed P<0.01). Chickadees\ntook seed from the seed stand more often at sites during\nplaybacks of C-rich calls (7 of the 12 sites)\nthan during playbacks of long-D calls (0 of the 12 sites;\nMcNemar change test, \u00012\n1 =5.14, two-tailed P< 0.05). None\nof the other contrasts differed significantly. Carolina\nchickadees took no seed during any playback at five of\nthe playback sites. However, birds approached to within\n10 m of the playback speaker during at least one of the\nplaybacks at every site.\nFirst-approach Vocal Responses\nThe first time an individual Carolina chickadee\napproached to within 10 m of the playback speaker, the\nvocal behaviour it gave in the next 1-min time period\ndepended upon the playback type (F4,7 =7.13, P=0.013).\nHowever, the response to C-rich calls was not statistically\ndifferent from the response to long-D calls for this\nresponse variable. Contrast analyses indicated that receivers produced significantly more chick-a-dees during\n0\n12\nPlayback type\n(c)\nBlank Nuthatch Gargle Long-D C-rich\n8\n4\n0\n4\n(b)\nNumber of 3\n1\n0\n12\n(a)\n8\n4\n2\nPlayback sites chickadees Playback sites\nFigure 2. Behavioural responses of chickadee receivers approaching\nthe playback speaker and taking seed from seed stand, as a function\nof playback type. (a) Number of playback sites at which at least one\nchickadee approached within 20 m of the playback speaker. (b)\nAverage (±SD) number of chickadee receivers to approach within\n20 m of the playback speaker across the 12 playback sites\n(m=median number). (c) Number of playback sites at which at least\none chickadee took seed from the seed stand.\n841FREEBERG & LUCAS: RESPONDING TO CHICK-A-DEE CALLSblank and nuthatch playbacks than during C-rich playbacks (Fig. 3a; blank: F1,7 =8.67, P=0.022; nuthatch:\nF1,7 =6.94, P=0.034). Furthermore, receivers produced\nsignificantly more chick-a-dees during C-rich playbacks\nthan during gargle playbacks (Fig. 3a; F1,7 =6.61,\nP=0.037). There was a significant effect of playback type\non fee-bee-fee-bay rates in the first-approach vocal\nresponse data (F4,7 =4.63, P=0.038). Contrast analyses\nindicated that playbacks of gargles evoked significantly\nmore fee-bee-fee-bays than did playbacks of C-rich calls\n(Fig. 3b; F1,7 =14.94, P=0.006). The rate at which\napproaching chickadees produced gargles was unaffected\nby playback type (Fig. 3c; F4,7 =0.75, P=0.590).\nThe time of day at which each playback was started was\nfound to have a significant effect on the chick-a-dee rates\nof receivers (F1,11 =5.35, P=0.04). Carolina chickadees\ngave fewer chick-a-dees in their first-approach vocal\nresponses the later in the morning the playback test\nbegan, across all playback types.\nTotal Vocal Production\nAs was the case with first-approach vocal responses, the\nplayback type affected total vocal production during\nthe entire 60-min playback interval. We found significant\neffects of playback type on chick-a-dee rates (F4,43 =4.72,\nP=0.003) and on fee-bee-fee-bay rates (F4,43 =6.42,\nP=0.001). However, unlike the first-approach vocal\nresponses, the chickadees’ vocal response to C-rich calls\ndiffered significantly from their response to long-D calls.\nContrast analyses for chick-a-dee responses in the total\nvocal production data indicated that chickadees produced more chick-a-dees during playbacks of C-rich calls\nthan during the four other playback types (Fig. 4a; blank:\nF1,43 =6.29, P=0.016; nuthatch: F1,43 =17.74, P=0.0001;\ngargle: F1,43 =5.82, P=0.020; long-D: F1,43 =9.29, P=\n0.004). Contrast analyses for fee-bee-fee-bay responses\nindicated that fee-bee-fee-bays were given to playbacks of\ngargles more often than to C-rich playbacks (Fig. 4b;\nF1,43 =11.12, P=0.002). We found no effect of playback\ntype on gargle rates, as was the case for the first-approach\nvocal responses (Fig. 4c; F4,43 =1.44, P=0.236).\n0\n12\nPlayback type\n(c)\nBlank Nuthatch Gargle Long-D C-rich\n8\n4\n0\n12\n(b)\nVocalizations (N/min)\n8\n4\n0\n12\n(a)\n8\n4\nFigure 3. First-approach vocal responses: the vocal rates of Carolina\nchickadees in the 1-min period following the first time a bird approached within 10 m of the playback speaker during a playback trial.\nLeast squares means (+SD) for (a) chick-a-dee, (b) fee-bee-fee-bay and\n(c) gargle calls. To generate the figures, data were backtransformed\nfrom the repeated measures ANCOVA models (see text).\n0\n30\nPlayback type\n(c)\nBlank Nuthatch Gargle Long-D C-rich\n20\n10\n0\n30\n(b)\nVocalizations (N/h)\n20\n10\n0\n30\n(a)\n20\n10\nFigure 4. Total vocal production: the vocal rates of Carolina chickadees across each entire 60-min playback trial. Least squares means\n(+SD) for (a) chick-a-dee, (b) fee-bee-fee-bay and (c) gargle calls. To\ngenerate the figures, data were backtransformed from the repeated\nmeasures ANCOVA models (see text).\n842 ANIMAL BEHAVIOUR, 63, 5DISCUSSION\nThe social organization of Carolina chickadees changes\nfrom a male and female pair defending a territory during\nthe breeding season to typically two or more pairs of\nunrelated males and females forming a flock and defending a joint territory during the autumn and winter\nmonths (Brewer 1961; Ekman 1989; Hogstad 1989;\nMatthysen 1990). Among several potentially adaptive\nreasons for forming flocks, the greater numbers of individuals may increase the possibility of detecting food\nresources on the flock’s territory (Lucas et al. 1999). For\nthis to be true, an individual locating a novel food source\nwould need to be able to communicate some information\nto flockmates. One of the most efficient means of communicating over potentially large distances and out of\nvisual contact is through acoustic signalling (Bradbury &\nVehrencamp 1998). Previous work with different species\nof chickadees suggested the possibility that different variants of the chick-a-dee vocal system might be associated\nwith the presence of different environmental stimuli or\nmotivational states of the signaller (Smith 1972; Gaddis\n1985; Ficken et al. 1994). In the present study, the\nnumber of sites at which Carolina chickadees approached\nwithin 20 m of the playback speaker was dependent upon\nthe type of call being broadcast, with calls containing C\nnotes (C-rich calls) eliciting approach more often than\nany other call type. Birds subsequently took seed from\nseed stands during playbacks of C-rich calls more often\nthan they did during playbacks of chick-a-dee calls that\ndid not contain C notes (long-D calls). Indeed, across the\n12 playback sites, Carolina chickadees never took a seed\nfrom the seed stand during a playback of a long-D call.\nIn addition to the data on taking seeds, we found\nresponse differences between C-rich and long-D chick-adee playbacks in the total vocal production data. We\nobserved more chick-a-dee calls during the 60-min playback trial when the playback was a C-rich call than when\nit was any other playback type. A possible explanation for\nthis is that birds approaching the playback speaker closely\nin response to C-rich playbacks, and subsequently taking\nseed, tended to return again and again to the stand. Thus,\nthe observed increased chick-a-dee rates to C-rich call\nplaybacks may have been a consequence of slightly more\nchickadees in the area (although we did not detect significant differences among playback types for the number of\nbirds approaching the playback speaker). Taken together,\nthe data on taking seed and total vocal production indicate that C-rich and long-D calls produce different vocal\nand approach responses in receivers.\nOne interpretation of our results is that calls containing\nC notes convey some information about the presence of\nfood and that the location of the signaller would provide\ninformation about the location of the food. Thus, the\ncontext in which the signal is given likely is important to\nreceivers as well as the signal itself (Smith 1968; Leger\n1993). The C-rich calls cannot be considered truly referential signals (see Evans 1997), referring exclusively to\nfood, because they are used in nonfood contexts, as are\nother variants of chick-a-dee calls (Smith 1972; Ficken et\nal. 1978; Gaddis 1985). A relatively high number of C\nnotes in a chick-a-dee call may, however, be probabilistically associated with the presence of a rich food resource\nin the environment. Another interpretation of these\nresults is that chick-a-dee calls with a relatively high\nnumber of C notes may signal novelty or a high motivation level on the part of the producer in the context of\na novel but nonthreatening environmental stimulus (a\nlarge amount of seed on the seed stand). In this sense, the\nC-rich calls in the present study would conform to ideas\nabout note composition, motivation and flock member\nmovement conveyed by earlier work with chick-a-dee\ncalls (Smith 1972; Hailman et al. 1985). Indeed, we might\nexpect a call system that exhibits nondiscrete variation\n(such as the chick-a-dee call system, where C-rich calls\ncould contain, for example, 3, 6, or even 10 C notes)\nto convey information about graded changes in the\nmotivation of the producer (Owings & Morton 1998).\nFive of our playback sites occurred within an area of the\nRoss Biological Reserve that has had permanent seed\nstands in place for over a decade, although the specific\nsites we used for our seed stands never had permanent\nseed stands. Carolina chickadees approached and subsequently took seeds during playbacks of C-rich calls at all\nfive of these playback sites, but did so only at two of the\nseven sites not near permanent seed stands. Chickadees\nnever took seed during playbacks of long-D calls, regardless of playback site (note that we played back all five\nplayback types at each of the 12 playback sites). While\nthis is a small sample, the results suggest that C-rich\nchick-a-dee calls may be most effective at producing\nseed-taking behaviour on the part of receivers in contexts\nin which the birds are already used to obtaining seed on\nstands, whereas long-D calls are ineffective at producing\nseed-taking behaviour irrespective of the feeding history\nof the birds in the population.\nIt has been suggested that the ratio of D notes to other\nnote types may convey information in chick-a-dee calls\n(Hailman et al. 1987). In other words, few or no D notes\nmay convey a different meaning to a receiver than would\nmany D notes, regardless of the presence of C notes in the\ncalls. Under this interpretation, playbacks of the C-rich\ncalls at the seed stands, because they had relatively few D\nnotes, may have been acted on by responding individuals\nas a signal indicating a novel but not agonistic context.\nEach of the C-rich and long-D calls (and gargles) were\nprobably perceived by responding individuals as coming\nfrom nonflock members, as all of the playback calls were\nrecorded from individuals that differed from those to\nwhich the calls were played back. Long-D calls may have\nbeen perceived as being aggressive or antagonistic, while\nC-rich calls with few or no D notes may not have been\nperceived as such, and the increased propensity to\napproach the speaker and seed stand may have simply\nbeen an incidental by-product of this. Further work is\nneeded to clarify this issue.\nThis study represents a first step to determine whether\nchick-a-dee calls that vary in note composition have\ndifferent meanings. We have focused on certain chick-adee call variants and possible differences in meaning from\nthe standpoint of the signal receiver, the assessment side\nof the communication system (Owings & Morton 1998).\n843FREEBERG & LUCAS: RESPONDING TO CHICK-A-DEE CALLSFuture work will need to address more closely the management side of the communication system, focusing on\nthe specific contexts in which calls varying in note\ncomposition (such as C-rich or long-D variants) are\nproduced. Furthermore, future work will need to look\nmore closely at how combinations of signals that vary in\nnote composition are used by chickadees in different\ncontexts (see Smith 1991; Leger 1993). It seems possible\nthat both note composition of individual calls and the\nordering of chick-a-dee calls in a calling sequence of a\nbird might depend upon the relationships between the\nsignaller and receivers, as well as upon whether the\ncontexts of the vocalizations were food, a predator, an\naggressive interaction, or the movement of the signaller.\nFor example, in flycatchers in the genus Sayornis, different vocal types are used in different social contexts, and\nthe ‘string lengths’ of vocal types (number of repetitions\nof a particular vocal type before the bird switches to\nanother vocal type) predict a bird’s subsequent behaviour\n(Smith 1969, 1970). Shifts between different vocal types\nare also predictive of behaviour in great crested flycatchers, Myiarchus crinitus (Smith & Smith 1996a, b).\nThe results of the present study support the suggestion\nof Ficken et al. (1994) that contextual differences in\nchick-a-dee call use vary considerably among chickadee\nspecies. In the Mexican chickadee, P. sclateri, birds produce calls with a relatively high number of C notes when\nnear a playback speaker broadcasting predator calls\n(Ficken et al. 1994). Thus, in the Mexican chickadee, C\nnotes appear to be used more in a predator mobbing\ncontext or when the birds are in a disturbed situation.\nHowever, strings of D notes appear to take on those\nfunctions in black-capped chickadees (Apel 1985, cited in\nFicken et al. 1994), and possibly Carolina chickadees (J. R.\nLucas & M. Lorenz, unpublished data). The C note has\nbeen suggested to function in flock movement in blackcapped chickadees (Hailman et al. 1985) and when birds\nleave a foraging patch in mountain chickadees (classified\nas Category II calls containing B elements in Gaddis\n1985). Phylogenies based on mitochondrial DNA comparisons place Carolina chickadees close to the blackcapped chickadee and mountain chickadee clade, and\nmore distantly to Mexican chickadees (Gill et al. 1993).\nThe admittedly small amount of empirical data thus far\nsuggests that note type and context relationships of the\nchick-a-dee call in these four species correlate with these\nphylogenetic differences; more comparative research on\nthis call system in these and other Poecile species is\nneeded to understand these relationships better.\nThe hypothetical amount of information that could\nbe conveyed in the chick-a-dee call system is immense\n(Hailman et al. 1985). This study provides the first experimental data in chickadee species to indicate that chicka-dee calls differing in terms of their note composition\ncan also differ in terms of their meaning to receivers.\nTogether with the question of note composition relationships to possible meanings in chick-a-dee calls, the fact\nthat characteristics of this call system, like human language, are learned (Nowicki 1989; Hughes et al. 1998)\nsuggests that this system may represent an informative\nanalogue to human language.\nAcknowledgments\nWe wish to thank Amber Cicotte, Amanda Jaurige and\nJulia Lapenta for assistance with data collection. This\nstudy was undertaken while T.M.F. was a postdoctoral\nfellow on a National Institutes of Health training grant\nto the Department of Audiology and Speech Sciences\nat Purdue University. We thank Adam Boyko, Janine\nClemmons, James Kellam, Joseph M. Macedonia, Donald\nH. Owings, Meredith J. West and two anonymous referees\nfor helpful comments on the manuscript, and Jessie Mae\nHemphill, Junior Kimbrough and Johnny Shines for helpful advice. The research described here adhered to the\nGuidelines for the Use of Animals in Research of the Association for the Study of Animal Behaviour and the Animal\nBehavior Society, and was carried out under Protocol No.\n00-003 of the Purdue University Animal Care and Use\nCommittee.\nReferences\nBradbury, J. W. & Vehrencamp, S. L. 1998. Principles of Animal\nCommunication. Sunderland, Massachusetts: Sinauer.\nBrewer, R. 1961. Comparative notes on the life history of the\nCarolina chickadee. Wilson Bulletin, 73, 348–373.\nDittus, W. P. J. 1984. Toque macaque food calls: semantic communication concerning food distribution in the environment.\nAnimal Behaviour, 32, 470–477.\nEkman, J. 1989. Ecology of non-breeding social systems of Parus.\nWilson Bulletin, 101, 263–288.\nEvans, C. S. 1997. Referential signals. In: Perspectives in Ethology. Vol.\n12: Communication (Ed. by D. Owings, M. D. Beecher & N. S.\nThompson), pp. 99–143. New York: Plenum.\nEvans, C. S. & Evans, L. 1999. Chicken food calls are functionally\nreferential. Animal Behaviour, 58, 307–319.\nEvans, C. S. & Marler, P. 1994. Food-calling and audience effects in\nmale chickens, Gallus gallus: their relationships to food availability,\ncourtship, and social facilitation. Animal Behaviour, 47, 1159–\n1170.\nEvans, C. S. & Marler, P. 1995. Language and animal communication: parallels and contrasts. In: Comparative Approaches\nto Cognitive Science (Ed. by H. L. Roitblat & J.-A. Meyer),\npp. 341–382. Cambridge, Massachusetts: MIT Press.\nFicken, M. S. 1981. Food finding in black-capped chickadees:\naltruistic communication? Wilson Bulletin, 93, 393–394.\nFicken, M. S., Ficken, R. W. & Witkin, S. R. 1978. The vocal\nrepertoire of the black-capped chickadee. Auk, 95, 34–48.\nFicken, M. S., Hailman, E. D. & Hailman, J. P. 1994. The\nchick-a-dee call system of the Mexican chickadee. Condor, 96,\n70–82.\nGaddis, P. K. 1985. Structure and variability in the vocal repertoire\nof the mountain chickadee. Wilson Bulletin, 97, 30–46.\nGill, F. B., Mostrom, A. M. & Mack, A. L. 1993. Speciation in North\nAmerican chickadees: I. Patterns of mtDNA genetic divergence.\nEvolution, 47, 195–212.\nGyger, M., Marler, P. & Pickert, R. 1987. Semantics of an avian\nalarm call system: the male domestic fowl, Gallus domesticus.\nBehaviour, 102, 15–40.\nHailman, J. P. 1989. The organization of the major vocalizations in\nthe Paridae. Wilson Bulletin, 101, 305–343.\nHailman, J. P. & Ficken, M. S. 1986. Combinatorial animal communication with computable syntax: chick-a-dee calling qualifies\nas ‘language’ by structural linguistics. Animal Behaviour, 34, 1899–\n1901.\n844 ANIMAL BEHAVIOUR, 63, 5Hailman, J. P., Ficken, M. S. & Ficken, R. W. 1985. The ‘chick-adee’ calls of Parus atricapillus: a recombinant system of animal\ncommunication compared with written English. Semiotica, 56,\n191–224.\nHailman, J. P., Ficken, M. S. & Ficken, R. W. 1987. Constraints on\nthe structure of combinatorial ‘chick-a-dee’ calls. Ethology, 75,\n62–80.\nHockett, C. F. 1960. Logical considerations in the study of\nanimal communication. In: Animal Sounds and Communication\n(Ed. by W. E. Lanyon & W. N. Tavolga), pp. 392–430.\nWashington, D.C: American Institute of Biological Sciences\nPublication No. 7.\nHogstad, O. 1989. Social organization and dominance behavior in\nsome Parus species. Wilson Bulletin, 101, 254–262.\nHughes, M., Nowicki, S. & Lohr, B. 1998. Call learning in blackcapped chickadees (Parus atricapillus): the role of experience\nin the development of ‘chick-a-dee’ calls. Ethology, 104, 232–\n249.\nHurd, C. R. 1996. Interspecific attraction to the mobbing calls of\nblack-capped chickadees (Parus atricapillus). Behavioral Ecology\nand Sociobiology, 38, 287–292.\nLeger, D. W. 1993. Contextual sources of information and\nresponses to animal communication signals. Psychological Bulletin,\n113, 295–304.\nLucas, J. R., Schraeder, A. & Jackson, C. 1999. Carolina chickadees\n(Aves, Paridae, Poecile carolinensis) vocalization rates: effects of\nbody mass and food availability under aviary conditions. Ethology,\n105, 503–520.\nMacedonia, J. M. & Evans, C. S. 1993. Variation among mammalian alarm call systems and the problem of meaning in animal\nsignals. Ethology, 93, 177–197.\nMarler, P. R. 1977. The structure of animal communication sounds.\nIn: Recognition of Complex Acoustic Signals (Ed. by T. H. Bullock),\npp. 17–35. Berlin: Dahlem Conferenzen.\nMatthysen, E. 1990. Nonbreeding social organization of Parus. In:\nCurrent Ornithology. Vol. 7 (Ed. by D. M. Power), pp. 209–249.\nNew York: Plenum.\nMerritt, P. G. 1981. Narrowly disjunct allopatry between blackcapped and Carolina chickadees in northern Indiana. Wilson\nBulletin, 93, 54–66.\nNowicki, S. 1989. Vocal plasticity in captive black-capped chickadees: the acoustic basis and rate of call convergence. Animal\nBehaviour, 37, 64–73.\nOwings, D. H. & Morton, E. S. 1998. Animal Vocal Communication:\na New Approach. Cambridge: Cambridge University Press.\nSAS Institute 1994. SAS/STAT Software. Release 6.09 and Release\n6.08 maintenance enhancements for PROC MIXED. Cary, North\nCarolina: SAS Institute.\nSeyfarth, R. M., Cheney, D. L. & Marler, P. 1980. Monkey responses\nto three different alarm calls: evidence of predator classification and\nsemantic communication. Science, 210, 801–803.\nSiegel, S. & Castellan, N. J. Jr 1988. Nonparametric Statistics for the\nBehavioral Sciences. 2nd edn. New York: McGraw-Hill.\nSmith, S. T. 1972. Communication and Other Social Behavior in Parus\ncarolinensis. Cambridge, Massachusetts: Nuttall Ornithological\nClub, Publication No. 11.\nSmith, W. J. 1968. Message-meaning analysis. In: Animal Communication: Techniques of Study and Results of Research (Ed. by T. A.\nSebeok), pp. 44–60. Bloomington: Indiana University Press.\nSmith, W. J. 1969. Displays of Sayornis phoebe (Aves, Tyrannidae).\nBehaviour, 33, 283–322.\nSmith, W. J. 1970. Displays of and message assortment in Sayornis\nspecies. Behaviour, 37, 85–112.\nSmith, W. J. 1991. Singing is based on two markedly different kinds\nof signaling. Journal of Theoretical Biology, 152, 241–253.\nSmith, W. J. & Smith, A. M. 1996a. Playback interactions with great\ncrested flycatchers, Myiarchus crinitus (Aves, Tyrannidae). Ethology,\n102, 724–735.\nSmith, W. J. & Smith, A. M. 1996b. Vocal signaling of the great\ncrested flycatcher, Myiarchus crinitus (Aves, Tyrannidae). Ethology,\n102, 705–723.\nSnowdon, C. T. 1990. Language capacities of nonhuman animals.\nYearbook of Physical Anthropology, 33, 215–243.\nSnowdon, C. T. 1993. A comparative approach to language parallels. In: Tools, Language, and Cognition in Human Evolution (Ed. by\nK. R. Gibson & T. Ingold), pp. 109–128. Cambridge: Cambridge\nUniversity Press.\nThirakhupt, K. 1985. Foraging ecology of sympatric parids: individual and population responses to winter food scarcity. Ph.D. thesis,\nPurdue University, West Lafayette, Indiana.\nUjhelyi, M. 1996. Is there any intermediate stage between animal\ncommunication and language? Journal of Theoretical Biology, 180,\n71–76.\nUjhelyi, M. 1998. Long-call structure in apes as a possible precursor\nfor language. In: Approaches to the Evolution of Language: Social\nand Cognitive Bases (Ed. by J. R. Hurford, M. Studdert-Kennedy &\nC. Knight), pp. 177–189. Cambridge: Cambridge University Press.\nVon Culin, H. J. & Lindsey, A. A. 1973. Two decades of vegetational\nchange in the Ross Biological Reserve. Proceedings of the Indiana\nAcademy of Sciences, 82, 187–197.\n845FREEBERG & LUCAS: RESPONDING TO CHICK-A-DEE CALLS", "affiliations": [{"university": "Purdue University", "country": "United States", "discipline": "Speech Science"}, {"university": "Purdue University", "country": "United States", "discipline": "Biology"}], "species_categories": ["Bird"], "specialized_species": ["Carolina chickadee"], "computational_stages": ["Data Collection", "Meaning Identification"], "linguistic_features": ["Discreteness and Syntax", "Semanticity", "Tradition and Cultural Transmission"], "status": "saved", "created_at": "2026-01-13T12:49:59.882738", "updated_at": "2026-01-13T16:24:41.191005", "committed_at": "2026-01-13T16:24:42.845174"}
{"id": "81edeca9-b19f-495c-ae44-7b0b6d01edcf", "title": "Mobbing calls of black-capped chickadees: effects of urgency on call production", "authors": ["Baker, Myron C", "Becker, April M"], "year": "2002", "journal": "The Wilson Bulletin", "abstract": "", "doi": "", "analysis_notes": "Mobbing Calls of Black-Capped Chickadees: Effects of Urgency on Call Production\nAuthor(s): Myron C. Baker and April M. Becker\nSource:\nThe Wilson Bulletin , Dec., 2002, Vol. 114, No. 4 (Dec., 2002), pp. 510-516\nPublished by: Wilson Ornithological Society\nStable URL: https://www.jstor.org/stable/4164496\nJSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide\nrange of content in a trusted digital archive. We use information technology and tools to increase productivity and\nfacilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.\nYour use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at\nhttps://about.jstor.org/terms\nWilson Ornithological Society is collaborating with JSTOR to digitize, preserve and extend\naccess to\nThe Wilson Bulletin\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/termsWilson Bull., 114(4), 2002, pp. 510-5 16\nMOBBING CALLS OF BLACK-CAPPED CHICKADEES:\nEFFECTS OF URGENCY ON CALL PRODUCTION\nMYRON C. BAKER'\"2 AND APRIL M. BECKER'\nABSTRACT.-Many animals advertise the presence of a predator threat through vocal signals. Black-capped\nChickadees (Poecile atricapilla) use their chick-a-dee call as a mobbing call when encountering a perched hawk\nor owl. This social signal appears to serve as an alert to other chickadees, causing them to rally to the vicinity\nof the predator and join in a chorus of calling. We asked the question: do chickadees vary the mobbing call in\na manner that could convey the immediacy of threat from a potential predator? We examined the responses of\nchickadees to a taxidermic mount of an avian predator presented at distances of I m and 6 m from each subject.\nVocal responses were recorded and analyzed for response latency, calling rate, and syllable composition of calls.\nDuring 5-min trials, the subjects responded more quickly and produced significantly more chick-a-dee calls for\npredator presentations at the 1-m distance than at the 6-m distance. Alterations of syllable composition of the\ncall also were observed under the two treatments. These results suggest that information about the immediacy\nof threat or proximity of a predator may be signaled by alteration of the rate of calling, with possible additional\ninformation contained in proportional changes in the different syllable types of the call. Studies of referential\n(symbolic) communication in birds and mammals often have failed to consider the problem of response urgency\nseparately from predator-type labeling in vocal signal design. Received 14 June 2002, accepted 16 October 2002.\nThe antipredator vocal signaling behavior\nof birds and mammals offers important re-\nsearch opportunities in the functional analysis\nof animal communication systems. Observa-\ntions of the utterances of warning calls or\nmobbing calls in the presence of predators\nraises questions about the nature of the infor-\nmation content of such vocal signals. If a vo-\ncalization contains variations that inform re-\ncipients about environmental events, such as\nthe presence of a predator, the signal is ref-\nerential (Evans 1997). Mammalian studies, es-\npecially of primates, call our attention to ques-\ntions about the cognitive processes involved\nin signals that employ acoustically distinct,\npredator-type-specific calls (Seyfarth et al.\n1980, Macedonia 1990, Zuberbuhler 2000,\nManser 2001, Fichtel and Kappeler 2002).\nThe difficulty in obtaining unequivocal evi-\ndence for representational cognition in anti-\npredator signaling has led to the notion of\n\"functional reference,\" which directs efforts\ntoward issues that are possible to address by\nexperimental approaches (Marler et al. 1992,\nEvans 1997). The concept of functionally ref-\nerential communication causes one to examine\nbehavioral response to vocal signals, testing\nthe hypothesis that the signals encode infor-\nmation about environmental events, whether a\nresponse to the signal is mediated by internal\nrepresentation or not (Marler et al. 1992).\nA problem often arising in the interpreta-\ntions of predator signaling is the discrimina-\ntion of predator class labeling from the im-\nmediacy of the predation threat. Two different\nkinds of signals might be used by small birds:\none for a raptor circling overhead and a dif-\nferent one for an approaching fox, but these\ntwo kinds of predators differ also in the ur-\ngency of response required of the prey. Few\nstudies have examined the possible separate\neffects of predator type and response urgency\n(Pereira and Macedonia 1991, Manser 2001).\nMarler et al. (1992) cast the issue in an im-\nportant light by arguing that antipredator calls\nusually will contain both motivational (e.g.,\nurgency) information as well as information\nabout kind of predator stimulus, with the rel-\native amounts of the two types of information\nlying on a continuum.\nIt was this latter hypothesis that led us to\nthe present study. Well described in the liter-\nature is the variable call of the Black-capped\nChickadee (Poecile atricapilla), the familiar\nchick-a-dee call, from which the species gets\nits common name. This call is multifunctional,\ncontaining information on flock identity, pop-\nulation identity, and location, but it also\nserves as a predator mobbing call (Ficken et\nal. 1978, Apel 1985, Smith 1991, Ficken and\n' Biology Dept., Colorado State Univ., Fort Collins,\nCO 80523, USA.\n2 Corresponding author; E-mail:\nmcbaker@ lamar.colostate.edu\n510\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/termsBaker and Becker * CHICKADEE MOBBING CALLS 511\n101 AKBC C C: C S1D\n10-~-\n0.5s\nFIG. 1. This chick-a-dee call of the Black-capped Chickadee illustrates the four types of syllables (A, B, C,\nD) usually contained in the call. Each type of syllable can vary in number and this was quantified in calls given\nby subjects when stimulated by a mount of a Prairie Falcon presented at I m and 6 m distances.\nPopp 1996, Hurd 1996). During mobbing\nevents, chick-a-dee calls are produced as one\nor more birds approach a predator in a gradual\nmanner, with frequent changes of position,\nand sometimes attack and dive at the predator,\nwhich may induce it to move. Other conspe-\ncifics as well as other species are attracted to\nthe site of mobbing. This \"harassment\" func-\ntion of mobbing calls has been noted in nu-\nmerous species of birds (Klump and Shalter\n1984, Ficken and Popp 1996).\nThe chick-a-dee call seems well designed\nfor many functions, at least potentially, be-\ncause the acoustic units that constitute the\nwhole call, the syllables or notes, can combine\nin various ways numerically to form a very\nlarge set of different call types. Although vir-\ntually all chick-a-dee calls observe the se-\nquential delivery of the four types of syllable\nin the most complete form of the call (syllable\nsequence A-4B->C->D; Fig. 1), one or more\nsyllable types can be deleted, or produced in\ndiffering numbers, indicating a combinatorial\nsignal that has been likened to syntax struc-\ntures in written language in which letters are\nrecombined to form a variety of different\nwords (Hailman et al. 1985). Therefore, such\na variably structured signal as the chick-a-dee\ncall encourages one to look for properties of\nthe call that convey different messages. Spec-\nulations have been advanced (Hailman et al.\n1987) that each of the four kinds of syllables\nmay signal different tendencies for movement.\nOur study reported here was a first step simply\nto determine if the chick-a-dee call was broad-\ncast with differing rates or the syllable com-\nposition altered in response to predator stim-\nulation that differed only in the urgency of the\nthreat, as indicated by a potential predator pre-\nsented at two different distances from sub-\njects.\nMETHODS\nWe obtained Black-capped Chickadees by trapping\nin natural populations occupying the riparian habitat\nzone of the Cache La Poudre River (40? 36' N, 1050\n05' W) near Fort Collins, Colorado, between 4 No-\nvember 2001 and 7 February 2002. During this period,\nwe brought a few birds at a time into the laboratory,\nheld them for approximately one week during testing,\nand then released them at the site of capture. At the\ntime of capture, we aged the birds by the distribution\nof the white band on the outer rectrices (Pyle et al.\n1987), which we have found to correlate well with the\ndegree of skull ossification in early and late fall ju-\nveniles. We banded the subjects for individual recog-\nnition, held them in individual cages (46 cm long, 22\ncm wide, 26 cm high) in a common room on natural\nphotoperiod, and fed them sunflower seeds and turkey\nstarter daily.\nWe conducted stimulus presentations in a large\nroom with the subject in its cage positioned in a sound\nattenuated box 90 cm above the floor. One side of the\nbox was open and facing a table on which a cardboard\nbarrier prevented the subject from seeing the stimulus\nlocated immediately behind the barrier. With a subject\non its perch in the cage, the base of the stimulus object\nwas 7 cm above the subject when in view. For the near\npresentation, we presented the stimulus at a distance\nof I m from a subject's cage, and for the far presen-\ntation, the table was moved across the room so the\nstimulus was 6 m from a subject's cage. A microphone\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/terms512 THE WILSON BULLETIN * Vol. 114, No. 4, December 2002\nwas located near the subject's cage and recorded all\nvocalizations.\nA trial consisted of transporting (<30 s) the subject\nin its home cage from the holding room to the test\nchamber, one of us taking a position out of sight of\nthe subject to later present the stimulus, and the other\nof us operating the recorder and timing the trial. A trial\nlasted 5 min. We waited to begin a trial until the sub-\nject started to move about in its cage, hopping between\nperches or eating a sunflower seed, which usually took\nfrom 0-4 min. Upon this movement, the tape recorder\nwas activated and one of us pulled a string that slowly\nmoved the stimulus from behind the cardboard barrier\ninto full view of the subject. Beginning when the sub-\nject gave its first vocalization we recorded calls for 5\nmin. Our data thus consisted of 5 min of vocalizations\nof a subject recorded on one day at one distance to the\nstimulus and 5 min of vocalizations recorded on the\nnext day at the other distance. We tested half the birds\n(n = 12) first at the I m distance and half (n = 12)\nfirst at the 6 m distance.\nThe predator stimulus was a taxidermic mount of a\nPrairie Falcon (Falco mexicanus) in a natural upright\nposture as if perched on a branch. Its head was turned\ntoward the cage of the subject so that its face was fully\nobservable. This is a common predator of small birds\n(Skinner 1938, Bailey and Niedrach 1965) and is seen\nfrequently in the habitats of chickadees in our study\narea, perched on the buildings and in trees on the cam-\npus of the university, and on other commercial build-\nings in Fort Collins.\nWe collected an additional data set on eight other\nchickadees acting as controls for the presentation of\nthe stimulus. We tested these birds at the 1 m distance\nwith the Prairie Falcon and a block of wood of the\nsame size as the predator mount. Four subjects first\nwere presented with the wood block on one day and\nthe predator on the next day, with the reverse order for\nthe other four subjects. This control examined the re-\nsponse of the subjects to a surprising object emerging\nfrom behind the cardboard barrier.\nFrom the stimulus sessions, we timed the latency to\nthe first vocalization of each subject, counted the num-\nber of calls, and tabulated the constituent syllable types\n(ABCD) and their numbers in each chick-a-dee call.\nWith this matched pairs design in which each subject\nserved as its own control, we examined differences\nbetween the two treatments with paired t-tests (Sokal\nand Rohlf 198 1 ) and an alpha level <0.05 for rejection\nof the null hypothesis. For comparison of age groups\nof subjects, we used an unpaired t-test and an alpha\nlevel <0.05.\nWhereas D syllables are discretely different from\nother syllable types in the chick-a-dee call, and can be\nassigned accurately to category, the introductory ABC\nsyllables sometimes exhibit intermediates (Hailman et\nal. 1985, Nowicki and Nelson 1990). When there were\nintermediates between A and B syllables we applied\nan arbitrary rule. Intermediates between these two syl-\nlable categories were defined as A syllables if the ini-\ntial upward frequency sweep (Fig. I) was less than half\nthe length of the downward frequency sweep, or as B\nsyllables if greater than half the range of the subse-\nquent downward frequency sweep. Intermediates be-\ntween B and C syllables were discriminated by the\nusually more harsh broadband characteristics of the C\nsyllable (Fig. 1). C syllables that were less noisy had\na lower peak frequency than B syllables. There were\nfewer intermediates between B and C syllables than\nbetween A and B. Intermediates were less than 5% of\nthe syllables scored. Our observations of the structure\nof the syllables of the chick-a-dee call followed the\ncomments and classifications used in previous studies\n(Apel 1985, Hailman et al. 1985, Nowicki and Nelson\n1990).\nRESULTS\nOf the 24 subjects presented with the Prai-\nrie Falcon mount at two distances, 15 were\n>1 year old (\"old birds\") and 9 were fledged\nduring the breeding season prior to testing\n(\"young birds\"). Comparing the two age\ngroups at the same distance from the predator\nshowed that they did not differ significantly\neither on the latency to the first call or the\nnumber of calls given; therefore they were\ncombined for a test of the two distance treat-\nments (Table 1). The subjects responded more\nquickly to the Prairie Falcon mount when pre-\nsented at 1-m distance than at 6-m distance,\nand they also gave more chick-a-dee calls to\nthe stimulus presented at 1 m than at 6 m (Ta-\nble 1). The control tests of the wood block\nversus the predator indicated a nearly com-\nplete absence of response to the wood block\n(1.4 calls ? 1.0 SE) and a high level of chick-\na-dee calling to the Prairie Falcon mount\n(26.3 calls ? 6.4 SE; t = 4.0, df = 7, P =\n0.005.\nDifferences in syllable composition of\nchick-a-dee calls given in the I-m compared\nto 6-m treatments primarily were in the rela-\ntive proportions of A and B syllables. We\nfound that (1) the number of A syllables per\ncall was greater in the 6-m treatment than the\n1-m treatment (x = 2.45 ? 0.65 SE and 1.53\n? 0.41 SE, respectively; t = 2.43, df = 23, P\n= 0.029), (2) the number of B syllables was\nfewer in the 6-m treatment than the 1-m treat-\nment (x = 0.83 ? 0.18 SE and 1.45 ? 0.19\nSE, respectively; t = 4.28, df = 23, P =\n0.001), and (3) the numbers of C and D syl-\nlables did not differ significantly between\ntreatments (mean number of C syllables: at 1\nm, 0.7 ? 0.4 SE; at 6 m, 0.1 ? 0.5 SE;t =\n1.56, df = 23, P 0. 14; mean number of D\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/termsBaker and Becker * CHICKADEE MOBBING CALLS 513\nTABLE 1. The response of Black-capped Chickadees to presentation of a mount of a Prairie Falcon near\n(I m) versus far (6 m) from their cage was significantly greater at the near distance as measured by the latency\nto the first call uttered (all birds: paired t = 3.7, df = 23, P = 0.001), and the number of chick-a-dee calls given\n(all birds: paired t = 2.8, df = 23, P = 0.009). Also, there were no significant differences by these measures\nwhen comparing older birds to younger birds at either distance of predator presentation.\nAll birds (n = 24) Old (n = 15) Young (n = 9) Old versus young\nVariable Mean SE Mean SE Mean SE df P\nLatency to first\ncall (s)\nPredator near 27.7 13.0 40.7 20.0 6.0 0.8 1.7 22 0.11\nPredator far 125.8 28.0 143.0 39.0 86.0 39.0 1.0 22 0.32\nNumber of calls\nPredator near 24.2 4.9 26.8 7.3 19.9 5.1 0.8 22 0.45\nPredator far 13.0 4.5 12.9 5.9 13.9 7.4 0.1 22 0.92\nsyllables: at I m, 2.7 ? 0.4 SE; at 6 m, 2.7\n? 0.5 SE; t = 0.21, df = 23, P = 0.84; Fig.\n2).\nUsing the total number of syllables in each\ncall as a measure of call length, we found that\ncall length of individuals did not differ sig-\nnificantly when the predator was at a distance\nof I m or 6 m (Jx = 6.4 syllables ? 0.3 SE\nand x = 6.1 syllables ? 0.5 SE, respectively;\nt = 0.54, df = 23, P 0.60).\nDISCUSSION\nWe conclude that urgency of response in\nmobbing calls correlates positively with the\nrate of calling by Black-capped Chickadees,\nwith possible additional information encoded\nin the syllable pattern of the chick-a-dee call.\nThese findings are consistent with the hypoth-\nesis that these call features communicate in-\nformation about the degree of threat posed by\na potential predator. From the lack of response\nto the wood block, it is also evident that the\nsubjects viewed the Prairie Falcon mount as a\nsignificant threat, not simply as a surprising\nobject suddenly entering the visual field. Our\nresults are in accord with observations of Apel\n(1985), who noted that the presentation of a\nmount of a Sharp-shinned Hawk (Accipiter\nstriatus) elicited the highest rate of calling\ncompared to that elicited by mounts of other\npotential predators. Sharp-shinned Hawks are\nwell known as important predators of small\npasserine birds. Thus, the high rate of calling\nto a known significant predator found in\nApel's predator presentations to field popula-\ntions of chickadees, together with our labo-\nratory findings of the highest calling to the\nnear distance presentation of the Prairie Fal-\ncon, suggest that the degree of threat is con-\nveyed by high calling rates.\nThere is some evidence in the literature that\nchickadees acquire information about the\nidentity of potential predators through a learn-\ning process (reviewed in Smith 1991). In the\npresent case, this might lead to the expectation\nthat young chickadees would not respond to\nthe Prairie Falcon mount but older birds\nwould respond strongly. Our results showing\nthat younger birds indeed did respond to the\npresentations may therefore indicate that by\nthe time of testing they had acquired sufficient\nexperience to recognize the Prairie Falcon as\na threat. Given the prevalence of this raptor in\nthe study area, this result may not be surpris-\ning.\nIt has been hypothesized that the different\nsyllables of the chick-a-dee call, in the Black-\ncapped Chickadee as well as in the Carolina\nChickadee (Poecile carolinensis) and Mexi-\ncan Chickadee (P. sclateri), may encode dif-\nferent information (Smith 1972; Hailman et al.\n1985, 1987; Ficken et al. 1994; Hailman and\nFicken 1996). Substantial data to examine this\nidea were gathered previously by Apel (1985)\nin an experimental study of Black-capped\nChickadee responses to different kinds of\npredators, both live and taxidermic mounts, in\nseveral contexts. In field presentations during\nboth summer and winter, different types of\npredators sometimes elicited different combi-\nnations of A, B, C, and D syllables (Apel\n1985). Apel concluded that the various sylla-\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/terms514 THE WILSON BULLETIN * Vol. 114, No. 4, December 2002\n1 m Distance\nA (26%)\nD (41%)\nB (24%)\nC(9%)\n6 m Distance\nA (47%) D (40%)\n_E ,,X~c (1%)\nB (12%)\nFIG. 2. These pie diagrams illustrate proportional\nchanges in syllable composition of chick-a-dee calls\ngiven under the two treatment conditions of presenta-\ntion of a Prairie Falcon mount at a near (I m) and far\n(6 m) distance. The data indicate that the chickadees\nincreased the proportion of A syllables and decreased\nB and C syllables when the predator mount was pre-\nsented at 6 m compared to I m distance. These dia-\ngrams summarize the pooled data for all birds, al-\nthough statistical results (see text) were derived from\npaired comparisons of each subject's calls under the\ntwo treatments.\nble alterations of the chick-a-dee call were\npredator-type dependent and constituted a\nfinely tuned predator recognition response. In\nparticular, Apel hypothesized that an increase\nin the number of A syllables indicated a high-\ner fear level in subjects, whereas a prepon-\nderance of D syllables indicated a less fearful\nstate in the chickadees. In general, the D syl-\nlable content of calls was greater in the mob-\nbing context than in nonmobbing situations.\nAlthough we are unable to make conclu-\nsions about fear levels in our subjects, the\nmost intense response, as measured by calling\nrate, was at the 1-m distance to the predator,\nand this treatment elicited fewer A syllables\nand more B syllables than the 6-m treatment.\nThus, in contrast to Apel's hypothesis, we\nconclude that a more immediate predation\nthreat causes a chickadee to shift its call to\ncontain fewer A syllables and more B sylla-\nbles. Apel also noted that on occasions of nat-\nural chickadee encounters with raptor preda-\ntors, strings of A syllables tend to be heard in\nbirds that have retreated to cover and become\nimmobile, perhaps stimulating alertness in\nothers. This observation may suggest an ap-\npropriate interpretation for our results of in-\ncreased A syllables in the 6-m treatment.\nSeeking cover and becoming immobile could\nbe a good strategy when a predator is first\nseen at a somewhat distant location. However,\nwe did not monitor activity levels in our sub-\njects under the two treatments of predator dis-\ntance and therefore have no data with which\nto address this idea. Although Apel tested sub-\njects with mounts of different kinds of avian\nand mammalian predators as well as examples\nof nonpredators of chickadees, an urgency ef-\nfect was not examined by direct experimen-\ntation, e.g., by varying the distance to a given\npredator, as a possible factor in the chicka-\ndee's responses. This large study (Apel 1985),\nhowever, set the stage for a more systematic\ndisentanglement of the possible effects of\npredator type and response urgency on the\nchickadee mobbing call.\nIn the Mexican Chickadee, the equivalent\nchick-a-dee call exhibited differences in syl-\nlable composition in undisturbed versus dis-\nturbed situations in natural populations (Fick-\nen et al. 1994). Two of the syllable types (A,\nD) predominated in calls on territory with the\nmate present (undisturbed), but in a mobbing\ncontext the AD combination was greatly re-\nduced while C syllables increased (Ficken et\nal. 1994). Although these results are not easily\ncompared to ours, they suggest that, as in our\nfindings, A syllables are reduced in number\nunder conditions of increased predator threat.\nResults of other research on species closely\nrelated to Black-capped Chickadees also are\ninstructive. Studies of the antipredator behav-\nior of the Great Tit (Parus major) have ad-\ndressed the question of vocal signaling in re-\nsponse to predators (Curio et al. 1983, Curio\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/termsBaker and Becker * CHICKADEE MOBBING CALLS 515\nand Regelmann 1985). With restrained live\npredators at fixed locations as stimuli, Great\nTits increased their rate of calling as they ap-\nproached a predator and decreased the rate as\nthey retreated from the predator. This finding\nis similar to ours in that calling rate was high-\ner in chickadees for the near presentation of\nthe Prairie Falcon. In other work, a simulated\nEurasian Sparrrowhawk (Accipter nisus) was\npresented to captive Willow Tits (Parus mon-\ntanus) at two different apparent distances (10\nand 40 m) by use of tiny models (7.2 cm\nwingspan and 1.8 cm wingspan, respectively)\npassed over a subject's cage at a height of 2\nm (Alatalo and Helle 1990). Only 16% of the\nbirds gave alarm calls to the larger (near)\nmodel but 59% gave alarm calls to the smaller\n(far) model. This simulation of predator dis-\ntance showed that the propensity to call was\nlow for a more immediate threat, suggesting\nthat calling might increase the risk of preda-\ntion. No data were provided on the rate of\ncalling or on call structure, so comparisons\nwith our results are limited. However, our sub-\njects all gave mobbing calls at the near dis-\ntance and did so at a high rate, opposite the\ngeneral pattern seen in the Willow Tit exper-\niment. A difference of potential significance is\nthat the simulated predator was a moving one\nin the Willow Tit experiment, whereas the\nPrairie Falcon, once moved into position, was\nmotionless. This difference could affect the\nperceived threat of predation.\nAlarm call variation in several fossorial\nmammals appears primarily to be indicative of\ndiffering levels of response urgency. Structur-\nally different alarm calls are given by Cali-\nfornia ground squirrels (Spermophilus beech-\neyi) to approaching aerial and terrestrial pred-\nators (Owings and Virginia 1978), but these\ncalls grade into one another and can be given\nin other contexts (Owings and Leger 1980).\nThese findings led to the interpretation that\nthese variant call structures signal differing\ndegrees of response urgency (Owings and\nHennessy 1984). Similar general conclusions\nhave been made for other species of ground\nsquirrels (e.g., Robinson 1981) and marmots\n(Blumstein and Armitage 1997).\nOur results on chickadees parallel these\nfindings in that we view urgency as a descrip-\ntor of motivational state, and the differences\nin calling rate and alteration of syllable com-\nposition as reflecting different levels of mo-\ntivation resulting from differences in the im-\nmediacy of predator threat. Therefore, results\nfrom studies that find structural differences in\nalarm calls given to two different classes of\npredator, such as raptor versus mammal,\nsometimes could be misinterpreted as repre-\nsenting more complex cognition than is war-\nranted, unless the immediacy of the threat is\nexamined experimentally as a possible cause\nof the observed differences in alarm calls.\nThe systematic teasing apart of predator la-\nbeling and response urgency as causes of dif-\nferences in vocal signals seldom has been ac-\ncomplished, in spite of the simple experimen-\ntal design required: at least two predator clas-\nses each presented at two levels of response\nurgency. Lemurs, for example, make their call\nselection appropriate to the predator class with\nonly minor vocal alteration signaling urgency\nin avian predation simulations (Macedonia\n1990, Pereira and Macedonia 1991). Other\nstudies also have found predator class labeling\nindependent of urgency (Seyfarth et al. 1980,\nFichtel and Kappeler 2002). In social mon-\ngooses (Suricata suricatta), apparently both\npredator type and urgency information are\ncontained in their antipredator calls (Manser\n2001).\nOur results on chickadee mobbing calls\nsuggest that calling rate and some structural\nalterations vary with the immediacy of pred-\nator threat. Whether these variations in call\nproperties represent signals that effect differ-\nent behavior patterns in conspecifics in the\narea of the calling bird is unknown. Our re-\nsults call attention to the need for studies of\nthe responses of receivers to determine if, for\nexample, the intensity of mobbing behavior or\ndefensive escape and hiding are elicited by the\ncall variations.\nACKNOWLEDGMENTS\nWe thank A. Henkel, J. Riley, M. Sawhney, and M.\nTovado for help with bird capture and maintenance.\nM. Ficken provided advice, a review of the manu-\nscript, and a copy of K. M. Apel's dissertation. We\nalso thank S. M. Smith, E. L. Kirshner, and an anon-\nymous reviewer for their critiques. The research was\nconducted during AMB's participation in the Hughes\nUndergraduate Research Scholars program at Colorado\nState Univ. Financial support also was from the Na-\ntional Science Foundation (IBN-0090400 to MCB).\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/terms516 THE WILSON BULLETIN * Vol. 114, No. 4, December 2002\nLITERATURE CITED\nALATALO, R. V. AND P. HELLE. 1990. Alarm calling by\nindividual Willow Tits, Parus montanus. Anim.\nBehav. 40:437-442.\nAPEL, K. M. 1985. Antipredator behavior in the Black-\ncapped Chickadee (Parus atricapillus). Ph.D.\ndiss., Univ. of Wisconsin, Milwaukee.\nBAILEY, A. M. AND R. J. NIEDRACH. 1965. Birds of\nColorado. Denver Museum of Natural History,\nColorado.\nBLUMSTEIN, D. T AND K. B. ARMITAGE. 1997. Alarm\ncalling in yellow-bellied marmots I: the meaning\nof situationally variable alarm calls. Anim. Behav.\n53:143-171.\nCuRIo, E., G. KLUMP, AND K. REGELMANN. 1983. An\nanti-predator response in the Great Tit (Parus ma-\njor): is it tuned to predator risk? Oecologia 60:83-\n88.\nCURIO, E. AND K. REGELMANN. 1985. The behavioural\ndynamics of Great Tits (Parus major) approaching\na predator. Z. Tierpsychol. 69:3-18.\nEVANS, C. S. 1997. Referential signals. Pp. 99-143 in\nPerspectives in ethology, vol. 12 (D. H. Owings,\nM. D. Beecher, and N. S. Thompson, Eds.). Ple-\nnum Press, New York.\nFICHTEL, C. AND P M. KAPPELER. 2002. Anti-predator\nbehavior of group-living Malagasy primates:\nmixed evidence for a referential alarm call system.\nBehav. Ecol. Sociobiol. 51:262-275.\nFICKEN, M. S., R. W. FICKEN, AND S. R. WITKIN. 1978.\nVocal repertoire of the Black-capped Chickadee.\nAuk 95:34-48.\nFICKEN, M. S., E. D. HAILMAN, AND J. P HAILMAN.\n1994. The chick-a-dee call system of the Mexican\nChickadee. Condor 96:70-82.\nFICKEN, M. S. AND J. POPP. 1996. A comparative anal-\nysis of passerine mobbing calls. Auk 113:370-\n380.\nHAILMAN, J. P AND M. S. FICKEN. 1996. Comparative\nanalysis of vocal repertoires with reference to\nchickadees. Pp. 136-159 in Ecology and evolution\nof acoustic communication in birds (D. E. Kroods-\nma and E. H. Miller, Eds.). Cornell Univ. Press,\nIthaca, New York.\nHAILMAN, J. P., M. S. FICKEN, AND R. W. FICKEN. 1985.\nThe \"chick-a-dee\" calls of Parus atricapillus : a\nrecombinant system of animal communication\ncompared with written English. Semiotica 56:\n191-224.\nHAILMAN, J. P., M. S. FICKEN, AND R. W. FICKEN. 1987.\nConstraints on the structure of combinatorial\n\"chick-a-dee\" calls. Ethology 75:62-80.\nHURD, C. R. 1996. Interspecific attraction to the mob-\nbing calls of Black-capped Chickadees (Parus\natricapillus). Behav. Ecol. Sociobiol. 38:287-292.\nKLUMP, G. M. AND M. D. SHALTER. 1984. Acoustic\nbehavior of birds and mammals in the predator\ncontext. Z. Tierpsychol. 66:189-226.\nMACEDONIA, J. M. 1990. What is communicated in the\nantipredator calls of lemurs: evidence from play-\nback experiments with ringtailed and ruffed le-\nmurs. Ethology 86:177-190.\nMANSER, M. B. 2001. The acoustic structure of suri-\ncate's alarm calls varies with predator type and\nlevel of response urgency. Proc. R. Soc. Lond. B\n268:2315-2324.\nMARLER, P., C. S. EVANS, AND M. D. HAUSER. 1992.\nAnimal signals: motivational, referential, or both?\nPp. 66-86 in Nonverbal vocal communication:\ncomparative and developmental approaches (H.\nPapousek, U. Jurgens, and M. Papousek, Eds.).\nCambridge Univ. Press, Cambridge, United King-\ndom.\nNowICKI, S. AND D. A. NELSON. 1990. Defining natural\ncategories in acoustic signals: comparison of three\nmethods applied to \"chick-a-dee\" call notes.\nEthology 86:89-101.\nOWINGS, D. H. AND D. F HENNESSY. 1984. The impor-\ntance of variation in sciurid visual and vocal com-\nmunication. Pp. 169-200 in Biology of ground\ndwelling squirrels: annual cycles, behavioral ecol-\nogy and sociality (J. 0. Murie and G. R. Michener,\nEds.). Univ. Nebraska Press, Lincoln.\nOWINGS, D. H. AND D. W. LEGER. 1980. Chatter vo-\ncalizations of California ground squirrels: preda-\ntor- and social-role specificity. Z. Tierpsychol. 54:\n163-184.\nOWINGS, D. H. AND R. A. VIRGINIA. 1978. Alarm calls\nof California ground squirrels (Spermophilus\nbeecheyi). Z. Tierpsychol. 46:58-70.\nPEREIRA, M. E. AND J. M. MACEDONIA. 1991. Response\nurgency does not determine antipredator call se-\nlection by ring-tailed lemurs. Anim. Behav. 41:\n543-544.\nPYLE, P., S. N. G. HOWELL, R. P. YUNICK, AND D. F.\nDESANTE. 1987. Identification guide to North\nAmerican passerines. Slate Creek Press, Bolinas,\nCalifornia.\nROBINSON, S. R. 1981. Alarm communication in Beld-\ning's ground squirrels. Z. Tierpsychol. 56:150-\n168.\nSEYFARTH, R. M., D. L. CHENEY, AND P MARLER. 1980.\nMonkey responses to three different alarm calls:\nevidence of predator classification and semantic\ncommunication. Science 210:801-803.\nSKINNER, M. P. 1938. Falco mexicanus: Prairie Falcon.\nPp. 18-42 in Life histories of North American\nbirds of prey, part II (A. C. Bent, Ed.). U. S. Natl.\nMus. Bull. 170:1-482.\nSMITH, S. M. 1991. The Black-capped Chickadee: be-\nhavioral ecology and natural history. Cornell\nUniv. Press, Ithaca, New York.\nSMITH, S. T 1972. Communication and other social\nbehavior in Parus carolinensis. Publ. Nuttall Or-\nnithol. Club 11:1-125.\nSOKAL, R. R. AND F J. ROHLF. 1981. Biometry, 2nd\ned. W. H. Freeman, San Francisco, California.\nZUBERBUHLER, K. 2000. Referential labeling in Diana\nmonkeys. Anim. Behav. 59:917-927.\nThis content downloaded from\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n�\n129.2.89.26 on Tue, 13 Jan 2026 21:24:52 UTC��������������\nAll use subject to https://about.jstor.org/terms", "affiliations": [{"university": "Colorado State University", "country": "United States", "discipline": "Biology"}, {"university": "Colorado State University", "country": "United States", "discipline": "Biology"}], "species_categories": ["Bird"], "specialized_species": ["Black-capped Chickadee", "Prairie Falcon"], "computational_stages": [], "linguistic_features": ["Semanticity", "Discreteness and Syntax", "Openness"], "status": "saved", "created_at": "2026-01-13T12:49:59.882743", "updated_at": "2026-01-13T16:25:24.637143", "committed_at": "2026-01-13T16:25:27.830519"}
{"id": "d8a55f37-8fd1-4877-97f9-3488d4e6c07d", "title": "Chick-a-dee call syntax,  social context,  and season affect vocal responses of Carolina chickadees (Poecile carolinensis)", "authors": ["Clucas,  Barbara A.", "Freeberg,  Todd M.", "Lucas,  Jeffrey R."], "year": "2004", "journal": "Behavioral Ecology and Sociobiology", "abstract": "", "doi": "10.1007/s00265-004-0847-9", "analysis_notes": "Behav Ecol Sociobiol (2004) 57:187–196\nDOI 10.1007/s00265-004-0847-9\nO R I G I N A L A R T I C L E\nBarbara A. Clucas · Todd M. Freeberg ·\nJeffrey R. Lucas\nChick-a-dee call syntax, social context, and season affect\nvocal responses of Carolina chickadees (\nPoecile carolinensis)\nReceived: 25 November 2003 / Revised: 30 July 2004 / Accepted: 17 August 2004 / Published online: 17 September 2004\n\u0017 Springer-Verlag 2004\nAbstract Chick-a-dee calls in many chickadee (Poecile)\nspecies are common vocal signals used in a diversity of\nsocial contacts. The calls consist of four notes, A, B, C,\nand D, which follow simple rules of syntax (note ordering\nand composition) to generate many unique call types. We\nused field playbacks with Carolina chickadees, P. carolinensis, to ask whether violations of a syntactical rule\naffected their vocal responses. We show that chickadee\nresponses to typical calls (e.g. AAAACCCC and CCCCDDDD) differ from responses to atypical calls (e.g.\nCACACACA and DCDCDCDC) depending on playback\nnote composition, season, and social context (presence of\nheterospecifics). In the fall/winter, playbacks of typical\ncalls with A and C notes elicited the greatest number of A\nand B notes in chick-a-dee call responses and typical calls\nwith D notes elicited the greatest number of C notes,\nwhen in the presence of heterospecifics. In contrast, the\ncorresponding atypical calls did not elicit similar responses. This suggests communicative significance is lost\nin calls that violate a rule of syntax in the fall/winter. In\nthe spring, neither chickadee feebeefeebay song rate nor\nchick-a-dee calls responses differed by playback type. We\nsuggest that call syntax is less salient for mated pairs in\nthe spring than it is for fall/winter flocks that rely more on\nconspecific communication for foraging success and flock\ncohesion. This study represents the first experimental\nevidence that chickadees attend to both note composition\nand ordering in chick-a-dee calls.\nKeywords Carolina chickadee · Chick-a-dee call ·\nPoecile · Syntax · Vocal communication\nIntroduction\nAnimals use vocal signals to accomplish a variety of\nsocial tasks and in some taxa selection may favor vocal\nrepertoires of greater complexity (Kroodsma 1977; Blumstein and Armitage 1997; Bradbury and Vehrencamp\n1998; Owings and Morton 1998; Ord et al. 2002). Certain\nspecies attain this complexity by varying the composition\nand possible order of different elements in structurally\ncomplex signals (Hailman and Ficken 1986). Additionally, the structure of the signals may follow simple rules\nof note composition and note ordering (e.g., Hailman\net al. 1985, 1987) and it is suggested that this ‘syntax’<001><fn><001> Note that throughout this paper, we\nare using ‘syntax’ to refer to note ordering and composition (Markovian syntax), and not in the language sense\nof different words being arranged in phrases or sentences\nsuch that changes in word ordering can alter phrase or\nsentence meaning.</fn>might be important in communication (Robinson 1984; Hailman and Ficken 1986;\nBalaban 1988; Kanwal et al. 1994).\nTo demonstrate the importance of syntax in a vocal\nsignaling system, it is not enough to show that signalers\nvary the syntax of their vocalizations; one must also show\nthat receivers respond to variation in syntax. Many avian\nstudies have shown that behavioral responses to local or\ntypical birdsong syntax are different compared to foreign\nor atypical syntax (e.g., Baker et al. 1987; Okanoya et al.\n2000; Holland et al. 2000). Similarly, several primate\nspecies that produce vocal signals governed by a rudimentary syntax give different behavioral responses to\natypical compared to typical vocalizations (Mitani and\nMarler 1989; Ghazanfar et al. 2001; Zuberbuhler 2002).\nThese studies suggest that animals attend to violations of\nCommunicated by W.A. Searcy\nB. A. Clucas · T. M. Freeberg · J. R. Lucas ())\nDepartment of Biological Sciences,\nPurdue University,\nWest Lafayette, IN, 47907, USA\ne-mail: jlucas@bilbo.bio.purdue.edu\nPresent address:\nB. A. Clucas, Animal Behavior Graduate Group,\nUniversity of California at Davis,\nOne Shields Avenue, Davis, CA, 95616, USA\nPresent address:\nT. M. Freeberg, Department of Psychology,\nUniversity of Tennessee,\nAustin Peay Building 303A, Knoxville, TN, 37996, USAsyntactical rules, and provide further evidence that syntax\npotentially plays a functional role in communication for\nthese species.\nHere, we begin an investigation of the importance to\nconspecific receivers of call syntax in the chick-a-dee call\nof Carolina chickadees, Poecile carolinensis. The chicka-dee call of Poecile species has been intensively analyzed in terms of the production rules governing the\ncomposition and ordering of its notes (Hailman et al.\n1985, 1987; Hailman and Ficken 1986; Ficken et al.\n1994). It is typically made up of four note types that are\ndistinguished by unique acoustic properties, and traditionally designated as A, B, C, and D (Hailman and\nFicken 1986; Ficken et al. 1994; Freeberg et al. 2003;\nBloomfield et al. 2003). The notes follow a general A-BC-D ordering (Hailman et al. 1985; see Fig. 1) and any\nnote can be omitted or repeated up to 30 or more times in\nthe call (Smith 1972). Therefore, the chick-a-dee call\nsystem has the potential to generate an enormous number\nof unique call types. The structural complexity of the\nchick-a-dee call is comparable to that of some birdsong.\nYet unlike most song in songbird species, the chick-a-dee\ncall is produced year round, during different social interactions and many environmental situations. Thus, in\ncontrast to birdsong, chick-a-dee call syntax may accomplish more than communicating species identity or\nsignaler status (e.g. mate choice and territorial functions).\nSeveral studies show that note composition (type and\nnumber of notes) in chick-a-dee calls correlates with the\ncontext of the vocalization (Gaddis 1985; Ficken et al.\n1994) and can affect the behavior of signal recipients\n(Freeberg and Lucas 2002). However, no study has tested\nwhether the order of the note types affect receiver perceptions and subsequent responses in a Poecile species.\nWe conducted field playbacks in the spring and fall/\nwinter of chick-a-dee call variants containing notes in\neither typical (e.g. AAAACCCC and CCCCDDDD) or\natypical (e.g. CACACACA and DCDCDCDC) order to\ntest the possible effect of this syntax violation on the\nvocal responses by Carolina chickadees. The playback\nvariants focused on C notes because previous work found\nthat chickadees responded differently to the presence of a\nstring of C notes in call playbacks compared to calls\nwithout these note types (Freeberg and Lucas 2002). We\nmeasured latency to arrive at playback site, vocalization\nrates, and note composition of chick-a-dee calls produced\nto test for differences in chickadees’ responses to typical\nrelative to atypical syntax call playbacks. Furthermore,\nwe examined the effect of season because chickadees are\nin mated pairs in the spring and in small flocks (often\nheterospecific) in the fall/winter (Brewer 1961; Smith\n1991) and these differences may influence vocal responses to playbacks. Differences in responses would\nsuggest note order is important for communication.\nMethods\nGeneration of playback sets\nWe recorded individual Carolina chickadees in an anechoic room\nunder identical conditions to generate a library of chick-a-dee calls.\nDuring recording, chickadees were housed individually in separate\n1-m3 cages, where birds could hear and often see one another in\nadjoining cages or rooms. The chick-a-dee calls were recorded with\nSaul Mineroff directional electret microphones, placed within 1 m\nof an individual, on Maxell XLII cassette tape using Marantz PMD\n222 portable cassette recorders. Calls were then digitized from\ncassette tape using Cool Edit Pro with 16-bit resolution and a\n22 kHz sampling rate.\nCarolina chickadees typically produce calls with the following\nnote combinations: AC, AD, CD, ACD, or ABD using a range of\nnote numbers (Smith 1972; Freeberg, unpublished data). Chick-adee calls in this Indiana population contain an average of 2.1 A\nnotes (median 2, SD 1.9, range 0–18), 0.1 B notes (median 0, SD\n0.4, range 0–5), 0.5 C notes (median 0, SD 1.1, range 0–9), and 3.4\nD notes (median 3, SD 3.3, range 0–25), based on 1,653 calls\nrecorded from birds at 13 independent field sites (Freeberg, unpublished data). We created eight-note calls that each had four\nnotes of two types (A and C, C and D, or A and D), which controlled for note numbers across playback variants. For calls containing C notes, we made call types with typical note ordering\n(AAAACCCC and CCCCDDDD) and call types with atypical note\nordering (CACACACA and DCDCDCDC). For calls not containing C notes, we made only typical note ordering (AAAADDDD).\nFor each of the eight playback sites, a unique set of these five\nplayback types was generated from previously recorded calls\n(sonagrams of two of the eight sets are given in Fig. 2).\nTo demonstrate that the typical chick-a-dee calls we created do\noccur naturally, we analyzed the syntax of 1,653 field-recorded\ncalls that were collected as part of a different study (Freeberg,\nunpublished data). Calls with the “AD” syntax that contained at\nleast three A notes and at least three D notes occurred 149 times\n(calls from 12 of 13 sites). Calls with the “AC” syntax that contained at least three A notes and at least three C notes occurred 3\ntimes (calls from 3 of 13 sites). Calls with the “CD” syntax that\ncontained at least three C notes and at least three D notes occurred\n22 times (calls from 11 of 13 sites). Calls containing an “ACA” or\n“CAC” note ordering (characteristic of the CACACACA note\ncomposition in our study), or containing an “CDC” or “DCD” note\nordering (characteristic of the DCDCDCDC note composition in\nFig. 1 Sonagrams of two exemplars of chick-a-dee calls of Carolina chickadees (Poecile carolinensis). Sonagrams were generated\nin Cool Edit Pro 2.0 on Windows XP platform, using the Blackmann-Harris windowing function at 256 band resolution. Note type\nclassifications (based on note type designation from Hailman et al.\n1985 and Freeberg and Lucas 2002) are indicated above each\nsonagram\n188our study), at any point in the call’s note composition, did not occur\nin that set of 1,653 calls. Thus, calls with the typical note ordering\nthat we used in our playback study do occur in this population, and\nour field sampling to date has not obtained a call with the sort of\natypical note ordering that we created.\nThere is a fairly smooth transition in the spectral properties of\nnotes given multiple times in a call (Freeberg et al. 2003). This\ntransition is disrupted by definition when calls are made (artificially) with atypical syntax. To ensure that the effect of note order\non chickadees’ responses to our playbacks was not confounded by\nthis, we constructed all calls (i.e., both typical and atypical calls) by\ncombining a single note taken from eight different calls to make a\nsingle playback call consisting of eight notes. Thus, a complete set\nof playback calls for one playback site would be A 1A 2A 3A 4C 5\nC6 C7 C8 , C 7A 4C 5A 1C 8A 2C6 A 3*, A1 A 2A 3A 4D 9D 10 D11 D 12 , C 5C 6C 7\nC8 D9 D 10D 11 D 12, and D 9C 6D 11 C5 D12 C8 D10 C 7* (notes derived from\nthe same bird are indicated with the same subscript and an asterisk\nindicates that the call has atypical note ordering, with the note\nordering for each of these playback types determined randomly).\nCool Edit Pro was used to construct each playback type for each\nplayback set by cutting single notes from the recorded calls. Internote intervals were set at approximately 0.03 s for all notes, the\nmean inter-note intervals measured from chickadee calls in this\npopulation (Freeberg and Lucas, unpublished data). To control for\ngeographic variation in note structure (Freeberg et al. 2003), all\nplayback calls were constructed from notes recorded from birds\ncaptured from the same population as those given playbacks.\nConstructed playback types were then recorded onto Maxell UR\ncassette tapes with a Marantz PMD 222 portable cassette recorder.\nEach playback type was dubbed onto a different tape at roughly one\nvocalization every 10 s for 3 min (the duration of the playback\nperiod in each 10-min block of trials).\nPlayback presentations\nPlaybacks were conducted at the Ross Biological Reserve in West\nLafayette, Indiana, during spring 2001 (March-May) and fall/winter\n2001–2002 (September-January). There were eight playback sites,\neach at least 250 m apart to ensure independence of sites (see\nFreeberg and Lucas 2002). Not all birds responding to the playbacks were banded; however in this study banded birds consistently\nresponded at only one site, within a season. It is possible that an\nunbanded bird responded at more than one site; however, assuming\nflock and pair membership were stable (see Brewer 1961; Dixon\n1963), this is unlikely.\nAt each of the eight sites, we conducted five different playback\npresentations, each on separate days with at least 7 days between\nconsecutive playbacks. One playback type was broadcast during a\npresentation and the order of playback type was randomized across\nsites. Therefore, 40 playback presentations were completed in each\nseason. Playbacks started between 0700 and 1030 hours EST with a\n10-min ‘pre-playback’ observation period to obtain data on background call rate unaffected by playback calls. A novel seed stand (2\nm high) was placed near a playback speaker (hung about 2 m high\nfrom a tree) on arrival to the site and was filled with sunflower\nseeds at the end of the ‘pre-playback’ period.\nThe experimental design was similar to that used by Freeberg\nand Lucas (2002). Briefly, we played back calls with a Marantz\nPMD 222 portable cassette recorder through a Saul Mineroff\npowered speaker. Trials lasted 60 min, which was divided into six\n10-min sections. Each 10-min section began with a 3-min playback\nof a certain call type and ended with 7 min of silence. Trials (including the pre-playback period) were recorded with a second\nportable cassette recorder for subsequent analysis.\nData collection and analyses\nWe collected data on the following:\n1. Number of chickadees vocalizing during the pre-playback period and number responding to each playback.\n2. Rates of major vocalizations during the pre-playback period.\nThese data would allow us to determine whether there were\nseasonal differences in production rates (number calls/h/bird) of\nchick-a-dee calls, gargle vocalizations (an agonistic vocal signal\nof Poecile species), and feebeefeebay songs (the territorial song\nof the species, given only by males).\nFig. 2 Sonagrams of the five\nplayback types from two of the\neight playback sets. Scale of the\naxes and sonagram generation\nparameters are the same as in\nFig. 1. The left panel of sonagrams is the playback set for\nPlayback Site 8, and the right\npanel of sonagrams is the\nplayback set for Playback Site\n5. Note that within each playback set, individual A notes are\nidentical (though ordering may\ndiffer) for the top three rows,\nindividual C notes are identical\n(though ordering may differ) for\nthe bottom four rows, and individual D notes are identical\n(though ordering may differ) for\nthe top row and the bottom two\nrows\n1893. Arrival time (min) for Carolina chickadee receivers to approach\nto within 20 m of the playback speaker and seed stand.\n4. Rates of chick-a-dees, gargles, and feebeefeebays during the\nplayback trial.\n5. Note composition of chick-a-dee call responses of Carolina\nchickadee receivers. Analysis of note composition was restricted to those calls given starting 10 min before the first bird\nbroke the 20-m barrier around the feeder and ending 10 min\nafter the bird(s) first broke the 20-m barrier. We used this 20min subset of calls to ensure that our data reflect a response to\nthe playback.\nRecordings of each playback trial allowed us to analyze receivers’ calls (Cool Edit Pro sound analysis program) to obtain the\nexact composition of all chick-a-dee call responses given within the\n20-min criterion time. Identifying individual receivers was not\npossible from these recordings. However, limiting calls analyzed to\na 20-min period (see previous paragraph) ensured calls analyzed\nwere responses from birds that approached close to the playback\nspeaker and were not multiple pairs/flocks approaching and departing from the playback site. We determined the average number\nof A, B, C, and D notes in calls produced by receivers at the\nplayback sites. The introductory A and B notes were sometimes\ndifficult to distinguish from each other, and inter-individual reliability for these notes was low (50%); therefore we combined these\nnote types in our analysis. A total of 1,502 chick-a-dee calls constituted the complete data set for analysis of note composition in\nbirds responding to our playbacks. B.A.C. scored the 1,502 calls\nthat went into the statistical analyses and T.M.F. independently\nscored 490 calls for inter-observer agreement measures. Independent scoring was within €1 note agreement for 428 of those calls\n(87%).\nWe analyzed the data on arrival times, vocal rates, and numbers\nof A+B, C, and D notes in calls of receivers using repeated measures ANCOVAs with a first-order autoregressive covariance\nstructure (Proc MIXED; SAS Institute 1994). The distributions\nof the data were highly skewed; therefore we log-transformed\n[ln(n+1)] the data for all of the data sets except the pre-playback\nvocal rates, where we log-log-transformed {ln[ln(n+1)+1]} the\ndata, to normalize residuals in the ANCOVA models. For the preplayback data, we tested for effects of season (fall/winter vs spring)\nand playback type. For the playback trial data, we tested for main\neffects of season, playback type, and social context (presence or\nabsence of tufted titmice, Baeolophus bicolor, or white-breasted\nnuthatches, Sitta carolinensis). We also tested for the effect of\nnumber of chickadees responding to our playbacks because vocalization rates will obviously vary with this number. Less obviously, the note composition of chick-a-dee calls given by responders might also vary if the syntax reflects, in part, communication\nbetween birds. To account for these effects, we included the\nnumber of chickadees we detected as covariates in the ANCOVA\nmodels. Playback site was used as the subject variable. All two-way\ninteractions between the main effects and the three-way interaction\nwere added to the models. Non-significant interaction terms were\ndropped from the model in order of decreasing P-value until all\nremaining interactions were significant (P<0.05). Note that the\ndegrees of freedom may vary depending on the interaction terms\nleft in the model. Where significant effects were detected, we tested\nfor significant differences between playback types, season, or social\ncontext using the DIFF option of the LSMEANS calculation in Proc\nMIXED. Below we only report differences that were significant at\na=0.05.\nWe divided the calls into their component parts (A+B, C and D\nnotes) to evaluate the effect of season, playback type and social\ncontext on call syntax. Doing so may inflate the probability of a\ntype I error by underestimating the true P-value (since each call is\nanalyzed three times). Therefore, we use a Bonferroni correction of\nthe a level to account for these multiple tests (a=0.05/3).\nFinally, we used repeated measures Poisson regression\n(GLIMMIX SAS macro in Littell et al. 1996) to evaluate whether\nthe number of responding birds changed between seasons, or\nchanged as a function of playback type.\nResults\nNumber of chickadees vocalizing/number responding\nto playbacks\nThe number of chickadees responding to our playbacks\nranged from 1–4 birds and did not vary with playback type (F=0.904,41, P=0.4735) season (F=0.181,41,\nP=0.6710), and social context (F=0.161,41, P=0.6914).\nRates of chick-a-dees, gargles, and feebeefeebays\nduring the pre-playback period\nCombining pre-playback intervals across all sites, there\nwas a significant effect of season on rates of chick-a-dee\ncall production (F1,14=5.1, P=0.041). More chick-a-dee\ncalls were produced in the fall/winter than in the spring\n(Fig. 3), and chick-a-dee rate increased with the number\nof chickadees observed (F1,15=6.31, P=0.0001). We did\nnot detect an effect of season on rates of gargle production (F1,14=0.00, P=0.96; see Fig. 4). Gargle rates did\nincrease significantly with an increase in the number\nof chickadees (F1,15=10.3, P=0.006). Finally, for feebeefeebay rates there was a significant interaction between the number of chickadees and season (F1,14=11.3,\nP=0.005), with a stronger effect of number of birds on\nsong rate in spring than in fall/winter.\nArrival time to approach within 20 m\nCarolina chickadee receivers generally approached the\nspeaker and seed stand within about 20 min of the start\nof the playback (spring: 18.3€2.8 SE min; fall/winter:\n17.7€3.1 SE min). We did not detect an effect of playback\ntype (F4,31=0.65, P=0.63) or season (F1,8 =0.52, P=0.49)\non arrival times of chickadees. However, arrival time was\nshorter with an increase in the number of responding birds\n(F1,9 =12.6, P=0.0062; b=-1.20€0.34, with log (n+1)\ntransform of arrival time).\nRates of chick-a-dees, gargles, and feebeefeebays\nduring the playback trial\nChick-a-dee rates\nThe main effect of playback type on chick-a-dee rates was\nnot significant (F4.73=1.1, P=0.35). We did not detect an\neffect of season (F1,73=0.00, P=0.99; Fig. 3) or social\ncontext (F1.73=0.12, P=0.73) on rates of chick-a-dee calls\nproduced by receivers. However, when we analyze patterns in chick-a-dee rates separately for each season, the\nnumber of chickadees responding contributes to variance\nin chick-a-dee rates (Table 1).\n190Gargle rates\nChickadee receivers produced no more gargle vocalizations to playbacks in the spring than they did in the\nfall/winter (Fig. 4; F1,73=2.67, P=0.11). We also did not\ndetect an effect of playback type or social context on\ngargle rates (Table 1). In both seasons, gargle rates increased significantly from pre-playback to playback intervals (Fig. 4; fall/winter: F1,60=32.3, P<0.0001; spring:\nF1,60=26.1, P<0.0001), indicating that birds were responding to our playbacks.\nFeebeefeebay rates\nThe interaction of season, number of responding birds and\nplayback type had an effect on rates of feebeefeebay\nproduction (F1,61=3.0, P=0.005). Therefore, analysis of\nfeebeefeebay rates is clearer when the data for the two\nseasons are evaluated separately. In the fall/winter, the\nchickadees rarely responded with feebeefeebay song but\nthe few songs given were to AAAADDDD playbacks\n(Fig. 5a; Table 1). Not surprisingly, male chickadees sang\nmore in the spring and the only factor that correlated\n(positively) with song rates was the number of responding\nbirds (Fig. 5b; Table 1). We added pre-playback feebeefeebay rates to the model to test whether our playbacks elicited a change in song rates. The pre- versus\nduring-playback main effect was significant for both\nseasons (Fig. 5; fall/winter: F1,60=9.52, P=0.003; spring:\nF1,60=9.41, P=0.003), with the average pre-playback rate\nsignificantly lower than the during-playback rate. This\ndemonstrates that feebeefeebay rates of receivers were\nstrongly influenced by our playbacks, especially in the\nspring when singing is most prevalent.\nFig. 3 Chick-a-dee rates (least squares means€SE) elicited by each\nplayback type in the fall (A) and spring (B). Playback types:\n“AD”=AAAADDDD; “AC”=AAAACCCC; “CD”=CCCCDDDD;\n“ca”=CACACACA; “dc”=DCDCDCDC. SE were back calculated\nfrom the log(n+1) transformation. Multiple comparisons suggest\nthat none of the means within each season are significantly different from one another (a=0.05)\nFig. 4 Gargle rates (least squares means€SE) elicited by each\nplayback type in the fall (A) and spring (B). SE were back calculated from the log(n+1) transformation. Multiple comparisons\nsuggest that none of the means within each season are significantly\ndifferent (a=0.05). Playback type and social context designations\nare the same as in Fig. 3\n191Note composition of chick-a-dee calls\nof Carolina chickadee receivers\nWe analyzed the effect of playback type and social context (presence or absence of titmice or nuthatches) for\neach note type in the chickadee call separately. In addition, we focus on trends within seasons following the\nrationale that playback type and social context are the\nmost critical effects that we are evaluating with respect to\nthe note composition of chick-a-dees given by responding\nbirds (noting that these relationships can nonetheless vary\nacross seasons).\nA+B notes\nThere were on average 1.85 A+B notes per call across all\ncalls we analyzed for this study (median=1, lower quartile=1, upper quartile=3, range=0 to 17 A+B notes per\ncall). In the fall/winter, the number of introductory notes\ngiven by the responding birds was affected by each of the\nindependent variables through a significant 3-way interaction (Table 2). Interestingly, holding number of birds\nresponding and social context constant, the number of\nintroductory notes was highest in response to the playbacks with typical syntax (especially AC playback),\ncompared to calls with atypical syntax (Fig. 6a). In the\nspring, there were no significant trends (Fig. 6b).\nC notes\nThe calls we analyzed had an average of 0.97 C notes\nin them (median=0, lower quartile=0, upper quartile=1,\nrange=0 to 12 C notes per call). In the fall/winter, the\nnumber of C notes in chick-a-dee calls elicited from our\nplaybacks was highest for playbacks with typical syntax,\nand this effect varied with playback note composition\nand was also affected by the presence of titmice and\nnuthatches. The two main effects, playback type and social context, and their interaction were significantly correlated with the number of C notes in the calls (Fig. 7a;\nTable 2). A multiple comparisons test indicates that the\nAAAADDDD and CCCCDDDD playbacks in the presence of titmice and nuthatches elicit chick-a-dee calls rich\nin C notes. All other typical combinations of note composition and social context in the fall/winter elicited calls\nwith fewer C notes, as did all of the atypical syntax\nplaybacks (Fig. 7a; Table 2). The number of birds responding did not affect the number of C notes in the calls\nFig. 5 Feebeefeebay rates (least squares means€SE) elicited by\neach playback type in the fall (A) and spring (B). SE were back\ncalculated from the log(n+1) transformation. Multiple comparisons\nare indicated with lines to the left of the playback designations;\nthose connected by a line are not significantly different at a=0.05.\nPlayback type designations are the same as in Fig. 3\nTable 1 Repeated measures\nanalysis of the effect of playback type, social context (presence of titmice or nuthatches),\nand number of Carolina chickadees (Poecile carolinensis) responding on chick-a-dee, gargle, and feebeefeebay call rates\nof responding Carolina chickadees. Call rates were number\nof calls/10 min of playback; this\nvalue was log(n+1) transformed\nto normalize the residuals. Only\nsignificant interaction terms\nwere retained in each model\nCall type Independent variable Spring Fall\nChick-a-dee Playback type F4,34 =0.54, P=0.71 F4,34 =0.18, P=0.95\nSocial context F1,34 =0.03, P=0.87 F1,34 =1.53, P=0.23\nNo. birds responding F1,35 =13.3, P=0.0009 F1,34 = 73.6, P=0.0008\nGargle Playback type F4,34 =0.51, P=0.73 F4,34 =0.19, P=0.94\nSocial context F1,34 =0.02, P=0.89 F4,34 =0.00, P=0.98\nNo. birds responding F1,35 =34.0, P=0.0001 F1,34 =37.0, P=0.0001\nFeebeefeebay Playback type F4,34 =0.04, P=0.99 F4,34 =2.66, P=0.049\nSocial context F1,34 =0.46, P=0.50 F1,30 =2.59, P=0.12\nNo. birds responding F1,7 =23.3, P=0.002 F1,7 = 4.01, P=0.09\n192(Table 2). In contrast to these fall/winter results, we did\nnot detect an effect of playback type or social context on\nC notes in the spring (Fig. 6b; Table 2), although the\nnumber of C notes in the calls did increase with the\nnumber of birds responding (b=0.20€0.07).\nTable 2 Repeated measures\nanalysis of the effect of playback type, social context (presence of titmice or nuthatches),\nand number of Carolina chickadees responding on note composition of chick-a-dee calls.\nThe number of notes in a call\nwas log(n+1) transformed. Only\nsignificant interaction terms\nwere retained in each model\nNote type Independent variable Spring Fall\nD Playback type F4,19 =1.62, P=0.211 F4,17 =1.96, P=0.15\nSocial context F1,19 =1.55, P=0.228 F1,17 =2.41, P=0.139\nNo. birds responding F1,11 =19.21, P=0.001 F1,9 =1.96, P=0.195\nNo. birds  social context NS F1,9 =8.73, P=0.016\nC Playback type F4,19 =0.03, P=0.99 F4,13 =5.39, P=0.009\nSocial context F1,19 =0.26, P=0.61 F1,13 =10.81, P=0.006\nNo. birds responding F1,11 =8.93, P=0.012 F1,16 =1.32, P=0.27\nPlayback  social context NS F4,13 =7.69, P=0.002\nA+B Playback type F4,19 =2.68, P=0.063 F4,17 =5.06, P=0.007\nSocial context F1,19 =3.26, P=0.087 F1,17 =1.44, P=0.25\nNo. birds responding F1,11 =19.42, P=0.001 F1,12 =0.01, P=0.91\nNo. birds responding  playback NS F4,12 =3.92, P=0.029\nFig. 6 Number of A+B notes (least squares means€SE) in chick-adee calls as a function of playback type in the fall (A) and spring\n(B). Playback type designations are the same as in Figure 3\nFig. 7 Number of C notes (least squares means€SE) in chick-adee calls as a function of playback type and social context in the\nfall (A) and spring (B). Playback types: “AD”=AAAADDDD;\n“AC”= AAAACCCC; “CD”=CCCCDDDD; “ca”=CACACACA;\n“dc”=DCDCDCDC. Social context: + modifier to call playback =\npresence of titmice and/or nuthatches; no modifier to call playback = absence of titmice and/or nuthatches. SE were back calculated from the log(n+1) transformation. Multiple comparisons are\nindicated with lines to the left of the playback designations; those\nconnected by a line are not significantly different at a=0.05\n193D notes\nThe calls we analyzed had an average of 4.56 D notes\n(median=4, lower quartile=2, upper quartile=6, range=0\nto 25 D notes per call). In the fall/winter, we did not\ndetect an effect of playback type on the number of D\nnotes in a call (Fig. 8a), but there was a significant effect\nof social context, through an interaction with the number of responding conspecifics. Chickadees increased the\nnumber of D notes with increasing number of conspecifics responding in the absence of titmice or nuthatches\n(b=0.43€0.14) but decreased the number of D notes with\nan increase in conspecifics responding in the presence of\ntitmice or nuthatches (b=0.11€0.10) (Table 2). Note that\nthe reduction in number of D notes in the presence of\nheterospecifics is caused by a change in note composition compared to chick-a-dee calls given when no heterospecifics were present. This response is not a simple\nreduction in chick-a-dee rates.\nIn the spring, there was a statistically not significant\neffect of playback type on the number of D notes in the\ncall and a significant interaction between playback type\nand number of responding birds (Table 2). As the number\nof birds responding increased in the spring, the number of\nD notes decreased, but the strongest decrease was for\ntypical AC calls (b=-0.50€0.23). In contrast, there was no\neffect of number of birds responding on the number of D\nnotes given in response to typical CD calls (b=0.01€\n0.20). The other three calls had intermediate effects\n(CD atypical: 0.008€0.22; AC atypical: 0.0026€0.31;\nAD typical: 0.251€0.21). Holding number of birds responding constant, the number of D notes per call given in\nresponse to normal AC calls was significantly less than\nthe number of D notes given in response to any other call.\nAll other comparisons were not significant.\nDiscussion\nThis study tested whether Carolina chickadees would attend to violations of a syntactical rule in their chick-a-dee\ncall by responding differently to call playbacks of typical\nnote order versus atypical note order. The results show\nthat although vocalization rates did not vary with playback type, there were subtle differences in the note\ncomposition of chick-a-dee call responses to typically\nordered calls compared to atypically ordered calls. Season\n(spring or fall/winter) and social context (presence or\nabsence of heterospecifics) also contributed to these response differences and may reflect the effect of seasonal\nchanges in chickadee social structure and heterospecific\ninteractions on intraspecific communication. Thus, note\norder affects response behavior and the presence of this\nnote order effect suggests that calls with atypical syntax\ncan lose communicative significance.\nWe conducted playbacks across two seasons, spring\nand fall/winter, because seasonal variation in social systems can affect the use of components of a vocal repertoire. An obvious example is the seasonal use of song in a\nwide variety of songbirds (see Kroodsma and Miller\n1996). Male song provides a mechanism for territory\ndefense and advertisement of its borders, and is often\ndropped entirely from male repertoires outside of the\nbreeding season. Thus it was not surprising that male\nchickadees sang almost exclusively in the spring when\nthey defend a territory with their mate, and very little the\nfall/winter when chickadees form small flocks (Smith\n1972; Smith 1991). In the spring, male chickadees increased song rates during all of our playbacks suggesting\nterritorial males investigate and aggressively respond to\nconspecific calls regardless of note order.\nChick-a-dee call responses were given at similar rates\nbetween season and rates did not differ between playback\ntypes within season. However, in the fall/winter the note\ncomposition of chick-a-dee call responses differed depending on the playback type. Specifically, chickadees\nproduced chick-a-dee calls with the most introductory (A\nand B) notes in response to typical AC playbacks (regardless of the presence of heterospecifics) and calls with\nthe most C notes in response to the other typical playbacks (AD and CD) when in the presence of het-\nFig. 8 Number of D notes (LSM€SE) in chick-a-dee calls as a\nfunction of playback in the fall (A) and spring (B). Playback type\ndesignations are the same as in Figure 3\n194erospecifics. Atypically ordered playbacks with the same\nnumber and composition of notes did not elicit similar\nresponses, suggesting that the chickadees do not perceive\nthem as the same call as the typically ordered playbacks.\nIn contrast to these fall/winter patterns, there was no\ndifference in the note composition of chick-a-dee calls\nelicited by different playbacks broadcast in the spring. We\nsuggest that this seasonal variation in vocal communication reflects seasonal changes in social structure. Unlike\nmated pairs in the spring, Carolina chickadees form small\nflocks of unrelated individuals during the fall that remain\ntogether throughout the winter (Brewer 1961; Dixon\n1963). The chick-a-dee call is thought to play an important communicative role in maintaining flock cohesion\nand facilitating foraging (Smith 1991). Thus, we might\nexpect chickadees to be more sensitive to differences in\nchick-a-dee call syntax from unknown birds (our playbacks) in the fall/winter compared to in the spring.\nHowever, what could explain the fact that different notes\nwere produced dependent on playback type and social\ncontext in the fall/winter? More fundamentally, why\nmight selection favor a call system that can generate\nmany unique call types using rules for note ordering and\ncomposition?\nObviously, the benefit of communicating among conspecifics is not the only factor that may affect the production and perception of vocal signals. The production of\nsignals is risky. By attracting the attention of unintended\nreceivers, animals can expose themselves to social and\npredation costs. For example, subordinates that vocalize in\nthe presence of a rich food source may elicit aggression\nfrom more dominant animals nearby (Wrangham 1977)\nand advertisement signals used during mating can be exploited by predators to localize and prey on signalers\n(Endler 1991; Ryan et al. 1982). One solution for minimizing the risks associated with communication would be\na flexible repertoire where different signals can be given\ndepending on circumstance. Thus, signalers might have\nthe option of using a subset of calls that are ‘cautious’ in\nthe sense that they are not easily heard or localized, and\nanother, more conspicuous, subset for use under less risky\nconditions to produce a richer set of information. A classic\nexample is the Tfflngara frog (Physalaemus pustulosus)\nwhine-chuck call system where males omit the conspicuous “chuck” element when predation risk is increased\n(Ryan 1985).\nDuring the fall/winter, chickadees often form mixed\nspecies flocks with other bird species, in particular with\nwhite-breasted nuthatches and tufted titmice (Brewer\n1961). Although chickadees are known as a ‘nuclear species’ in the mixed species flocks, they are the subordinate\nmembers (Morse 1970; Cimprich and Grubb 1994). It is\nsuggested that heterospecifics may exploit communication between chickadees to find food and this could incur\ncompetition costs for chickadees (Sullivan 1984). Indeed,\nCimprich and Grubb (1994) showed that when tufted\ntitmice were experimentally removed, chickadees experienced increased nutritional condition. Thus, in the\ncontext of titmice or nuthatches in close proximity, the\nincreased numbers of C notes in chick-a-dee calls in response to our typical call playbacks by chickadees may be\nrelated to competition with those more dominant species.\nAlternatively, chickadees may only respond with more\nC notes when in the presence of heterospecifics because\npredation risk is decreased in larger mixed species flocks\n(Gaddis 1980; Pravosudov and Grubb 1999; Dolby and\nGrubb 2000). Krams (2001) found that sparrowhawks\n(Accipiter nisus) attacked models of great tits (Parus\nmajor) more during playbacks of long-range, trilled calls\nthan during short-range, high-pitched calls. Similar to\ntrilled notes, C notes are harsh ‘chick’ like notes that have\na large bandwidth and are thus likely to be relatively easy\nto localize, by predators and heterospecifics alike (Marten\nand Marler 1977; Wiley 1991; Krams 2001). Therefore,\nchick-a-dee calls containing C notes may be riskier than\ncalls with other note compositions. For example, introductory notes (A and B) are high frequency whistles and\nmight be harder to locate. This might explain why\nchickadees increased the number of introductory notes in\nresponse to a typical call playbacks compared to their\nresponse to the atypical call playbacks. Nonetheless,\nstudies of predator responses to chick-a-dee calls varying\nin note composition are needed (Lima 2002), as well as\nexperiments that examine chickadee vocalizations given\nin varying degrees of predation risk.\nOther playback studies have tested for the significance\nof note ordering in vocalizations by measuring differences\nin responses to typical versus atypical note ordering\n(Mitani and Marler 1989; Esser et al. 1997, Okanoya\net al. 2000; Holland et al. 2000; Ghazanfar et al. 2001;\nZuberbuhler 2002). However, it can be argued that\ndemonstrating these different response behaviors to signals with atypical syntax that do not occur naturally is\ntrivial (e.g., Evans and Marler 1995). Therefore, we are\nhesitant to make broad generalizations about the role of\nnote ordering in the chick-a-dee call system at this point.\nStill, we do believe that simply demonstrating an effect of\nnote ordering on receiver responses is an important initial\nstep to take in understanding the perceptual, affective, and\npossibly referential aspects of the chick-a-dee call. We are\nalso aware that the resolution of our results could improve\nby not only accounting for the number of birds responding\nto our playbacks, but by analyzing note composition of\nchick-a-dee responses by individual.\nThe importance of note order in the chick-a-dee calls\nof signalers has been suggested in several previous studies\n(Smith 1972, Hailman et al. 1985, Hailman and Ficken\n1986). However, it was also important to demonstrate that\nbehavioral responses varied dependent on syntactical\nproperties. Additionally, the importance of the context in\nwhich signals are produced and received was demonstrated by the differences in vocal responses seen between\nseasons and by the differences due to social context. This\nstudy provides a preliminary examination of the importance of syntax and further experimental playbacks with\nCarolina chickadees and other Poecile species are needed\nto examine the functional role of syntax in this complex\ncommunication system.\n195Acknowledgements We would like to thank Jack P. Hailman,\nWilliam Searcy, Terry Ord, Vladimir Pravosudov and an anonymous reviewer for constructive comments on the manuscript and\nJeff Buckley and Joe Strummer for helpful advice. This research\nwas partially funded by a Howard Hughes undergraduate research\naward to Barbara Clucas. This study adhered to the Guidelines for\nthe Use of Animals in Research of the Association for the Study of\nAnimal Behaviour and the Animal Behavior Society, and was\ncarried out under Protocol No. 00–003 of the Purdue University\nAnimal Care and Use Committee.\nReferences\nBalaban E (1988) Bird song syntax — learned intraspecific variation is meaningful. Proc Natl Acad of Sci USA 85:3657–3660\nBaker MC, Bjerke TK, Lampe HU, Espmark YO (1987) Sexualresponse of female yellowhammers to differences in regional\nsong dialects and repertoire sizes. Anim Behav 35:395–401\nBloomfield LL, Sturdy CB, Phillmore LS, Weisman RG (2003)\nOpen-ended categorization of chick-a-dee calls by black-capped chickadees (Poecile atricapilla). J Comp Psychol 117:290–\n301\nBlumstein DT, Armitage KB (1997) Does sociality drive the evolution of communicative complexity? A comparative test with\nground-dwelling sciurid alarm calls. Am Nat 150:179–200\nBradbury JW, Vehrencamp SL (1998) Principles of animal communication. Sinauer, University of California, San Diego\nBrewer R (1961) Comparative notes on the life history of the\nCarolina chickadee. Wilson Bull 73:348–373\nCimprich DA, Grubb TC (1994) Consequences for Carolina\nchickadees of foraging with tufted titmice in winter. Ecology\n75:1615–1625\nDixon KL (1963) Some aspects of social organization in the Carolina chickadee. Proc Int Ornithol Congr 13:240–258\nDolby AS, Grubb TC (2000) Social context affects risk taking by a\nsatellite species in a mixed species foraging group Behav Ecol\n11:110–114\nEndler JA (1991) Variation in the appearance of guppy color patterns to guppies and their predators under different visual\nconditions Vision Res 31:587–608\nEsser K, Condon CJ, Suga N, Kanwal JS (1997) Syntax processing\nby auditory cortical neurons in the FM-FM area of the mustached bat Pteronotus parnelli. Proc Natl Acad Sci USA\n94:14019–14024\nEvans CS, Marler P (1995) Language and animal communication:\nparallels and contrasts. In Roitblat HL and Meyer J-A (eds)\nComparative approaches to cognitive science. MIT Press,\nCambridge, Mass., pp 341–382\nFicken MS, Hailman ED, Hailman JP (1994) The chick-a-dee call\nsystem of the Mexican chickadee. Condor 96:70–82\nFreeberg TM, Lucas JR (2002) Receivers respond differently to\nchick-a-dee calls varying in note composition in Carolina\nchickadees (Poecile carolinensis). Anim Behav 63:837–845\nFreeberg TM, Lucas JR, Clucas B (2003) Variation in chick-a-dee\ncalls of a population of Carolina chickadees, Poecile carolinensis: identity and redundancy within note types. JASA\n113:2127–2136\nGaddis PK (1980) Mixed flocks, accipiters, and antipredator behavior. Condor 82:348–349\nGaddis PK (1985) Structure and variability in the vocal repertoire\nof the mountain chickadee. Wilson Bull 97:30–46\nGhanzanfar AA, Smith-Rohrberg D, Hauser MD (2001) The role of\ntemporal cues in rhesus monkey vocal recognition: orienting\nasummetries to reversed calls. Brain Behav Evol 58:163–172\nHailman JP,Ficken MS (1986) Combinational animal communication with computable syntax: chick-a-dee calling qualifies\nas ‘language’ by structural linguistics. Anim Behav 34:1899–\n1901\nHailman JP, Ficken MS,Ficken RW (1985) The “chick-a-dee” calls\nof Parus atricapillus: a recombinant system of animal communication compared with written English. Semiotica 56:191–\n224\nHailman JP, Ficken MS, Ficken RW (1987) Constraints on the\nstructure of combinatorial chick-a-dee calls. Ethology 75:62–80\nHolland J, Dabelsteen T, Paris AL (2000) Coding in the song of the\nwren: importance of rhythmicity, syntax and element structure.\nAnim Behav 60:463–470\nKanwal JS, Matsumura S, Ohlemiller K, Suga N (1994) Analysis of\nacoustic elements and syntax in communication sounds emitted\nby moustached bats. J Acoust Soc Am 96:1229–1254\nKrams I (2001) Communication in crested tits and the risk of\npredation. Anim Behav 61:1065–1068\nKroodsma DE (1977) Correlates of song organization among North\nAmerican wrens. Am Nat 111:995–1008\nKroodsma DE, and Miller EH (eds) (1996) Ecology and evolution\nof acoustic communication in birds. Cornell University Press,\nIthaca, New York\nLima SL (2002) Putting predators back into behavioral predatorprey interactions. Trends Ecol Evol 17:70–75\nLittell, RC, Milliken GA, Stroup WW, Wolfinger RD (1996) SAS\nsystem for mixed models. SAS Institute, Cary, N. C.\nMarten K, Marler P (1977) Sound transmission and its significance\nfor animal vocalization. Behav Ecol 11:110–114\nMitani JC, Marler P (1989) A phonological analysis of male gibbon\nsinging behaviour. Behavior 109:20–45\nMorse DH (1970) Ecological aspects of some mixed-species foraging flocks of birds. Ecol Monogr 40:119–168\nOkanoya K, Tsumaki S, Honda E (2000) Perception of temporal properties in self-generated song by Bengalese finches\n(Lonchura striata var. domestica). J Comp Psychol 114:239–\n245\nOrd TJ, Blumstein DT, Evans C S (2002) Ecology and signal\nevolution in lizards. Biol J Linn Soc 77:127–148\nOwings DH, Morton ES (1998) Animal vocal communication: a\nnew approach. Cambridge University Press, Cambridge\nPravosudov VV, Grubb TC (1999) Effects of dominance on vigilance in avian social groups. Auk 116:241–246\nRobinson JG (1984) Syntactic structures in the vocalizations of\nwedge-capped capuchin monkeys, Cebus olivaceus. Behavior\n90:46–79\nRyan MJ (1985) The Tfflngara frog: A study in sexual selection and\ncommunication. University of Chicago Press, Chicago\nRyan MJ, Tuttle MD, Rand AS (1982) Bat predation and sexual\nadvertisement in a neotropical frog. Am Nat 119:136–139\nSAS Institute (1994) SAS/STAT Software. Release 6.09 and Release 6.08 maintenance enhancements for PROC MIXED. SAS\nInstitute, Cary, N.C.\nSmith ST (1972) Communication and other social behavior in Parus\ncarolinensis. Publ Nuttall Ornithol Club 11:1–125\nSmith SM (1991) The black-capped chickadee: behavioral ecology\nand natural history. Cornell University Press, New York\nSullivan KA (1984) Information exploitation by downy woodpeckers in mixed-species flocks Behavior 91:294–311\nWiley RH (1991) Associations of song properties with habitats for\nterritorial oscine birds of Eastern North America. Am Nat\n138:973–993\nWrangham RW (1977) Feeding behaviour of chimpanzees in\nGombe National Park, Tanzania. In: Clutton-Brock TH (ed)\nPrimate ecology: studies of feeding and ranging behaviour\nin lemurs, monkeys, and apes. Academic Press, New York,\npp 503–538\nZuberbuhler K (2002) A syntactic rule in forest monkey communication. Anim Behav 63: 293–299\n196", "affiliations": [{"university": "Purdue University", "country": "United States", "discipline": "Biology"}, {"university": "University of California, Davis", "country": "United States", "discipline": "Biology"}, {"university": "University of Tennessee", "country": "United States", "discipline": "Psychology"}], "species_categories": ["Bird"], "specialized_species": ["Carolina chickadee"], "computational_stages": ["Sequence Representation", "Meaning Identification"], "linguistic_features": ["Discreteness and Syntax", "Semanticity"], "status": "saved", "created_at": "2026-01-13T12:49:59.882748", "updated_at": "2026-01-13T16:26:38.465708", "committed_at": "2026-01-13T16:26:40.512890"}
{"id": "fd6a7c5e-ab05-4f44-907c-4ce04759cd43", "title": "Allometry of Alarm Calls: Black-Capped Chickadees Encode Information About Predator Size", "authors": ["Templeton,  Christopher N.", "Greene,  Erick", "Davis,  Kate"], "year": "2005", "journal": "Science", "abstract": "", "doi": "10.1126/science.1108841", "analysis_notes": "the stimulus duration-response relation in Fig.\n4B would not have remained linear). Thus,\nphosphorylation and arrestin binding are unlikely to constitute the standard termination of\nolfactory responses. Possibly, phosphorylation\nis important for desensitization in situations\nof prolonged and intense stimulation.\nA short-lived receptor-odorant complex\ndoes not preclude an overall high olfactory\nsensitivity. Repeated bindings of odorant\nmolecules to the same receptor allow signal\nintegration, especially if receptor phosphorylation does not occur (unlike in vision, where\na photon acts only once and a photobleached\npigment molecule is nonfunctional). The total\nrate of odorant-binding events is also amplified by orders of magnitude by the total number of receptor molecules on an ORN. The\nsupralinear interactions occurring when unitary transduction domains overlap can further\nenhance sensitivity at intermediate odorant\nconcentrations and durations. Finally, a high\nconvergence of sensory input at the glomerulus (23) may boost sensitivity. The glomerulus is the synaptic plexus in the olfactory\nbulb that integrates signals from all ORNs\nexpressing the same odorant receptor species.\nIn principle, this convergence can increase\nindefinitely by simply expanding the surface\narea of the olfactory epithelium and therefore\nthe number of ORNs expressing a given odorant receptor. This increase in convergence may\nexplain why the olfactory sensitivity in many\nanimals is much higher than it is in humans.\nUnlike the retinotopic map in vision, which\nimposes a functional limit on the degree of\nconvergence from photoreceptors, no corresponding limitation exists in olfaction.\nReferences and Notes\n1. L. B. Buck, Cell 100, 611 (2000).\n2. D. Schild, D. Restrepo, Physiol. Rev. 78, 429 (1998).\n3. H. R. Matthews, J. Reisert, Curr. Opin. Neurobiol. 13,\n469 (2003).\n4. A. Menini, C. Picco, S. Firestein, Nature 373, 435\n(1995).\n5. G. Lowe, G. H. Gold, Proc. Natl. Acad. Sci. U.S.A. 92,\n7864 (1995).\n6. G. H. Gold, G. Lowe, Nature 376, 27 (1995).\n7. S. Firestein, C. Picco, A. Menini, J. Physiol. 468, 1 (1993).\n8. D. A. Baylor, T. D. Lamb, K.-W. Yau, J. Physiol. 288,\n613 (1979).\n9. T. D. Lamb, P. A. McNaughton, K.-W. Yau, J. Physiol.\n319, 463 (1981).\n10. G. Lowe, G. H. Gold, J. Physiol. 442, 147 (1991).\n11. J. Reisert, H. R. Matthews, J. Gen. Physiol. 112, 529\n(1998).\n12. Materials and methods as well as additional notes are\navailable as supporting material on Science Online.\n13. S. J. Kleene, Neuroscience 66, 1001 (1995).\n14. J. del Castillo, B. Katz, J. Physiol. 124, 560 (1954).\n15. S. Serizawa et al., Science 302, 2088 (2003).\n16. J. W. Lewcock, R. R. Reed, Proc. Natl. Acad. Sci.\nU.S.A. 101, 1069 (2004).\n17. J. J. Tesmer, R. K. Sunahara, A. G. Gilman, S. R. Sprang,\nScience 278, 1907 (1997).\n18. Leskov et al., Neuron 27, 525 (2000).\n19. K.-W. Yau, Invest. Ophthalmol. Vis. Sci. 35, 9 (1994).\n20. T. M. Dawson et al., Science 259, 825 (1993).\n21. S. Schleicher, I. Boekhoff, J. Arriza, R. J. Lefkowitz, H.\nBreer, Proc. Natl. Acad. Sci. U.S.A. 90, 1420 (1993).\n22. K. Peppel et al., J. Biol. Chem. 272, 25425 (1997).\n23. P. Mombaerts et al., Cell 87, 675 (1996).\n24. K. Nakatani, K.-W. Yau, Nature 334, 69 (1988).\n25. K. Nakatani, K.-W. Yau, J. Physiol. 395, 695 (1988).\n26. We thank D. A. Baylor, P. A. Fuchs, J. S. Kauer, T. D.\nLamb, J. Nathans, R. R. Reed, F. Rieke, D. T. Yue, and\nmembers of the Yau laboratory, especially J. Bradley\nand C.-Y. Su, for critique and discussions, V. Kefalov\nfor help in initial experiments, and D. Chaudhuri for\nhelp in computations using MatLab. V.B. also thanks\nD. McClellen for instruction in scientific writing. This\nwork was supported by Howard Hughes Medical\nInstitute and grants from NIH (DC06904) and the\nHuman Frontier Science Program.\nSupporting Online Material\nwww.sciencemag.org/cgi/content/full/308/5730/1931/\nDC1\nMaterials and Methods\nFigs. S1 to S4\nReferences and Notes\n18 January 2005; accepted 3 May 2005\n10.1126/science.1109886\nAllometry of Alarm Calls:\nBlack-Capped Chickadees Encode\nInformation About Predator Size\nChristopher N. Templeton,1\n*. Erick Greene,1 Kate Davis2\nMany animals produce alarm signals when they detect a potential predator,\nbut we still know little about the information contained in these signals.\nUsing presentations of 15 species of live predators, we show that acoustic\nfeatures of the mobbing calls of black-capped chickadees (Poecile atricapilla)\nvary with the size of the predator. Companion playback experiments revealed\nthat chickadees detect this information and that the intensity of mobbing\nbehavior is related to the size and threat of the potential predator. This study\ndemonstrates an unsuspected level of complexity and sophistication in avian\nalarm calls.\nPredation is a major cause of mortality for\nmost species of animals, and many produce\nalarm signals when they perceive a potential\npredator (1). Alarm calls often differ in\nacoustic structure, depending on the situation\nin which they are produced (2–5). If a\nspecies is preyed upon by different predators\nthat use different hunting strategies or vary\nin the degree of danger they present, selection can favor variation in alarm signals\nFig. 4. (A) Unitary responses for two odorants\nwith different potencies\non the same cell are\nvery similar. (Top) Relation between response amplitude and\nodorant concentration\nfor acetophenone and\ncineole odorants. Each\npoint represents the average of four to eight\nstimulus trials. Although\nthe duration of acetophenone stimulation\nwas twice as long as\nthat for cineole, the\nresponse with all receptors bound by acetophenone was a factor\nof 7 less than the response to cineole. (Bottom) Variance/mean\nanalysis of the unitary response to the two odorants. The quantal responses to the two odorants\nwere similar (0.48 pA for cineole and 0.56 pA for acetophenone). Thirty trials each of 100 mM\ncineole at 25-ms duration and 2 mM acetophenone at 50-ms duration. The two stimuli were\nchosen to produce responses of comparable amplitudes. The slight difference in response kinetics\nfor the two odorants was due to a change in cell condition during the experiment; this was not\nobserved in other experiments. We chose this cell because of the large difference in efficacy\nbetween the two odorants. (B) Estimation of cineole dwell-time on the receptor. (Top) Relation\nbetween response amplitude and cineole concentration at two durations. Even when all receptors\nwere bound (Q1 mM cineole), the response amplitude increased linearly with the odorant pulse\nduration. Each point represents the average of 3 to 20 stimulus trials. (Bottom) Complete data\nfrom the same experiment at a saturating cineole concentration of 2 mM and applied for four\ndifferent durations. (Inset) Linear increase of the response with odorant duration. The time intercept of the linear-regression fit is near zero.\n0 2\n-10\n-5\n0\n0 1 2\n0\n30\n60\n0 1 2\n0\n15\n30\n0 1\n-30\n-15\n0\n0 25 50\n0\n15\n30\nAMean (pA)\nt (s)\n0\n5\nσ2(pA2\n)\ncineole (25 ms)\nacetophenone (50 ms)\npA\nConc. (mM) Conc. (mM)\nB\n2 mM cineole\n50 ms\n25 ms\npA pA\nt (s)\npA\nT (ms)\nR EPORTS\n1934 24 JUNE 2005 VOL 308 SCIENCE www.sciencemag.org\nDownloaded from https://www.science.org at University of Maryland College Park on January 13, 2026\nthat encode this information (6). Such variation in alarm signals can be used to transfer information about the type of predator\nEreferential alarm call systems (7)^, the degree\nof threat that a predator represents Erisk-based\nsystems (8)^, or both (9, 10).\nIn addition to discriminating among\nbroad types of predators (e.g., raptor versus\nsnake), discriminating among morphologically similar predators within a single type\n(e.g., different species of raptors) could also\nbe adaptive if the predators vary in the\ndegree of threat they pose. One species that\nis faced with numerous, morphologically\nsimilar predators is the black-capped chickadee (Poecile atricapilla). Chickadees are\nsmall, common songbirds that are widespread throughout North America. In the nonbreeding season, chickadees form flocks of six\nto eight birds (11). They use an elaborate\nsystem of vocalizations to mediate social\ninteractions in these flocks (12, 13) and to\nwarn conspecifics about predators (14, 15).\nChickadees produce two very different\nalarm signals in response to predators: When\nflying raptors are detected, chickadees produce a high-frequency, low-amplitude Bseet[\nalarm call; in response to a perched or stationary predator, they produce a loud, broadband Bchick-a-dee[ alarm call that is composed\nof several types of syllables (16) (Fig. 1A).\nWhereas the Bseet[ alarm call functions to\nwarn of flying predators, the Bchick-a-dee[\nmobbing alarm call recruits other chickadees\nEand often many other species (17)^ that\nharass, or mob, a perched predator. This\nBchick-a-dee[ call is a complex vocalization\nthat is also produced in many other situations\nand encodes information about food and\nidentity (both individual and flock) in addition to information about predators (11).\nWe examined variation in the mobbing\nvocalizations and behavior of black-capped\nchickadees by conducting predator presentations and playback experiments with chickadees living under semi-natural conditions in\nlarge, outdoor experimental aviaries (18).\nWe presented flocks of color-marked chickadees with 13 species of live, perched raptors\nand two species of live mammalian predators. The predators varied considerably in\nbody size (e.g., factor of 20 difference in\nbody mass between northern pygmy-owl and\ngreat horned owl), activity patterns, hunting\nstrategies, and diet (Table 1). The raptors\nranged from small, maneuverable predators\nwhose diets include many small birds, to\nlarge, less maneuverable predators that eat\nfew small birds. We also used two types of\ncontrols: a procedural control with a live\nbobwhite quail (Colinus virginianus); and no\npresentation, with observers present as they\nwould be during predator presentations. During each predator presentation, two observers\nrecorded chickadee vocalizations, noting the\ncolor band combination of each calling individual. By conducting controlled presentations of live predators to birds living under\nsemi-natural conditions, we could isolate\nvocal responses to specific species of predators from other features such as the location, behavior, or movement pattern of the\npredator.\nSpectrographic analyses of the more than\n5000 Bchick-a-dee[ mobbing alarm calls we\nrecorded (Fig. 1) revealed previously unsuspected levels of acoustic variation. The\nnumber of mobbing calls produced in response\nto each predator was highly variable [analysis of variance (ANOVA): F16, 34 0 5.17, P G\n0.0001^, with the smaller, higher risk, predators eliciting significantly more calls than the\nlarger predators or controls (Tukey_s post hoc\ntests: P G 0.05). The total number of syllables\nper alarm call differed among predator treatments (F 0 3.05, P G 0.0001). In particular,\nthe average number of D syllables, or notes,\nper call differed significantly across predator\ntreatments (F 0 7.771, P G 0.0001). There\nwas a strong inverse relationship between the\nnumber of D notes per alarm call and the\nwingspan of the raptors, with the smallest\npredators eliciting calls with the most D notes\n(Fig. 2A; r2 0 0.512, P G 0.0001). There was\nalso a strong inverse relationship between the\nnumber of D notes and predator body length\nwhen both the mammals and raptors were\n1\nDivision of Biological Sciences, University of Montana,\nMissoula, MT 59812, USA. 2\nRaptors of the Rockies,\nPost Office Box 250, Florence, MT 59833, USA.\n*Present address: Department of Biology, Box 351800,\nUniversity of Washington, Seattle, WA 98195, USA.\n.To whom correspondence should be addressed.\nE-mail: ctemple2@u.washington.edu\nFig. 1. Features of the\n‘‘chick-a-dee’’ mobbing\nvocalization. (A) The\ncall usually contains\nboth ‘‘chick’’ sections\n(A, B, and C syllable\ntypes) and ‘‘dee’’ sections (D syllable types)\n(11). (B) Acoustic variables measured from\npower spectrum analy0\n3\n6\n9\n0 0.5 1.0\n) z Hk( ycneuqer F -50\n-30\n-20\n-10\n0\n-40\n1 2 3 4 5 6\nFrequency (kHz)\nevit al e R ) Bd( edutil p m\nA\nA\nABC C D D D\nB\nF1\nF2\nL U\nP\nM\n\"chick\" \"dee\"\nTime (s) ses from the center of a D note. The\namplitude has been scaled relative to the\nhighest energy overtone (dB 0 0). Acoustic\nvariables were the peak frequency (P), the\nlower and upper frequencies above –10 dB\n(L and U, respectively), the frequency of the\nfirst and second peaks above –30 dB (F1\nand F2, respectively), and the maximum\nfrequency peak above –30 dB (M). The\nbandwidth at –10 dB was calculated by\nsubtracting L from U; the bandwidth at –30\ndB was calculated by subtracting F1 from M.\nThe interval between overtones was determined by subtracting F1 from F2.\nsaw-whet\npygmy-owl\nCooper's\nperegrine\nred tail\ngreat horned\ngyrfalcon\ngreat\ngray\nkestrel\nshort-eared\nprairie\nrough-leg\nbobwhite\nmerlin\ncat\nferret\n1.5\n3.5\n2.0\n2.5\n3.0\n4.0\n1.0\n4.5 ll acr ep s te on Df or eb mu N\n10 20 40 30 60 50\nPredator body length (cm)\n1.5\n3.5\n2.0\n2.5\n3.0\n4.0\n1.0\n4.5\n20 40 100 60 120 80 140\nsaw-whet\npygmy-owl\nCooper's\nperegrine\nred tail\ngreat horned\ngyrfalcon\ngreat\ngray\nkestrel\nshort-eared\nprairie\nrough-leg\nbobwhite\nmerlin\nll acr ep set on Df or eb mu N\nPredator wingspan (cm)\nB\nA\nFig. 2. Chickadees vary their mobbing calls in\nresponse to variation in predator body size. (A)\nMean number of D syllables per call as a function\nof wingspan for raptors ( y 0 4.4 – 0.02x; r2 0\n0.512, P G 0.0001). (B) Mean number of D\nsyllables per call as a function of body length for\nraptors and mammals ( y 0 4.4 – 0.4x; r\n2 0 0.361,\nP G 0.0001). Each taxonomic group of raptors is\nrepresented by a different symbol (&, owl; r,\nfalcon; h, hawk; \u0001, mammal). A bobwhite quail\n(>) was used as the procedural control. The\ndashed line displays the mean number of D\nnotes per control trial without any stimulus.\nR EPORTS\nwww.sciencemag.org SCIENCE VOL 308 24 JUNE 2005 1935Downloaded from https://www.science.org at University of Maryland College Park on January 13, 2026\nincluded in the analysis (Fig. 2B; r2 0 0.361,\nP G 0.0001).\nMany other acoustic features of these\nmobbing calls (Fig. 1) also varied in relation\nto the predator treatment. For example, in\ncomparisons of mobbing calls given in response to a northern pygmy-owl and a great\nhorned owl (small and large predators, respectively), the duration of the Bdee[ section\n(all D notes) was significantly longer (ANOVA:\nF1,14 0 9.984, P 0 0.003), the interval between\nthe Bchick[ and Bdee[ sections was significantly shorter (F 0 11.364, P 0 0.001), the\nfirst D note of each call was shorter (F 0\n9.984, P 0 0.003), and the interval between\nthe first and second D notes was also shorter\nin small predator alarm call variants (F 0\n9.043, P 0 0.004). Calls that chickadees\nproduced during the large predator presentations tended to have D notes that contained more high-energy peaks above –10\ndB (F 0 2.855, P 0 0.097) spanning a wider\nbandwidth (F 0 2.719, P 0 0.105) than those\nproduced during encounters with small predators. D notes elicited by large predators also\ntended to have more widely spaced overtones\n(F 0 3.385, P 0 0.071). No differences were\nobserved in any of the other measured features\n(P 9 0.2 for all).\nDo these acoustic differences in mobbing\ncalls transmit information about the potential\npredator to other chickadees? We conducted\nplayback experiments (18) to test how\nchickadees reacted to the mobbing calls that\nthey produced in response to different predators by broadcasting variations of the\nBchick-a-dee[ alarm vocalization associated\nwith different predators. We played mobbing\ncalls that flock mates produced in response\nto a great horned owl (large predator), a northern pygmy-owl (small predator), and control\ncalls of a pine siskin (Carduelis pinus).\nChickadees exhibited longer and more intense\nmobbing behavior when they heard alarm\ncalls recorded in response to a pygmy-owl\nthan when they heard alarm calls recorded in\nresponse to a great horned owl or control vocalizations (Fig. 3). They produced significantly more Bchick-a-dee[ calls in response to\nplayback of mobbing alarm calls elicited by a\nsmall predator than they did when presented\nwith playbacks of mobbing calls elicited by a\nlarge predator or control vocalizations (Fig.\n3A; Kruskal-Wallis K 0 11.50, P 0 0.003).\nChickadees approached the hidden speaker\nmore closely in response to the small predator\nmobbing call treatment than in response to the\nlarge predator mobbing call or control treatments (K 0 14.69, P 0 0.001); more individuals approached within 3 m (Fig. 3B; K 0\n14.40, P 0 0.001) and within 1 m (K 0 11.34,\nP 0 0.003) of the speaker in response to the\nsmall predator alarm calls than in response to\nthe large predator alarm calls or control\nvocalizations. After playback of small predator alarm calls, chickadees also mobbed for\nlonger periods than they did after playback of\nlarge predator alarm calls and control sounds\n(K 0 12.69, P 0 0.002).\nPrevious studies have shown that animals\nproduce different antipredator vocalizations\nfor aerial and terrestrial predators. Most of\nthese studies, however, have presented these\ntwo types of predators in different ways\n(19–21), potentially confounding the interpretation that prey distinguish between types\nof predators and not their location or\nTable 1. Species presented to chickadee flocks. Length and wingspan were measured from animals used\nin experiments; mass (26) and diet information (27–29) were summarized from published accounts. The\nsex of each raptor used in the experiments is indicated in brackets.\nPredator species Mass\n(g)\nLength\n(cm)\nWingspan\n(cm)\nTime\nactive Primary diet\nHawks\nCooper’s hawk\n(Accipiter cooperii) [F]\n450 44 81 Day Small birds\nRed-tailed hawk\n(Buteo jamaicensis) [F]\n1,080 53 120 Day Small mammals, few birds\nRough-legged hawk\n(B. lagopus) [M]\n990 49 138 Day Small mammals\nFalcons\nAmerican kestrel\n(Falco sparverius) [M]\n117 25 58 Day Inverts, small mammals,\nsmall birds\nMerlin (F. columbarius) [F] 190 28 61 Day Small birds\nPeregrine falcon\n(F. mexicanus) [F]\n720 47 120 Day Medium-sized birds\nPrairie falcon\n(F. peregrinus) [F]\n720 45 100 Day Small mammals, some birds\nGyrfalcon (F. rusticolus) [M] 1,400 52 115 Day Medium-sized mammals and birds\nOwls\nNorthern pygmy-owl\n(Glaucidium gnoma) [M]\n70 15 31 Day Small birds, small mammals\nSaw-whet owl\n(Aegolius acadicus) [M]\n80 17 39 Night Small mammals, some small birds\nShort-eared owl\n(Asio flammeus) [M]\n350 34 89 Both Small mammals\nGreat horned owl\n(Bubo virginianus) [M]\n1,400 48 121 Night Small to medium-sized mammals\nGreat gray owl\n(Strix nebulosa) [M]\n1,080 58 132 Both Small mammals\nMammals\nDomestic cat\n(Felis domesticus)\n15,000 45 — Both Birds, small mammals, insects\nFerret (Mustela putorius) 1,000 32 — Day Small mammals, eggs, some\nsmall birds\nControl\nBobwhite quail\n(Colinus virginianus)\n170 22 42 Day Seeds, insects\n0\n20\n10\n30\n0\n2\n4\n3\n5\n1\nControl Large\nPredator\nSmall\nPredator\nsll ac \" eed- a- kci hc\" # r ekaeps gni hcaor ppa sdri B\n6\n40 A\nB\nAlarm Call Treatment\nFig. 3. Chickadees respond to predator-specific\nacoustic variations in their mobbing alarm calls.\nTwo behavioral variables were used to quantify\nchickadees’ responses to the three playback\nstimuli: control sounds (pine siskin calls), ‘‘chicka-dee’’ calls produced in response to a large\npredator (great horned owl), and ‘‘chick-a-dee’’\ncalls produced in response to a small predator\n(northern pygmy-owl). (A) Boxplots (showing\nmedian, interquartile range (IQR), range, and\noutliers) of the number of ‘‘chick-a-dee’’ calls\nproduced during the first 90 s after the start of\neach playback treatment. (B) Boxplots of the\nnumber of birds approaching within 3 m of the\nspeaker after each treatment. All pairwise\ncomparisons were significantly different (MannWhitney U, P G 0.05).\nR EPORTS\n1936 24 JUNE 2005 VOL 308 SCIENCE www.sciencemag.org\nDownloaded from https://www.science.org at University of Maryland College Park on January 13, 2026\nbehavior. Our results show that chickadees do\nnot vocally discriminate between raptors and\nmammals when they are presented in similar\nways, and thus the Bchick-a-dee[ call does not\nrefer specifically to the type of predator.\nInstead, these vocal signals likely contain information about the degree of threat\nthat a predator represents. Maneuverability\n(e.g., as measured by turning radius, or\nradial acceleration) is extremely important\nin determining the outcome of predator-prey\ninteractions and is inversely related to wingspan and body size in birds (22, 23). Body\nsize may be a good predictor of risk for\nchickadees: Small raptors tend to be much\nmore maneuverable than larger raptors and\nlikely pose a greater threat to chickadees.\nIn addition to being one of the most subtle and sophisticated signaling systems yet\ndiscovered, this system is unusual in that it\ncombines aspects of both referential and\nrisk-based antipredator vocalization systems\n(10, 24, 25). To denote the presence of a rapidly moving predator (e.g., raptor in flight),\nchickadees produce a Bseet[ alarm call. When\nthey encounter a stationary predator (e.g.,\nperched raptor), they use the Bchick-a-dee[\nmobbing call. These two vocalizations appear\nto be functionally referential to the type of\npredator encounter (i.e., each denotes a specific type of encounter). In addition, we have\nshown that subtle variation in the Bchick-adee[ mobbing call reflects the size of a\nspecific predator, a characteristic of a riskbased system. Thus, chickadees convey information about predators at two different levels:\nA coarse level of encoding (Bseet[ or Bchicka-dee[) signifies the type of predator encounter, and a fine level of encoding (variants of\nBchick-a-dee[) signifies the degree of danger\npresented by that specific predator encounter.\nThe Bchick-a-dee[ vocalization is remarkably versatile; it is used in many different\ncontexts and apparently conveys many different types of information. The fact that so\nmuch information can be transmitted by subtle\nvariations in one type of vocalization raises\nsome fascinating questions about how finely\nchickadees can discriminate between similar\nstimuli, and how they categorize different aspects of their environment.\nReferences and Notes\n1. J. W. Bradbury, S. L. Vehrencamp, Principles of Animal\nCommunication (Sinauer Associates, Sunderland, MA,\n1998).\n2. P. Marler, Nature 176, 6 (1955).\n3. P. W. Sherman, Science 197, 1246 (1977).\n4. R. M. Seyfarth, D. L. Cheney, P. Marler, Anim. Behav.\n28, 1070 (1980).\n5. C. S. Evans, L. Evans, P. Marler, Anim. Behav. 46, 23\n(1993).\n6. M. D. Hauser, The Evolution of Communication (MIT\nPress, Cambridge, MA, 1996).\n7. D. L. Cheney, R. M. Seyfarth, How Monkeys See the\nWorld (Univ. of Chicago Press, Chicago, 1990).\n8. J. M. Macedonia, C. S. Evans, Ethology 93, 177\n(1993).\n9. M. B. Manser, R. M. Seyfarth, D. L. Cheney, Trends\nCognit. Sci. 6, 55 (2002).\n10. R. M. Seyfarth, D. L. Cheney, Annu. Rev. Psychol. 54,\n145 (2003).\n11. S. M. Smith, The Black-Capped Chickadee: Behavioral\nEcology and Natural History (Cornell Univ. Press,\nIthaca, NY, 1991).\n12. S. Nowicki, Behav. Ecol. Sociobiol. 12, 317 (1983).\n13. D. J. Mennill, L. Ratcliffe, P. T. Boag, Science 296, 873\n(2002).\n14. M. S. Ficken, S. R. Witkin, Auk 94, 156 (1977).\n15. M. C. Baker, A. M. Becker, Wilson Bull. 114, 510 (2002).\n16. M. S. Ficken, R. W. Ficken, S. R. Witkin, Auk 95, 34\n(1978).\n17. C. R. Hurd, Behav. Ecol. Sociobiol. 38, 287 (1996).\n18. See supporting data on Science Online.\n19. E. Greene, T. Meagher, Anim. Behav. 55, 511 (1998).\n20. D. T. Blumstein, Behaviour 136, 731 (1999).\n21. A. Le Roux, T. P. Jackson, M. L. Cherry, Behaviour 138,\n757 (2001).\n22. H. C. Howland, J. Theor. Biol. 47, 333 (1974).\n23. K. P. Dial, Auk 120, 941 (2003).\n24. C. S. Evans, Perspect. Ethol. 12, 99 (1997).\n25. D. T. Blumstein, Evol. Commun. 3, 135 (1999).\n26. D. A. Sibley, The Sibley Guide to Birds (Knopf, New\nYork, 2000).\n27. P. A. Johnsgard, Hawks, Eagles, and Falcons of North\nAmerica (Smithsonian Institution Press, Washington,\nDC, 1990).\n28. P. A. Johnsgard, North American Owls: Biology and\nNatural History (Smithsonian Institution Press, Washington, DC, ed. 2, 2002).\n29. K. R. Foresman, The Wild Mammals of Montana\n(Allen, Lawrence, KS, 2001).\n30. We thank K. Dial for discussions about scaling; J.\nGraham for statistical advice; C. Eldermire, N. Schwab,\nand C. Putnam for help with data collection; and D.\nEmlen, B. Walker, and M. Parker for helpful comments\non the manuscript. Supported by donations from\nMarchie’s Nursery, Caras Nursery, Swift Instruments,\nand the Birdwatcher’s Country Store.\nSupporting Online Material\nwww.sciencemag.org/cgi/content/full/308/5730/1934/\nDC1\nMaterials and Methods\n17 December 2004; accepted 4 May 2005\n10.1126/science.1108841\nR EPORTS\nwww.sciencemag.org SCIENCE VOL 308 24 JUNE 2005 1937Downloaded from https://www.science.org at University of Maryland College Park on January 13, 2026", "affiliations": [{"university": "University of Montana", "country": "United States", "discipline": "Biology"}], "species_categories": ["Bird", "Other"], "specialized_species": ["black-capped chickadee", "northern pygmy-owl", "great horned owl", "bobwhite quail", "American kestrel", "Cooper's hawk", "red-tailed hawk", "rough-legged hawk", "peregrine falcon", "gyrfalcon", "great gray owl", "saw-whet owl", "short-eared owl", "merlin", "domestic cat", "ferret"], "computational_stages": [], "linguistic_features": ["Semanticity", "Discreteness and Syntax", "Recursion"], "status": "saved", "created_at": "2026-01-13T12:49:59.882753", "updated_at": "2026-01-13T16:27:22.310408", "committed_at": "2026-01-13T16:27:28.655692"}
